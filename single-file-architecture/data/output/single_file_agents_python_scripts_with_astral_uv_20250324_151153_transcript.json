{
  "original_file": "data/audio/single_file_agents_python_scripts_with_astral_uv_20250324_151153.mp3",
  "text": "What's up engineers, NDDevDan here. Something I think about a lot is how can we maximize our compute usage with powerful AI agents while steering clear of the roadmap of companies like OpenAI. When OpenAI releases an agent, 1,256 startups are immediately destroyed, eviscerated. For example, if you were building a research agent, OpenAI's deep research just ate your breakfast, lunch, and dinner. Imagine all your time, engineering resources, and time investment vanished, instantly cooked. From startups to individual engineers, it doesn't matter how great your work is, or how far you've scaled your AI coding, or what technical innovation you've found, if you invest in the wrong agent, in the wrong tool, in the wrong product, you're at risk of getting bulldozed by OpenAI and other gen tech companies. How can we stay ahead and build powerful, effective agents while staying out of the way of the generative AI roadmap? I spend a lot of time in this space and I want to share a pattern with you for building powerful, lean, compute-gobbling AI agents that can help you move fast, iterate, and scale your compute usage while staying out of the way. Then, near the end of this video, we're going to discuss why we care about agents so much, and I'll explain why I and other engineers are so obsessed with agents. Agents are everything, and I'll explain why in this video. By using Astral's all-in-one Python tool, UV, and by combining it with powerful AI coding techniques, we can build and deploy single-file agents. So what is a single-file agent, and how does it help us move fast, scale our compute, and avoid getting disrupted by big tech companies? I have this simple project here in Cursor, and right away you'll notice something weird. We only have two files. We have a file database, and a Python file. So before we dive into the agent architecture, let's just run our agent with UV and let me show you how powerful this single file is. UV run, SFA, single file agent, dash D, analytics.database will pass in that database file, dash P for prompt, list, all tables and their columns. Dash C lets us set the compute that our agent can use. We'll set this to 10. Let's kick off our DuckDB AI agent. You can see here, it's kicking off the first compute loop and it only needed one shot to complete this. You can see we have a single function argument call. You can see we're using the rich Python library to format the output here. This agent in particular is powered by OpenAI's O3 mini. So what just happened there? How is it able to pack in so much intelligence and capability into a single Python file? We're gonna dive into that in just a second, but I wanna show you the full agentic loop that our agent can go through. So let's run this again, but let's ask our DuckDB AI agent to do something more complex for us. I'm gonna say users score greater than 80 and status active. So you can see here, this is the wrong table name. It has to figure out where these columns are coming from and what the exact name of these columns are. So there's a lot that I'm kind of leaving up to our agent to figure out and it's gonna run that exact same pattern. So we now have an agent loop, only this time it's going to take a more iterative approach. So you can see there, it's listing tables. It found the user table. It then is running this describe table arguments tool call so that it can understand what this table looks like. There's the output for that. And then at the end here, it's running run final SQL query. It is the final tool call, the final function call, and we can see the exact query it's running and the exact outputs. We have an AI agent that is adept at operating DuckDB local databases. So this is super powerful. As a series of tools at its disposal, it can use to solve the problem of information discovery to understand the structure of the database. And then it has full autonomy, right up to 10 compute loops to solve the problem and return. the results to us. We're using multiple libraries inside of a single file. So how is this possible? We have to give credit to Astral's UV. You can think of this as bun for Python. It's the all-in-one Python ecosystem manager. It basically replaces every other Python tool. And most importantly for us, for these powerful single file agents, it gives us this ability, run scripts with support for inline dependency metadata. Let's dive into this feature right now so we can see how we're building out these powerful single file agents. So if we open up our DuckDB OpenAI agent here, you can see right at the top of this file, something fascinating, right? We have dependencies. You know, you saw with this single command here, right? We had UV run. This creates a sandbox environment. This allows us to run the script as a standalone file with these dependencies included. So we have OpenAI, Rich, and Pydantic. So this is the first key aspect of the single file agent structure. We need to be able to load and use dependencies from any Python library. Most importantly, we need a model provider, right? So now we have this, we have access to this and our single file agent. Now, what does the agentic structure look like for this agent? You can see we're using Pydantic to create our argument structure. So for instance, for our list table args, we have the model pass and reasoning. This is a powerful pattern to help you understand what your language model was thinking at every single step. If we open up every one of these tool argument structures, I'm always requesting reasoning. You can see it there, you can see it there, so on and so forth, right? So that's a super important pattern you can use when building your agents, always passing reasoning, and then always log the reasoning. So you can see we have tools, we have the agent prompt, but the most important thing is the agentic loop down here. So let's go ahead and break this down. And then let's go ahead and look at how we can distribute this pattern with AI coding to scale it up to an entirely new AI agent. So at the start here, we're pulling up the agentic loop. So we're pulling up the agentic loop, and then we're pulling up the reasoning loop. So we're pulling up the reasoning loop, and then we're pulling up the agentic loop. in all of our arguments. We have our dash d for database, dash p for prompt, dash c for compute. We have our open AI key check here. We're then making our database path global so that every single function can access it. We're building our prompt and then we're running the main agentic loop. So this is where all the magic happens. This is where we give our AI agent full control to run tools, run functions, gather feedback, build up its context, and solve the problem we want solved. Let's open this up. So we're doing our compute loop check here and then as you can imagine we're running our intelligence. So we're using o3mini. You can see here we're requiring a tool call. With every loop we want our LLM to execute a tool. We're then looking for tool calls. Once we find a tool which we should always have, we are running our process of determining which tool to select. You can build any type of structure, any type of map you want to handle this. I'm just doing this with the simplest pattern possible here. We just have a bunch of if statements that parse the arguments and then call the function. We then take the result and we pass it back in to the language model. We pass it back into our context window. Very importantly here we also have an exception. So if something goes wrong inside of the tool, we're also passing this back to the model. We want our agent to just solve the problem. We want to design a great prompt. We want to design great tools and then just hand off the problem to our agent. We go off. We go on about our day. We go, you know, solve other specific problems. And then in parallel it's solving this problem that we gave it really well thanks to our clean agent design. So this is one agent pattern that I'm working with. But I want to point out something that's really powerful here. You saw the list tables, describe, sample. But we also have this run test SQL query and run final SQL query. From the tech ecosphere you may have picked up on this idea of verifiable domains and closed loop systems. This is something that we talk about in principled AI coding specifically for the AI coding domain. But it really applies to all agentic technology. We can do something interesting here with this run test SQL query. Let's go ahead and open up the arguments. And you can see here it looks the same as our run final SQL query and we can go ahead and fire off our agent again and just take a look to see if it's actually going to kick off this call. Sometimes it completely skips the run test SQL query because it just doesn't need it, it doesn't need the test. But we can do something like this, create a new table, high score users from the user table and select all users with score greater than 80 that are active and 2025. Let's pass it off to our DuckDB AI agent and just see how it does with this. I'm also going to kick up the compute loop just in case it needs a little bit more energy. Let's kick that off and let's see how it does here. So you can see it's first validating the structure right and needs to find the table so it's running list tables. It's seeing the schema structure of that table. It's now running this test SQL command so it's verifying that what we're going to ask for will work. Instead of looking for human in the loop feedback or instead of running the final query, what it's doing here is running this test SQL query. This is a really important pattern for building out great agents. You don't have to wait to close the loop to let your agent fully validate the process. So I have this run test SQL, it's running this internally, adding more information to its context window, gathering information about how to solve the problem of creating this query, creating this new table, and then finally after it's validated it, it's then running this final query here. So after validation it's now saying we can take this query, it's safe, it works, it looks good. Let's go ahead and run this final query and create this new table. So now of course if we hit up and we hit up again let's get a smaller command to work with and we just say list all tables and one sample row for each table and we fire that off. We should now get this brand new high score. So there's the high score users and the users table. So this is fantastic. There's the sample. Our AI agent is understanding these table structures. It's understanding what we want and what we want to do and then it's giving us these concrete outputs. You can see here how important it is to have the reasoning inside your agents. Right? It is explaining the results we're getting back here in a really concise way. And this is really cool. You can see in the reasoning, it's saying, the sample row from user and high scores is exactly the same. So it's just gonna return the top result. Okay? So this is really powerful. I hope you can see that, you know, single file agents are powerful, but having a great AI agent structure with the right tools and the right order is equally as powerful, right? It doesn't matter if you can build an agent, it matters if you can build an effective agent. Shout out to Anthropic for writing, you know, this great post on building effective agents. This document contains a lot of really key information. I brought it up several times on the channel. I think it encapsulates a lot of the key ideas and serves as a great starting point for building out agents, right? They kind of end their story here with agents with this simple loop, right? Which is effectively all an agent is. You have an LLM call environment to an LLM call, and then they stop kind of whenever they need to. But all the magic happens in this loop, right? It happens in this agentic loop. And this is where, you know, many structures can take place. This is where many fortunes will be made and lost, you know, due to just going after the wrong thing, going after the wrong idea. And, you know, again, this is why I want to bring this up. The single file agents enable us to build lean compute machines. You don't want to over invest into any one idea. We all kind of know that there are going to be new slews of AI coding agents. I would recommend not spending a bunch of time in the research space, in the AI coding space. It's not to say that you can't. I think we're all exploring in all the kind of top go-to use cases for agents. I think that's important. But this is why I bring up this pattern of building lightweight, lean, single file agents so that you don't over invest. But at the same time, you can get a lot of value by building out a lean implementation. So this is an important pattern. I think pre-verification is just as important as post-verification or closed loop verification. Like I mentioned, this is something we talk about in principled AI coding. More on that later in the video. Having a test command run and then a final command run, whatever your domain specific problem is. If your domain is verifiable, I highly recommend you check out this pattern of giving your agent tools to solve the problem, but also tools to pre-verify that the answer that they're going to give you is the correct answer, all right? And so that's what we're doing here with our DuckDB single file agent. So what's the next step with this, right? We have these powerful single file agents with a great agentic structure that can solve problems for us. We're gonna need many different types of AI agents, not just this one, right? We're gonna need, for instance, an SQLite agent. How can we take this agent and the agent structure and basically duplicate it, make a couple of tweaks to it so that we can scale and reuse our single file agent pattern, right? With this powerful tooling thanks to Astral's UV, we can now churn out these powerful condensed agents. So how can we do that? We all already know the answer to this, especially if you've been with the channel or if your eyes are open in the tech ecosystem at all right now. We can do this with AI coding. So now that we have this agent working in a single file with a great agent pattern and all dependencies encapsulated, we can iterate at light speed with powerful AI coding techniques, many of which we've discussed in principled AI coding. We're overdue for AI coding on the channel, so let's go ahead and write up a concise AI coding spec prompt to create a new SQLite single file agent. And then I'll pitch principled AI coding for those who aren't aware of what it is and how it can accelerate your engineering. I also have some updates coming for existing members. We're gonna have some nice lightweight tooling to help us utilize all the principles we learned inside the course. So more on that in a second, let's first build out our SQLite AI agent. So this is gonna be relatively simple since DuckDB and SQLite are very, very similar. What we'll do here is open the terminal. We'll type CP SFA. We'll basically just copy this, create an SQLite version. SQLite, great. I'm also going to touch aicode.sh. And this is where we're gonna build out our context model and prompt so that we can quickly reuse our. single file agent pattern in a reusable, scalable way. I use AIDR as my primary AI coding workhorse. You can deploy this pattern with any AI coding tool you want. Of course, use Cursor, Windsurfer, Klein, whatever your deal is, go ahead and hop into that. I like to use AIDR and Cursor side-by-side. And let me show you a new pattern. And let me also just kind of, you know, share some of the advantages you get when you use a AI coding tool like AIDR. So I'm just gonna paste this in here since I've done this a million times. Let's start with just this blob here, okay? So we're passing in our prompt as the first argument. We're kicking off AIDR. I wanna run the O3 mini model in architect mode with the high reasoning effort. This is some of the best compute you can get right now. I want Claw 3.5 Sonnet to make the edits that O3 mini suggests. And then we have a couple of configurations here just to speed things up. And then in my context, you can see I'm passing in, I want every single Python file available as the context. Okay? The message is just gonna be the prompt. So whatever we pass in here, we can, you know, run this now and say, SHAI, and then just pass in whatever prompt. And then we can start getting AI coding changes in on this, right? Let me show you a little hint of what I have coming for principled AI coding members. There's a big theme right now about scaling compute usage and just throwing more compute at the problem. And then your problem will be solved, you know, basically just by turning up the knob. We can see that this is true even for AI coding. It's gonna look really stupid, but you're gonna understand how powerful this is as we work through this. I'm literally gonna copy this command. I'm gonna paste it here. So let me turn off cursor tabs. We can write this by ourselves here. I'm gonna say, double check all changes requested to make sure they've been implemented. And that's it. And so what we end up with here is a prompt chain of length four, right? We have an architect drafting the changes and then an editor writing the changes. And then again, we have an architect double checking all the changes that just happened in a brand new instance. And then we have an editor to write those changes, right? To write anything that was, you know, potentially missed. Fantastic. So now we're going to actually write the prompt. This is gonna be really simple. I'm going to get. the path to this. I'm just going to say update and then I'll say refactor to target SQLite databases. Keep all functions the same but target SQLite databases with SQLite 3. So I'm being specific about what library I want used here. Update tools and prompt to reference SQLite. Okay because if we open up this file you can see here if we just search DuckDB we have you know many references. You can see on the side here we have many references to DuckDB. So that's it. That's the prompt. I'm going to copy this and I have this kind of reusable AI coding configuration. Right you can think of this as a kind of just generic AI coding script that we can call that runs a compute enhanced AI coding chain of assistants. Right we have two aider assistants in architect mode. We're just going to copy this. We do dollar sign pb paste. That's it. So this is going to update. It's going to kick off two AI coding assistants running back to back. This is our first shot and this is our reflection step. Right all right so there we go. We're getting our changes. We're updating our tool calls to reference SQLite instead of DuckDB. And then at some point here we're going to see our prompt get updated. So you can see there all those tools. That looks great. We're on final SQL query. Now we're referencing SQLite instead of DuckDB. You can see we had an update in the prompt and now we're running the reflection. Right so remember the reflection is literally just this. Double check all changes. Request it and we're pacing the prompt in again. So let's see what happens now. We've already taken one shot at architect and editor with aider and now we're running again. So you can see here look at how many things were missed. Right we have the architect saying hey you missed this here. Hey you missed this here. And then the editor is coming in and actually changing those things. Right so we can now search SQLite. And so we should see a bunch of references to SQLite now with that new syntax. As a test we can also come in here and search DuckDB. Right so this is really good. We don't see any references to DuckDB anymore. Fantastic. And now we should be able to run our SQLite agent just as we did our DuckDB OpenAI agent. So in order to do that we need to pull in an SQLite. version of this, I'll paste this in, and you can see my SQLite extension showing this table here, right? So this is our users table, let's go ahead and close this. So we now have this ready for our new SQLite agent. Let's go ahead and save this. And now let's just run our SQLite agent, SFA, single file agent, and we're gonna run our SQLite version, dash D, analytics, SQLite database, dash P, list five rows from user table. And for our compute, we'll just say five, right? Should be pretty simple. So far so good, right? Our code compiles, so that looks great. We have our first tool call, that looks awesome. There it is. So SQLite running just like our DuckDB did. We're getting a slightly different output format because of course we're using SQLite. We were able to reuse our existing single file agent architecture. We made an update to it with a clean prompt chain of length four, where every prompt was us kicking off Adr. We have an architect and then an editor, and then we just basically doubled it, right? Our reflection actually saved us a little bit of energy. This idea of scaling up your compute really does translate to almost anywhere you're using language models, anywhere you're running a prompt, right? Even if it's embedded inside of a tool like Adr, right? You have to remember all of these tools, right? Cursor, Adr, ChatGPT, Claude, right? Every one of these tools at the end is running the new fundamental unit of knowledge work. It's all about the prompt and agents is how we scale the prompt up. This is how we scale up our impact. At the beginning, I said we would talk about, why is everyone so obsessed with agents? This is why, it's because agents lets us scale up our compute usage. And in the age of generative AI, when you scale your compute, you scale your impact. This is a big theme on the Andi Dev Dan channel. Right now in Q1, 2025, the most important thing we can do is figure out how to scale our compute. Agents are the name of the game. You just saw what we did here with a DuckDB domain-specific focus agent with only five tools, right? It gathers context, it understands the structure, it then internally validates for hard problems, and then it gives us the fun. final result, right? When we take Astral's UV and the ability to package dependencies and these isolated single file agents, right? These single file scripts, this really lets us move fast, scale or compute and get work done and solve problems fast without over investing, right? I think that's a really big theme. You don't want to over invest in this massive monolithic tool that, you know, you're trying to deploy in tens and hundreds of ways, just build one agent, make it do one thing extremely well and keep it lean and lightweight, right? It's all about that agentic structure. What does your loop look like? How can your agent get smarter? How can your agent gather context to solve that specific problem you're trying to solve? All right. This is the key. This code base is going to be linked in the description for you. Drop the like, drop the sub and, you know, drop a comment. Let me know how deep into agents you are right now. Are you on the surface? Are you, you know, trying to understand agent structures? Are you using any agents right now? And, you know, let me know what you think about this idea to build out these single file agents that you can quickly reuse and redeploy with the help of, you know, whatever your favorite AI coding tooling is. At a high level, the longer your prompt chain, the more compute you're using, right? And when we think about it, what's happening in this agent loop that we're running here in both our SQLite and our OpenAI version, you know, what's happening here, we can kick this off again. Let's go ahead and ask another question here. Let's list five users, GT, greater than, status, archived, or pending. All right. Let's kick that off. And fantastic. So we can see that we have status, archived, or pending. Age is always over 30, right? And this is running in this agentic loop. It's solving this problem automatically. It has the tools it needs to do the job. And, you know, something I want to mention here, you can think about an agent as a elongated prompt chain, right? It's a series of prompt calls over and over and over again, targeting a specific domain problem. And it's all about figuring out how to best solve that problem with the compute that you give it. And so if an error occurred here, we would probably need to give, you know, more compute, more, or, you know, loops, we're running O3 mini is a powerful reasoning model. So, you know, as it's thinking through what tools to call and solving these problems, it's doing an extraordinary job. An interesting way to think about the AI agent is that the more compute you're giving it, basically what we're doing is we're extending the prompt chain, right? We're elongating the number of compute runs that it has. So if we wanted to solve a really hard problem, for instance, you know, OpenAI's deep research tool, this thing runs for five to 30 minutes, right? So you can imagine, you know, it's compute loop is, you know, blasted up to like a hundred across various tools, various functions, you know, various capabilities. That's a really powerful idea we're gonna be looking into more on the channel. Like I mentioned, I'm gonna have these single file agents in a code base for you to check out, tweak and make your own. I'll add a couple additional versions here that I was playing with so that you can, you know, check them out and build out your own. I have a version where I have the meta prompt we've talked about on the channel inside of a single file agent. You can just quickly query your meta prompting agent to generate a new prompt for you. Things are moving fast, agents are here. One of the most important agents and one of the most important things you can do right now is learn how to write code with AI and not just learn, but really scale your capabilities with writing code with AI. Many of you on the channel, you've already dove in to principled AI coding. Let me just pitch this for those who haven't taken it yet. This is really important and I wanna make sure I'm sharing this tool so that everyone is understanding the state engineering is in and how they can progress, keep up and thrive in the new world of generative AI. So principled AI coding is my take on how to transition from the old ways of engineering to the new way. We now have over a thousand engineers that have taken principled AI coding, that have a new perspective and actionable patterns and principles they can use for their engineering in today's landscape of generative AI and more importantly, for the next wave of generative AI based engineering. So, I don't know if you've noticed, if your eyes are open, you've probably noticed this, but software engineering has changed and it's time to change with it. is the largest productivity multiplier for engineers to ever exist. It's something that you can't miss out on, okay? If you miss out on this, you'll be left behind. I think 2025 is the last year where you can write code without AI and really be useful, right? Really be employable. Really be able to contribute in a meaningful way. Go on Twitter for five seconds. Go on Reddit and, you know, just type in AI Coding. Type in Cursor. Type in Aitor. Type in Klein. Type in any one of these tools and you'll understand that there are engineers all the way from noob beginners to senior, expert, principal, big name engineers, right, that you, you know, likely look up to. They understand this curve, right? They understand these two curves. You are either using the tool that helps you scale your impact or you're not, okay? And, you know, just to say it really bluntly, if you're not writing code with AI, if you're still manually coding, you are not using the best tool for the job anymore. If you're writing code with AI, you are absolutely on an upward curve, okay? Principal AI Coding was built to help you make this transition in the shortest amount of time possible, okay? The only thing better than experience is experience earned faster. We focus on principles, not tools. Principles, not models, okay? There's going to be an onslaught of agents, of tools, of models. You know this already, right? You're, you're aware of this. We need principles to endure change over time. So, you know, this course helps you get there. It helps you endure change with principles. And one of the key principles we talk about in lesson three is context, model, prompt. These are the big three, the most important elements we're getting worked on in AI coding, but really with all of generative AI. There are eight lessons in this course. They take you from beginner to intermediate to advanced. We talk about big topics that are, you know, really becoming mainstream in the generative AI, AI coding world. We talk about the spec prompt, right? Scaling up your work by writing larger prompts, larger specs. And we talk about, you know, a big topic that's come up recently is this idea of closing the loop, right? by creating these closed-loop, self-verifiable systems, your AI coding tools and your agentic systems can actually get the work done by themselves. If you give them enough direction, if you tell them where to go and how to resolve and give them feedback, you close the loop, okay? This is a really important, powerful pattern. This is gonna be big over 2025 and 2026. People are already starting to talk about this more. This is getting uncovered. So you wanna move on this stuff before it really, really hits the masses, okay? So eight lessons here. Lots of great reviews. Feel free to check out tons of the other videos and AI coding content I have on the channel. This is here for you. And just to mention it, I have a no-questions-asked refund before lesson four. This is basically risk-free at this point, right? So hop in. If you don't like my style, if you don't like the video, if you don't understand what's happening, if it's too complex or if it's not complex enough and you're too much of an omni-chat engineer and you already know what I'm gonna say in the next six videos or whatever, that's fine. You get a full refund before you start lesson four. No questions asked. We've had zero issues with this. There's a lot of value here. And I just wanna pitch it on the channel. For all existing Principled AI Coding members, I'm gonna be rolling out some new tooling that helps us use the patterns we learned in Principled AI Coding in a cool, lightweight way. I'm building this on top of the powerful all-in-one tool, UV. So it's gonna be super simple to set up, use, and deploy. And we're, of course, going to continue using our top-of-the-line, most customizable, configurable, powerful AI Coding Assistant, AIDR. So stay tuned for that. And even if you don't use AIDR, even if you're not a fan of CLI-based, full-control AI Coding Assistants, that's fine. Again, we use AIDR as a tool here to showcase the principles. This course is not about AIDR, okay? So just to quickly mention that, and yeah, that's Principled AI Coding. I'm gonna hop in here before, you know, the next wave of coding comes, which I'm gonna be preparing everyone for, again, inside this course. Those lessons are in the works, they're in the queue, but that's gonna be for later in this year. Just to say it out loud here, right now, AI Coding... is the wave. The next wave that's upon us is agentic coding. When you fully close the loop, what you end up with is systems that can operate on their own. So stay tuned, stay locked in. I hope you can understand why agents are so important in the age of AI. You first start with the prompt. You then move to prompt chains. You have a series of LLM-based calls that can do work on your behalf. And then you move to AI agents, right? The structure where you give them the tools they need to solve the problem. And then you let them learn, gather information, execute, get feedback. Agents is how we continue to scale our compute. This is where we're going to be focused on the channel. It's all about scaling compute usage, maximizing what you can do. It's all about AI coding so that you can write faster than ever, so that you can build out these agents fast, just to come full circle here. That's why the single file agent pattern is so important, because we meet at the intersection of three important innovations. We have Astral's UV, allowing us to bundle dependencies into a single file. We have self-validating agent patterns, where we can write great tools and great prompts to allow the agent to self-verify before it returns the response to us. And then of course, we have powerful AI coding techniques. Many of these we cover in principle AI coding. This lets us reuse, scale, clone, and duplicate our single file AI agents into many different domains. You can imagine we have an agent that builds agents. Okay. So we have a lot of big ideas to cover on the channel. If you're interested in this, if you made it this far in the video, you know what to do. Drop the like, drop the sub, leave a comment, stay connected, and whatever happens, stay focused and keep building.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.236328125,
      "compression_ratio": 1.4647302627563477,
      "end": 6.159999847412109,
      "no_speech_prob": 0.013422844931483269,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " What's up engineers, NDDevDan here. Something I think about a lot is how can we maximize our",
      "tokens": [
        50364,
        708,
        311,
        493,
        11955,
        11,
        40709,
        11089,
        85,
        17087,
        510,
        13,
        6595,
        286,
        519,
        466,
        257,
        688,
        307,
        577,
        393,
        321,
        19874,
        527,
        50672
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.236328125,
      "compression_ratio": 1.4647302627563477,
      "end": 12.399999618530273,
      "no_speech_prob": 0.013422844931483269,
      "seek": 0,
      "start": 6.159999847412109,
      "temperature": 0.0,
      "text": " compute usage with powerful AI agents while steering clear of the roadmap of companies",
      "tokens": [
        50672,
        14722,
        14924,
        365,
        4005,
        7318,
        12554,
        1339,
        14823,
        1850,
        295,
        264,
        35738,
        295,
        3431,
        50984
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.236328125,
      "compression_ratio": 1.4647302627563477,
      "end": 21.920000076293945,
      "no_speech_prob": 0.013422844931483269,
      "seek": 0,
      "start": 12.399999618530273,
      "temperature": 0.0,
      "text": " like OpenAI. When OpenAI releases an agent, 1,256 startups are immediately destroyed,",
      "tokens": [
        50984,
        411,
        7238,
        48698,
        13,
        1133,
        7238,
        48698,
        16952,
        364,
        9461,
        11,
        502,
        11,
        6074,
        21,
        28041,
        366,
        4258,
        8937,
        11,
        51460
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.236328125,
      "compression_ratio": 1.4647302627563477,
      "end": 27.920000076293945,
      "no_speech_prob": 0.013422844931483269,
      "seek": 0,
      "start": 21.920000076293945,
      "temperature": 0.0,
      "text": " eviscerated. For example, if you were building a research agent, OpenAI's deep research",
      "tokens": [
        51460,
        1073,
        271,
        1776,
        770,
        13,
        1171,
        1365,
        11,
        498,
        291,
        645,
        2390,
        257,
        2132,
        9461,
        11,
        7238,
        48698,
        311,
        2452,
        2132,
        51760
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.1948784738779068,
      "compression_ratio": 1.6715867519378662,
      "end": 34.31999969482422,
      "no_speech_prob": 0.0004238776455167681,
      "seek": 2792,
      "start": 27.920000076293945,
      "temperature": 0.0,
      "text": " just ate your breakfast, lunch, and dinner. Imagine all your time, engineering resources,",
      "tokens": [
        50364,
        445,
        8468,
        428,
        8201,
        11,
        6349,
        11,
        293,
        6148,
        13,
        11739,
        439,
        428,
        565,
        11,
        7043,
        3593,
        11,
        50684
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.1948784738779068,
      "compression_ratio": 1.6715867519378662,
      "end": 40.15999984741211,
      "no_speech_prob": 0.0004238776455167681,
      "seek": 2792,
      "start": 34.31999969482422,
      "temperature": 0.0,
      "text": " and time investment vanished, instantly cooked. From startups to individual engineers,",
      "tokens": [
        50684,
        293,
        565,
        6078,
        37518,
        11,
        13518,
        9267,
        13,
        3358,
        28041,
        281,
        2609,
        11955,
        11,
        50976
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.1948784738779068,
      "compression_ratio": 1.6715867519378662,
      "end": 44.63999938964844,
      "no_speech_prob": 0.0004238776455167681,
      "seek": 2792,
      "start": 40.15999984741211,
      "temperature": 0.0,
      "text": " it doesn't matter how great your work is, or how far you've scaled your AI coding,",
      "tokens": [
        50976,
        309,
        1177,
        380,
        1871,
        577,
        869,
        428,
        589,
        307,
        11,
        420,
        577,
        1400,
        291,
        600,
        36039,
        428,
        7318,
        17720,
        11,
        51200
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.1948784738779068,
      "compression_ratio": 1.6715867519378662,
      "end": 50.720001220703125,
      "no_speech_prob": 0.0004238776455167681,
      "seek": 2792,
      "start": 44.63999938964844,
      "temperature": 0.0,
      "text": " or what technical innovation you've found, if you invest in the wrong agent, in the wrong tool,",
      "tokens": [
        51200,
        420,
        437,
        6191,
        8504,
        291,
        600,
        1352,
        11,
        498,
        291,
        1963,
        294,
        264,
        2085,
        9461,
        11,
        294,
        264,
        2085,
        2290,
        11,
        51504
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.1948784738779068,
      "compression_ratio": 1.6715867519378662,
      "end": 57.52000045776367,
      "no_speech_prob": 0.0004238776455167681,
      "seek": 2792,
      "start": 50.720001220703125,
      "temperature": 0.0,
      "text": " in the wrong product, you're at risk of getting bulldozed by OpenAI and other gen tech companies.",
      "tokens": [
        51504,
        294,
        264,
        2085,
        1674,
        11,
        291,
        434,
        412,
        3148,
        295,
        1242,
        4693,
        2595,
        11312,
        538,
        7238,
        48698,
        293,
        661,
        1049,
        7553,
        3431,
        13,
        51844
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.19615106284618378,
      "compression_ratio": 1.6875,
      "end": 64.63999938964844,
      "no_speech_prob": 3.705285053001717e-05,
      "seek": 5752,
      "start": 57.91999816894531,
      "temperature": 0.0,
      "text": " How can we stay ahead and build powerful, effective agents while staying out of the way",
      "tokens": [
        50384,
        1012,
        393,
        321,
        1754,
        2286,
        293,
        1322,
        4005,
        11,
        4942,
        12554,
        1339,
        7939,
        484,
        295,
        264,
        636,
        50720
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.19615106284618378,
      "compression_ratio": 1.6875,
      "end": 70.80000305175781,
      "no_speech_prob": 3.705285053001717e-05,
      "seek": 5752,
      "start": 64.63999938964844,
      "temperature": 0.0,
      "text": " of the generative AI roadmap? I spend a lot of time in this space and I want to share a",
      "tokens": [
        50720,
        295,
        264,
        1337,
        1166,
        7318,
        35738,
        30,
        286,
        3496,
        257,
        688,
        295,
        565,
        294,
        341,
        1901,
        293,
        286,
        528,
        281,
        2073,
        257,
        51028
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.19615106284618378,
      "compression_ratio": 1.6875,
      "end": 77.19999694824219,
      "no_speech_prob": 3.705285053001717e-05,
      "seek": 5752,
      "start": 70.80000305175781,
      "temperature": 0.0,
      "text": " pattern with you for building powerful, lean, compute-gobbling AI agents that can help you",
      "tokens": [
        51028,
        5102,
        365,
        291,
        337,
        2390,
        4005,
        11,
        11659,
        11,
        14722,
        12,
        70,
        996,
        18262,
        7318,
        12554,
        300,
        393,
        854,
        291,
        51348
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.19615106284618378,
      "compression_ratio": 1.6875,
      "end": 83.12000274658203,
      "no_speech_prob": 3.705285053001717e-05,
      "seek": 5752,
      "start": 77.19999694824219,
      "temperature": 0.0,
      "text": " move fast, iterate, and scale your compute usage while staying out of the way. Then,",
      "tokens": [
        51348,
        1286,
        2370,
        11,
        44497,
        11,
        293,
        4373,
        428,
        14722,
        14924,
        1339,
        7939,
        484,
        295,
        264,
        636,
        13,
        1396,
        11,
        51644
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.17673815786838531,
      "compression_ratio": 1.5402299165725708,
      "end": 87.76000213623047,
      "no_speech_prob": 0.1688317209482193,
      "seek": 8312,
      "start": 83.12000274658203,
      "temperature": 0.0,
      "text": " near the end of this video, we're going to discuss why we care about agents so much,",
      "tokens": [
        50364,
        2651,
        264,
        917,
        295,
        341,
        960,
        11,
        321,
        434,
        516,
        281,
        2248,
        983,
        321,
        1127,
        466,
        12554,
        370,
        709,
        11,
        50596
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.17673815786838531,
      "compression_ratio": 1.5402299165725708,
      "end": 94.72000122070312,
      "no_speech_prob": 0.1688317209482193,
      "seek": 8312,
      "start": 87.76000213623047,
      "temperature": 0.0,
      "text": " and I'll explain why I and other engineers are so obsessed with agents. Agents are everything,",
      "tokens": [
        50596,
        293,
        286,
        603,
        2903,
        983,
        286,
        293,
        661,
        11955,
        366,
        370,
        16923,
        365,
        12554,
        13,
        2725,
        791,
        366,
        1203,
        11,
        50944
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.17673815786838531,
      "compression_ratio": 1.5402299165725708,
      "end": 101.83999633789062,
      "no_speech_prob": 0.1688317209482193,
      "seek": 8312,
      "start": 94.72000122070312,
      "temperature": 0.0,
      "text": " and I'll explain why in this video. By using Astral's all-in-one Python tool, UV, and by",
      "tokens": [
        50944,
        293,
        286,
        603,
        2903,
        983,
        294,
        341,
        960,
        13,
        3146,
        1228,
        12884,
        2155,
        311,
        439,
        12,
        259,
        12,
        546,
        15329,
        2290,
        11,
        17887,
        11,
        293,
        538,
        51300
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.20245398581027985,
      "compression_ratio": 1.4863388538360596,
      "end": 108.72000122070312,
      "no_speech_prob": 0.00026528502348810434,
      "seek": 10184,
      "start": 101.83999633789062,
      "temperature": 0.0,
      "text": " combining it with powerful AI coding techniques, we can build and deploy single-file agents.",
      "tokens": [
        50364,
        21928,
        309,
        365,
        4005,
        7318,
        17720,
        7512,
        11,
        321,
        393,
        1322,
        293,
        7274,
        2167,
        12,
        69,
        794,
        12554,
        13,
        50708
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.20245398581027985,
      "compression_ratio": 1.4863388538360596,
      "end": 117.76000213623047,
      "no_speech_prob": 0.00026528502348810434,
      "seek": 10184,
      "start": 113.44000244140625,
      "temperature": 0.0,
      "text": " So what is a single-file agent, and how does it help us move fast, scale our compute,",
      "tokens": [
        50944,
        407,
        437,
        307,
        257,
        2167,
        12,
        69,
        794,
        9461,
        11,
        293,
        577,
        775,
        309,
        854,
        505,
        1286,
        2370,
        11,
        4373,
        527,
        14722,
        11,
        51160
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.20245398581027985,
      "compression_ratio": 1.4863388538360596,
      "end": 124.0,
      "no_speech_prob": 0.00026528502348810434,
      "seek": 10184,
      "start": 117.76000213623047,
      "temperature": 0.0,
      "text": " and avoid getting disrupted by big tech companies? I have this simple project here in Cursor,",
      "tokens": [
        51160,
        293,
        5042,
        1242,
        42271,
        538,
        955,
        7553,
        3431,
        30,
        286,
        362,
        341,
        2199,
        1716,
        510,
        294,
        383,
        2156,
        284,
        11,
        51472
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.25429341197013855,
      "compression_ratio": 1.1463414430618286,
      "end": 130.8800048828125,
      "no_speech_prob": 0.42609739303588867,
      "seek": 12400,
      "start": 124.0,
      "temperature": 0.0,
      "text": " and right away you'll notice something weird. We only have two files. We have a file database,",
      "tokens": [
        50364,
        293,
        558,
        1314,
        291,
        603,
        3449,
        746,
        3657,
        13,
        492,
        787,
        362,
        732,
        7098,
        13,
        492,
        362,
        257,
        3991,
        8149,
        11,
        50708
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 132.9599975347519,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 131.05999755859375,
      "temperature": 0.0,
      "text": " and a Python file.",
      "tokens": [
        50364,
        293,
        257,
        15329,
        3991,
        13,
        50459
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 135.55999755859375,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 132.9599975347519,
      "temperature": 0.0,
      "text": " So before we dive into the agent architecture,",
      "tokens": [
        50459,
        407,
        949,
        321,
        9192,
        666,
        264,
        9461,
        9482,
        11,
        50589
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 138.43999767303467,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 135.55999755859375,
      "temperature": 0.0,
      "text": " let's just run our agent with UV",
      "tokens": [
        50589,
        718,
        311,
        445,
        1190,
        527,
        9461,
        365,
        17887,
        50733
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 141.71999740600586,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 138.43999767303467,
      "temperature": 0.0,
      "text": " and let me show you how powerful this single file is.",
      "tokens": [
        50733,
        293,
        718,
        385,
        855,
        291,
        577,
        4005,
        341,
        2167,
        3991,
        307,
        13,
        50897
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 145.39999771118164,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 141.71999740600586,
      "temperature": 0.0,
      "text": " UV run, SFA, single file agent,",
      "tokens": [
        50897,
        17887,
        1190,
        11,
        318,
        19684,
        11,
        2167,
        3991,
        9461,
        11,
        51081
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 148.99999809265137,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 145.39999771118164,
      "temperature": 0.0,
      "text": " dash D, analytics.database will pass in that database file,",
      "tokens": [
        51081,
        8240,
        413,
        11,
        15370,
        13,
        20367,
        455,
        651,
        486,
        1320,
        294,
        300,
        8149,
        3991,
        11,
        51261
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 153.5999984741211,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 148.99999809265137,
      "temperature": 0.0,
      "text": " dash P for prompt, list, all tables and their columns.",
      "tokens": [
        51261,
        8240,
        430,
        337,
        12391,
        11,
        1329,
        11,
        439,
        8020,
        293,
        641,
        13766,
        13,
        51491
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 156.83999824523926,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 153.5999984741211,
      "temperature": 0.0,
      "text": " Dash C lets us set the compute that our agent can use.",
      "tokens": [
        51491,
        23453,
        383,
        6653,
        505,
        992,
        264,
        14722,
        300,
        527,
        9461,
        393,
        764,
        13,
        51653
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2527053654193878,
      "compression_ratio": 1.5732218027114868,
      "end": 158.21999740600586,
      "no_speech_prob": 0.054998960345983505,
      "seek": 0,
      "start": 156.83999824523926,
      "temperature": 0.0,
      "text": " We'll set this to 10.",
      "tokens": [
        51653,
        492,
        603,
        992,
        341,
        281,
        1266,
        13,
        51722
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 160.9799976348877,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 158.21999740600586,
      "temperature": 0.0,
      "text": " Let's kick off our DuckDB AI agent.",
      "tokens": [
        50364,
        961,
        311,
        4437,
        766,
        527,
        29266,
        27735,
        7318,
        9461,
        13,
        50502
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 163.37999725341797,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 160.9799976348877,
      "temperature": 0.0,
      "text": " You can see here, it's kicking off the first compute loop",
      "tokens": [
        50502,
        509,
        393,
        536,
        510,
        11,
        309,
        311,
        19137,
        766,
        264,
        700,
        14722,
        6367,
        50622
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 166.8599967956543,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 163.37999725341797,
      "temperature": 0.0,
      "text": " and it only needed one shot to complete this.",
      "tokens": [
        50622,
        293,
        309,
        787,
        2978,
        472,
        3347,
        281,
        3566,
        341,
        13,
        50796
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 169.53999710083008,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 166.8599967956543,
      "temperature": 0.0,
      "text": " You can see we have a single function argument call.",
      "tokens": [
        50796,
        509,
        393,
        536,
        321,
        362,
        257,
        2167,
        2445,
        6770,
        818,
        13,
        50930
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 172.33999633789062,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 169.53999710083008,
      "temperature": 0.0,
      "text": " You can see we're using the rich Python library",
      "tokens": [
        50930,
        509,
        393,
        536,
        321,
        434,
        1228,
        264,
        4593,
        15329,
        6405,
        51070
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 174.31999588012695,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 172.33999633789062,
      "temperature": 0.0,
      "text": " to format the output here.",
      "tokens": [
        51070,
        281,
        7877,
        264,
        5598,
        510,
        13,
        51169
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 178.37999725341797,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 174.31999588012695,
      "temperature": 0.0,
      "text": " This agent in particular is powered by OpenAI's O3 mini.",
      "tokens": [
        51169,
        639,
        9461,
        294,
        1729,
        307,
        17786,
        538,
        7238,
        48698,
        311,
        422,
        18,
        8382,
        13,
        51372
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 179.99999618530273,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 178.37999725341797,
      "temperature": 0.0,
      "text": " So what just happened there?",
      "tokens": [
        51372,
        407,
        437,
        445,
        2011,
        456,
        30,
        51453
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 182.73999786376953,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 179.99999618530273,
      "temperature": 0.0,
      "text": " How is it able to pack in so much intelligence",
      "tokens": [
        51453,
        1012,
        307,
        309,
        1075,
        281,
        2844,
        294,
        370,
        709,
        7599,
        51590
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 186.45999908447266,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 182.73999786376953,
      "temperature": 0.0,
      "text": " and capability into a single Python file?",
      "tokens": [
        51590,
        293,
        13759,
        666,
        257,
        2167,
        15329,
        3991,
        30,
        51776
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.20253759622573853,
      "compression_ratio": 1.6233333349227905,
      "end": 187.8599967956543,
      "no_speech_prob": 8.750276174396276e-05,
      "seek": 2716,
      "start": 186.45999908447266,
      "temperature": 0.0,
      "text": " We're gonna dive into that in just a second,",
      "tokens": [
        51776,
        492,
        434,
        799,
        9192,
        666,
        300,
        294,
        445,
        257,
        1150,
        11,
        51846
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 190.4199981689453,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 188.49999618530273,
      "temperature": 0.0,
      "text": " but I wanna show you the full agentic loop",
      "tokens": [
        50396,
        457,
        286,
        1948,
        855,
        291,
        264,
        1577,
        9461,
        299,
        6367,
        50492
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 191.53999710083008,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 190.4199981689453,
      "temperature": 0.0,
      "text": " that our agent can go through.",
      "tokens": [
        50492,
        300,
        527,
        9461,
        393,
        352,
        807,
        13,
        50548
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 192.8599967956543,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 191.53999710083008,
      "temperature": 0.0,
      "text": " So let's run this again,",
      "tokens": [
        50548,
        407,
        718,
        311,
        1190,
        341,
        797,
        11,
        50614
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 195.37999725341797,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 192.8599967956543,
      "temperature": 0.0,
      "text": " but let's ask our DuckDB AI agent",
      "tokens": [
        50614,
        457,
        718,
        311,
        1029,
        527,
        29266,
        27735,
        7318,
        9461,
        50740
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 196.65999603271484,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 195.37999725341797,
      "temperature": 0.0,
      "text": " to do something more complex for us.",
      "tokens": [
        50740,
        281,
        360,
        746,
        544,
        3997,
        337,
        505,
        13,
        50804
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 199.73999786376953,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 196.65999603271484,
      "temperature": 0.0,
      "text": " I'm gonna say users score greater than 80",
      "tokens": [
        50804,
        286,
        478,
        799,
        584,
        5022,
        6175,
        5044,
        813,
        4688,
        50958
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 201.97999572753906,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 199.73999786376953,
      "temperature": 0.0,
      "text": " and status active.",
      "tokens": [
        50958,
        293,
        6558,
        4967,
        13,
        51070
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 204.93999481201172,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 201.97999572753906,
      "temperature": 0.0,
      "text": " So you can see here, this is the wrong table name.",
      "tokens": [
        51070,
        407,
        291,
        393,
        536,
        510,
        11,
        341,
        307,
        264,
        2085,
        3199,
        1315,
        13,
        51218
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 207.65999603271484,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 204.93999481201172,
      "temperature": 0.0,
      "text": " It has to figure out where these columns are coming from",
      "tokens": [
        51218,
        467,
        575,
        281,
        2573,
        484,
        689,
        613,
        13766,
        366,
        1348,
        490,
        51354
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 209.73999786376953,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 207.65999603271484,
      "temperature": 0.0,
      "text": " and what the exact name of these columns are.",
      "tokens": [
        51354,
        293,
        437,
        264,
        1900,
        1315,
        295,
        613,
        13766,
        366,
        13,
        51458
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 211.73999786376953,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 209.73999786376953,
      "temperature": 0.0,
      "text": " So there's a lot that I'm kind of leaving up",
      "tokens": [
        51458,
        407,
        456,
        311,
        257,
        688,
        300,
        286,
        478,
        733,
        295,
        5012,
        493,
        51558
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 212.89999389648438,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 211.73999786376953,
      "temperature": 0.0,
      "text": " to our agent to figure out",
      "tokens": [
        51558,
        281,
        527,
        9461,
        281,
        2573,
        484,
        51616
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 214.86000061035156,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 212.89999389648438,
      "temperature": 0.0,
      "text": " and it's gonna run that exact same pattern.",
      "tokens": [
        51616,
        293,
        309,
        311,
        799,
        1190,
        300,
        1900,
        912,
        5102,
        13,
        51714
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.19170443713665009,
      "compression_ratio": 1.7725752592086792,
      "end": 216.6999969482422,
      "no_speech_prob": 0.0003569691034499556,
      "seek": 5680,
      "start": 214.86000061035156,
      "temperature": 0.0,
      "text": " So we now have an agent loop,",
      "tokens": [
        51714,
        407,
        321,
        586,
        362,
        364,
        9461,
        6367,
        11,
        51806
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 219.93999481201172,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 216.6999969482422,
      "temperature": 0.0,
      "text": " only this time it's going to take a more iterative approach.",
      "tokens": [
        50364,
        787,
        341,
        565,
        309,
        311,
        516,
        281,
        747,
        257,
        544,
        17138,
        1166,
        3109,
        13,
        50526
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 222.4199981689453,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 219.93999481201172,
      "temperature": 0.0,
      "text": " So you can see there, it's listing tables.",
      "tokens": [
        50526,
        407,
        291,
        393,
        536,
        456,
        11,
        309,
        311,
        22161,
        8020,
        13,
        50650
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 223.57999420166016,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 222.4199981689453,
      "temperature": 0.0,
      "text": " It found the user table.",
      "tokens": [
        50650,
        467,
        1352,
        264,
        4195,
        3199,
        13,
        50708
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 227.33999633789062,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 223.57999420166016,
      "temperature": 0.0,
      "text": " It then is running this describe table arguments tool call",
      "tokens": [
        50708,
        467,
        550,
        307,
        2614,
        341,
        6786,
        3199,
        12869,
        2290,
        818,
        50896
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 229.73999786376953,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 227.33999633789062,
      "temperature": 0.0,
      "text": " so that it can understand what this table looks like.",
      "tokens": [
        50896,
        370,
        300,
        309,
        393,
        1223,
        437,
        341,
        3199,
        1542,
        411,
        13,
        51016
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 231.0199966430664,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 229.73999786376953,
      "temperature": 0.0,
      "text": " There's the output for that.",
      "tokens": [
        51016,
        821,
        311,
        264,
        5598,
        337,
        300,
        13,
        51080
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 234.73999786376953,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 231.0199966430664,
      "temperature": 0.0,
      "text": " And then at the end here, it's running run final SQL query.",
      "tokens": [
        51080,
        400,
        550,
        412,
        264,
        917,
        510,
        11,
        309,
        311,
        2614,
        1190,
        2572,
        19200,
        14581,
        13,
        51266
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 237.57999420166016,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 234.73999786376953,
      "temperature": 0.0,
      "text": " It is the final tool call, the final function call,",
      "tokens": [
        51266,
        467,
        307,
        264,
        2572,
        2290,
        818,
        11,
        264,
        2572,
        2445,
        818,
        11,
        51408
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 239.81999969482422,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 237.57999420166016,
      "temperature": 0.0,
      "text": " and we can see the exact query it's running",
      "tokens": [
        51408,
        293,
        321,
        393,
        536,
        264,
        1900,
        14581,
        309,
        311,
        2614,
        51520
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 241.65999603271484,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 239.81999969482422,
      "temperature": 0.0,
      "text": " and the exact outputs.",
      "tokens": [
        51520,
        293,
        264,
        1900,
        23930,
        13,
        51612
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.20202851295471191,
      "compression_ratio": 1.836501955986023,
      "end": 243.0999984741211,
      "no_speech_prob": 0.0002653013216331601,
      "seek": 8564,
      "start": 241.65999603271484,
      "temperature": 0.0,
      "text": " We have an AI agent that is adept",
      "tokens": [
        51612,
        492,
        362,
        364,
        7318,
        9461,
        300,
        307,
        614,
        5250,
        51684
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.2726145386695862,
      "compression_ratio": 1.5416666269302368,
      "end": 246.93999481201172,
      "no_speech_prob": 0.12937824428081512,
      "seek": 11204,
      "start": 243.13999938964844,
      "temperature": 0.0,
      "text": " at operating DuckDB local databases.",
      "tokens": [
        50366,
        412,
        7447,
        29266,
        27735,
        2654,
        22380,
        13,
        50556
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.2726145386695862,
      "compression_ratio": 1.5416666269302368,
      "end": 248.0999984741211,
      "no_speech_prob": 0.12937824428081512,
      "seek": 11204,
      "start": 246.93999481201172,
      "temperature": 0.0,
      "text": " So this is super powerful.",
      "tokens": [
        50556,
        407,
        341,
        307,
        1687,
        4005,
        13,
        50614
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.2726145386695862,
      "compression_ratio": 1.5416666269302368,
      "end": 250.86000061035156,
      "no_speech_prob": 0.12937824428081512,
      "seek": 11204,
      "start": 248.0999984741211,
      "temperature": 0.0,
      "text": " As a series of tools at its disposal,",
      "tokens": [
        50614,
        1018,
        257,
        2638,
        295,
        3873,
        412,
        1080,
        26400,
        11,
        50752
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.2726145386695862,
      "compression_ratio": 1.5416666269302368,
      "end": 254.25999450683594,
      "no_speech_prob": 0.12937824428081512,
      "seek": 11204,
      "start": 250.86000061035156,
      "temperature": 0.0,
      "text": " it can use to solve the problem of information discovery",
      "tokens": [
        50752,
        309,
        393,
        764,
        281,
        5039,
        264,
        1154,
        295,
        1589,
        12114,
        50922
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.2726145386695862,
      "compression_ratio": 1.5416666269302368,
      "end": 256.8199996948242,
      "no_speech_prob": 0.12937824428081512,
      "seek": 11204,
      "start": 254.25999450683594,
      "temperature": 0.0,
      "text": " to understand the structure of the database.",
      "tokens": [
        50922,
        281,
        1223,
        264,
        3877,
        295,
        264,
        8149,
        13,
        51050
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.2726145386695862,
      "compression_ratio": 1.5416666269302368,
      "end": 260.13999938964844,
      "no_speech_prob": 0.12937824428081512,
      "seek": 11204,
      "start": 256.8199996948242,
      "temperature": 0.0,
      "text": " And then it has full autonomy, right up to 10 compute loops",
      "tokens": [
        51050,
        400,
        550,
        309,
        575,
        1577,
        27278,
        11,
        558,
        493,
        281,
        1266,
        14722,
        16121,
        51216
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.2726145386695862,
      "compression_ratio": 1.5416666269302368,
      "end": 262.13999938964844,
      "no_speech_prob": 0.12937824428081512,
      "seek": 11204,
      "start": 260.13999938964844,
      "temperature": 0.0,
      "text": " to solve the problem and return.",
      "tokens": [
        51216,
        281,
        5039,
        264,
        1154,
        293,
        2736,
        13,
        51316
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 264.139995098114,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 262.1199951171875,
      "temperature": 0.0,
      "text": " the results to us.",
      "tokens": [
        50364,
        264,
        3542,
        281,
        505,
        13,
        50465
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 267.37999534606934,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 264.139995098114,
      "temperature": 0.0,
      "text": " We're using multiple libraries inside of a single file.",
      "tokens": [
        50465,
        492,
        434,
        1228,
        3866,
        15148,
        1854,
        295,
        257,
        2167,
        3991,
        13,
        50627
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 268.2999949455261,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 267.37999534606934,
      "temperature": 0.0,
      "text": " So how is this possible?",
      "tokens": [
        50627,
        407,
        577,
        307,
        341,
        1944,
        30,
        50673
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 271.69999504089355,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 268.2999949455261,
      "temperature": 0.0,
      "text": " We have to give credit to Astral's UV.",
      "tokens": [
        50673,
        492,
        362,
        281,
        976,
        5397,
        281,
        12884,
        2155,
        311,
        17887,
        13,
        50843
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 274.6599950790405,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 271.69999504089355,
      "temperature": 0.0,
      "text": " You can think of this as bun for Python.",
      "tokens": [
        50843,
        509,
        393,
        519,
        295,
        341,
        382,
        6702,
        337,
        15329,
        13,
        50991
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 277.87999534606934,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 274.6599950790405,
      "temperature": 0.0,
      "text": " It's the all-in-one Python ecosystem manager.",
      "tokens": [
        50991,
        467,
        311,
        264,
        439,
        12,
        259,
        12,
        546,
        15329,
        11311,
        6598,
        13,
        51152
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 281.0599956512451,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 277.87999534606934,
      "temperature": 0.0,
      "text": " It basically replaces every other Python tool.",
      "tokens": [
        51152,
        467,
        1936,
        46734,
        633,
        661,
        15329,
        2290,
        13,
        51311
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 282.899995803833,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 281.0599956512451,
      "temperature": 0.0,
      "text": " And most importantly for us,",
      "tokens": [
        51311,
        400,
        881,
        8906,
        337,
        505,
        11,
        51403
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 285.25999450683594,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 282.899995803833,
      "temperature": 0.0,
      "text": " for these powerful single file agents,",
      "tokens": [
        51403,
        337,
        613,
        4005,
        2167,
        3991,
        12554,
        11,
        51521
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 287.1399955749512,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 285.25999450683594,
      "temperature": 0.0,
      "text": " it gives us this ability,",
      "tokens": [
        51521,
        309,
        2709,
        505,
        341,
        3485,
        11,
        51615
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 292.1399955749512,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 287.1399955749512,
      "temperature": 0.0,
      "text": " run scripts with support for inline dependency metadata.",
      "tokens": [
        50364,
        1190,
        23294,
        365,
        1406,
        337,
        294,
        1889,
        33621,
        26603,
        13,
        50614
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 294.3999938964844,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 292.47999572753906,
      "temperature": 0.0,
      "text": " Let's dive into this feature right now",
      "tokens": [
        50631,
        961,
        311,
        9192,
        666,
        341,
        4111,
        558,
        586,
        50727
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 296.1999969482422,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 294.3999938964844,
      "temperature": 0.0,
      "text": " so we can see how we're building out",
      "tokens": [
        50727,
        370,
        321,
        393,
        536,
        577,
        321,
        434,
        2390,
        484,
        50817
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 297.99999618530273,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 296.1999969482422,
      "temperature": 0.0,
      "text": " these powerful single file agents.",
      "tokens": [
        50817,
        613,
        4005,
        2167,
        3991,
        12554,
        13,
        50907
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 306.4599952697754,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 302.57999420166016,
      "temperature": 0.0,
      "text": " So if we open up our DuckDB OpenAI agent here,",
      "tokens": [
        51136,
        407,
        498,
        321,
        1269,
        493,
        527,
        29266,
        27735,
        7238,
        48698,
        9461,
        510,
        11,
        51330
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 308.7199935913086,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 306.4599952697754,
      "temperature": 0.0,
      "text": " you can see right at the top of this file,",
      "tokens": [
        51330,
        291,
        393,
        536,
        558,
        412,
        264,
        1192,
        295,
        341,
        3991,
        11,
        51443
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 310.5599937438965,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 308.7199935913086,
      "temperature": 0.0,
      "text": " something fascinating, right?",
      "tokens": [
        51443,
        746,
        10343,
        11,
        558,
        30,
        51535
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 312.47999572753906,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 310.5599937438965,
      "temperature": 0.0,
      "text": " We have dependencies.",
      "tokens": [
        51535,
        492,
        362,
        36606,
        13,
        51631
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 315.5999946594238,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 312.47999572753906,
      "temperature": 0.0,
      "text": " You know, you saw with this single command here, right?",
      "tokens": [
        51631,
        509,
        458,
        11,
        291,
        1866,
        365,
        341,
        2167,
        5622,
        510,
        11,
        558,
        30,
        51787
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 317.23999404907227,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 315.5999946594238,
      "temperature": 0.0,
      "text": " We had UV run.",
      "tokens": [
        50364,
        492,
        632,
        17887,
        1190,
        13,
        50446
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 320.1799964904785,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 317.23999404907227,
      "temperature": 0.0,
      "text": " This creates a sandbox environment.",
      "tokens": [
        50446,
        639,
        7829,
        257,
        42115,
        2823,
        13,
        50593
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 323.5199966430664,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 320.1799964904785,
      "temperature": 0.0,
      "text": " This allows us to run the script as a standalone file",
      "tokens": [
        50593,
        639,
        4045,
        505,
        281,
        1190,
        264,
        5755,
        382,
        257,
        37454,
        3991,
        50760
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 325.65999603271484,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 323.5199966430664,
      "temperature": 0.0,
      "text": " with these dependencies included.",
      "tokens": [
        50760,
        365,
        613,
        36606,
        5556,
        13,
        50867
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 328.0199966430664,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 325.65999603271484,
      "temperature": 0.0,
      "text": " So we have OpenAI, Rich, and Pydantic.",
      "tokens": [
        50867,
        407,
        321,
        362,
        7238,
        48698,
        11,
        6781,
        11,
        293,
        430,
        6655,
        7128,
        13,
        50985
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 330.1999969482422,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 328.0199966430664,
      "temperature": 0.0,
      "text": " So this is the first key aspect",
      "tokens": [
        50985,
        407,
        341,
        307,
        264,
        700,
        2141,
        4171,
        51094
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 332.2199935913086,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 330.1999969482422,
      "temperature": 0.0,
      "text": " of the single file agent structure.",
      "tokens": [
        51094,
        295,
        264,
        2167,
        3991,
        9461,
        3877,
        13,
        51195
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 334.4399948120117,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 332.2199935913086,
      "temperature": 0.0,
      "text": " We need to be able to load and use dependencies",
      "tokens": [
        51195,
        492,
        643,
        281,
        312,
        1075,
        281,
        3677,
        293,
        764,
        36606,
        51306
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 336.9599914550781,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 334.4399948120117,
      "temperature": 0.0,
      "text": " from any Python library.",
      "tokens": [
        51306,
        490,
        604,
        15329,
        6405,
        13,
        51432
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 339.67999267578125,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 336.9599914550781,
      "temperature": 0.0,
      "text": " Most importantly, we need a model provider, right?",
      "tokens": [
        51432,
        4534,
        8906,
        11,
        321,
        643,
        257,
        2316,
        12398,
        11,
        558,
        30,
        51568
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 340.55999755859375,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 339.67999267578125,
      "temperature": 0.0,
      "text": " So now we have this,",
      "tokens": [
        51568,
        407,
        586,
        321,
        362,
        341,
        11,
        51612
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 342.7199935913086,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 340.55999755859375,
      "temperature": 0.0,
      "text": " we have access to this and our single file agent.",
      "tokens": [
        51612,
        321,
        362,
        2105,
        281,
        341,
        293,
        527,
        2167,
        3991,
        9461,
        13,
        51720
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 345.3199920654297,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 342.7199935913086,
      "temperature": 0.0,
      "text": " Now, what does the agentic structure look like",
      "tokens": [
        51720,
        823,
        11,
        437,
        775,
        264,
        9461,
        299,
        3877,
        574,
        411,
        51850
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 346.87999725341797,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 346.0399932861328,
      "temperature": 0.0,
      "text": " for this agent?",
      "tokens": [
        50400,
        337,
        341,
        9461,
        30,
        50442
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 347.6999969482422,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 346.87999725341797,
      "temperature": 0.0,
      "text": " You can see we're using Pydantic",
      "tokens": [
        50442,
        509,
        393,
        536,
        321,
        434,
        1228,
        430,
        6655,
        7128,
        50483
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 349.9599914550781,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 347.6999969482422,
      "temperature": 0.0,
      "text": " to create our argument structure.",
      "tokens": [
        50483,
        281,
        1884,
        527,
        6770,
        3877,
        13,
        50596
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 353.05999755859375,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 349.9599914550781,
      "temperature": 0.0,
      "text": " So for instance, for our list table args,",
      "tokens": [
        50596,
        407,
        337,
        5197,
        11,
        337,
        527,
        1329,
        3199,
        3882,
        82,
        11,
        50751
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 355.3999938964844,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 353.05999755859375,
      "temperature": 0.0,
      "text": " we have the model pass and reasoning.",
      "tokens": [
        50751,
        321,
        362,
        264,
        2316,
        1320,
        293,
        21577,
        13,
        50868
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 357.99999237060547,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 355.3999938964844,
      "temperature": 0.0,
      "text": " This is a powerful pattern to help you understand",
      "tokens": [
        50868,
        639,
        307,
        257,
        4005,
        5102,
        281,
        854,
        291,
        1223,
        50998
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 360.99999237060547,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 357.99999237060547,
      "temperature": 0.0,
      "text": " what your language model was thinking at every single step.",
      "tokens": [
        50998,
        437,
        428,
        2856,
        2316,
        390,
        1953,
        412,
        633,
        2167,
        1823,
        13,
        51148
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 364.2199935913086,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 360.99999237060547,
      "temperature": 0.0,
      "text": " If we open up every one of these tool argument structures,",
      "tokens": [
        51148,
        759,
        321,
        1269,
        493,
        633,
        472,
        295,
        613,
        2290,
        6770,
        9227,
        11,
        51309
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 366.6399917602539,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 364.2199935913086,
      "temperature": 0.0,
      "text": " I'm always requesting reasoning.",
      "tokens": [
        51309,
        286,
        478,
        1009,
        31937,
        21577,
        13,
        51430
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 368.75999450683594,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 366.6399917602539,
      "temperature": 0.0,
      "text": " You can see it there, you can see it there,",
      "tokens": [
        51430,
        509,
        393,
        536,
        309,
        456,
        11,
        291,
        393,
        536,
        309,
        456,
        11,
        51536
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 369.6999969482422,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 368.75999450683594,
      "temperature": 0.0,
      "text": " so on and so forth, right?",
      "tokens": [
        51536,
        370,
        322,
        293,
        370,
        5220,
        11,
        558,
        30,
        51583
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 371.5199966430664,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 369.6999969482422,
      "temperature": 0.0,
      "text": " So that's a super important pattern",
      "tokens": [
        51583,
        407,
        300,
        311,
        257,
        1687,
        1021,
        5102,
        51674
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 373.67999267578125,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 371.5199966430664,
      "temperature": 0.0,
      "text": " you can use when building your agents,",
      "tokens": [
        51674,
        291,
        393,
        764,
        562,
        2390,
        428,
        12554,
        11,
        51782
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 375.07999420166016,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 373.67999267578125,
      "temperature": 0.0,
      "text": " always passing reasoning,",
      "tokens": [
        51782,
        1009,
        8437,
        21577,
        11,
        51852
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 377.2199935913086,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 375.8399963378906,
      "temperature": 0.0,
      "text": " and then always log the reasoning.",
      "tokens": [
        50402,
        293,
        550,
        1009,
        3565,
        264,
        21577,
        13,
        50471
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 378.35999298095703,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 377.2199935913086,
      "temperature": 0.0,
      "text": " So you can see we have tools,",
      "tokens": [
        50471,
        407,
        291,
        393,
        536,
        321,
        362,
        3873,
        11,
        50528
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 379.35999298095703,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 378.35999298095703,
      "temperature": 0.0,
      "text": " we have the agent prompt,",
      "tokens": [
        50528,
        321,
        362,
        264,
        9461,
        12391,
        11,
        50578
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 382.2799987792969,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 379.35999298095703,
      "temperature": 0.0,
      "text": " but the most important thing is the agentic loop down here.",
      "tokens": [
        50578,
        457,
        264,
        881,
        1021,
        551,
        307,
        264,
        9461,
        299,
        6367,
        760,
        510,
        13,
        50724
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 383.7199935913086,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 382.2799987792969,
      "temperature": 0.0,
      "text": " So let's go ahead and break this down.",
      "tokens": [
        50724,
        407,
        718,
        311,
        352,
        2286,
        293,
        1821,
        341,
        760,
        13,
        50796
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 384.55999755859375,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 383.7199935913086,
      "temperature": 0.0,
      "text": " And then let's go ahead",
      "tokens": [
        50796,
        400,
        550,
        718,
        311,
        352,
        2286,
        50838
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 387.3199920654297,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 384.55999755859375,
      "temperature": 0.0,
      "text": " and look at how we can distribute this pattern",
      "tokens": [
        50838,
        293,
        574,
        412,
        577,
        321,
        393,
        20594,
        341,
        5102,
        50976
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 392.0399932861328,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 387.3199920654297,
      "temperature": 0.0,
      "text": " with AI coding to scale it up to an entirely new AI agent.",
      "tokens": [
        50976,
        365,
        7318,
        17720,
        281,
        4373,
        309,
        493,
        281,
        364,
        7696,
        777,
        7318,
        9461,
        13,
        51212
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 393.0,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 392.0399932861328,
      "temperature": 0.0,
      "text": " So at the start here,",
      "tokens": [
        51212,
        407,
        412,
        264,
        722,
        510,
        11,
        51260
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 394.8399963378906,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 393.0,
      "temperature": 0.0,
      "text": " we're pulling up the agentic loop.",
      "tokens": [
        51260,
        321,
        434,
        8407,
        493,
        264,
        9461,
        299,
        6367,
        13,
        51352
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 396.63999938964844,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 394.8399963378906,
      "temperature": 0.0,
      "text": " So we're pulling up the agentic loop,",
      "tokens": [
        51352,
        407,
        321,
        434,
        8407,
        493,
        264,
        9461,
        299,
        6367,
        11,
        51442
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 398.8399963378906,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 396.63999938964844,
      "temperature": 0.0,
      "text": " and then we're pulling up the reasoning loop.",
      "tokens": [
        51442,
        293,
        550,
        321,
        434,
        8407,
        493,
        264,
        21577,
        6367,
        13,
        51552
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 58,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 400.63999938964844,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 398.8399963378906,
      "temperature": 0.0,
      "text": " So we're pulling up the reasoning loop,",
      "tokens": [
        51552,
        407,
        321,
        434,
        8407,
        493,
        264,
        21577,
        6367,
        11,
        51642
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 59,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 402.8399963378906,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 400.63999938964844,
      "temperature": 0.0,
      "text": " and then we're pulling up the agentic loop.",
      "tokens": [
        51642,
        293,
        550,
        321,
        434,
        8407,
        493,
        264,
        9461,
        299,
        6367,
        13,
        51752
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.20756246149539948,
      "compression_ratio": 1.790697693824768,
      "end": 398.69999265670776,
      "no_speech_prob": 0.04336019232869148,
      "seek": 0,
      "start": 393.17999267578125,
      "temperature": 0.0,
      "text": " in all of our arguments. We have our dash d for database, dash p for prompt, dash c for compute.",
      "tokens": [
        50364,
        294,
        439,
        295,
        527,
        12869,
        13,
        492,
        362,
        527,
        8240,
        274,
        337,
        8149,
        11,
        8240,
        280,
        337,
        12391,
        11,
        8240,
        269,
        337,
        14722,
        13,
        50640
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.20756246149539948,
      "compression_ratio": 1.790697693824768,
      "end": 404.2199926376343,
      "no_speech_prob": 0.04336019232869148,
      "seek": 0,
      "start": 398.69999265670776,
      "temperature": 0.0,
      "text": " We have our open AI key check here. We're then making our database path global so that every",
      "tokens": [
        50640,
        492,
        362,
        527,
        1269,
        7318,
        2141,
        1520,
        510,
        13,
        492,
        434,
        550,
        1455,
        527,
        8149,
        3100,
        4338,
        370,
        300,
        633,
        50916
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.20756246149539948,
      "compression_ratio": 1.790697693824768,
      "end": 408.85999298095703,
      "no_speech_prob": 0.04336019232869148,
      "seek": 0,
      "start": 404.2199926376343,
      "temperature": 0.0,
      "text": " single function can access it. We're building our prompt and then we're running the main",
      "tokens": [
        50916,
        2167,
        2445,
        393,
        2105,
        309,
        13,
        492,
        434,
        2390,
        527,
        12391,
        293,
        550,
        321,
        434,
        2614,
        264,
        2135,
        51148
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.20756246149539948,
      "compression_ratio": 1.790697693824768,
      "end": 412.5399932861328,
      "no_speech_prob": 0.04336019232869148,
      "seek": 0,
      "start": 408.85999298095703,
      "temperature": 0.0,
      "text": " agentic loop. So this is where all the magic happens. This is where we give our AI agent",
      "tokens": [
        51148,
        9461,
        299,
        6367,
        13,
        407,
        341,
        307,
        689,
        439,
        264,
        5585,
        2314,
        13,
        639,
        307,
        689,
        321,
        976,
        527,
        7318,
        9461,
        51332
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.20756246149539948,
      "compression_ratio": 1.790697693824768,
      "end": 419.2599925994873,
      "no_speech_prob": 0.04336019232869148,
      "seek": 0,
      "start": 412.5399932861328,
      "temperature": 0.0,
      "text": " full control to run tools, run functions, gather feedback, build up its context, and solve the",
      "tokens": [
        51332,
        1577,
        1969,
        281,
        1190,
        3873,
        11,
        1190,
        6828,
        11,
        5448,
        5824,
        11,
        1322,
        493,
        1080,
        4319,
        11,
        293,
        5039,
        264,
        51668
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.1890609711408615,
      "compression_ratio": 1.7413127422332764,
      "end": 423.2599925994873,
      "no_speech_prob": 0.2658589780330658,
      "seek": 2608,
      "start": 419.33999252319336,
      "temperature": 0.0,
      "text": " problem we want solved. Let's open this up. So we're doing our compute loop check here",
      "tokens": [
        50368,
        1154,
        321,
        528,
        13041,
        13,
        961,
        311,
        1269,
        341,
        493,
        13,
        407,
        321,
        434,
        884,
        527,
        14722,
        6367,
        1520,
        510,
        50564
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.1890609711408615,
      "compression_ratio": 1.7413127422332764,
      "end": 427.6599922180176,
      "no_speech_prob": 0.2658589780330658,
      "seek": 2608,
      "start": 423.8199920654297,
      "temperature": 0.0,
      "text": " and then as you can imagine we're running our intelligence. So we're using",
      "tokens": [
        50592,
        293,
        550,
        382,
        291,
        393,
        3811,
        321,
        434,
        2614,
        527,
        7599,
        13,
        407,
        321,
        434,
        1228,
        50784
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.1890609711408615,
      "compression_ratio": 1.7413127422332764,
      "end": 434.299991607666,
      "no_speech_prob": 0.2658589780330658,
      "seek": 2608,
      "start": 427.6599922180176,
      "temperature": 0.0,
      "text": " o3mini. You can see here we're requiring a tool call. With every loop we want our LLM to execute",
      "tokens": [
        50784,
        277,
        18,
        2367,
        72,
        13,
        509,
        393,
        536,
        510,
        321,
        434,
        24165,
        257,
        2290,
        818,
        13,
        2022,
        633,
        6367,
        321,
        528,
        527,
        441,
        43,
        44,
        281,
        14483,
        51116
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.1890609711408615,
      "compression_ratio": 1.7413127422332764,
      "end": 440.0599937438965,
      "no_speech_prob": 0.2658589780330658,
      "seek": 2608,
      "start": 434.299991607666,
      "temperature": 0.0,
      "text": " a tool. We're then looking for tool calls. Once we find a tool which we should always have,",
      "tokens": [
        51116,
        257,
        2290,
        13,
        492,
        434,
        550,
        1237,
        337,
        2290,
        5498,
        13,
        3443,
        321,
        915,
        257,
        2290,
        597,
        321,
        820,
        1009,
        362,
        11,
        51404
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.1890609711408615,
      "compression_ratio": 1.7413127422332764,
      "end": 445.8999938964844,
      "no_speech_prob": 0.2658589780330658,
      "seek": 2608,
      "start": 440.0599937438965,
      "temperature": 0.0,
      "text": " we are running our process of determining which tool to select. You can build any type of structure,",
      "tokens": [
        51404,
        321,
        366,
        2614,
        527,
        1399,
        295,
        23751,
        597,
        2290,
        281,
        3048,
        13,
        509,
        393,
        1322,
        604,
        2010,
        295,
        3877,
        11,
        51696
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.19474637508392334,
      "compression_ratio": 1.8827362060546875,
      "end": 449.49999237060547,
      "no_speech_prob": 0.024052763357758522,
      "seek": 5272,
      "start": 445.8999938964844,
      "temperature": 0.0,
      "text": " any type of map you want to handle this. I'm just doing this with the simplest pattern possible",
      "tokens": [
        50364,
        604,
        2010,
        295,
        4471,
        291,
        528,
        281,
        4813,
        341,
        13,
        286,
        478,
        445,
        884,
        341,
        365,
        264,
        22811,
        5102,
        1944,
        50544
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.19474637508392334,
      "compression_ratio": 1.8827362060546875,
      "end": 454.5399932861328,
      "no_speech_prob": 0.024052763357758522,
      "seek": 5272,
      "start": 449.49999237060547,
      "temperature": 0.0,
      "text": " here. We just have a bunch of if statements that parse the arguments and then call the function.",
      "tokens": [
        50544,
        510,
        13,
        492,
        445,
        362,
        257,
        3840,
        295,
        498,
        12363,
        300,
        48377,
        264,
        12869,
        293,
        550,
        818,
        264,
        2445,
        13,
        50796
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.19474637508392334,
      "compression_ratio": 1.8827362060546875,
      "end": 459.739990234375,
      "no_speech_prob": 0.024052763357758522,
      "seek": 5272,
      "start": 454.5399932861328,
      "temperature": 0.0,
      "text": " We then take the result and we pass it back in to the language model. We pass it back into our",
      "tokens": [
        50796,
        492,
        550,
        747,
        264,
        1874,
        293,
        321,
        1320,
        309,
        646,
        294,
        281,
        264,
        2856,
        2316,
        13,
        492,
        1320,
        309,
        646,
        666,
        527,
        51056
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.19474637508392334,
      "compression_ratio": 1.8827362060546875,
      "end": 465.739990234375,
      "no_speech_prob": 0.024052763357758522,
      "seek": 5272,
      "start": 459.739990234375,
      "temperature": 0.0,
      "text": " context window. Very importantly here we also have an exception. So if something goes wrong inside of",
      "tokens": [
        51056,
        4319,
        4910,
        13,
        4372,
        8906,
        510,
        321,
        611,
        362,
        364,
        11183,
        13,
        407,
        498,
        746,
        1709,
        2085,
        1854,
        295,
        51356
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.19474637508392334,
      "compression_ratio": 1.8827362060546875,
      "end": 471.4199905395508,
      "no_speech_prob": 0.024052763357758522,
      "seek": 5272,
      "start": 465.739990234375,
      "temperature": 0.0,
      "text": " the tool, we're also passing this back to the model. We want our agent to just solve the problem.",
      "tokens": [
        51356,
        264,
        2290,
        11,
        321,
        434,
        611,
        8437,
        341,
        646,
        281,
        264,
        2316,
        13,
        492,
        528,
        527,
        9461,
        281,
        445,
        5039,
        264,
        1154,
        13,
        51640
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.19474637508392334,
      "compression_ratio": 1.8827362060546875,
      "end": 475.09999084472656,
      "no_speech_prob": 0.024052763357758522,
      "seek": 5272,
      "start": 471.4199905395508,
      "temperature": 0.0,
      "text": " We want to design a great prompt. We want to design great tools and then just hand off the",
      "tokens": [
        51640,
        492,
        528,
        281,
        1715,
        257,
        869,
        12391,
        13,
        492,
        528,
        281,
        1715,
        869,
        3873,
        293,
        550,
        445,
        1011,
        766,
        264,
        51824
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.22590042650699615,
      "compression_ratio": 1.6514084339141846,
      "end": 479.8199920654297,
      "no_speech_prob": 0.00108170579187572,
      "seek": 8192,
      "start": 475.09999084472656,
      "temperature": 0.0,
      "text": " problem to our agent. We go off. We go on about our day. We go, you know, solve other specific",
      "tokens": [
        50364,
        1154,
        281,
        527,
        9461,
        13,
        492,
        352,
        766,
        13,
        492,
        352,
        322,
        466,
        527,
        786,
        13,
        492,
        352,
        11,
        291,
        458,
        11,
        5039,
        661,
        2685,
        50600
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.22590042650699615,
      "compression_ratio": 1.6514084339141846,
      "end": 484.4599914550781,
      "no_speech_prob": 0.00108170579187572,
      "seek": 8192,
      "start": 479.8199920654297,
      "temperature": 0.0,
      "text": " problems. And then in parallel it's solving this problem that we gave it really well",
      "tokens": [
        50600,
        2740,
        13,
        400,
        550,
        294,
        8952,
        309,
        311,
        12606,
        341,
        1154,
        300,
        321,
        2729,
        309,
        534,
        731,
        50832
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.22590042650699615,
      "compression_ratio": 1.6514084339141846,
      "end": 490.5399932861328,
      "no_speech_prob": 0.00108170579187572,
      "seek": 8192,
      "start": 484.4599914550781,
      "temperature": 0.0,
      "text": " thanks to our clean agent design. So this is one agent pattern that I'm working with. But I want",
      "tokens": [
        50832,
        3231,
        281,
        527,
        2541,
        9461,
        1715,
        13,
        407,
        341,
        307,
        472,
        9461,
        5102,
        300,
        286,
        478,
        1364,
        365,
        13,
        583,
        286,
        528,
        51136
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.22590042650699615,
      "compression_ratio": 1.6514084339141846,
      "end": 495.3399963378906,
      "no_speech_prob": 0.00108170579187572,
      "seek": 8192,
      "start": 490.5399932861328,
      "temperature": 0.0,
      "text": " to point out something that's really powerful here. You saw the list tables, describe, sample.",
      "tokens": [
        51136,
        281,
        935,
        484,
        746,
        300,
        311,
        534,
        4005,
        510,
        13,
        509,
        1866,
        264,
        1329,
        8020,
        11,
        6786,
        11,
        6889,
        13,
        51376
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.22590042650699615,
      "compression_ratio": 1.6514084339141846,
      "end": 502.1399917602539,
      "no_speech_prob": 0.00108170579187572,
      "seek": 8192,
      "start": 495.3399963378906,
      "temperature": 0.0,
      "text": " But we also have this run test SQL query and run final SQL query. From the tech ecosphere you may",
      "tokens": [
        51376,
        583,
        321,
        611,
        362,
        341,
        1190,
        1500,
        19200,
        14581,
        293,
        1190,
        2572,
        19200,
        14581,
        13,
        3358,
        264,
        7553,
        11007,
        6605,
        291,
        815,
        51716
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.19306829571723938,
      "compression_ratio": 1.5708154439926147,
      "end": 508.9399948120117,
      "no_speech_prob": 0.0008830161532387137,
      "seek": 10896,
      "start": 502.1399917602539,
      "temperature": 0.0,
      "text": " have picked up on this idea of verifiable domains and closed loop systems. This is something that",
      "tokens": [
        50364,
        362,
        6183,
        493,
        322,
        341,
        1558,
        295,
        1306,
        30876,
        25514,
        293,
        5395,
        6367,
        3652,
        13,
        639,
        307,
        746,
        300,
        50704
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.19306829571723938,
      "compression_ratio": 1.5708154439926147,
      "end": 514.4599914550781,
      "no_speech_prob": 0.0008830161532387137,
      "seek": 10896,
      "start": 508.9399948120117,
      "temperature": 0.0,
      "text": " we talk about in principled AI coding specifically for the AI coding domain. But it really applies",
      "tokens": [
        50704,
        321,
        751,
        466,
        294,
        3681,
        15551,
        7318,
        17720,
        4682,
        337,
        264,
        7318,
        17720,
        9274,
        13,
        583,
        309,
        534,
        13165,
        50980
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.19306829571723938,
      "compression_ratio": 1.5708154439926147,
      "end": 519.6599960327148,
      "no_speech_prob": 0.0008830161532387137,
      "seek": 10896,
      "start": 514.4599914550781,
      "temperature": 0.0,
      "text": " to all agentic technology. We can do something interesting here with this run test SQL query.",
      "tokens": [
        50980,
        281,
        439,
        9461,
        299,
        2899,
        13,
        492,
        393,
        360,
        746,
        1880,
        510,
        365,
        341,
        1190,
        1500,
        19200,
        14581,
        13,
        51240
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.19306829571723938,
      "compression_ratio": 1.5708154439926147,
      "end": 523.9799957275391,
      "no_speech_prob": 0.0008830161532387137,
      "seek": 10896,
      "start": 519.6599960327148,
      "temperature": 0.0,
      "text": " Let's go ahead and open up the arguments. And you can see here it looks the",
      "tokens": [
        51240,
        961,
        311,
        352,
        2286,
        293,
        1269,
        493,
        264,
        12869,
        13,
        400,
        291,
        393,
        536,
        510,
        309,
        1542,
        264,
        51456
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 529.199990272522,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 524.239990234375,
      "temperature": 0.0,
      "text": " same as our run final SQL query and we can go ahead and fire off our agent",
      "tokens": [
        50364,
        912,
        382,
        527,
        1190,
        2572,
        19200,
        14581,
        293,
        321,
        393,
        352,
        2286,
        293,
        2610,
        766,
        527,
        9461,
        50612
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 532.7999906539917,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 529.199990272522,
      "temperature": 0.0,
      "text": " again and just take a look to see if it's actually going to kick off this",
      "tokens": [
        50612,
        797,
        293,
        445,
        747,
        257,
        574,
        281,
        536,
        498,
        309,
        311,
        767,
        516,
        281,
        4437,
        766,
        341,
        50792
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 537.159990310669,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 532.7999906539917,
      "temperature": 0.0,
      "text": " call. Sometimes it completely skips the run test SQL query because it just",
      "tokens": [
        50792,
        818,
        13,
        4803,
        309,
        2584,
        1110,
        2600,
        264,
        1190,
        1500,
        19200,
        14581,
        570,
        309,
        445,
        51010
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 540.8399906158447,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 537.159990310669,
      "temperature": 0.0,
      "text": " doesn't need it, it doesn't need the test. But we can do something like this, create",
      "tokens": [
        51010,
        1177,
        380,
        643,
        309,
        11,
        309,
        1177,
        380,
        643,
        264,
        1500,
        13,
        583,
        321,
        393,
        360,
        746,
        411,
        341,
        11,
        1884,
        51194
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 548.319990158081,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 540.8399906158447,
      "temperature": 0.0,
      "text": " a new table, high score users from the user table and select all users with",
      "tokens": [
        51194,
        257,
        777,
        3199,
        11,
        1090,
        6175,
        5022,
        490,
        264,
        4195,
        3199,
        293,
        3048,
        439,
        5022,
        365,
        51568
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 554.5599899291992,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 548.319990158081,
      "temperature": 0.0,
      "text": " score greater than 80 that are active and 2025. Let's pass it off to our DuckDB",
      "tokens": [
        50364,
        6175,
        5044,
        813,
        4688,
        300,
        366,
        4967,
        293,
        945,
        17,
        20,
        13,
        961,
        311,
        1320,
        309,
        766,
        281,
        527,
        29266,
        27735,
        50676
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 558.3599891662598,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 554.5599899291992,
      "temperature": 0.0,
      "text": " AI agent and just see how it does with this. I'm also going to kick up the",
      "tokens": [
        50676,
        7318,
        9461,
        293,
        445,
        536,
        577,
        309,
        775,
        365,
        341,
        13,
        286,
        478,
        611,
        516,
        281,
        4437,
        493,
        264,
        50866
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 561.6399917602539,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 558.3599891662598,
      "temperature": 0.0,
      "text": " compute loop just in case it needs a little bit more energy. Let's kick that",
      "tokens": [
        50866,
        14722,
        6367,
        445,
        294,
        1389,
        309,
        2203,
        257,
        707,
        857,
        544,
        2281,
        13,
        961,
        311,
        4437,
        300,
        51030
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 566.0399894714355,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 561.6399917602539,
      "temperature": 0.0,
      "text": " off and let's see how it does here. So you can see it's first validating the",
      "tokens": [
        51030,
        766,
        293,
        718,
        311,
        536,
        577,
        309,
        775,
        510,
        13,
        407,
        291,
        393,
        536,
        309,
        311,
        700,
        7363,
        990,
        264,
        51250
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 569.239990234375,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 566.0399894714355,
      "temperature": 0.0,
      "text": " structure right and needs to find the table so it's running list tables. It's",
      "tokens": [
        51250,
        3877,
        558,
        293,
        2203,
        281,
        915,
        264,
        3199,
        370,
        309,
        311,
        2614,
        1329,
        8020,
        13,
        467,
        311,
        51410
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 574.6399917602539,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 569.239990234375,
      "temperature": 0.0,
      "text": " seeing the schema structure of that table. It's now running this test SQL",
      "tokens": [
        51410,
        2577,
        264,
        34078,
        3877,
        295,
        300,
        3199,
        13,
        467,
        311,
        586,
        2614,
        341,
        1500,
        19200,
        51680
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 579.1999893188477,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 574.6399917602539,
      "temperature": 0.0,
      "text": " command so it's verifying that what we're going to ask for will work. Instead",
      "tokens": [
        50364,
        5622,
        370,
        309,
        311,
        1306,
        5489,
        300,
        437,
        321,
        434,
        516,
        281,
        1029,
        337,
        486,
        589,
        13,
        7156,
        50592
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 583.3199920654297,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 579.1999893188477,
      "temperature": 0.0,
      "text": " of looking for human in the loop feedback or instead of running the",
      "tokens": [
        50592,
        295,
        1237,
        337,
        1952,
        294,
        264,
        6367,
        5824,
        420,
        2602,
        295,
        2614,
        264,
        50798
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 587.1199913024902,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 583.3199920654297,
      "temperature": 0.0,
      "text": " final query, what it's doing here is running this test SQL query. This is a",
      "tokens": [
        50798,
        2572,
        14581,
        11,
        437,
        309,
        311,
        884,
        510,
        307,
        2614,
        341,
        1500,
        19200,
        14581,
        13,
        639,
        307,
        257,
        50988
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 591.3999938964844,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 587.1199913024902,
      "temperature": 0.0,
      "text": " really important pattern for building out great agents. You don't have to wait",
      "tokens": [
        50988,
        534,
        1021,
        5102,
        337,
        2390,
        484,
        869,
        12554,
        13,
        509,
        500,
        380,
        362,
        281,
        1699,
        51202
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 596.1999893188477,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 591.3999938964844,
      "temperature": 0.0,
      "text": " to close the loop to let your agent fully validate the process. So I",
      "tokens": [
        51202,
        281,
        1998,
        264,
        6367,
        281,
        718,
        428,
        9461,
        4498,
        29562,
        264,
        1399,
        13,
        407,
        286,
        51442
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 600.9599914550781,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 596.1999893188477,
      "temperature": 0.0,
      "text": " have this run test SQL, it's running this internally, adding more information to",
      "tokens": [
        51442,
        362,
        341,
        1190,
        1500,
        19200,
        11,
        309,
        311,
        2614,
        341,
        19501,
        11,
        5127,
        544,
        1589,
        281,
        51680
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 604.4399871826172,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 600.9599914550781,
      "temperature": 0.0,
      "text": " its context window, gathering information about how to solve the",
      "tokens": [
        51680,
        1080,
        4319,
        4910,
        11,
        13519,
        1589,
        466,
        577,
        281,
        5039,
        264,
        51854
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 609.4399871826172,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 604.4799880981445,
      "temperature": 0.0,
      "text": " problem of creating this query, creating this new table, and then finally",
      "tokens": [
        50366,
        1154,
        295,
        4084,
        341,
        14581,
        11,
        4084,
        341,
        777,
        3199,
        11,
        293,
        550,
        2721,
        50614
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 613.5199890136719,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 609.4399871826172,
      "temperature": 0.0,
      "text": " after it's validated it, it's then running this final query here. So",
      "tokens": [
        50614,
        934,
        309,
        311,
        40693,
        309,
        11,
        309,
        311,
        550,
        2614,
        341,
        2572,
        14581,
        510,
        13,
        407,
        50818
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 617.4399871826172,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 613.5199890136719,
      "temperature": 0.0,
      "text": " after validation it's now saying we can take this query, it's safe, it",
      "tokens": [
        50818,
        934,
        24071,
        309,
        311,
        586,
        1566,
        321,
        393,
        747,
        341,
        14581,
        11,
        309,
        311,
        3273,
        11,
        309,
        51014
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 622.1599884033203,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 617.4399871826172,
      "temperature": 0.0,
      "text": " works, it looks good. Let's go ahead and run this final query and create this new",
      "tokens": [
        51014,
        1985,
        11,
        309,
        1542,
        665,
        13,
        961,
        311,
        352,
        2286,
        293,
        1190,
        341,
        2572,
        14581,
        293,
        1884,
        341,
        777,
        51250
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 626.1999893188477,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 622.1599884033203,
      "temperature": 0.0,
      "text": " table. So now of course if we hit up and we hit up again let's get a smaller",
      "tokens": [
        51250,
        3199,
        13,
        407,
        586,
        295,
        1164,
        498,
        321,
        2045,
        493,
        293,
        321,
        2045,
        493,
        797,
        718,
        311,
        483,
        257,
        4356,
        51452
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 631.8399887084961,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 626.1999893188477,
      "temperature": 0.0,
      "text": " command to work with and we just say list all tables and one sample",
      "tokens": [
        51452,
        5622,
        281,
        589,
        365,
        293,
        321,
        445,
        584,
        1329,
        439,
        8020,
        293,
        472,
        6889,
        51734
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 636.9199905395508,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 631.8399887084961,
      "temperature": 0.0,
      "text": " row for each table and we fire that off. We should now get this brand new high",
      "tokens": [
        50364,
        5386,
        337,
        1184,
        3199,
        293,
        321,
        2610,
        300,
        766,
        13,
        492,
        820,
        586,
        483,
        341,
        3360,
        777,
        1090,
        50618
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 640.359992980957,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 636.9199905395508,
      "temperature": 0.0,
      "text": " score. So there's the high score users and the users table. So this is",
      "tokens": [
        50618,
        6175,
        13,
        407,
        456,
        311,
        264,
        1090,
        6175,
        5022,
        293,
        264,
        5022,
        3199,
        13,
        407,
        341,
        307,
        50790
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 645.119987487793,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 640.359992980957,
      "temperature": 0.0,
      "text": " fantastic. There's the sample. Our AI agent is understanding these table",
      "tokens": [
        50790,
        5456,
        13,
        821,
        311,
        264,
        6889,
        13,
        2621,
        7318,
        9461,
        307,
        3701,
        613,
        3199,
        51028
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 648.5599899291992,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 645.119987487793,
      "temperature": 0.0,
      "text": " structures. It's understanding what we want and what we want to do and then",
      "tokens": [
        51028,
        9227,
        13,
        467,
        311,
        3701,
        437,
        321,
        528,
        293,
        437,
        321,
        528,
        281,
        360,
        293,
        550,
        51200
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 652.4799957275391,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 648.5599899291992,
      "temperature": 0.0,
      "text": " it's giving us these concrete outputs. You can see here how",
      "tokens": [
        51200,
        309,
        311,
        2902,
        505,
        613,
        9859,
        23930,
        13,
        509,
        393,
        536,
        510,
        577,
        51396
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 657.2799835205078,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 652.4799957275391,
      "temperature": 0.0,
      "text": " important it is to have the reasoning inside your agents.",
      "tokens": [
        51396,
        1021,
        309,
        307,
        281,
        362,
        264,
        21577,
        1854,
        428,
        12554,
        13,
        51636
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 656.1399877667427,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 655.2999877929688,
      "temperature": 0.0,
      "text": " Right?",
      "tokens": [
        50364,
        1779,
        30,
        50406
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 659.4599876403809,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 656.1399877667427,
      "temperature": 0.0,
      "text": " It is explaining the results we're getting back here",
      "tokens": [
        50406,
        467,
        307,
        13468,
        264,
        3542,
        321,
        434,
        1242,
        646,
        510,
        50572
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 661.0199875831604,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 659.4599876403809,
      "temperature": 0.0,
      "text": " in a really concise way.",
      "tokens": [
        50572,
        294,
        257,
        534,
        44882,
        636,
        13,
        50650
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 662.1599879264832,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 661.0199875831604,
      "temperature": 0.0,
      "text": " And this is really cool.",
      "tokens": [
        50650,
        400,
        341,
        307,
        534,
        1627,
        13,
        50707
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 663.9399881362915,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 662.1599879264832,
      "temperature": 0.0,
      "text": " You can see in the reasoning, it's saying,",
      "tokens": [
        50707,
        509,
        393,
        536,
        294,
        264,
        21577,
        11,
        309,
        311,
        1566,
        11,
        50796
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 666.2999877929688,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 663.9399881362915,
      "temperature": 0.0,
      "text": " the sample row from user and high scores",
      "tokens": [
        50796,
        264,
        6889,
        5386,
        490,
        4195,
        293,
        1090,
        13444,
        50914
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 667.8799877166748,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 666.2999877929688,
      "temperature": 0.0,
      "text": " is exactly the same.",
      "tokens": [
        50914,
        307,
        2293,
        264,
        912,
        13,
        50993
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 670.3799877166748,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 667.8799877166748,
      "temperature": 0.0,
      "text": " So it's just gonna return the top result.",
      "tokens": [
        50993,
        407,
        309,
        311,
        445,
        799,
        2736,
        264,
        1192,
        1874,
        13,
        51118
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 671.2199878692627,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 670.3799877166748,
      "temperature": 0.0,
      "text": " Okay?",
      "tokens": [
        51118,
        1033,
        30,
        51160
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 672.0599880218506,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 671.2199878692627,
      "temperature": 0.0,
      "text": " So this is really powerful.",
      "tokens": [
        51160,
        407,
        341,
        307,
        534,
        4005,
        13,
        51202
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 673.3399887084961,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 672.0599880218506,
      "temperature": 0.0,
      "text": " I hope you can see that, you know,",
      "tokens": [
        51202,
        286,
        1454,
        291,
        393,
        536,
        300,
        11,
        291,
        458,
        11,
        51266
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 674.9999885559082,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 673.3399887084961,
      "temperature": 0.0,
      "text": " single file agents are powerful,",
      "tokens": [
        51266,
        2167,
        3991,
        12554,
        366,
        4005,
        11,
        51349
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 677.7199878692627,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 674.9999885559082,
      "temperature": 0.0,
      "text": " but having a great AI agent structure",
      "tokens": [
        51349,
        457,
        1419,
        257,
        869,
        7318,
        9461,
        3877,
        51485
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 680.2999877929688,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 677.7199878692627,
      "temperature": 0.0,
      "text": " with the right tools and the right order",
      "tokens": [
        51485,
        365,
        264,
        558,
        3873,
        293,
        264,
        558,
        1668,
        51614
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 682.2799873352051,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 680.2999877929688,
      "temperature": 0.0,
      "text": " is equally as powerful, right?",
      "tokens": [
        51614,
        307,
        12309,
        382,
        4005,
        11,
        558,
        30,
        51713
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.23620644211769104,
      "compression_ratio": 1.7568492889404297,
      "end": 684.0799884796143,
      "no_speech_prob": 0.01065168809145689,
      "seek": 0,
      "start": 682.2799873352051,
      "temperature": 0.0,
      "text": " It doesn't matter if you can build an agent,",
      "tokens": [
        51713,
        467,
        1177,
        380,
        1871,
        498,
        291,
        393,
        1322,
        364,
        9461,
        11,
        51803
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 686.5999870300293,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 684.0799884796143,
      "temperature": 0.0,
      "text": " it matters if you can build an effective agent.",
      "tokens": [
        50364,
        309,
        7001,
        498,
        291,
        393,
        1322,
        364,
        4942,
        9461,
        13,
        50490
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 688.5199890136719,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 686.5999870300293,
      "temperature": 0.0,
      "text": " Shout out to Anthropic for writing, you know,",
      "tokens": [
        50490,
        32749,
        484,
        281,
        12727,
        39173,
        337,
        3579,
        11,
        291,
        458,
        11,
        50586
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 691.0799865722656,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 688.5199890136719,
      "temperature": 0.0,
      "text": " this great post on building effective agents.",
      "tokens": [
        50586,
        341,
        869,
        2183,
        322,
        2390,
        4942,
        12554,
        13,
        50714
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 693.3199882507324,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 691.0799865722656,
      "temperature": 0.0,
      "text": " This document contains a lot of really key information.",
      "tokens": [
        50714,
        639,
        4166,
        8306,
        257,
        688,
        295,
        534,
        2141,
        1589,
        13,
        50826
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 694.8999862670898,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 693.3199882507324,
      "temperature": 0.0,
      "text": " I brought it up several times on the channel.",
      "tokens": [
        50826,
        286,
        3038,
        309,
        493,
        2940,
        1413,
        322,
        264,
        2269,
        13,
        50905
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 697.0799865722656,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 694.8999862670898,
      "temperature": 0.0,
      "text": " I think it encapsulates a lot of the key ideas",
      "tokens": [
        50905,
        286,
        519,
        309,
        38745,
        26192,
        257,
        688,
        295,
        264,
        2141,
        3487,
        51014
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 699.1599884033203,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 697.0799865722656,
      "temperature": 0.0,
      "text": " and serves as a great starting point",
      "tokens": [
        51014,
        293,
        13451,
        382,
        257,
        869,
        2891,
        935,
        51118
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 700.7999877929688,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 699.1599884033203,
      "temperature": 0.0,
      "text": " for building out agents, right?",
      "tokens": [
        51118,
        337,
        2390,
        484,
        12554,
        11,
        558,
        30,
        51200
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 703.9599876403809,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 700.7999877929688,
      "temperature": 0.0,
      "text": " They kind of end their story here with agents",
      "tokens": [
        51200,
        814,
        733,
        295,
        917,
        641,
        1657,
        510,
        365,
        12554,
        51358
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 705.1999893188477,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 703.9599876403809,
      "temperature": 0.0,
      "text": " with this simple loop, right?",
      "tokens": [
        51358,
        365,
        341,
        2199,
        6367,
        11,
        558,
        30,
        51420
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 706.8399887084961,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 705.1999893188477,
      "temperature": 0.0,
      "text": " Which is effectively all an agent is.",
      "tokens": [
        51420,
        3013,
        307,
        8659,
        439,
        364,
        9461,
        307,
        13,
        51502
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 709.5999870300293,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 706.8399887084961,
      "temperature": 0.0,
      "text": " You have an LLM call environment to an LLM call,",
      "tokens": [
        51502,
        509,
        362,
        364,
        441,
        43,
        44,
        818,
        2823,
        281,
        364,
        441,
        43,
        44,
        818,
        11,
        51640
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.1985359787940979,
      "compression_ratio": 1.7757009267807007,
      "end": 711.6399879455566,
      "no_speech_prob": 0.0009110205573961139,
      "seek": 2878,
      "start": 709.5999870300293,
      "temperature": 0.0,
      "text": " and then they stop kind of whenever they need to.",
      "tokens": [
        51640,
        293,
        550,
        436,
        1590,
        733,
        295,
        5699,
        436,
        643,
        281,
        13,
        51742
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 715.9199867248535,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 711.6399879455566,
      "temperature": 0.0,
      "text": " But all the magic happens in this loop, right?",
      "tokens": [
        50364,
        583,
        439,
        264,
        5585,
        2314,
        294,
        341,
        6367,
        11,
        558,
        30,
        50578
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 717.4799880981445,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 715.9199867248535,
      "temperature": 0.0,
      "text": " It happens in this agentic loop.",
      "tokens": [
        50578,
        467,
        2314,
        294,
        341,
        9461,
        299,
        6367,
        13,
        50656
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 718.619987487793,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 717.4799880981445,
      "temperature": 0.0,
      "text": " And this is where, you know,",
      "tokens": [
        50656,
        400,
        341,
        307,
        689,
        11,
        291,
        458,
        11,
        50713
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 720.5999908447266,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 718.619987487793,
      "temperature": 0.0,
      "text": " many structures can take place.",
      "tokens": [
        50713,
        867,
        9227,
        393,
        747,
        1081,
        13,
        50812
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 723.8399887084961,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 720.5999908447266,
      "temperature": 0.0,
      "text": " This is where many fortunes will be made and lost,",
      "tokens": [
        50812,
        639,
        307,
        689,
        867,
        10506,
        279,
        486,
        312,
        1027,
        293,
        2731,
        11,
        50974
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 725.9799880981445,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 723.8399887084961,
      "temperature": 0.0,
      "text": " you know, due to just going after the wrong thing,",
      "tokens": [
        50974,
        291,
        458,
        11,
        3462,
        281,
        445,
        516,
        934,
        264,
        2085,
        551,
        11,
        51081
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 727.0399856567383,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 725.9799880981445,
      "temperature": 0.0,
      "text": " going after the wrong idea.",
      "tokens": [
        51081,
        516,
        934,
        264,
        2085,
        1558,
        13,
        51134
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 729.3599853515625,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 727.0399856567383,
      "temperature": 0.0,
      "text": " And, you know, again, this is why I want to bring this up.",
      "tokens": [
        51134,
        400,
        11,
        291,
        458,
        11,
        797,
        11,
        341,
        307,
        983,
        286,
        528,
        281,
        1565,
        341,
        493,
        13,
        51250
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 730.9599914550781,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 729.3599853515625,
      "temperature": 0.0,
      "text": " The single file agents enable us",
      "tokens": [
        51250,
        440,
        2167,
        3991,
        12554,
        9528,
        505,
        51330
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 733.8399887084961,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 730.9599914550781,
      "temperature": 0.0,
      "text": " to build lean compute machines.",
      "tokens": [
        51330,
        281,
        1322,
        11659,
        14722,
        8379,
        13,
        51474
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 736.2799911499023,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 733.8399887084961,
      "temperature": 0.0,
      "text": " You don't want to over invest into any one idea.",
      "tokens": [
        51474,
        509,
        500,
        380,
        528,
        281,
        670,
        1963,
        666,
        604,
        472,
        1558,
        13,
        51596
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 738.7199859619141,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 736.2799911499023,
      "temperature": 0.0,
      "text": " We all kind of know that there are going to be",
      "tokens": [
        51596,
        492,
        439,
        733,
        295,
        458,
        300,
        456,
        366,
        516,
        281,
        312,
        51718
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.19991721212863922,
      "compression_ratio": 1.8090277910232544,
      "end": 740.8799896240234,
      "no_speech_prob": 0.0003053465043194592,
      "seek": 5634,
      "start": 738.7199859619141,
      "temperature": 0.0,
      "text": " new slews of AI coding agents.",
      "tokens": [
        51718,
        777,
        2426,
        14358,
        295,
        7318,
        17720,
        12554,
        13,
        51826
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 742.9999847412109,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 740.8799896240234,
      "temperature": 0.0,
      "text": " I would recommend not spending a bunch of time",
      "tokens": [
        50364,
        286,
        576,
        2748,
        406,
        6434,
        257,
        3840,
        295,
        565,
        50470
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 745.7999877929688,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 742.9999847412109,
      "temperature": 0.0,
      "text": " in the research space, in the AI coding space.",
      "tokens": [
        50470,
        294,
        264,
        2132,
        1901,
        11,
        294,
        264,
        7318,
        17720,
        1901,
        13,
        50610
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 747.0999908447266,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 745.7999877929688,
      "temperature": 0.0,
      "text": " It's not to say that you can't.",
      "tokens": [
        50610,
        467,
        311,
        406,
        281,
        584,
        300,
        291,
        393,
        380,
        13,
        50675
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 748.6399841308594,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 747.0999908447266,
      "temperature": 0.0,
      "text": " I think we're all exploring",
      "tokens": [
        50675,
        286,
        519,
        321,
        434,
        439,
        12736,
        50752
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 752.1999893188477,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 748.6399841308594,
      "temperature": 0.0,
      "text": " in all the kind of top go-to use cases for agents.",
      "tokens": [
        50752,
        294,
        439,
        264,
        733,
        295,
        1192,
        352,
        12,
        1353,
        764,
        3331,
        337,
        12554,
        13,
        50930
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 753.2999877929688,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 752.1999893188477,
      "temperature": 0.0,
      "text": " I think that's important.",
      "tokens": [
        50930,
        286,
        519,
        300,
        311,
        1021,
        13,
        50985
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 755.5599899291992,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 753.2999877929688,
      "temperature": 0.0,
      "text": " But this is why I bring up this pattern",
      "tokens": [
        50985,
        583,
        341,
        307,
        983,
        286,
        1565,
        493,
        341,
        5102,
        51098
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 759.4999847412109,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 755.5599899291992,
      "temperature": 0.0,
      "text": " of building lightweight, lean, single file agents",
      "tokens": [
        51098,
        295,
        2390,
        22052,
        11,
        11659,
        11,
        2167,
        3991,
        12554,
        51295
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 761.0799865722656,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 759.4999847412109,
      "temperature": 0.0,
      "text": " so that you don't over invest.",
      "tokens": [
        51295,
        370,
        300,
        291,
        500,
        380,
        670,
        1963,
        13,
        51374
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 763.3799896240234,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 761.0799865722656,
      "temperature": 0.0,
      "text": " But at the same time, you can get a lot of value",
      "tokens": [
        51374,
        583,
        412,
        264,
        912,
        565,
        11,
        291,
        393,
        483,
        257,
        688,
        295,
        2158,
        51489
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 765.2599868774414,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 763.3799896240234,
      "temperature": 0.0,
      "text": " by building out a lean implementation.",
      "tokens": [
        51489,
        538,
        2390,
        484,
        257,
        11659,
        11420,
        13,
        51583
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 766.6399841308594,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 765.2599868774414,
      "temperature": 0.0,
      "text": " So this is an important pattern.",
      "tokens": [
        51583,
        407,
        341,
        307,
        364,
        1021,
        5102,
        13,
        51652
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.19851535558700562,
      "compression_ratio": 1.811188817024231,
      "end": 769.2199859619141,
      "no_speech_prob": 0.002472593914717436,
      "seek": 8558,
      "start": 766.6399841308594,
      "temperature": 0.0,
      "text": " I think pre-verification is just as important",
      "tokens": [
        51652,
        286,
        519,
        659,
        12,
        331,
        3774,
        307,
        445,
        382,
        1021,
        51781
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.2529757618904114,
      "compression_ratio": 1.5573770999908447,
      "end": 773.4199905395508,
      "no_speech_prob": 0.02096281759440899,
      "seek": 11392,
      "start": 769.2199859619141,
      "temperature": 0.0,
      "text": " as post-verification or closed loop verification.",
      "tokens": [
        50364,
        382,
        2183,
        12,
        331,
        3774,
        420,
        5395,
        6367,
        30206,
        13,
        50574
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.2529757618904114,
      "compression_ratio": 1.5573770999908447,
      "end": 774.8999862670898,
      "no_speech_prob": 0.02096281759440899,
      "seek": 11392,
      "start": 773.4199905395508,
      "temperature": 0.0,
      "text": " Like I mentioned, this is something we talk about",
      "tokens": [
        50574,
        1743,
        286,
        2835,
        11,
        341,
        307,
        746,
        321,
        751,
        466,
        50648
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.2529757618904114,
      "compression_ratio": 1.5573770999908447,
      "end": 776.4999847412109,
      "no_speech_prob": 0.02096281759440899,
      "seek": 11392,
      "start": 774.8999862670898,
      "temperature": 0.0,
      "text": " in principled AI coding.",
      "tokens": [
        50648,
        294,
        3681,
        15551,
        7318,
        17720,
        13,
        50728
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 58,
      "avg_logprob": -0.2529757618904114,
      "compression_ratio": 1.5573770999908447,
      "end": 777.8599853515625,
      "no_speech_prob": 0.02096281759440899,
      "seek": 11392,
      "start": 776.4999847412109,
      "temperature": 0.0,
      "text": " More on that later in the video.",
      "tokens": [
        50728,
        5048,
        322,
        300,
        1780,
        294,
        264,
        960,
        13,
        50796
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 59,
      "avg_logprob": -0.2529757618904114,
      "compression_ratio": 1.5573770999908447,
      "end": 781.8199844360352,
      "no_speech_prob": 0.02096281759440899,
      "seek": 11392,
      "start": 777.8599853515625,
      "temperature": 0.0,
      "text": " Having a test command run and then a final command run,",
      "tokens": [
        50796,
        10222,
        257,
        1500,
        5622,
        1190,
        293,
        550,
        257,
        2572,
        5622,
        1190,
        11,
        50994
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 60,
      "avg_logprob": -0.2529757618904114,
      "compression_ratio": 1.5573770999908447,
      "end": 784.0999908447266,
      "no_speech_prob": 0.02096281759440899,
      "seek": 11392,
      "start": 781.8199844360352,
      "temperature": 0.0,
      "text": " whatever your domain specific problem is.",
      "tokens": [
        50994,
        2035,
        428,
        9274,
        2685,
        1154,
        307,
        13,
        51108
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 61,
      "avg_logprob": -0.2529757618904114,
      "compression_ratio": 1.5573770999908447,
      "end": 786.3799896240234,
      "no_speech_prob": 0.02096281759440899,
      "seek": 11392,
      "start": 784.0999908447266,
      "temperature": 0.0,
      "text": " If your domain is verifiable,",
      "tokens": [
        51108,
        759,
        428,
        9274,
        307,
        1306,
        30876,
        11,
        51222
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 788.919985294342,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 786.3599853515625,
      "temperature": 0.0,
      "text": " I highly recommend you check out this pattern",
      "tokens": [
        50364,
        286,
        5405,
        2748,
        291,
        1520,
        484,
        341,
        5102,
        50492
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 792.5999851226807,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 788.919985294342,
      "temperature": 0.0,
      "text": " of giving your agent tools to solve the problem,",
      "tokens": [
        50492,
        295,
        2902,
        428,
        9461,
        3873,
        281,
        5039,
        264,
        1154,
        11,
        50676
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 795.5599851608276,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 792.5999851226807,
      "temperature": 0.0,
      "text": " but also tools to pre-verify",
      "tokens": [
        50676,
        457,
        611,
        3873,
        281,
        659,
        12,
        331,
        2505,
        50824
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 797.2399854660034,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 795.5599851608276,
      "temperature": 0.0,
      "text": " that the answer that they're going to give you",
      "tokens": [
        50824,
        300,
        264,
        1867,
        300,
        436,
        434,
        516,
        281,
        976,
        291,
        50908
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 798.9199857711792,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 797.2399854660034,
      "temperature": 0.0,
      "text": " is the correct answer, all right?",
      "tokens": [
        50908,
        307,
        264,
        3006,
        1867,
        11,
        439,
        558,
        30,
        50992
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 800.3599853515625,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 798.9199857711792,
      "temperature": 0.0,
      "text": " And so that's what we're doing here",
      "tokens": [
        50992,
        400,
        370,
        300,
        311,
        437,
        321,
        434,
        884,
        510,
        51064
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 802.5999851226807,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 800.3599853515625,
      "temperature": 0.0,
      "text": " with our DuckDB single file agent.",
      "tokens": [
        51064,
        365,
        527,
        29266,
        27735,
        2167,
        3991,
        9461,
        13,
        51176
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 804.7199859619141,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 802.5999851226807,
      "temperature": 0.0,
      "text": " So what's the next step with this, right?",
      "tokens": [
        51176,
        407,
        437,
        311,
        264,
        958,
        1823,
        365,
        341,
        11,
        558,
        30,
        51282
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 806.3399848937988,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 804.7199859619141,
      "temperature": 0.0,
      "text": " We have these powerful single file agents",
      "tokens": [
        51282,
        492,
        362,
        613,
        4005,
        2167,
        3991,
        12554,
        51363
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 808.2199859619141,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 806.3399848937988,
      "temperature": 0.0,
      "text": " with a great agentic structure",
      "tokens": [
        51363,
        365,
        257,
        869,
        9461,
        299,
        3877,
        51457
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 809.8399848937988,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 808.2199859619141,
      "temperature": 0.0,
      "text": " that can solve problems for us.",
      "tokens": [
        51457,
        300,
        393,
        5039,
        2740,
        337,
        505,
        13,
        51538
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 813.1799850463867,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 809.8399848937988,
      "temperature": 0.0,
      "text": " We're gonna need many different types of AI agents,",
      "tokens": [
        51538,
        492,
        434,
        799,
        643,
        867,
        819,
        3467,
        295,
        7318,
        12554,
        11,
        51705
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.21425719559192657,
      "compression_ratio": 1.7543859481811523,
      "end": 814.4799861907959,
      "no_speech_prob": 0.001225500600412488,
      "seek": 0,
      "start": 813.1799850463867,
      "temperature": 0.0,
      "text": " not just this one, right?",
      "tokens": [
        51705,
        406,
        445,
        341,
        472,
        11,
        558,
        30,
        51770
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 817.3199844360352,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 814.4799861907959,
      "temperature": 0.0,
      "text": " We're gonna need, for instance, an SQLite agent.",
      "tokens": [
        50364,
        492,
        434,
        799,
        643,
        11,
        337,
        5197,
        11,
        364,
        19200,
        642,
        9461,
        13,
        50506
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 819.7599868774414,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 817.3199844360352,
      "temperature": 0.0,
      "text": " How can we take this agent and the agent structure",
      "tokens": [
        50506,
        1012,
        393,
        321,
        747,
        341,
        9461,
        293,
        264,
        9461,
        3877,
        50628
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 821.5999870300293,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 819.7599868774414,
      "temperature": 0.0,
      "text": " and basically duplicate it,",
      "tokens": [
        50628,
        293,
        1936,
        23976,
        309,
        11,
        50720
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 822.7199859619141,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 821.5999870300293,
      "temperature": 0.0,
      "text": " make a couple of tweaks to it",
      "tokens": [
        50720,
        652,
        257,
        1916,
        295,
        46664,
        281,
        309,
        50776
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 824.7599868774414,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 822.7199859619141,
      "temperature": 0.0,
      "text": " so that we can scale and reuse",
      "tokens": [
        50776,
        370,
        300,
        321,
        393,
        4373,
        293,
        26225,
        50878
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 827.3199844360352,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 824.7599868774414,
      "temperature": 0.0,
      "text": " our single file agent pattern, right?",
      "tokens": [
        50878,
        527,
        2167,
        3991,
        9461,
        5102,
        11,
        558,
        30,
        51006
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 829.9599838256836,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 827.3199844360352,
      "temperature": 0.0,
      "text": " With this powerful tooling thanks to Astral's UV,",
      "tokens": [
        51006,
        2022,
        341,
        4005,
        46593,
        3231,
        281,
        12884,
        2155,
        311,
        17887,
        11,
        51138
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 833.2799835205078,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 829.9599838256836,
      "temperature": 0.0,
      "text": " we can now churn out these powerful condensed agents.",
      "tokens": [
        51138,
        321,
        393,
        586,
        417,
        925,
        484,
        613,
        4005,
        36398,
        12554,
        13,
        51304
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 834.9599838256836,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 833.2799835205078,
      "temperature": 0.0,
      "text": " So how can we do that?",
      "tokens": [
        51304,
        407,
        577,
        393,
        321,
        360,
        300,
        30,
        51388
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 837.159984588623,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 834.9599838256836,
      "temperature": 0.0,
      "text": " We all already know the answer to this,",
      "tokens": [
        51388,
        492,
        439,
        1217,
        458,
        264,
        1867,
        281,
        341,
        11,
        51498
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 839.1199836730957,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 837.159984588623,
      "temperature": 0.0,
      "text": " especially if you've been with the channel",
      "tokens": [
        51498,
        2318,
        498,
        291,
        600,
        668,
        365,
        264,
        2269,
        51596
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 841.1999855041504,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 839.1199836730957,
      "temperature": 0.0,
      "text": " or if your eyes are open",
      "tokens": [
        51596,
        420,
        498,
        428,
        2575,
        366,
        1269,
        51700
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.21824975311756134,
      "compression_ratio": 1.6812080144882202,
      "end": 842.8399848937988,
      "no_speech_prob": 0.0064881411381065845,
      "seek": 2812,
      "start": 841.1999855041504,
      "temperature": 0.0,
      "text": " in the tech ecosystem at all right now.",
      "tokens": [
        51700,
        294,
        264,
        7553,
        11311,
        412,
        439,
        558,
        586,
        13,
        51782
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 845.1199836730957,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 842.8399848937988,
      "temperature": 0.0,
      "text": " We can do this with AI coding.",
      "tokens": [
        50364,
        492,
        393,
        360,
        341,
        365,
        7318,
        17720,
        13,
        50478
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 852.9599838256836,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 849.7999839782715,
      "temperature": 0.0,
      "text": " So now that we have this agent working in a single file",
      "tokens": [
        50712,
        407,
        586,
        300,
        321,
        362,
        341,
        9461,
        1364,
        294,
        257,
        2167,
        3991,
        50870
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 854.9599838256836,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 852.9599838256836,
      "temperature": 0.0,
      "text": " with a great agent pattern",
      "tokens": [
        50870,
        365,
        257,
        869,
        9461,
        5102,
        50970
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 857.3999862670898,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 854.9599838256836,
      "temperature": 0.0,
      "text": " and all dependencies encapsulated,",
      "tokens": [
        50970,
        293,
        439,
        36606,
        38745,
        6987,
        11,
        51092
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 859.1599884033203,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 857.3999862670898,
      "temperature": 0.0,
      "text": " we can iterate at light speed",
      "tokens": [
        51092,
        321,
        393,
        44497,
        412,
        1442,
        3073,
        51180
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 861.3599853515625,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 859.1599884033203,
      "temperature": 0.0,
      "text": " with powerful AI coding techniques,",
      "tokens": [
        51180,
        365,
        4005,
        7318,
        17720,
        7512,
        11,
        51290
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 865.9199829101562,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 861.3599853515625,
      "temperature": 0.0,
      "text": " many of which we've discussed in principled AI coding.",
      "tokens": [
        51290,
        867,
        295,
        597,
        321,
        600,
        7152,
        294,
        3681,
        15551,
        7318,
        17720,
        13,
        51518
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 868.119987487793,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 865.9199829101562,
      "temperature": 0.0,
      "text": " We're overdue for AI coding on the channel,",
      "tokens": [
        51518,
        492,
        434,
        19853,
        622,
        337,
        7318,
        17720,
        322,
        264,
        2269,
        11,
        51628
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.22329264879226685,
      "compression_ratio": 1.5945945978164673,
      "end": 870.7199859619141,
      "no_speech_prob": 0.001477923826314509,
      "seek": 5648,
      "start": 868.119987487793,
      "temperature": 0.0,
      "text": " so let's go ahead and write up a concise",
      "tokens": [
        51628,
        370,
        718,
        311,
        352,
        2286,
        293,
        2464,
        493,
        257,
        44882,
        51758
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 872.0799865722656,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 870.7199859619141,
      "temperature": 0.0,
      "text": " AI coding spec prompt",
      "tokens": [
        50364,
        7318,
        17720,
        1608,
        12391,
        50432
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 875.2799835205078,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 872.0799865722656,
      "temperature": 0.0,
      "text": " to create a new SQLite single file agent.",
      "tokens": [
        50432,
        281,
        1884,
        257,
        777,
        19200,
        642,
        2167,
        3991,
        9461,
        13,
        50592
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 877.3999862670898,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 875.2799835205078,
      "temperature": 0.0,
      "text": " And then I'll pitch principled AI coding",
      "tokens": [
        50592,
        400,
        550,
        286,
        603,
        7293,
        3681,
        15551,
        7318,
        17720,
        50698
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 879.6799850463867,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 877.3999862670898,
      "temperature": 0.0,
      "text": " for those who aren't aware of what it is",
      "tokens": [
        50698,
        337,
        729,
        567,
        3212,
        380,
        3650,
        295,
        437,
        309,
        307,
        50812
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 882.0799865722656,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 879.6799850463867,
      "temperature": 0.0,
      "text": " and how it can accelerate your engineering.",
      "tokens": [
        50812,
        293,
        577,
        309,
        393,
        21341,
        428,
        7043,
        13,
        50932
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 885.0399856567383,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 882.0799865722656,
      "temperature": 0.0,
      "text": " I also have some updates coming for existing members.",
      "tokens": [
        50932,
        286,
        611,
        362,
        512,
        9205,
        1348,
        337,
        6741,
        2679,
        13,
        51080
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 887.119987487793,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 885.0399856567383,
      "temperature": 0.0,
      "text": " We're gonna have some nice lightweight tooling",
      "tokens": [
        51080,
        492,
        434,
        799,
        362,
        512,
        1481,
        22052,
        46593,
        51184
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 889.9999847412109,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 887.119987487793,
      "temperature": 0.0,
      "text": " to help us utilize all the principles we learned",
      "tokens": [
        51184,
        281,
        854,
        505,
        16117,
        439,
        264,
        9156,
        321,
        3264,
        51328
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 891.1599884033203,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 889.9999847412109,
      "temperature": 0.0,
      "text": " inside the course.",
      "tokens": [
        51328,
        1854,
        264,
        1164,
        13,
        51386
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 892.3599853515625,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 891.1599884033203,
      "temperature": 0.0,
      "text": " So more on that in a second,",
      "tokens": [
        51386,
        407,
        544,
        322,
        300,
        294,
        257,
        1150,
        11,
        51446
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 896.3199844360352,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 892.3599853515625,
      "temperature": 0.0,
      "text": " let's first build out our SQLite AI agent.",
      "tokens": [
        51446,
        718,
        311,
        700,
        1322,
        484,
        527,
        19200,
        642,
        7318,
        9461,
        13,
        51644
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.19072572886943817,
      "compression_ratio": 1.613793134689331,
      "end": 897.8399887084961,
      "no_speech_prob": 0.10373628884553909,
      "seek": 8436,
      "start": 896.3199844360352,
      "temperature": 0.0,
      "text": " So this is gonna be relatively simple",
      "tokens": [
        51644,
        407,
        341,
        307,
        799,
        312,
        7226,
        2199,
        51720
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 900.9999847412109,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 897.8399887084961,
      "temperature": 0.0,
      "text": " since DuckDB and SQLite are very, very similar.",
      "tokens": [
        50364,
        1670,
        29266,
        27735,
        293,
        19200,
        642,
        366,
        588,
        11,
        588,
        2531,
        13,
        50522
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 902.5599822998047,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 900.9999847412109,
      "temperature": 0.0,
      "text": " What we'll do here is open the terminal.",
      "tokens": [
        50522,
        708,
        321,
        603,
        360,
        510,
        307,
        1269,
        264,
        14709,
        13,
        50600
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 904.3599853515625,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 902.5599822998047,
      "temperature": 0.0,
      "text": " We'll type CP SFA.",
      "tokens": [
        50600,
        492,
        603,
        2010,
        22431,
        318,
        19684,
        13,
        50690
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 905.9599838256836,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 904.3599853515625,
      "temperature": 0.0,
      "text": " We'll basically just copy this,",
      "tokens": [
        50690,
        492,
        603,
        1936,
        445,
        5055,
        341,
        11,
        50770
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 907.5599822998047,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 905.9599838256836,
      "temperature": 0.0,
      "text": " create an SQLite version.",
      "tokens": [
        50770,
        1884,
        364,
        19200,
        642,
        3037,
        13,
        50850
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 908.4799880981445,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 907.5599822998047,
      "temperature": 0.0,
      "text": " SQLite, great.",
      "tokens": [
        50850,
        19200,
        642,
        11,
        869,
        13,
        50896
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 911.9599838256836,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 908.4799880981445,
      "temperature": 0.0,
      "text": " I'm also going to touch aicode.sh.",
      "tokens": [
        50896,
        286,
        478,
        611,
        516,
        281,
        2557,
        257,
        299,
        1429,
        13,
        2716,
        13,
        51070
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 913.1999816894531,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 911.9599838256836,
      "temperature": 0.0,
      "text": " And this is where we're gonna build out",
      "tokens": [
        51070,
        400,
        341,
        307,
        689,
        321,
        434,
        799,
        1322,
        484,
        51132
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 915.9999847412109,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 913.1999816894531,
      "temperature": 0.0,
      "text": " our context model and prompt",
      "tokens": [
        51132,
        527,
        4319,
        2316,
        293,
        12391,
        51272
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.27675336599349976,
      "compression_ratio": 1.452054738998413,
      "end": 917.7999877929688,
      "no_speech_prob": 0.05748196318745613,
      "seek": 11148,
      "start": 915.9999847412109,
      "temperature": 0.0,
      "text": " so that we can quickly reuse our.",
      "tokens": [
        51272,
        370,
        300,
        321,
        393,
        2661,
        26225,
        527,
        13,
        51362
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 921.1399829387665,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 917.4199829101562,
      "temperature": 0.0,
      "text": " single file agent pattern in a reusable, scalable way.",
      "tokens": [
        50364,
        2167,
        3991,
        9461,
        5102,
        294,
        257,
        41807,
        11,
        38481,
        636,
        13,
        50550
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 924.7199831008911,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 921.1399829387665,
      "temperature": 0.0,
      "text": " I use AIDR as my primary AI coding workhorse.",
      "tokens": [
        50550,
        286,
        764,
        316,
        2777,
        49,
        382,
        452,
        6194,
        7318,
        17720,
        589,
        45079,
        13,
        50729
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 926.6799831390381,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 924.7199831008911,
      "temperature": 0.0,
      "text": " You can deploy this pattern",
      "tokens": [
        50729,
        509,
        393,
        7274,
        341,
        5102,
        50827
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 928.4399833679199,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 926.6799831390381,
      "temperature": 0.0,
      "text": " with any AI coding tool you want.",
      "tokens": [
        50827,
        365,
        604,
        7318,
        17720,
        2290,
        291,
        528,
        13,
        50915
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 930.6399831771851,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 928.4399833679199,
      "temperature": 0.0,
      "text": " Of course, use Cursor, Windsurfer, Klein,",
      "tokens": [
        50915,
        2720,
        1164,
        11,
        764,
        383,
        2156,
        284,
        11,
        43082,
        374,
        612,
        11,
        33327,
        11,
        51025
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 932.7199831008911,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 930.6399831771851,
      "temperature": 0.0,
      "text": " whatever your deal is, go ahead and hop into that.",
      "tokens": [
        51025,
        2035,
        428,
        2028,
        307,
        11,
        352,
        2286,
        293,
        3818,
        666,
        300,
        13,
        51129
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 934.9199829101562,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 932.7199831008911,
      "temperature": 0.0,
      "text": " I like to use AIDR and Cursor side-by-side.",
      "tokens": [
        51129,
        286,
        411,
        281,
        764,
        316,
        2777,
        49,
        293,
        383,
        2156,
        284,
        1252,
        12,
        2322,
        12,
        1812,
        13,
        51239
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 936.5399837493896,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 934.9199829101562,
      "temperature": 0.0,
      "text": " And let me show you a new pattern.",
      "tokens": [
        51239,
        400,
        718,
        385,
        855,
        291,
        257,
        777,
        5102,
        13,
        51320
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 937.8799819946289,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 936.5399837493896,
      "temperature": 0.0,
      "text": " And let me also just kind of, you know,",
      "tokens": [
        51320,
        400,
        718,
        385,
        611,
        445,
        733,
        295,
        11,
        291,
        458,
        11,
        51387
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 940.7399826049805,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 937.8799819946289,
      "temperature": 0.0,
      "text": " share some of the advantages you get",
      "tokens": [
        51387,
        2073,
        512,
        295,
        264,
        14906,
        291,
        483,
        51530
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 942.9399833679199,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 940.7399826049805,
      "temperature": 0.0,
      "text": " when you use a AI coding tool like AIDR.",
      "tokens": [
        51530,
        562,
        291,
        764,
        257,
        7318,
        17720,
        2290,
        411,
        316,
        2777,
        49,
        13,
        51640
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 944.3599834442139,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 942.9399833679199,
      "temperature": 0.0,
      "text": " So I'm just gonna paste this in here",
      "tokens": [
        51640,
        407,
        286,
        478,
        445,
        799,
        9163,
        341,
        294,
        510,
        51711
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.21403293311595917,
      "compression_ratio": 1.6891025304794312,
      "end": 946.1799831390381,
      "no_speech_prob": 0.0373242162168026,
      "seek": 0,
      "start": 944.3599834442139,
      "temperature": 0.0,
      "text": " since I've done this a million times.",
      "tokens": [
        51711,
        1670,
        286,
        600,
        1096,
        341,
        257,
        2459,
        1413,
        13,
        51802
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 948.2999820709229,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 946.1799831390381,
      "temperature": 0.0,
      "text": " Let's start with just this blob here, okay?",
      "tokens": [
        50364,
        961,
        311,
        722,
        365,
        445,
        341,
        46115,
        510,
        11,
        1392,
        30,
        50470
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 951.0599822998047,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 948.2999820709229,
      "temperature": 0.0,
      "text": " So we're passing in our prompt as the first argument.",
      "tokens": [
        50470,
        407,
        321,
        434,
        8437,
        294,
        527,
        12391,
        382,
        264,
        700,
        6770,
        13,
        50608
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 952.3799819946289,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 951.0599822998047,
      "temperature": 0.0,
      "text": " We're kicking off AIDR.",
      "tokens": [
        50608,
        492,
        434,
        19137,
        766,
        316,
        2777,
        49,
        13,
        50674
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 955.8199844360352,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 952.3799819946289,
      "temperature": 0.0,
      "text": " I wanna run the O3 mini model in architect mode",
      "tokens": [
        50674,
        286,
        1948,
        1190,
        264,
        422,
        18,
        8382,
        2316,
        294,
        6331,
        4391,
        50846
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 957.539981842041,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 955.8199844360352,
      "temperature": 0.0,
      "text": " with the high reasoning effort.",
      "tokens": [
        50846,
        365,
        264,
        1090,
        21577,
        4630,
        13,
        50932
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 960.3399810791016,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 957.539981842041,
      "temperature": 0.0,
      "text": " This is some of the best compute you can get right now.",
      "tokens": [
        50932,
        639,
        307,
        512,
        295,
        264,
        1151,
        14722,
        291,
        393,
        483,
        558,
        586,
        13,
        51072
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 963.2199821472168,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 960.3399810791016,
      "temperature": 0.0,
      "text": " I want Claw 3.5 Sonnet to make the edits",
      "tokens": [
        51072,
        286,
        528,
        383,
        5901,
        805,
        13,
        20,
        5185,
        7129,
        281,
        652,
        264,
        41752,
        51216
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 964.9799842834473,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 963.2199821472168,
      "temperature": 0.0,
      "text": " that O3 mini suggests.",
      "tokens": [
        51216,
        300,
        422,
        18,
        8382,
        13409,
        13,
        51304
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 966.6399841308594,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 964.9799842834473,
      "temperature": 0.0,
      "text": " And then we have a couple of configurations here",
      "tokens": [
        51304,
        400,
        550,
        321,
        362,
        257,
        1916,
        295,
        31493,
        510,
        51387
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 967.9399833679199,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 966.6399841308594,
      "temperature": 0.0,
      "text": " just to speed things up.",
      "tokens": [
        51387,
        445,
        281,
        3073,
        721,
        493,
        13,
        51452
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 970.5799827575684,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 967.9399833679199,
      "temperature": 0.0,
      "text": " And then in my context, you can see I'm passing in,",
      "tokens": [
        51452,
        400,
        550,
        294,
        452,
        4319,
        11,
        291,
        393,
        536,
        286,
        478,
        8437,
        294,
        11,
        51584
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 973.6999816894531,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 970.5799827575684,
      "temperature": 0.0,
      "text": " I want every single Python file available as the context.",
      "tokens": [
        51584,
        286,
        528,
        633,
        2167,
        15329,
        3991,
        2435,
        382,
        264,
        4319,
        13,
        51740
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.2170291393995285,
      "compression_ratio": 1.6273884773254395,
      "end": 974.539981842041,
      "no_speech_prob": 0.0016743625747039914,
      "seek": 2876,
      "start": 973.6999816894531,
      "temperature": 0.0,
      "text": " Okay?",
      "tokens": [
        51740,
        1033,
        30,
        51782
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 976.2999839782715,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 974.5799827575684,
      "temperature": 0.0,
      "text": " The message is just gonna be the prompt.",
      "tokens": [
        50366,
        440,
        3636,
        307,
        445,
        799,
        312,
        264,
        12391,
        13,
        50452
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 979.0599822998047,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 976.2999839782715,
      "temperature": 0.0,
      "text": " So whatever we pass in here, we can, you know,",
      "tokens": [
        50452,
        407,
        2035,
        321,
        1320,
        294,
        510,
        11,
        321,
        393,
        11,
        291,
        458,
        11,
        50590
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 981.97998046875,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 979.0599822998047,
      "temperature": 0.0,
      "text": " run this now and say, SHAI,",
      "tokens": [
        50590,
        1190,
        341,
        586,
        293,
        584,
        11,
        38820,
        40,
        11,
        50736
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 984.1199798583984,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 981.97998046875,
      "temperature": 0.0,
      "text": " and then just pass in whatever prompt.",
      "tokens": [
        50736,
        293,
        550,
        445,
        1320,
        294,
        2035,
        12391,
        13,
        50843
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 986.0399856567383,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 984.1199798583984,
      "temperature": 0.0,
      "text": " And then we can start getting AI coding changes",
      "tokens": [
        50843,
        400,
        550,
        321,
        393,
        722,
        1242,
        7318,
        17720,
        2962,
        50939
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 986.9399795532227,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 986.0399856567383,
      "temperature": 0.0,
      "text": " in on this, right?",
      "tokens": [
        50939,
        294,
        322,
        341,
        11,
        558,
        30,
        50984
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 989.0599822998047,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 986.9399795532227,
      "temperature": 0.0,
      "text": " Let me show you a little hint of what I have coming",
      "tokens": [
        50984,
        961,
        385,
        855,
        291,
        257,
        707,
        12075,
        295,
        437,
        286,
        362,
        1348,
        51090
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 991.0199813842773,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 989.0599822998047,
      "temperature": 0.0,
      "text": " for principled AI coding members.",
      "tokens": [
        51090,
        337,
        3681,
        15551,
        7318,
        17720,
        2679,
        13,
        51188
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 994.5799865722656,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 991.0199813842773,
      "temperature": 0.0,
      "text": " There's a big theme right now about scaling compute usage",
      "tokens": [
        51188,
        821,
        311,
        257,
        955,
        6314,
        558,
        586,
        466,
        21589,
        14722,
        14924,
        51366
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 997.8199844360352,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 994.5799865722656,
      "temperature": 0.0,
      "text": " and just throwing more compute at the problem.",
      "tokens": [
        51366,
        293,
        445,
        10238,
        544,
        14722,
        412,
        264,
        1154,
        13,
        51528
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 999.9399795532227,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 997.8199844360352,
      "temperature": 0.0,
      "text": " And then your problem will be solved, you know,",
      "tokens": [
        51528,
        400,
        550,
        428,
        1154,
        486,
        312,
        13041,
        11,
        291,
        458,
        11,
        51634
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.21784791350364685,
      "compression_ratio": 1.7821428775787354,
      "end": 1002.0199813842773,
      "no_speech_prob": 0.009859454818069935,
      "seek": 5712,
      "start": 999.9399795532227,
      "temperature": 0.0,
      "text": " basically just by turning up the knob.",
      "tokens": [
        51634,
        1936,
        445,
        538,
        6246,
        493,
        264,
        26759,
        13,
        51738
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1004.8599853515625,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1002.0199813842773,
      "temperature": 0.0,
      "text": " We can see that this is true even for AI coding.",
      "tokens": [
        50364,
        492,
        393,
        536,
        300,
        341,
        307,
        2074,
        754,
        337,
        7318,
        17720,
        13,
        50506
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1006.1199798583984,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1004.8599853515625,
      "temperature": 0.0,
      "text": " It's gonna look really stupid,",
      "tokens": [
        50506,
        467,
        311,
        799,
        574,
        534,
        6631,
        11,
        50569
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1008.2599792480469,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1006.1199798583984,
      "temperature": 0.0,
      "text": " but you're gonna understand how powerful this is",
      "tokens": [
        50569,
        457,
        291,
        434,
        799,
        1223,
        577,
        4005,
        341,
        307,
        50676
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1009.2599792480469,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1008.2599792480469,
      "temperature": 0.0,
      "text": " as we work through this.",
      "tokens": [
        50676,
        382,
        321,
        589,
        807,
        341,
        13,
        50726
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1012.2999801635742,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1009.2599792480469,
      "temperature": 0.0,
      "text": " I'm literally gonna copy this command.",
      "tokens": [
        50726,
        286,
        478,
        3736,
        799,
        5055,
        341,
        5622,
        13,
        50878
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1014.1399841308594,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1012.2999801635742,
      "temperature": 0.0,
      "text": " I'm gonna paste it here.",
      "tokens": [
        50878,
        286,
        478,
        799,
        9163,
        309,
        510,
        13,
        50970
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1015.3399810791016,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1014.1399841308594,
      "temperature": 0.0,
      "text": " So let me turn off cursor tabs.",
      "tokens": [
        50970,
        407,
        718,
        385,
        1261,
        766,
        28169,
        20743,
        13,
        51030
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1016.8999862670898,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1015.3399810791016,
      "temperature": 0.0,
      "text": " We can write this by ourselves here.",
      "tokens": [
        51030,
        492,
        393,
        2464,
        341,
        538,
        4175,
        510,
        13,
        51108
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1021.3399810791016,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1016.8999862670898,
      "temperature": 0.0,
      "text": " I'm gonna say, double check all changes requested",
      "tokens": [
        51108,
        286,
        478,
        799,
        584,
        11,
        3834,
        1520,
        439,
        2962,
        16436,
        51330
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1023.97998046875,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1021.3399810791016,
      "temperature": 0.0,
      "text": " to make sure they've been implemented.",
      "tokens": [
        51330,
        281,
        652,
        988,
        436,
        600,
        668,
        12270,
        13,
        51462
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1024.7999801635742,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1023.97998046875,
      "temperature": 0.0,
      "text": " And that's it.",
      "tokens": [
        51462,
        400,
        300,
        311,
        309,
        13,
        51503
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1025.9199829101562,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1024.7999801635742,
      "temperature": 0.0,
      "text": " And so what we end up with here",
      "tokens": [
        51503,
        400,
        370,
        437,
        321,
        917,
        493,
        365,
        510,
        51559
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1028.6599807739258,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1025.9199829101562,
      "temperature": 0.0,
      "text": " is a prompt chain of length four, right?",
      "tokens": [
        51559,
        307,
        257,
        12391,
        5021,
        295,
        4641,
        1451,
        11,
        558,
        30,
        51696
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.2236669510602951,
      "compression_ratio": 1.6611841917037964,
      "end": 1031.219985961914,
      "no_speech_prob": 0.0004108455905225128,
      "seek": 8460,
      "start": 1028.6599807739258,
      "temperature": 0.0,
      "text": " We have an architect drafting the changes",
      "tokens": [
        51696,
        492,
        362,
        364,
        6331,
        46378,
        264,
        2962,
        51824
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1033.0799865722656,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1031.219985961914,
      "temperature": 0.0,
      "text": " and then an editor writing the changes.",
      "tokens": [
        50364,
        293,
        550,
        364,
        9839,
        3579,
        264,
        2962,
        13,
        50457
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1036.5399856567383,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1033.0799865722656,
      "temperature": 0.0,
      "text": " And then again, we have an architect double checking",
      "tokens": [
        50457,
        400,
        550,
        797,
        11,
        321,
        362,
        364,
        6331,
        3834,
        8568,
        50630
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1039.4599838256836,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1036.5399856567383,
      "temperature": 0.0,
      "text": " all the changes that just happened in a brand new instance.",
      "tokens": [
        50630,
        439,
        264,
        2962,
        300,
        445,
        2011,
        294,
        257,
        3360,
        777,
        5197,
        13,
        50776
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1041.8999862670898,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1039.4599838256836,
      "temperature": 0.0,
      "text": " And then we have an editor to write those changes, right?",
      "tokens": [
        50776,
        400,
        550,
        321,
        362,
        364,
        9839,
        281,
        2464,
        729,
        2962,
        11,
        558,
        30,
        50898
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1044.499984741211,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1041.8999862670898,
      "temperature": 0.0,
      "text": " To write anything that was, you know, potentially missed.",
      "tokens": [
        50898,
        1407,
        2464,
        1340,
        300,
        390,
        11,
        291,
        458,
        11,
        7263,
        6721,
        13,
        51028
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1045.3199844360352,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1044.499984741211,
      "temperature": 0.0,
      "text": " Fantastic.",
      "tokens": [
        51028,
        21320,
        13,
        51069
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 58,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1046.8199768066406,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1045.3199844360352,
      "temperature": 0.0,
      "text": " So now we're going to actually write the prompt.",
      "tokens": [
        51069,
        407,
        586,
        321,
        434,
        516,
        281,
        767,
        2464,
        264,
        12391,
        13,
        51144
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 59,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1047.97998046875,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1046.8199768066406,
      "temperature": 0.0,
      "text": " This is gonna be really simple.",
      "tokens": [
        51144,
        639,
        307,
        799,
        312,
        534,
        2199,
        13,
        51202
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 60,
      "avg_logprob": -0.2076277732849121,
      "compression_ratio": 1.6875,
      "end": 1048.8199768066406,
      "no_speech_prob": 0.0009399363771080971,
      "seek": 11380,
      "start": 1047.97998046875,
      "temperature": 0.0,
      "text": " I'm going to get.",
      "tokens": [
        51202,
        286,
        478,
        516,
        281,
        483,
        13,
        51244
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.25144973397254944,
      "compression_ratio": 1.6344537734985352,
      "end": 1054.9599804878235,
      "no_speech_prob": 0.018831271678209305,
      "seek": 0,
      "start": 1048.47998046875,
      "temperature": 0.0,
      "text": " the path to this. I'm just going to say update and then I'll say refactor to target SQLite databases.",
      "tokens": [
        50364,
        264,
        3100,
        281,
        341,
        13,
        286,
        478,
        445,
        516,
        281,
        584,
        5623,
        293,
        550,
        286,
        603,
        584,
        1895,
        15104,
        281,
        3779,
        19200,
        642,
        22380,
        13,
        50688
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.25144973397254944,
      "compression_ratio": 1.6344537734985352,
      "end": 1063.1999807357788,
      "no_speech_prob": 0.018831271678209305,
      "seek": 0,
      "start": 1055.9999804496765,
      "temperature": 0.0,
      "text": " Keep all functions the same but target SQLite databases with SQLite 3. So I'm being specific",
      "tokens": [
        50740,
        5527,
        439,
        6828,
        264,
        912,
        457,
        3779,
        19200,
        642,
        22380,
        365,
        19200,
        642,
        805,
        13,
        407,
        286,
        478,
        885,
        2685,
        51100
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.25144973397254944,
      "compression_ratio": 1.6344537734985352,
      "end": 1071.9199810028076,
      "no_speech_prob": 0.018831271678209305,
      "seek": 0,
      "start": 1063.1999807357788,
      "temperature": 0.0,
      "text": " about what library I want used here. Update tools and prompt to reference SQLite. Okay because if",
      "tokens": [
        51100,
        466,
        437,
        6405,
        286,
        528,
        1143,
        510,
        13,
        28923,
        3873,
        293,
        12391,
        281,
        6408,
        19200,
        642,
        13,
        1033,
        570,
        498,
        51536
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.25144973397254944,
      "compression_ratio": 1.6344537734985352,
      "end": 1076.639980316162,
      "no_speech_prob": 0.018831271678209305,
      "seek": 0,
      "start": 1071.9199810028076,
      "temperature": 0.0,
      "text": " we open up this file you can see here if we just search DuckDB we have you know many references.",
      "tokens": [
        51536,
        321,
        1269,
        493,
        341,
        3991,
        291,
        393,
        536,
        510,
        498,
        321,
        445,
        3164,
        29266,
        27735,
        321,
        362,
        291,
        458,
        867,
        15400,
        13,
        51772
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.1955389529466629,
      "compression_ratio": 1.860544204711914,
      "end": 1080.9599800109863,
      "no_speech_prob": 0.001345835393294692,
      "seek": 2816,
      "start": 1076.639980316162,
      "temperature": 0.0,
      "text": " You can see on the side here we have many references to DuckDB. So that's it. That's",
      "tokens": [
        50364,
        509,
        393,
        536,
        322,
        264,
        1252,
        510,
        321,
        362,
        867,
        15400,
        281,
        29266,
        27735,
        13,
        407,
        300,
        311,
        309,
        13,
        663,
        311,
        50580
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.1955389529466629,
      "compression_ratio": 1.860544204711914,
      "end": 1086.7199821472168,
      "no_speech_prob": 0.001345835393294692,
      "seek": 2816,
      "start": 1080.9599800109863,
      "temperature": 0.0,
      "text": " the prompt. I'm going to copy this and I have this kind of reusable AI coding configuration.",
      "tokens": [
        50580,
        264,
        12391,
        13,
        286,
        478,
        516,
        281,
        5055,
        341,
        293,
        286,
        362,
        341,
        733,
        295,
        41807,
        7318,
        17720,
        11694,
        13,
        50868
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.1955389529466629,
      "compression_ratio": 1.860544204711914,
      "end": 1092.5599822998047,
      "no_speech_prob": 0.001345835393294692,
      "seek": 2816,
      "start": 1086.7199821472168,
      "temperature": 0.0,
      "text": " Right you can think of this as a kind of just generic AI coding script that we can call that",
      "tokens": [
        50868,
        1779,
        291,
        393,
        519,
        295,
        341,
        382,
        257,
        733,
        295,
        445,
        19577,
        7318,
        17720,
        5755,
        300,
        321,
        393,
        818,
        300,
        51160
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.1955389529466629,
      "compression_ratio": 1.860544204711914,
      "end": 1097.919979095459,
      "no_speech_prob": 0.001345835393294692,
      "seek": 2816,
      "start": 1092.5599822998047,
      "temperature": 0.0,
      "text": " runs a compute enhanced AI coding chain of assistants. Right we have two aider assistants",
      "tokens": [
        51160,
        6676,
        257,
        14722,
        21191,
        7318,
        17720,
        5021,
        295,
        34949,
        13,
        1779,
        321,
        362,
        732,
        36669,
        34949,
        51428
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.1955389529466629,
      "compression_ratio": 1.860544204711914,
      "end": 1101.8399810791016,
      "no_speech_prob": 0.001345835393294692,
      "seek": 2816,
      "start": 1097.919979095459,
      "temperature": 0.0,
      "text": " in architect mode. We're just going to copy this. We do dollar sign pb paste. That's it.",
      "tokens": [
        51428,
        294,
        6331,
        4391,
        13,
        492,
        434,
        445,
        516,
        281,
        5055,
        341,
        13,
        492,
        360,
        7241,
        1465,
        280,
        65,
        9163,
        13,
        663,
        311,
        309,
        13,
        51624
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.1955389529466629,
      "compression_ratio": 1.860544204711914,
      "end": 1106.079978942871,
      "no_speech_prob": 0.001345835393294692,
      "seek": 2816,
      "start": 1101.8399810791016,
      "temperature": 0.0,
      "text": " So this is going to update. It's going to kick off two AI coding assistants running back to back.",
      "tokens": [
        51624,
        407,
        341,
        307,
        516,
        281,
        5623,
        13,
        467,
        311,
        516,
        281,
        4437,
        766,
        732,
        7318,
        17720,
        34949,
        2614,
        646,
        281,
        646,
        13,
        51836
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.1820286363363266,
      "compression_ratio": 1.8452380895614624,
      "end": 1112.2399787902832,
      "no_speech_prob": 0.0009849938796833158,
      "seek": 5760,
      "start": 1106.079978942871,
      "temperature": 0.0,
      "text": " This is our first shot and this is our reflection step. Right all right so there we go. We're",
      "tokens": [
        50364,
        639,
        307,
        527,
        700,
        3347,
        293,
        341,
        307,
        527,
        12914,
        1823,
        13,
        1779,
        439,
        558,
        370,
        456,
        321,
        352,
        13,
        492,
        434,
        50672
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.1820286363363266,
      "compression_ratio": 1.8452380895614624,
      "end": 1118.6399841308594,
      "no_speech_prob": 0.0009849938796833158,
      "seek": 5760,
      "start": 1112.2399787902832,
      "temperature": 0.0,
      "text": " getting our changes. We're updating our tool calls to reference SQLite instead of DuckDB.",
      "tokens": [
        50672,
        1242,
        527,
        2962,
        13,
        492,
        434,
        25113,
        527,
        2290,
        5498,
        281,
        6408,
        19200,
        642,
        2602,
        295,
        29266,
        27735,
        13,
        50992
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.1820286363363266,
      "compression_ratio": 1.8452380895614624,
      "end": 1122.5599822998047,
      "no_speech_prob": 0.0009849938796833158,
      "seek": 5760,
      "start": 1118.6399841308594,
      "temperature": 0.0,
      "text": " And then at some point here we're going to see our prompt get updated. So you can see there",
      "tokens": [
        50992,
        400,
        550,
        412,
        512,
        935,
        510,
        321,
        434,
        516,
        281,
        536,
        527,
        12391,
        483,
        10588,
        13,
        407,
        291,
        393,
        536,
        456,
        51188
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.1820286363363266,
      "compression_ratio": 1.8452380895614624,
      "end": 1127.4399795532227,
      "no_speech_prob": 0.0009849938796833158,
      "seek": 5760,
      "start": 1122.5599822998047,
      "temperature": 0.0,
      "text": " all those tools. That looks great. We're on final SQL query. Now we're referencing SQLite instead",
      "tokens": [
        51188,
        439,
        729,
        3873,
        13,
        663,
        1542,
        869,
        13,
        492,
        434,
        322,
        2572,
        19200,
        14581,
        13,
        823,
        321,
        434,
        40582,
        19200,
        642,
        2602,
        51432
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.1820286363363266,
      "compression_ratio": 1.8452380895614624,
      "end": 1131.9999771118164,
      "no_speech_prob": 0.0009849938796833158,
      "seek": 5760,
      "start": 1127.4399795532227,
      "temperature": 0.0,
      "text": " of DuckDB. You can see we had an update in the prompt and now we're running the reflection.",
      "tokens": [
        51432,
        295,
        29266,
        27735,
        13,
        509,
        393,
        536,
        321,
        632,
        364,
        5623,
        294,
        264,
        12391,
        293,
        586,
        321,
        434,
        2614,
        264,
        12914,
        13,
        51660
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.20739658176898956,
      "compression_ratio": 1.7852760553359985,
      "end": 1136.9599838256836,
      "no_speech_prob": 0.006692714523524046,
      "seek": 8352,
      "start": 1131.9999771118164,
      "temperature": 0.0,
      "text": " Right so remember the reflection is literally just this. Double check all changes. Request it and",
      "tokens": [
        50364,
        1779,
        370,
        1604,
        264,
        12914,
        307,
        3736,
        445,
        341,
        13,
        16633,
        1520,
        439,
        2962,
        13,
        1300,
        20343,
        309,
        293,
        50612
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.20739658176898956,
      "compression_ratio": 1.7852760553359985,
      "end": 1141.6799774169922,
      "no_speech_prob": 0.006692714523524046,
      "seek": 8352,
      "start": 1136.9599838256836,
      "temperature": 0.0,
      "text": " we're pacing the prompt in again. So let's see what happens now. We've already taken one shot",
      "tokens": [
        50612,
        321,
        434,
        43285,
        264,
        12391,
        294,
        797,
        13,
        407,
        718,
        311,
        536,
        437,
        2314,
        586,
        13,
        492,
        600,
        1217,
        2726,
        472,
        3347,
        50848
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.20739658176898956,
      "compression_ratio": 1.7852760553359985,
      "end": 1146.7199783325195,
      "no_speech_prob": 0.006692714523524046,
      "seek": 8352,
      "start": 1141.6799774169922,
      "temperature": 0.0,
      "text": " at architect and editor with aider and now we're running again. So you can see here look at how",
      "tokens": [
        50848,
        412,
        6331,
        293,
        9839,
        365,
        36669,
        293,
        586,
        321,
        434,
        2614,
        797,
        13,
        407,
        291,
        393,
        536,
        510,
        574,
        412,
        577,
        51100
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.20739658176898956,
      "compression_ratio": 1.7852760553359985,
      "end": 1151.5199813842773,
      "no_speech_prob": 0.006692714523524046,
      "seek": 8352,
      "start": 1146.7199783325195,
      "temperature": 0.0,
      "text": " many things were missed. Right we have the architect saying hey you missed this here. Hey you missed",
      "tokens": [
        51100,
        867,
        721,
        645,
        6721,
        13,
        1779,
        321,
        362,
        264,
        6331,
        1566,
        4177,
        291,
        6721,
        341,
        510,
        13,
        1911,
        291,
        6721,
        51340
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.20739658176898956,
      "compression_ratio": 1.7852760553359985,
      "end": 1156.47998046875,
      "no_speech_prob": 0.006692714523524046,
      "seek": 8352,
      "start": 1151.5199813842773,
      "temperature": 0.0,
      "text": " this here. And then the editor is coming in and actually changing those things. Right so we can",
      "tokens": [
        51340,
        341,
        510,
        13,
        400,
        550,
        264,
        9839,
        307,
        1348,
        294,
        293,
        767,
        4473,
        729,
        721,
        13,
        1779,
        370,
        321,
        393,
        51588
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.20739658176898956,
      "compression_ratio": 1.7852760553359985,
      "end": 1161.9199829101562,
      "no_speech_prob": 0.006692714523524046,
      "seek": 8352,
      "start": 1156.47998046875,
      "temperature": 0.0,
      "text": " now search SQLite. And so we should see a bunch of references to SQLite now with that new syntax.",
      "tokens": [
        51588,
        586,
        3164,
        19200,
        642,
        13,
        400,
        370,
        321,
        820,
        536,
        257,
        3840,
        295,
        15400,
        281,
        19200,
        642,
        586,
        365,
        300,
        777,
        28431,
        13,
        51860
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.1965363472700119,
      "compression_ratio": 1.45641028881073,
      "end": 1166.7199783325195,
      "no_speech_prob": 0.0004108387802261859,
      "seek": 11344,
      "start": 1162.2399826049805,
      "temperature": 0.0,
      "text": " As a test we can also come in here and search DuckDB. Right so this is really good. We don't",
      "tokens": [
        50380,
        1018,
        257,
        1500,
        321,
        393,
        611,
        808,
        294,
        510,
        293,
        3164,
        29266,
        27735,
        13,
        1779,
        370,
        341,
        307,
        534,
        665,
        13,
        492,
        500,
        380,
        50604
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.1965363472700119,
      "compression_ratio": 1.45641028881073,
      "end": 1173.8399810791016,
      "no_speech_prob": 0.0004108387802261859,
      "seek": 11344,
      "start": 1166.7199783325195,
      "temperature": 0.0,
      "text": " see any references to DuckDB anymore. Fantastic. And now we should be able to run our SQLite agent",
      "tokens": [
        50604,
        536,
        604,
        15400,
        281,
        29266,
        27735,
        3602,
        13,
        21320,
        13,
        400,
        586,
        321,
        820,
        312,
        1075,
        281,
        1190,
        527,
        19200,
        642,
        9461,
        50960
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.1965363472700119,
      "compression_ratio": 1.45641028881073,
      "end": 1179.3599853515625,
      "no_speech_prob": 0.0004108387802261859,
      "seek": 11344,
      "start": 1173.8399810791016,
      "temperature": 0.0,
      "text": " just as we did our DuckDB OpenAI agent. So in order to do that we need to pull in an SQLite.",
      "tokens": [
        50960,
        445,
        382,
        321,
        630,
        527,
        29266,
        27735,
        7238,
        48698,
        9461,
        13,
        407,
        294,
        1668,
        281,
        360,
        300,
        321,
        643,
        281,
        2235,
        294,
        364,
        19200,
        642,
        13,
        51236
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1181.6199779510498,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1179.5399780273438,
      "temperature": 0.0,
      "text": " version of this, I'll paste this in,",
      "tokens": [
        50364,
        3037,
        295,
        341,
        11,
        286,
        603,
        9163,
        341,
        294,
        11,
        50468
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1184.779977798462,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1181.6199779510498,
      "temperature": 0.0,
      "text": " and you can see my SQLite extension",
      "tokens": [
        50468,
        293,
        291,
        393,
        536,
        452,
        19200,
        642,
        10320,
        50626
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1186.6599779129028,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1184.779977798462,
      "temperature": 0.0,
      "text": " showing this table here, right?",
      "tokens": [
        50626,
        4099,
        341,
        3199,
        510,
        11,
        558,
        30,
        50720
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1188.899977684021,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1186.6599779129028,
      "temperature": 0.0,
      "text": " So this is our users table, let's go ahead and close this.",
      "tokens": [
        50720,
        407,
        341,
        307,
        527,
        5022,
        3199,
        11,
        718,
        311,
        352,
        2286,
        293,
        1998,
        341,
        13,
        50832
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1191.5399780273438,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1188.899977684021,
      "temperature": 0.0,
      "text": " So we now have this ready for our new SQLite agent.",
      "tokens": [
        50832,
        407,
        321,
        586,
        362,
        341,
        1919,
        337,
        527,
        777,
        19200,
        642,
        9461,
        13,
        50964
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1193.1799783706665,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1191.5399780273438,
      "temperature": 0.0,
      "text": " Let's go ahead and save this.",
      "tokens": [
        50964,
        961,
        311,
        352,
        2286,
        293,
        3155,
        341,
        13,
        51046
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1195.8199787139893,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1193.1799783706665,
      "temperature": 0.0,
      "text": " And now let's just run our SQLite agent,",
      "tokens": [
        51046,
        400,
        586,
        718,
        311,
        445,
        1190,
        527,
        19200,
        642,
        9461,
        11,
        51178
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1197.4199771881104,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1195.8199787139893,
      "temperature": 0.0,
      "text": " SFA, single file agent,",
      "tokens": [
        51178,
        318,
        19684,
        11,
        2167,
        3991,
        9461,
        11,
        51258
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1199.4999771118164,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1197.4199771881104,
      "temperature": 0.0,
      "text": " and we're gonna run our SQLite version,",
      "tokens": [
        51258,
        293,
        321,
        434,
        799,
        1190,
        527,
        19200,
        642,
        3037,
        11,
        51362
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1202.439977645874,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1199.4999771118164,
      "temperature": 0.0,
      "text": " dash D, analytics, SQLite database,",
      "tokens": [
        51362,
        8240,
        413,
        11,
        15370,
        11,
        19200,
        642,
        8149,
        11,
        51509
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1206.579978942871,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1202.439977645874,
      "temperature": 0.0,
      "text": " dash P, list five rows from user table.",
      "tokens": [
        51509,
        8240,
        430,
        11,
        1329,
        1732,
        13241,
        490,
        4195,
        3199,
        13,
        51716
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 1208.6999778747559,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 1206.579978942871,
      "temperature": 0.0,
      "text": " And for our compute, we'll just say five, right?",
      "tokens": [
        51716,
        400,
        337,
        527,
        14722,
        11,
        321,
        603,
        445,
        584,
        1732,
        11,
        558,
        30,
        51822
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1209.6999778747559,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1208.6999778747559,
      "temperature": 0.0,
      "text": " Should be pretty simple.",
      "tokens": [
        50364,
        6454,
        312,
        1238,
        2199,
        13,
        50414
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1210.5399780273438,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1209.6999778747559,
      "temperature": 0.0,
      "text": " So far so good, right?",
      "tokens": [
        50414,
        407,
        1400,
        370,
        665,
        11,
        558,
        30,
        50456
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1212.0999794006348,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1210.5399780273438,
      "temperature": 0.0,
      "text": " Our code compiles, so that looks great.",
      "tokens": [
        50456,
        2621,
        3089,
        715,
        4680,
        11,
        370,
        300,
        1542,
        869,
        13,
        50534
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1214.299976348877,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1212.0999794006348,
      "temperature": 0.0,
      "text": " We have our first tool call, that looks awesome.",
      "tokens": [
        50534,
        492,
        362,
        527,
        700,
        2290,
        818,
        11,
        300,
        1542,
        3476,
        13,
        50644
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1215.1399765014648,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1214.299976348877,
      "temperature": 0.0,
      "text": " There it is.",
      "tokens": [
        50644,
        821,
        309,
        307,
        13,
        50686
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1219.1399765014648,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1215.1399765014648,
      "temperature": 0.0,
      "text": " So SQLite running just like our DuckDB did.",
      "tokens": [
        50686,
        407,
        19200,
        642,
        2614,
        445,
        411,
        527,
        29266,
        27735,
        630,
        13,
        50886
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1221.1399765014648,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1219.1399765014648,
      "temperature": 0.0,
      "text": " We're getting a slightly different output format",
      "tokens": [
        50886,
        492,
        434,
        1242,
        257,
        4748,
        819,
        5598,
        7877,
        50986
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1222.7399787902832,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1221.1399765014648,
      "temperature": 0.0,
      "text": " because of course we're using SQLite.",
      "tokens": [
        50986,
        570,
        295,
        1164,
        321,
        434,
        1228,
        19200,
        642,
        13,
        51066
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1224.2599792480469,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1222.7399787902832,
      "temperature": 0.0,
      "text": " We were able to reuse",
      "tokens": [
        51066,
        492,
        645,
        1075,
        281,
        26225,
        51142
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1226.5399780273438,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1224.2599792480469,
      "temperature": 0.0,
      "text": " our existing single file agent architecture.",
      "tokens": [
        51142,
        527,
        6741,
        2167,
        3991,
        9461,
        9482,
        13,
        51256
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1229.6199798583984,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1226.5399780273438,
      "temperature": 0.0,
      "text": " We made an update to it with a clean prompt chain",
      "tokens": [
        51256,
        492,
        1027,
        364,
        5623,
        281,
        309,
        365,
        257,
        2541,
        12391,
        5021,
        51410
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1233.079978942871,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1229.6199798583984,
      "temperature": 0.0,
      "text": " of length four, where every prompt was us kicking off Adr.",
      "tokens": [
        51410,
        295,
        4641,
        1451,
        11,
        689,
        633,
        12391,
        390,
        505,
        19137,
        766,
        1999,
        81,
        13,
        51583
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1235.0599784851074,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1233.079978942871,
      "temperature": 0.0,
      "text": " We have an architect and then an editor,",
      "tokens": [
        51583,
        492,
        362,
        364,
        6331,
        293,
        550,
        364,
        9839,
        11,
        51682
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 1236.7399787902832,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 1235.0599784851074,
      "temperature": 0.0,
      "text": " and then we just basically doubled it, right?",
      "tokens": [
        51682,
        293,
        550,
        321,
        445,
        1936,
        24405,
        309,
        11,
        558,
        30,
        51766
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1239.8999786376953,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1236.7399787902832,
      "temperature": 0.0,
      "text": " Our reflection actually saved us a little bit of energy.",
      "tokens": [
        50364,
        2621,
        12914,
        767,
        6624,
        505,
        257,
        707,
        857,
        295,
        2281,
        13,
        50522
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1242.299976348877,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1239.8999786376953,
      "temperature": 0.0,
      "text": " This idea of scaling up your compute",
      "tokens": [
        50522,
        639,
        1558,
        295,
        21589,
        493,
        428,
        14722,
        50642
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1245.0599746704102,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1242.299976348877,
      "temperature": 0.0,
      "text": " really does translate to almost anywhere",
      "tokens": [
        50642,
        534,
        775,
        13799,
        281,
        1920,
        4992,
        50780
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1246.7799758911133,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1245.0599746704102,
      "temperature": 0.0,
      "text": " you're using language models,",
      "tokens": [
        50780,
        291,
        434,
        1228,
        2856,
        5245,
        11,
        50866
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1248.8399810791016,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1246.7799758911133,
      "temperature": 0.0,
      "text": " anywhere you're running a prompt, right?",
      "tokens": [
        50866,
        4992,
        291,
        434,
        2614,
        257,
        12391,
        11,
        558,
        30,
        50969
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1251.459976196289,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1248.8399810791016,
      "temperature": 0.0,
      "text": " Even if it's embedded inside of a tool like Adr, right?",
      "tokens": [
        50969,
        2754,
        498,
        309,
        311,
        16741,
        1854,
        295,
        257,
        2290,
        411,
        1999,
        81,
        11,
        558,
        30,
        51100
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1253.2999801635742,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1251.459976196289,
      "temperature": 0.0,
      "text": " You have to remember all of these tools, right?",
      "tokens": [
        51100,
        509,
        362,
        281,
        1604,
        439,
        295,
        613,
        3873,
        11,
        558,
        30,
        51192
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1256.6799774169922,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1253.2999801635742,
      "temperature": 0.0,
      "text": " Cursor, Adr, ChatGPT, Claude, right?",
      "tokens": [
        51192,
        383,
        2156,
        284,
        11,
        1999,
        81,
        11,
        27503,
        38,
        47,
        51,
        11,
        12947,
        2303,
        11,
        558,
        30,
        51361
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1258.47998046875,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1256.6799774169922,
      "temperature": 0.0,
      "text": " Every one of these tools at the end",
      "tokens": [
        51361,
        2048,
        472,
        295,
        613,
        3873,
        412,
        264,
        917,
        51451
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1261.8999786376953,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1258.47998046875,
      "temperature": 0.0,
      "text": " is running the new fundamental unit of knowledge work.",
      "tokens": [
        51451,
        307,
        2614,
        264,
        777,
        8088,
        4985,
        295,
        3601,
        589,
        13,
        51622
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 1263.6199798583984,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 1261.8999786376953,
      "temperature": 0.0,
      "text": " It's all about the prompt",
      "tokens": [
        51622,
        467,
        311,
        439,
        466,
        264,
        12391,
        51708
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1266.739974975586,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1263.6199798583984,
      "temperature": 0.0,
      "text": " and agents is how we scale the prompt up.",
      "tokens": [
        50364,
        293,
        12554,
        307,
        577,
        321,
        4373,
        264,
        12391,
        493,
        13,
        50520
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1269.1399765014648,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1266.739974975586,
      "temperature": 0.0,
      "text": " This is how we scale up our impact.",
      "tokens": [
        50520,
        639,
        307,
        577,
        321,
        4373,
        493,
        527,
        2712,
        13,
        50640
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1270.97998046875,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1269.1399765014648,
      "temperature": 0.0,
      "text": " At the beginning, I said we would talk about,",
      "tokens": [
        50640,
        1711,
        264,
        2863,
        11,
        286,
        848,
        321,
        576,
        751,
        466,
        11,
        50732
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1273.3399810791016,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1270.97998046875,
      "temperature": 0.0,
      "text": " why is everyone so obsessed with agents?",
      "tokens": [
        50732,
        983,
        307,
        1518,
        370,
        16923,
        365,
        12554,
        30,
        50850
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1275.739974975586,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1273.3399810791016,
      "temperature": 0.0,
      "text": " This is why, it's because agents",
      "tokens": [
        50850,
        639,
        307,
        983,
        11,
        309,
        311,
        570,
        12554,
        50970
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1278.579978942871,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1275.739974975586,
      "temperature": 0.0,
      "text": " lets us scale up our compute usage.",
      "tokens": [
        50970,
        6653,
        505,
        4373,
        493,
        527,
        14722,
        14924,
        13,
        51112
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1280.2199783325195,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1278.579978942871,
      "temperature": 0.0,
      "text": " And in the age of generative AI,",
      "tokens": [
        51112,
        400,
        294,
        264,
        3205,
        295,
        1337,
        1166,
        7318,
        11,
        51194
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1283.9399795532227,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1280.2199783325195,
      "temperature": 0.0,
      "text": " when you scale your compute, you scale your impact.",
      "tokens": [
        51194,
        562,
        291,
        4373,
        428,
        14722,
        11,
        291,
        4373,
        428,
        2712,
        13,
        51380
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1286.97998046875,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1283.9399795532227,
      "temperature": 0.0,
      "text": " This is a big theme on the Andi Dev Dan channel.",
      "tokens": [
        51380,
        639,
        307,
        257,
        955,
        6314,
        322,
        264,
        400,
        72,
        9096,
        3394,
        2269,
        13,
        51532
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1289.0399780273438,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1286.97998046875,
      "temperature": 0.0,
      "text": " Right now in Q1, 2025,",
      "tokens": [
        51532,
        1779,
        586,
        294,
        1249,
        16,
        11,
        39209,
        11,
        51635
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1290.4999771118164,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1289.0399780273438,
      "temperature": 0.0,
      "text": " the most important thing we can do",
      "tokens": [
        51635,
        264,
        881,
        1021,
        551,
        321,
        393,
        360,
        51708
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 1293.3399810791016,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 1290.4999771118164,
      "temperature": 0.0,
      "text": " is figure out how to scale our compute.",
      "tokens": [
        51708,
        307,
        2573,
        484,
        577,
        281,
        4373,
        527,
        14722,
        13,
        51850
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 1295.1799774169922,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 1294.0199813842773,
      "temperature": 0.0,
      "text": " Agents are the name of the game.",
      "tokens": [
        50398,
        2725,
        791,
        366,
        264,
        1315,
        295,
        264,
        1216,
        13,
        50456
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 1296.6999816894531,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 1295.1799774169922,
      "temperature": 0.0,
      "text": " You just saw what we did here",
      "tokens": [
        50456,
        509,
        445,
        1866,
        437,
        321,
        630,
        510,
        50532
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 1300.2199783325195,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 1296.6999816894531,
      "temperature": 0.0,
      "text": " with a DuckDB domain-specific focus agent",
      "tokens": [
        50532,
        365,
        257,
        29266,
        27735,
        9274,
        12,
        29258,
        1879,
        9461,
        50708
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 1303.0599746704102,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 1300.2199783325195,
      "temperature": 0.0,
      "text": " with only five tools, right?",
      "tokens": [
        50708,
        365,
        787,
        1732,
        3873,
        11,
        558,
        30,
        50850
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 1306.0199813842773,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 1303.0599746704102,
      "temperature": 0.0,
      "text": " It gathers context, it understands the structure,",
      "tokens": [
        50850,
        467,
        290,
        11850,
        4319,
        11,
        309,
        15146,
        264,
        3877,
        11,
        50998
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 1309.4199829101562,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 1306.0199813842773,
      "temperature": 0.0,
      "text": " it then internally validates for hard problems,",
      "tokens": [
        50998,
        309,
        550,
        19501,
        7363,
        1024,
        337,
        1152,
        2740,
        11,
        51168
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 1310.9399719238281,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 1309.4199829101562,
      "temperature": 0.0,
      "text": " and then it gives us the fun.",
      "tokens": [
        51168,
        293,
        550,
        309,
        2709,
        505,
        264,
        1019,
        13,
        51244
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1311.6799756288528,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1310.5999755859375,
      "temperature": 0.0,
      "text": " final result, right?",
      "tokens": [
        50364,
        2572,
        1874,
        11,
        558,
        30,
        50418
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1315.69997549057,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1311.6799756288528,
      "temperature": 0.0,
      "text": " When we take Astral's UV and the ability to package",
      "tokens": [
        50418,
        1133,
        321,
        747,
        12884,
        2155,
        311,
        17887,
        293,
        264,
        3485,
        281,
        7372,
        50619
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1319.8999757766724,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1315.69997549057,
      "temperature": 0.0,
      "text": " dependencies and these isolated single file agents, right?",
      "tokens": [
        50619,
        36606,
        293,
        613,
        14621,
        2167,
        3991,
        12554,
        11,
        558,
        30,
        50829
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1322.9399757385254,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1319.8999757766724,
      "temperature": 0.0,
      "text": " These single file scripts, this really lets us move fast,",
      "tokens": [
        50829,
        1981,
        2167,
        3991,
        23294,
        11,
        341,
        534,
        6653,
        505,
        1286,
        2370,
        11,
        50981
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1327.379976272583,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1322.9399757385254,
      "temperature": 0.0,
      "text": " scale or compute and get work done and solve problems fast",
      "tokens": [
        50981,
        4373,
        420,
        14722,
        293,
        483,
        589,
        1096,
        293,
        5039,
        2740,
        2370,
        51203
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1329.6599750518799,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1327.379976272583,
      "temperature": 0.0,
      "text": " without over investing, right?",
      "tokens": [
        51203,
        1553,
        670,
        10978,
        11,
        558,
        30,
        51317
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1330.739974975586,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1329.6599750518799,
      "temperature": 0.0,
      "text": " I think that's a really big theme.",
      "tokens": [
        51317,
        286,
        519,
        300,
        311,
        257,
        534,
        955,
        6314,
        13,
        51371
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1333.7599754333496,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1330.739974975586,
      "temperature": 0.0,
      "text": " You don't want to over invest in this massive monolithic",
      "tokens": [
        51371,
        509,
        500,
        380,
        528,
        281,
        670,
        1963,
        294,
        341,
        5994,
        1108,
        42878,
        51522
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1336.379976272583,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1333.7599754333496,
      "temperature": 0.0,
      "text": " tool that, you know, you're trying to deploy in tens and",
      "tokens": [
        51522,
        2290,
        300,
        11,
        291,
        458,
        11,
        291,
        434,
        1382,
        281,
        7274,
        294,
        10688,
        293,
        51653
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.26673418283462524,
      "compression_ratio": 1.6712802648544312,
      "end": 1339.1399765014648,
      "no_speech_prob": 0.11594191938638687,
      "seek": 0,
      "start": 1336.379976272583,
      "temperature": 0.0,
      "text": " hundreds of ways, just build one agent, make it do one",
      "tokens": [
        51653,
        6779,
        295,
        2098,
        11,
        445,
        1322,
        472,
        9461,
        11,
        652,
        309,
        360,
        472,
        51791
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1342.9799766540527,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1339.1399765014648,
      "temperature": 0.0,
      "text": " thing extremely well and keep it lean and lightweight,",
      "tokens": [
        50364,
        551,
        4664,
        731,
        293,
        1066,
        309,
        11659,
        293,
        22052,
        11,
        50556
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1343.8199768066406,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1342.9799766540527,
      "temperature": 0.0,
      "text": " right?",
      "tokens": [
        50556,
        558,
        30,
        50598
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1345.3799743652344,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1343.8199768066406,
      "temperature": 0.0,
      "text": " It's all about that agentic structure.",
      "tokens": [
        50598,
        467,
        311,
        439,
        466,
        300,
        9461,
        299,
        3877,
        13,
        50676
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1346.5399742126465,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1345.3799743652344,
      "temperature": 0.0,
      "text": " What does your loop look like?",
      "tokens": [
        50676,
        708,
        775,
        428,
        6367,
        574,
        411,
        30,
        50734
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1347.9999771118164,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1346.5399742126465,
      "temperature": 0.0,
      "text": " How can your agent get smarter?",
      "tokens": [
        50734,
        1012,
        393,
        428,
        9461,
        483,
        20294,
        30,
        50807
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1351.2599754333496,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1347.9999771118164,
      "temperature": 0.0,
      "text": " How can your agent gather context to solve that specific",
      "tokens": [
        50807,
        1012,
        393,
        428,
        9461,
        5448,
        4319,
        281,
        5039,
        300,
        2685,
        50970
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1352.9999771118164,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1351.2599754333496,
      "temperature": 0.0,
      "text": " problem you're trying to solve?",
      "tokens": [
        50970,
        1154,
        291,
        434,
        1382,
        281,
        5039,
        30,
        51057
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1353.8399772644043,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1352.9999771118164,
      "temperature": 0.0,
      "text": " All right.",
      "tokens": [
        51057,
        1057,
        558,
        13,
        51099
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1355.0599746704102,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1353.8399772644043,
      "temperature": 0.0,
      "text": " This is the key.",
      "tokens": [
        51099,
        639,
        307,
        264,
        2141,
        13,
        51160
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1357.739974975586,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1355.0599746704102,
      "temperature": 0.0,
      "text": " This code base is going to be linked in the description",
      "tokens": [
        51160,
        639,
        3089,
        3096,
        307,
        516,
        281,
        312,
        9408,
        294,
        264,
        3855,
        51294
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1358.5799751281738,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1357.739974975586,
      "temperature": 0.0,
      "text": " for you.",
      "tokens": [
        51294,
        337,
        291,
        13,
        51336
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1361.1399765014648,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1358.5799751281738,
      "temperature": 0.0,
      "text": " Drop the like, drop the sub and, you know, drop a comment.",
      "tokens": [
        51336,
        17675,
        264,
        411,
        11,
        3270,
        264,
        1422,
        293,
        11,
        291,
        458,
        11,
        3270,
        257,
        2871,
        13,
        51464
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1364.1799774169922,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1361.1399765014648,
      "temperature": 0.0,
      "text": " Let me know how deep into agents you are right now.",
      "tokens": [
        51464,
        961,
        385,
        458,
        577,
        2452,
        666,
        12554,
        291,
        366,
        558,
        586,
        13,
        51616
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1365.299976348877,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1364.1799774169922,
      "temperature": 0.0,
      "text": " Are you on the surface?",
      "tokens": [
        51616,
        2014,
        291,
        322,
        264,
        3753,
        30,
        51672
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.21300627291202545,
      "compression_ratio": 1.7933332920074463,
      "end": 1368.1199760437012,
      "no_speech_prob": 0.020644845440983772,
      "seek": 2854,
      "start": 1365.299976348877,
      "temperature": 0.0,
      "text": " Are you, you know, trying to understand agent structures?",
      "tokens": [
        51672,
        2014,
        291,
        11,
        291,
        458,
        11,
        1382,
        281,
        1223,
        9461,
        9227,
        30,
        51813
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1370.2799758911133,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1368.1199760437012,
      "temperature": 0.0,
      "text": " Are you using any agents right now?",
      "tokens": [
        50364,
        2014,
        291,
        1228,
        604,
        12554,
        558,
        586,
        30,
        50472
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1372.9199752807617,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1370.2799758911133,
      "temperature": 0.0,
      "text": " And, you know, let me know what you think about this idea",
      "tokens": [
        50472,
        400,
        11,
        291,
        458,
        11,
        718,
        385,
        458,
        437,
        291,
        519,
        466,
        341,
        1558,
        50604
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1376.6399765014648,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1372.9199752807617,
      "temperature": 0.0,
      "text": " to build out these single file agents that you can quickly",
      "tokens": [
        50604,
        281,
        1322,
        484,
        613,
        2167,
        3991,
        12554,
        300,
        291,
        393,
        2661,
        50790
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1379.5199737548828,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1376.6399765014648,
      "temperature": 0.0,
      "text": " reuse and redeploy with the help of, you know,",
      "tokens": [
        50790,
        26225,
        293,
        14328,
        2384,
        365,
        264,
        854,
        295,
        11,
        291,
        458,
        11,
        50934
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1382.0599746704102,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1379.5199737548828,
      "temperature": 0.0,
      "text": " whatever your favorite AI coding tooling is.",
      "tokens": [
        50934,
        2035,
        428,
        2954,
        7318,
        17720,
        46593,
        307,
        13,
        51061
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1384.1599731445312,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1382.0599746704102,
      "temperature": 0.0,
      "text": " At a high level, the longer your prompt chain,",
      "tokens": [
        51061,
        1711,
        257,
        1090,
        1496,
        11,
        264,
        2854,
        428,
        12391,
        5021,
        11,
        51166
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1386.3199768066406,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1384.1599731445312,
      "temperature": 0.0,
      "text": " the more compute you're using, right?",
      "tokens": [
        51166,
        264,
        544,
        14722,
        291,
        434,
        1228,
        11,
        558,
        30,
        51274
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1387.959976196289,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1386.3199768066406,
      "temperature": 0.0,
      "text": " And when we think about it,",
      "tokens": [
        51274,
        400,
        562,
        321,
        519,
        466,
        309,
        11,
        51356
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1390.959976196289,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1387.959976196289,
      "temperature": 0.0,
      "text": " what's happening in this agent loop that we're running here",
      "tokens": [
        51356,
        437,
        311,
        2737,
        294,
        341,
        9461,
        6367,
        300,
        321,
        434,
        2614,
        510,
        51506
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1393.3999786376953,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1390.959976196289,
      "temperature": 0.0,
      "text": " in both our SQLite and our OpenAI version,",
      "tokens": [
        51506,
        294,
        1293,
        527,
        19200,
        642,
        293,
        527,
        7238,
        48698,
        3037,
        11,
        51628
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1394.2799758911133,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1393.3999786376953,
      "temperature": 0.0,
      "text": " you know, what's happening here,",
      "tokens": [
        51628,
        291,
        458,
        11,
        437,
        311,
        2737,
        510,
        11,
        51672
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1395.239974975586,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1394.2799758911133,
      "temperature": 0.0,
      "text": " we can kick this off again.",
      "tokens": [
        51672,
        321,
        393,
        4437,
        341,
        766,
        797,
        13,
        51720
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.1903737187385559,
      "compression_ratio": 1.8057324886322021,
      "end": 1396.959976196289,
      "no_speech_prob": 0.003222414990887046,
      "seek": 5752,
      "start": 1395.239974975586,
      "temperature": 0.0,
      "text": " Let's go ahead and ask another question here.",
      "tokens": [
        51720,
        961,
        311,
        352,
        2286,
        293,
        1029,
        1071,
        1168,
        510,
        13,
        51806
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1400.0199737548828,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1396.959976196289,
      "temperature": 0.0,
      "text": " Let's list five users, GT, greater than,",
      "tokens": [
        50364,
        961,
        311,
        1329,
        1732,
        5022,
        11,
        17530,
        11,
        5044,
        813,
        11,
        50517
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1403.079978942871,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1400.0199737548828,
      "temperature": 0.0,
      "text": " status, archived, or pending.",
      "tokens": [
        50517,
        6558,
        11,
        3912,
        3194,
        11,
        420,
        32110,
        13,
        50670
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1404.1599731445312,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1403.079978942871,
      "temperature": 0.0,
      "text": " All right.",
      "tokens": [
        50670,
        1057,
        558,
        13,
        50724
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1405.239974975586,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1404.1599731445312,
      "temperature": 0.0,
      "text": " Let's kick that off.",
      "tokens": [
        50724,
        961,
        311,
        4437,
        300,
        766,
        13,
        50778
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1406.079978942871,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1405.239974975586,
      "temperature": 0.0,
      "text": " And",
      "tokens": [
        50778,
        400,
        50820
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1409.8799743652344,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1409.0399780273438,
      "temperature": 0.0,
      "text": " fantastic.",
      "tokens": [
        50968,
        5456,
        13,
        51010
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1413.1599731445312,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1409.8799743652344,
      "temperature": 0.0,
      "text": " So we can see that we have status, archived, or pending.",
      "tokens": [
        51010,
        407,
        321,
        393,
        536,
        300,
        321,
        362,
        6558,
        11,
        3912,
        3194,
        11,
        420,
        32110,
        13,
        51174
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1415.2999725341797,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1413.1599731445312,
      "temperature": 0.0,
      "text": " Age is always over 30, right?",
      "tokens": [
        51174,
        16280,
        307,
        1009,
        670,
        2217,
        11,
        558,
        30,
        51281
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1417.6399765014648,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1415.2999725341797,
      "temperature": 0.0,
      "text": " And this is running in this agentic loop.",
      "tokens": [
        51281,
        400,
        341,
        307,
        2614,
        294,
        341,
        9461,
        299,
        6367,
        13,
        51398
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1419.1999740600586,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1417.6399765014648,
      "temperature": 0.0,
      "text": " It's solving this problem automatically.",
      "tokens": [
        51398,
        467,
        311,
        12606,
        341,
        1154,
        6772,
        13,
        51476
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1421.2199783325195,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1419.1999740600586,
      "temperature": 0.0,
      "text": " It has the tools it needs to do the job.",
      "tokens": [
        51476,
        467,
        575,
        264,
        3873,
        309,
        2203,
        281,
        360,
        264,
        1691,
        13,
        51577
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.234490767121315,
      "compression_ratio": 1.5907173156738281,
      "end": 1423.239974975586,
      "no_speech_prob": 0.005641823168843985,
      "seek": 8636,
      "start": 1421.2199783325195,
      "temperature": 0.0,
      "text": " And, you know, something I want to mention here,",
      "tokens": [
        51577,
        400,
        11,
        291,
        458,
        11,
        746,
        286,
        528,
        281,
        2152,
        510,
        11,
        51678
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1424.4799728393555,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1423.239974975586,
      "temperature": 0.0,
      "text": " you can think about an agent",
      "tokens": [
        50364,
        291,
        393,
        519,
        466,
        364,
        9461,
        50426
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1427.4999771118164,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1424.4799728393555,
      "temperature": 0.0,
      "text": " as a elongated prompt chain, right?",
      "tokens": [
        50426,
        382,
        257,
        40786,
        770,
        12391,
        5021,
        11,
        558,
        30,
        50577
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1430.4799728393555,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1427.4999771118164,
      "temperature": 0.0,
      "text": " It's a series of prompt calls over and over and over again,",
      "tokens": [
        50577,
        467,
        311,
        257,
        2638,
        295,
        12391,
        5498,
        670,
        293,
        670,
        293,
        670,
        797,
        11,
        50726
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1432.9999771118164,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1430.4799728393555,
      "temperature": 0.0,
      "text": " targeting a specific domain problem.",
      "tokens": [
        50726,
        17918,
        257,
        2685,
        9274,
        1154,
        13,
        50852
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1435.3199768066406,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1432.9999771118164,
      "temperature": 0.0,
      "text": " And it's all about figuring out how to best solve",
      "tokens": [
        50852,
        400,
        309,
        311,
        439,
        466,
        15213,
        484,
        577,
        281,
        1151,
        5039,
        50968
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1437.4799728393555,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1435.3199768066406,
      "temperature": 0.0,
      "text": " that problem with the compute that you give it.",
      "tokens": [
        50968,
        300,
        1154,
        365,
        264,
        14722,
        300,
        291,
        976,
        309,
        13,
        51076
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1438.8799743652344,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1437.4799728393555,
      "temperature": 0.0,
      "text": " And so if an error occurred here,",
      "tokens": [
        51076,
        400,
        370,
        498,
        364,
        6713,
        11068,
        510,
        11,
        51146
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1440.5599822998047,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1438.8799743652344,
      "temperature": 0.0,
      "text": " we would probably need to give, you know,",
      "tokens": [
        51146,
        321,
        576,
        1391,
        643,
        281,
        976,
        11,
        291,
        458,
        11,
        51230
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 58,
      "avg_logprob": -0.21441873908042908,
      "compression_ratio": 1.6666666269302368,
      "end": 1441.8799743652344,
      "no_speech_prob": 0.00806165300309658,
      "seek": 11264,
      "start": 1440.5599822998047,
      "temperature": 0.0,
      "text": " more compute, more,",
      "tokens": [
        51230,
        544,
        14722,
        11,
        544,
        11,
        51296
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1444.9999730587006,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1441.6599731445312,
      "temperature": 0.0,
      "text": " or, you know, loops, we're running O3 mini",
      "tokens": [
        50364,
        420,
        11,
        291,
        458,
        11,
        16121,
        11,
        321,
        434,
        2614,
        422,
        18,
        8382,
        50531
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1446.0799732208252,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1444.9999730587006,
      "temperature": 0.0,
      "text": " is a powerful reasoning model.",
      "tokens": [
        50531,
        307,
        257,
        4005,
        21577,
        2316,
        13,
        50585
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1448.1599731445312,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1446.0799732208252,
      "temperature": 0.0,
      "text": " So, you know, as it's thinking through what tools to call",
      "tokens": [
        50585,
        407,
        11,
        291,
        458,
        11,
        382,
        309,
        311,
        1953,
        807,
        437,
        3873,
        281,
        818,
        50689
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1449.2399730682373,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1448.1599731445312,
      "temperature": 0.0,
      "text": " and solving these problems,",
      "tokens": [
        50689,
        293,
        12606,
        613,
        2740,
        11,
        50743
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1450.919973373413,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1449.2399730682373,
      "temperature": 0.0,
      "text": " it's doing an extraordinary job.",
      "tokens": [
        50743,
        309,
        311,
        884,
        364,
        10581,
        1691,
        13,
        50827
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1453.3199729919434,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1450.919973373413,
      "temperature": 0.0,
      "text": " An interesting way to think about the AI agent is",
      "tokens": [
        50827,
        1107,
        1880,
        636,
        281,
        519,
        466,
        264,
        7318,
        9461,
        307,
        50947
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1454.7399730682373,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1453.3199729919434,
      "temperature": 0.0,
      "text": " that the more compute you're giving it,",
      "tokens": [
        50947,
        300,
        264,
        544,
        14722,
        291,
        434,
        2902,
        309,
        11,
        51018
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1455.759973526001,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1454.7399730682373,
      "temperature": 0.0,
      "text": " basically what we're doing is",
      "tokens": [
        51018,
        1936,
        437,
        321,
        434,
        884,
        307,
        51069
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1457.8799724578857,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1455.759973526001,
      "temperature": 0.0,
      "text": " we're extending the prompt chain, right?",
      "tokens": [
        51069,
        321,
        434,
        24360,
        264,
        12391,
        5021,
        11,
        558,
        30,
        51175
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1461.6399726867676,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1457.8799724578857,
      "temperature": 0.0,
      "text": " We're elongating the number of compute runs that it has.",
      "tokens": [
        51175,
        492,
        434,
        40786,
        990,
        264,
        1230,
        295,
        14722,
        6676,
        300,
        309,
        575,
        13,
        51363
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1463.9599723815918,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1461.6399726867676,
      "temperature": 0.0,
      "text": " So if we wanted to solve a really hard problem,",
      "tokens": [
        51363,
        407,
        498,
        321,
        1415,
        281,
        5039,
        257,
        534,
        1152,
        1154,
        11,
        51479
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1467.2799739837646,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1463.9599723815918,
      "temperature": 0.0,
      "text": " for instance, you know, OpenAI's deep research tool,",
      "tokens": [
        51479,
        337,
        5197,
        11,
        291,
        458,
        11,
        7238,
        48698,
        311,
        2452,
        2132,
        2290,
        11,
        51645
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 1470.5599727630615,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 1467.2799739837646,
      "temperature": 0.0,
      "text": " this thing runs for five to 30 minutes, right?",
      "tokens": [
        51645,
        341,
        551,
        6676,
        337,
        1732,
        281,
        2217,
        2077,
        11,
        558,
        30,
        51809
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1471.8799724578857,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1470.5599727630615,
      "temperature": 0.0,
      "text": " So you can imagine, you know,",
      "tokens": [
        50364,
        407,
        291,
        393,
        3811,
        11,
        291,
        458,
        11,
        50430
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1473.9999732971191,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1471.8799724578857,
      "temperature": 0.0,
      "text": " it's compute loop is, you know,",
      "tokens": [
        50430,
        309,
        311,
        14722,
        6367,
        307,
        11,
        291,
        458,
        11,
        50536
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1477.4399719238281,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1473.9999732971191,
      "temperature": 0.0,
      "text": " blasted up to like a hundred across various tools,",
      "tokens": [
        50536,
        12035,
        292,
        493,
        281,
        411,
        257,
        3262,
        2108,
        3683,
        3873,
        11,
        50708
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1480.0799713134766,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1477.4399719238281,
      "temperature": 0.0,
      "text": " various functions, you know, various capabilities.",
      "tokens": [
        50708,
        3683,
        6828,
        11,
        291,
        458,
        11,
        3683,
        10862,
        13,
        50840
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1481.4799728393555,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1480.0799713134766,
      "temperature": 0.0,
      "text": " That's a really powerful idea",
      "tokens": [
        50840,
        663,
        311,
        257,
        534,
        4005,
        1558,
        50910
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1484.0799713134766,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1481.4799728393555,
      "temperature": 0.0,
      "text": " we're gonna be looking into more on the channel.",
      "tokens": [
        50910,
        321,
        434,
        799,
        312,
        1237,
        666,
        544,
        322,
        264,
        2269,
        13,
        51040
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1486.5199737548828,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1484.0799713134766,
      "temperature": 0.0,
      "text": " Like I mentioned, I'm gonna have these single file agents",
      "tokens": [
        51040,
        1743,
        286,
        2835,
        11,
        286,
        478,
        799,
        362,
        613,
        2167,
        3991,
        12554,
        51162
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1488.1999740600586,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1486.5199737548828,
      "temperature": 0.0,
      "text": " in a code base for you to check out,",
      "tokens": [
        51162,
        294,
        257,
        3089,
        3096,
        337,
        291,
        281,
        1520,
        484,
        11,
        51246
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1489.7599716186523,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1488.1999740600586,
      "temperature": 0.0,
      "text": " tweak and make your own.",
      "tokens": [
        51246,
        29879,
        293,
        652,
        428,
        1065,
        13,
        51324
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1491.279972076416,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1489.7599716186523,
      "temperature": 0.0,
      "text": " I'll add a couple additional versions here",
      "tokens": [
        51324,
        286,
        603,
        909,
        257,
        1916,
        4497,
        9606,
        510,
        51400
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1492.9999732971191,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1491.279972076416,
      "temperature": 0.0,
      "text": " that I was playing with so that you can, you know,",
      "tokens": [
        51400,
        300,
        286,
        390,
        2433,
        365,
        370,
        300,
        291,
        393,
        11,
        291,
        458,
        11,
        51486
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1494.4399719238281,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1492.9999732971191,
      "temperature": 0.0,
      "text": " check them out and build out your own.",
      "tokens": [
        51486,
        1520,
        552,
        484,
        293,
        1322,
        484,
        428,
        1065,
        13,
        51558
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1496.839973449707,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1494.4399719238281,
      "temperature": 0.0,
      "text": " I have a version where I have the meta prompt",
      "tokens": [
        51558,
        286,
        362,
        257,
        3037,
        689,
        286,
        362,
        264,
        19616,
        12391,
        51678
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1498.0799713134766,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1496.839973449707,
      "temperature": 0.0,
      "text": " we've talked about on the channel",
      "tokens": [
        51678,
        321,
        600,
        2825,
        466,
        322,
        264,
        2269,
        51740
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 1499.6399726867676,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 1498.0799713134766,
      "temperature": 0.0,
      "text": " inside of a single file agent.",
      "tokens": [
        51740,
        1854,
        295,
        257,
        2167,
        3991,
        9461,
        13,
        51818
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1502.8799743652344,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1499.6399726867676,
      "temperature": 0.0,
      "text": " You can just quickly query your meta prompting agent",
      "tokens": [
        50364,
        509,
        393,
        445,
        2661,
        14581,
        428,
        19616,
        12391,
        278,
        9461,
        50526
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1504.1999740600586,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1502.8799743652344,
      "temperature": 0.0,
      "text": " to generate a new prompt for you.",
      "tokens": [
        50526,
        281,
        8460,
        257,
        777,
        12391,
        337,
        291,
        13,
        50592
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1506.3599700927734,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1504.1999740600586,
      "temperature": 0.0,
      "text": " Things are moving fast, agents are here.",
      "tokens": [
        50592,
        9514,
        366,
        2684,
        2370,
        11,
        12554,
        366,
        510,
        13,
        50700
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1507.839973449707,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1506.3599700927734,
      "temperature": 0.0,
      "text": " One of the most important agents",
      "tokens": [
        50700,
        1485,
        295,
        264,
        881,
        1021,
        12554,
        50774
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1510.959976196289,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1507.839973449707,
      "temperature": 0.0,
      "text": " and one of the most important things you can do right now",
      "tokens": [
        50774,
        293,
        472,
        295,
        264,
        881,
        1021,
        721,
        291,
        393,
        360,
        558,
        586,
        50930
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1514.9999694824219,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1510.959976196289,
      "temperature": 0.0,
      "text": " is learn how to write code with AI and not just learn,",
      "tokens": [
        50930,
        307,
        1466,
        577,
        281,
        2464,
        3089,
        365,
        7318,
        293,
        406,
        445,
        1466,
        11,
        51132
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1518.119972229004,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1514.9999694824219,
      "temperature": 0.0,
      "text": " but really scale your capabilities",
      "tokens": [
        51132,
        457,
        534,
        4373,
        428,
        10862,
        51288
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1519.8799743652344,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1518.119972229004,
      "temperature": 0.0,
      "text": " with writing code with AI.",
      "tokens": [
        51288,
        365,
        3579,
        3089,
        365,
        7318,
        13,
        51376
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1520.8199768066406,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1519.8799743652344,
      "temperature": 0.0,
      "text": " Many of you on the channel,",
      "tokens": [
        51376,
        5126,
        295,
        291,
        322,
        264,
        2269,
        11,
        51423
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1523.3599700927734,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1520.8199768066406,
      "temperature": 0.0,
      "text": " you've already dove in to principled AI coding.",
      "tokens": [
        51423,
        291,
        600,
        1217,
        23287,
        294,
        281,
        3681,
        15551,
        7318,
        17720,
        13,
        51550
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1526.0799713134766,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1523.3599700927734,
      "temperature": 0.0,
      "text": " Let me just pitch this for those who haven't taken it yet.",
      "tokens": [
        51550,
        961,
        385,
        445,
        7293,
        341,
        337,
        729,
        567,
        2378,
        380,
        2726,
        309,
        1939,
        13,
        51686
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1527.3999710083008,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1526.0799713134766,
      "temperature": 0.0,
      "text": " This is really important",
      "tokens": [
        51686,
        639,
        307,
        534,
        1021,
        51752
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 1529.3999710083008,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 1527.3999710083008,
      "temperature": 0.0,
      "text": " and I wanna make sure I'm sharing this tool",
      "tokens": [
        51752,
        293,
        286,
        1948,
        652,
        988,
        286,
        478,
        5414,
        341,
        2290,
        51852
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1531.5999755859375,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1530.1599731445312,
      "temperature": 0.0,
      "text": " so that everyone is understanding",
      "tokens": [
        50402,
        370,
        300,
        1518,
        307,
        3701,
        50474
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1534.7999725341797,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1531.5999755859375,
      "temperature": 0.0,
      "text": " the state engineering is in and how they can progress,",
      "tokens": [
        50474,
        264,
        1785,
        7043,
        307,
        294,
        293,
        577,
        436,
        393,
        4205,
        11,
        50634
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1538.6399765014648,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1534.7999725341797,
      "temperature": 0.0,
      "text": " keep up and thrive in the new world of generative AI.",
      "tokens": [
        50634,
        1066,
        493,
        293,
        21233,
        294,
        264,
        777,
        1002,
        295,
        1337,
        1166,
        7318,
        13,
        50826
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1541.3599700927734,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1538.6399765014648,
      "temperature": 0.0,
      "text": " So principled AI coding is my take",
      "tokens": [
        50826,
        407,
        3681,
        15551,
        7318,
        17720,
        307,
        452,
        747,
        50962
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1544.5999755859375,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1541.3599700927734,
      "temperature": 0.0,
      "text": " on how to transition from the old ways of engineering",
      "tokens": [
        50962,
        322,
        577,
        281,
        6034,
        490,
        264,
        1331,
        2098,
        295,
        7043,
        51124
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1545.5999755859375,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1544.5999755859375,
      "temperature": 0.0,
      "text": " to the new way.",
      "tokens": [
        51124,
        281,
        264,
        777,
        636,
        13,
        51174
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1548.5399703979492,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1545.5999755859375,
      "temperature": 0.0,
      "text": " We now have over a thousand engineers",
      "tokens": [
        51174,
        492,
        586,
        362,
        670,
        257,
        4714,
        11955,
        51321
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1550.119972229004,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1548.5399703979492,
      "temperature": 0.0,
      "text": " that have taken principled AI coding,",
      "tokens": [
        51321,
        300,
        362,
        2726,
        3681,
        15551,
        7318,
        17720,
        11,
        51400
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1553.8599700927734,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1550.119972229004,
      "temperature": 0.0,
      "text": " that have a new perspective and actionable patterns",
      "tokens": [
        51400,
        300,
        362,
        257,
        777,
        4585,
        293,
        45098,
        8294,
        51587
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 1556.719970703125,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 1553.8599700927734,
      "temperature": 0.0,
      "text": " and principles they can use for their engineering",
      "tokens": [
        51587,
        293,
        9156,
        436,
        393,
        764,
        337,
        641,
        7043,
        51730
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 1559.4799728393555,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 1556.719970703125,
      "temperature": 0.0,
      "text": " in today's landscape of generative AI",
      "tokens": [
        50364,
        294,
        965,
        311,
        9661,
        295,
        1337,
        1166,
        7318,
        50502
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 1560.3599700927734,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 1559.4799728393555,
      "temperature": 0.0,
      "text": " and more importantly,",
      "tokens": [
        50502,
        293,
        544,
        8906,
        11,
        50546
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 1564.4399719238281,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 1560.3599700927734,
      "temperature": 0.0,
      "text": " for the next wave of generative AI based engineering.",
      "tokens": [
        50546,
        337,
        264,
        958,
        5772,
        295,
        1337,
        1166,
        7318,
        2361,
        7043,
        13,
        50750
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 1566.719970703125,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 1564.4399719238281,
      "temperature": 0.0,
      "text": " So, I don't know if you've noticed,",
      "tokens": [
        50750,
        407,
        11,
        286,
        500,
        380,
        458,
        498,
        291,
        600,
        5694,
        11,
        50864
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 1568.5599746704102,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 1566.719970703125,
      "temperature": 0.0,
      "text": " if your eyes are open, you've probably noticed this,",
      "tokens": [
        50864,
        498,
        428,
        2575,
        366,
        1269,
        11,
        291,
        600,
        1391,
        5694,
        341,
        11,
        50956
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 1570.3599700927734,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 1568.5599746704102,
      "temperature": 0.0,
      "text": " but software engineering has changed",
      "tokens": [
        50956,
        457,
        4722,
        7043,
        575,
        3105,
        51046
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 1572.3999786376953,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 1570.3599700927734,
      "temperature": 0.0,
      "text": " and it's time to change with it.",
      "tokens": [
        51046,
        293,
        309,
        311,
        565,
        281,
        1319,
        365,
        309,
        13,
        51148
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1576.5599706172943,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1572.719970703125,
      "temperature": 0.0,
      "text": " is the largest productivity multiplier for engineers to ever exist.",
      "tokens": [
        50364,
        307,
        264,
        6443,
        15604,
        44106,
        337,
        11955,
        281,
        1562,
        2514,
        13,
        50556
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1579.4399704933167,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1576.5599706172943,
      "temperature": 0.0,
      "text": " It's something that you can't miss out on, okay?",
      "tokens": [
        50556,
        467,
        311,
        746,
        300,
        291,
        393,
        380,
        1713,
        484,
        322,
        11,
        1392,
        30,
        50700
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1581.759970664978,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1579.4399704933167,
      "temperature": 0.0,
      "text": " If you miss out on this, you'll be left behind.",
      "tokens": [
        50700,
        759,
        291,
        1713,
        484,
        322,
        341,
        11,
        291,
        603,
        312,
        1411,
        2261,
        13,
        50816
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1585.759970664978,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1581.759970664978,
      "temperature": 0.0,
      "text": " I think 2025 is the last year where you can write code without AI",
      "tokens": [
        50816,
        286,
        519,
        39209,
        307,
        264,
        1036,
        1064,
        689,
        291,
        393,
        2464,
        3089,
        1553,
        7318,
        51016
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1589.0399703979492,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1586.3999710083008,
      "temperature": 0.0,
      "text": " and really be useful, right?",
      "tokens": [
        51048,
        293,
        534,
        312,
        4420,
        11,
        558,
        30,
        51180
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1590.2399711608887,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1589.0399703979492,
      "temperature": 0.0,
      "text": " Really be employable.",
      "tokens": [
        51180,
        4083,
        312,
        3188,
        712,
        13,
        51240
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1594.639970779419,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1590.799970626831,
      "temperature": 0.0,
      "text": " Really be able to contribute in a meaningful way.",
      "tokens": [
        51268,
        4083,
        312,
        1075,
        281,
        10586,
        294,
        257,
        10995,
        636,
        13,
        51460
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1596.0799713134766,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1594.639970779419,
      "temperature": 0.0,
      "text": " Go on Twitter for five seconds.",
      "tokens": [
        51460,
        1037,
        322,
        5794,
        337,
        1732,
        3949,
        13,
        51532
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1598.3999710083008,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1596.0799713134766,
      "temperature": 0.0,
      "text": " Go on Reddit and, you know, just type in AI Coding.",
      "tokens": [
        51532,
        1037,
        322,
        32210,
        293,
        11,
        291,
        458,
        11,
        445,
        2010,
        294,
        7318,
        383,
        8616,
        13,
        51648
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1599.3599700927734,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1598.3999710083008,
      "temperature": 0.0,
      "text": " Type in Cursor.",
      "tokens": [
        51648,
        15576,
        294,
        383,
        2156,
        284,
        13,
        51696
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1600.719970703125,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1599.3599700927734,
      "temperature": 0.0,
      "text": " Type in Aitor.",
      "tokens": [
        51696,
        15576,
        294,
        316,
        3029,
        13,
        51764
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.22405290603637695,
      "compression_ratio": 1.6464285850524902,
      "end": 1601.7599716186523,
      "no_speech_prob": 0.014727362431585789,
      "seek": 0,
      "start": 1600.719970703125,
      "temperature": 0.0,
      "text": " Type in Klein.",
      "tokens": [
        51764,
        15576,
        294,
        33327,
        13,
        51816
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.19823512434959412,
      "compression_ratio": 1.7649253606796265,
      "end": 1606.159969329834,
      "no_speech_prob": 0.00033534629619680345,
      "seek": 2904,
      "start": 1601.7599716186523,
      "temperature": 0.0,
      "text": " Type in any one of these tools and you'll understand that there are engineers",
      "tokens": [
        50364,
        15576,
        294,
        604,
        472,
        295,
        613,
        3873,
        293,
        291,
        603,
        1223,
        300,
        456,
        366,
        11955,
        50584
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.19823512434959412,
      "compression_ratio": 1.7649253606796265,
      "end": 1611.1999702453613,
      "no_speech_prob": 0.00033534629619680345,
      "seek": 2904,
      "start": 1606.719970703125,
      "temperature": 0.0,
      "text": " all the way from noob beginners to senior, expert, principal,",
      "tokens": [
        50612,
        439,
        264,
        636,
        490,
        572,
        996,
        26992,
        281,
        7965,
        11,
        5844,
        11,
        9716,
        11,
        50836
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.19823512434959412,
      "compression_ratio": 1.7649253606796265,
      "end": 1614.2399711608887,
      "no_speech_prob": 0.00033534629619680345,
      "seek": 2904,
      "start": 1611.1999702453613,
      "temperature": 0.0,
      "text": " big name engineers, right, that you, you know, likely look up to.",
      "tokens": [
        50836,
        955,
        1315,
        11955,
        11,
        558,
        11,
        300,
        291,
        11,
        291,
        458,
        11,
        3700,
        574,
        493,
        281,
        13,
        50988
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.19823512434959412,
      "compression_ratio": 1.7649253606796265,
      "end": 1616.319969177246,
      "no_speech_prob": 0.00033534629619680345,
      "seek": 2904,
      "start": 1614.2399711608887,
      "temperature": 0.0,
      "text": " They understand this curve, right?",
      "tokens": [
        50988,
        814,
        1223,
        341,
        7605,
        11,
        558,
        30,
        51092
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.19823512434959412,
      "compression_ratio": 1.7649253606796265,
      "end": 1617.8399696350098,
      "no_speech_prob": 0.00033534629619680345,
      "seek": 2904,
      "start": 1616.319969177246,
      "temperature": 0.0,
      "text": " They understand these two curves.",
      "tokens": [
        51092,
        814,
        1223,
        613,
        732,
        19490,
        13,
        51168
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.19823512434959412,
      "compression_ratio": 1.7649253606796265,
      "end": 1623.5199699401855,
      "no_speech_prob": 0.00033534629619680345,
      "seek": 2904,
      "start": 1617.8399696350098,
      "temperature": 0.0,
      "text": " You are either using the tool that helps you scale your impact or you're not, okay?",
      "tokens": [
        51168,
        509,
        366,
        2139,
        1228,
        264,
        2290,
        300,
        3665,
        291,
        4373,
        428,
        2712,
        420,
        291,
        434,
        406,
        11,
        1392,
        30,
        51452
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.19823512434959412,
      "compression_ratio": 1.7649253606796265,
      "end": 1627.0399703979492,
      "no_speech_prob": 0.00033534629619680345,
      "seek": 2904,
      "start": 1623.5199699401855,
      "temperature": 0.0,
      "text": " And, you know, just to say it really bluntly,",
      "tokens": [
        51452,
        400,
        11,
        291,
        458,
        11,
        445,
        281,
        584,
        309,
        534,
        32246,
        356,
        11,
        51628
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.19823512434959412,
      "compression_ratio": 1.7649253606796265,
      "end": 1630.319969177246,
      "no_speech_prob": 0.00033534629619680345,
      "seek": 2904,
      "start": 1627.0399703979492,
      "temperature": 0.0,
      "text": " if you're not writing code with AI, if you're still manually coding,",
      "tokens": [
        51628,
        498,
        291,
        434,
        406,
        3579,
        3089,
        365,
        7318,
        11,
        498,
        291,
        434,
        920,
        16945,
        17720,
        11,
        51792
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1632.719970703125,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1630.319969177246,
      "temperature": 0.0,
      "text": " you are not using the best tool for the job anymore.",
      "tokens": [
        50364,
        291,
        366,
        406,
        1228,
        264,
        1151,
        2290,
        337,
        264,
        1691,
        3602,
        13,
        50484
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1637.1999740600586,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1632.719970703125,
      "temperature": 0.0,
      "text": " If you're writing code with AI, you are absolutely on an upward curve, okay?",
      "tokens": [
        50484,
        759,
        291,
        434,
        3579,
        3089,
        365,
        7318,
        11,
        291,
        366,
        3122,
        322,
        364,
        23452,
        7605,
        11,
        1392,
        30,
        50708
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1640.2399673461914,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1637.1999740600586,
      "temperature": 0.0,
      "text": " Principal AI Coding was built to help you make this transition",
      "tokens": [
        50708,
        38575,
        7318,
        383,
        8616,
        390,
        3094,
        281,
        854,
        291,
        652,
        341,
        6034,
        50860
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1643.5199737548828,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1640.2399673461914,
      "temperature": 0.0,
      "text": " in the shortest amount of time possible, okay?",
      "tokens": [
        50860,
        294,
        264,
        31875,
        2372,
        295,
        565,
        1944,
        11,
        1392,
        30,
        51024
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1648.1599731445312,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1643.5199737548828,
      "temperature": 0.0,
      "text": " The only thing better than experience is experience earned faster.",
      "tokens": [
        51024,
        440,
        787,
        551,
        1101,
        813,
        1752,
        307,
        1752,
        12283,
        4663,
        13,
        51256
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1650.5599670410156,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1648.1599731445312,
      "temperature": 0.0,
      "text": " We focus on principles, not tools.",
      "tokens": [
        51256,
        492,
        1879,
        322,
        9156,
        11,
        406,
        3873,
        13,
        51376
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1652.7999725341797,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1650.5599670410156,
      "temperature": 0.0,
      "text": " Principles, not models, okay?",
      "tokens": [
        51376,
        38372,
        2622,
        11,
        406,
        5245,
        11,
        1392,
        30,
        51488
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1657.119972229004,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1652.7999725341797,
      "temperature": 0.0,
      "text": " There's going to be an onslaught of agents, of tools, of models.",
      "tokens": [
        51488,
        821,
        311,
        516,
        281,
        312,
        364,
        18818,
        875,
        1599,
        295,
        12554,
        11,
        295,
        3873,
        11,
        295,
        5245,
        13,
        51704
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1658.319969177246,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1657.119972229004,
      "temperature": 0.0,
      "text": " You know this already, right?",
      "tokens": [
        51704,
        509,
        458,
        341,
        1217,
        11,
        558,
        30,
        51764
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.16967593133449554,
      "compression_ratio": 1.6700336933135986,
      "end": 1659.839973449707,
      "no_speech_prob": 0.0020189506467431784,
      "seek": 5760,
      "start": 1658.319969177246,
      "temperature": 0.0,
      "text": " You're, you're aware of this.",
      "tokens": [
        51764,
        509,
        434,
        11,
        291,
        434,
        3650,
        295,
        341,
        13,
        51840
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1662.7999725341797,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1659.9199676513672,
      "temperature": 0.0,
      "text": " We need principles to endure change over time.",
      "tokens": [
        50368,
        492,
        643,
        9156,
        281,
        24732,
        1319,
        670,
        565,
        13,
        50512
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1664.4799728393555,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1662.7999725341797,
      "temperature": 0.0,
      "text": " So, you know, this course helps you get there.",
      "tokens": [
        50512,
        407,
        11,
        291,
        458,
        11,
        341,
        1164,
        3665,
        291,
        483,
        456,
        13,
        50596
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1667.4399719238281,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1664.4799728393555,
      "temperature": 0.0,
      "text": " It helps you endure change with principles.",
      "tokens": [
        50596,
        467,
        3665,
        291,
        24732,
        1319,
        365,
        9156,
        13,
        50744
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1672.5599670410156,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1667.4399719238281,
      "temperature": 0.0,
      "text": " And one of the key principles we talk about in lesson three is context, model, prompt.",
      "tokens": [
        50744,
        400,
        472,
        295,
        264,
        2141,
        9156,
        321,
        751,
        466,
        294,
        6898,
        1045,
        307,
        4319,
        11,
        2316,
        11,
        12391,
        13,
        51000
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1677.0399703979492,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1672.5599670410156,
      "temperature": 0.0,
      "text": " These are the big three, the most important elements we're getting worked on in AI coding,",
      "tokens": [
        51000,
        1981,
        366,
        264,
        955,
        1045,
        11,
        264,
        881,
        1021,
        4959,
        321,
        434,
        1242,
        2732,
        322,
        294,
        7318,
        17720,
        11,
        51224
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1679.839973449707,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1677.0399703979492,
      "temperature": 0.0,
      "text": " but really with all of generative AI.",
      "tokens": [
        51224,
        457,
        534,
        365,
        439,
        295,
        1337,
        1166,
        7318,
        13,
        51364
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1681.839973449707,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1679.839973449707,
      "temperature": 0.0,
      "text": " There are eight lessons in this course.",
      "tokens": [
        51364,
        821,
        366,
        3180,
        8820,
        294,
        341,
        1164,
        13,
        51464
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1684.1599731445312,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1681.839973449707,
      "temperature": 0.0,
      "text": " They take you from beginner to intermediate to advanced.",
      "tokens": [
        51464,
        814,
        747,
        291,
        490,
        22080,
        281,
        19376,
        281,
        7339,
        13,
        51580
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.1783984750509262,
      "compression_ratio": 1.7870036363601685,
      "end": 1686.8799743652344,
      "no_speech_prob": 0.0002652980911079794,
      "seek": 8712,
      "start": 1684.1599731445312,
      "temperature": 0.0,
      "text": " We talk about big topics that are, you know,",
      "tokens": [
        51580,
        492,
        751,
        466,
        955,
        8378,
        300,
        366,
        11,
        291,
        458,
        11,
        51716
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.16050271689891815,
      "compression_ratio": 1.4808743000030518,
      "end": 1691.3599700927734,
      "no_speech_prob": 0.0033762194216251373,
      "seek": 11416,
      "start": 1687.4399719238281,
      "temperature": 0.0,
      "text": " really becoming mainstream in the generative AI, AI coding world.",
      "tokens": [
        50392,
        534,
        5617,
        15960,
        294,
        264,
        1337,
        1166,
        7318,
        11,
        7318,
        17720,
        1002,
        13,
        50588
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.16050271689891815,
      "compression_ratio": 1.4808743000030518,
      "end": 1693.1999740600586,
      "no_speech_prob": 0.0033762194216251373,
      "seek": 11416,
      "start": 1691.3599700927734,
      "temperature": 0.0,
      "text": " We talk about the spec prompt, right?",
      "tokens": [
        50588,
        492,
        751,
        466,
        264,
        1608,
        12391,
        11,
        558,
        30,
        50680
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.16050271689891815,
      "compression_ratio": 1.4808743000030518,
      "end": 1697.9999694824219,
      "no_speech_prob": 0.0033762194216251373,
      "seek": 11416,
      "start": 1693.1999740600586,
      "temperature": 0.0,
      "text": " Scaling up your work by writing larger prompts, larger specs.",
      "tokens": [
        50680,
        2747,
        4270,
        493,
        428,
        589,
        538,
        3579,
        4833,
        41095,
        11,
        4833,
        27911,
        13,
        50920
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.16050271689891815,
      "compression_ratio": 1.4808743000030518,
      "end": 1700.959976196289,
      "no_speech_prob": 0.0033762194216251373,
      "seek": 11416,
      "start": 1697.9999694824219,
      "temperature": 0.0,
      "text": " And we talk about, you know, a big topic that's come up recently",
      "tokens": [
        50920,
        400,
        321,
        751,
        466,
        11,
        291,
        458,
        11,
        257,
        955,
        4829,
        300,
        311,
        808,
        493,
        3938,
        51068
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.16050271689891815,
      "compression_ratio": 1.4808743000030518,
      "end": 1703.5999755859375,
      "no_speech_prob": 0.0033762194216251373,
      "seek": 11416,
      "start": 1700.959976196289,
      "temperature": 0.0,
      "text": " is this idea of closing the loop, right?",
      "tokens": [
        51068,
        307,
        341,
        1558,
        295,
        10377,
        264,
        6367,
        11,
        558,
        30,
        51200
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1708.3399682044983,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1703.7799682617188,
      "temperature": 0.0,
      "text": " by creating these closed-loop, self-verifiable systems,",
      "tokens": [
        50364,
        538,
        4084,
        613,
        5395,
        12,
        46623,
        11,
        2698,
        12,
        331,
        30876,
        3652,
        11,
        50592
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1711.6799683570862,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1708.3399682044983,
      "temperature": 0.0,
      "text": " your AI coding tools and your agentic systems",
      "tokens": [
        50592,
        428,
        7318,
        17720,
        3873,
        293,
        428,
        9461,
        299,
        3652,
        50759
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1714.2399682998657,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1711.6799683570862,
      "temperature": 0.0,
      "text": " can actually get the work done by themselves.",
      "tokens": [
        50759,
        393,
        767,
        483,
        264,
        589,
        1096,
        538,
        2969,
        13,
        50887
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1715.639967918396,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1714.2399682998657,
      "temperature": 0.0,
      "text": " If you give them enough direction,",
      "tokens": [
        50887,
        759,
        291,
        976,
        552,
        1547,
        3513,
        11,
        50957
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1717.4399681091309,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1715.639967918396,
      "temperature": 0.0,
      "text": " if you tell them where to go and how to resolve",
      "tokens": [
        50957,
        498,
        291,
        980,
        552,
        689,
        281,
        352,
        293,
        577,
        281,
        14151,
        51047
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1720.5799674987793,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1717.4399681091309,
      "temperature": 0.0,
      "text": " and give them feedback, you close the loop, okay?",
      "tokens": [
        51047,
        293,
        976,
        552,
        5824,
        11,
        291,
        1998,
        264,
        6367,
        11,
        1392,
        30,
        51204
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1722.7799682617188,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1720.5799674987793,
      "temperature": 0.0,
      "text": " This is a really important, powerful pattern.",
      "tokens": [
        51204,
        639,
        307,
        257,
        534,
        1021,
        11,
        4005,
        5102,
        13,
        51314
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1725.4399681091309,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1722.7799682617188,
      "temperature": 0.0,
      "text": " This is gonna be big over 2025 and 2026.",
      "tokens": [
        51314,
        639,
        307,
        799,
        312,
        955,
        670,
        39209,
        293,
        945,
        10880,
        13,
        51447
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1726.9399681091309,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1725.4399681091309,
      "temperature": 0.0,
      "text": " People are already starting to talk about this more.",
      "tokens": [
        51447,
        3432,
        366,
        1217,
        2891,
        281,
        751,
        466,
        341,
        544,
        13,
        51522
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1728.0399684906006,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1726.9399681091309,
      "temperature": 0.0,
      "text": " This is getting uncovered.",
      "tokens": [
        51522,
        639,
        307,
        1242,
        37729,
        13,
        51577
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1729.2799682617188,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1728.0399684906006,
      "temperature": 0.0,
      "text": " So you wanna move on this stuff",
      "tokens": [
        51577,
        407,
        291,
        1948,
        1286,
        322,
        341,
        1507,
        51639
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1731.3799686431885,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1729.2799682617188,
      "temperature": 0.0,
      "text": " before it really, really hits the masses, okay?",
      "tokens": [
        51639,
        949,
        309,
        534,
        11,
        534,
        8664,
        264,
        23935,
        11,
        1392,
        30,
        51744
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.27551352977752686,
      "compression_ratio": 1.713395595550537,
      "end": 1733.0799674987793,
      "no_speech_prob": 0.00037408247590065,
      "seek": 0,
      "start": 1731.3799686431885,
      "temperature": 0.0,
      "text": " So eight lessons here.",
      "tokens": [
        51744,
        407,
        3180,
        8820,
        510,
        13,
        51829
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1734.3799686431885,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1733.3799686431885,
      "temperature": 0.0,
      "text": " Lots of great reviews.",
      "tokens": [
        50379,
        15908,
        295,
        869,
        10229,
        13,
        50429
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1737.1199684143066,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1734.3799686431885,
      "temperature": 0.0,
      "text": " Feel free to check out tons of the other videos",
      "tokens": [
        50429,
        14113,
        1737,
        281,
        1520,
        484,
        9131,
        295,
        264,
        661,
        2145,
        50566
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1739.819969177246,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1737.1199684143066,
      "temperature": 0.0,
      "text": " and AI coding content I have on the channel.",
      "tokens": [
        50566,
        293,
        7318,
        17720,
        2701,
        286,
        362,
        322,
        264,
        2269,
        13,
        50701
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1740.7199668884277,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1739.819969177246,
      "temperature": 0.0,
      "text": " This is here for you.",
      "tokens": [
        50701,
        639,
        307,
        510,
        337,
        291,
        13,
        50746
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1741.6799697875977,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1740.7199668884277,
      "temperature": 0.0,
      "text": " And just to mention it,",
      "tokens": [
        50746,
        400,
        445,
        281,
        2152,
        309,
        11,
        50794
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1745.1799697875977,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1741.6799697875977,
      "temperature": 0.0,
      "text": " I have a no-questions-asked refund before lesson four.",
      "tokens": [
        50794,
        286,
        362,
        257,
        572,
        12,
        20343,
        626,
        12,
        3863,
        292,
        29384,
        949,
        6898,
        1451,
        13,
        50969
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1747.1399688720703,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1745.1799697875977,
      "temperature": 0.0,
      "text": " This is basically risk-free at this point, right?",
      "tokens": [
        50969,
        639,
        307,
        1936,
        3148,
        12,
        10792,
        412,
        341,
        935,
        11,
        558,
        30,
        51067
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1747.9799690246582,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1747.1399688720703,
      "temperature": 0.0,
      "text": " So hop in.",
      "tokens": [
        51067,
        407,
        3818,
        294,
        13,
        51109
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1749.8799667358398,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1747.9799690246582,
      "temperature": 0.0,
      "text": " If you don't like my style, if you don't like the video,",
      "tokens": [
        51109,
        759,
        291,
        500,
        380,
        411,
        452,
        3758,
        11,
        498,
        291,
        500,
        380,
        411,
        264,
        960,
        11,
        51204
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1751.3399696350098,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1749.8799667358398,
      "temperature": 0.0,
      "text": " if you don't understand what's happening,",
      "tokens": [
        51204,
        498,
        291,
        500,
        380,
        1223,
        437,
        311,
        2737,
        11,
        51277
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1753.9399681091309,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1751.3399696350098,
      "temperature": 0.0,
      "text": " if it's too complex or if it's not complex enough",
      "tokens": [
        51277,
        498,
        309,
        311,
        886,
        3997,
        420,
        498,
        309,
        311,
        406,
        3997,
        1547,
        51407
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1756.1399688720703,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1753.9399681091309,
      "temperature": 0.0,
      "text": " and you're too much of an omni-chat engineer",
      "tokens": [
        51407,
        293,
        291,
        434,
        886,
        709,
        295,
        364,
        3406,
        3722,
        12,
        20057,
        11403,
        51517
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1757.4799690246582,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1756.1399688720703,
      "temperature": 0.0,
      "text": " and you already know what I'm gonna say",
      "tokens": [
        51517,
        293,
        291,
        1217,
        458,
        437,
        286,
        478,
        799,
        584,
        51584
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1760.5799674987793,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1757.4799690246582,
      "temperature": 0.0,
      "text": " in the next six videos or whatever, that's fine.",
      "tokens": [
        51584,
        294,
        264,
        958,
        2309,
        2145,
        420,
        2035,
        11,
        300,
        311,
        2489,
        13,
        51739
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.17593231797218323,
      "compression_ratio": 1.7485713958740234,
      "end": 1762.8799667358398,
      "no_speech_prob": 0.0023966289591044188,
      "seek": 2930,
      "start": 1760.5799674987793,
      "temperature": 0.0,
      "text": " You get a full refund before you start lesson four.",
      "tokens": [
        51739,
        509,
        483,
        257,
        1577,
        29384,
        949,
        291,
        722,
        6898,
        1451,
        13,
        51854
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1764.0199699401855,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1762.9199676513672,
      "temperature": 0.0,
      "text": " No questions asked.",
      "tokens": [
        50366,
        883,
        1651,
        2351,
        13,
        50421
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1765.8799667358398,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1764.0199699401855,
      "temperature": 0.0,
      "text": " We've had zero issues with this.",
      "tokens": [
        50421,
        492,
        600,
        632,
        4018,
        2663,
        365,
        341,
        13,
        50514
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1767.1799697875977,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1765.8799667358398,
      "temperature": 0.0,
      "text": " There's a lot of value here.",
      "tokens": [
        50514,
        821,
        311,
        257,
        688,
        295,
        2158,
        510,
        13,
        50579
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1769.1199645996094,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1767.1799697875977,
      "temperature": 0.0,
      "text": " And I just wanna pitch it on the channel.",
      "tokens": [
        50579,
        400,
        286,
        445,
        1948,
        7293,
        309,
        322,
        264,
        2269,
        13,
        50676
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1772.1799697875977,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1769.1199645996094,
      "temperature": 0.0,
      "text": " For all existing Principled AI Coding members,",
      "tokens": [
        50676,
        1171,
        439,
        6741,
        38372,
        15551,
        7318,
        383,
        8616,
        2679,
        11,
        50829
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1774.4199676513672,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1772.1799697875977,
      "temperature": 0.0,
      "text": " I'm gonna be rolling out some new tooling",
      "tokens": [
        50829,
        286,
        478,
        799,
        312,
        9439,
        484,
        512,
        777,
        46593,
        50941
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1776.8799667358398,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1774.4199676513672,
      "temperature": 0.0,
      "text": " that helps us use the patterns we learned",
      "tokens": [
        50941,
        300,
        3665,
        505,
        764,
        264,
        8294,
        321,
        3264,
        51064
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1779.7799682617188,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1776.8799667358398,
      "temperature": 0.0,
      "text": " in Principled AI Coding in a cool, lightweight way.",
      "tokens": [
        51064,
        294,
        38372,
        15551,
        7318,
        383,
        8616,
        294,
        257,
        1627,
        11,
        22052,
        636,
        13,
        51209
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1783.219970703125,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1779.7799682617188,
      "temperature": 0.0,
      "text": " I'm building this on top of the powerful all-in-one tool, UV.",
      "tokens": [
        51209,
        286,
        478,
        2390,
        341,
        322,
        1192,
        295,
        264,
        4005,
        439,
        12,
        259,
        12,
        546,
        2290,
        11,
        17887,
        13,
        51381
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1787.319969177246,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1783.219970703125,
      "temperature": 0.0,
      "text": " So it's gonna be super simple to set up, use, and deploy.",
      "tokens": [
        51381,
        407,
        309,
        311,
        799,
        312,
        1687,
        2199,
        281,
        992,
        493,
        11,
        764,
        11,
        293,
        7274,
        13,
        51586
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.20269425213336945,
      "compression_ratio": 1.600000023841858,
      "end": 1789.5399703979492,
      "no_speech_prob": 0.0003740818938240409,
      "seek": 5910,
      "start": 1787.319969177246,
      "temperature": 0.0,
      "text": " And we're, of course, going to continue using",
      "tokens": [
        51586,
        400,
        321,
        434,
        11,
        295,
        1164,
        11,
        516,
        281,
        2354,
        1228,
        51697
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1794.199966430664,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1789.5399703979492,
      "temperature": 0.0,
      "text": " our top-of-the-line, most customizable, configurable,",
      "tokens": [
        50364,
        527,
        1192,
        12,
        2670,
        12,
        3322,
        12,
        1889,
        11,
        881,
        47922,
        11,
        22192,
        712,
        11,
        50597
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1796.9999694824219,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1794.199966430664,
      "temperature": 0.0,
      "text": " powerful AI Coding Assistant, AIDR.",
      "tokens": [
        50597,
        4005,
        7318,
        383,
        8616,
        14890,
        11,
        316,
        2777,
        49,
        13,
        50737
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1798.3399658203125,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1796.9999694824219,
      "temperature": 0.0,
      "text": " So stay tuned for that.",
      "tokens": [
        50737,
        407,
        1754,
        10870,
        337,
        300,
        13,
        50804
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1800.9999694824219,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1798.3399658203125,
      "temperature": 0.0,
      "text": " And even if you don't use AIDR,",
      "tokens": [
        50804,
        400,
        754,
        498,
        291,
        500,
        380,
        764,
        316,
        2777,
        49,
        11,
        50937
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1803.5399703979492,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1800.9999694824219,
      "temperature": 0.0,
      "text": " even if you're not a fan of CLI-based,",
      "tokens": [
        50937,
        754,
        498,
        291,
        434,
        406,
        257,
        3429,
        295,
        12855,
        40,
        12,
        6032,
        11,
        51064
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1807.3399658203125,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1803.5399703979492,
      "temperature": 0.0,
      "text": " full-control AI Coding Assistants, that's fine.",
      "tokens": [
        51064,
        1577,
        12,
        40905,
        7318,
        383,
        8616,
        49633,
        1719,
        11,
        300,
        311,
        2489,
        13,
        51254
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1810.5399703979492,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1807.3399658203125,
      "temperature": 0.0,
      "text": " Again, we use AIDR as a tool here",
      "tokens": [
        51254,
        3764,
        11,
        321,
        764,
        316,
        2777,
        49,
        382,
        257,
        2290,
        510,
        51414
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1812.099967956543,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1810.5399703979492,
      "temperature": 0.0,
      "text": " to showcase the principles.",
      "tokens": [
        51414,
        281,
        20388,
        264,
        9156,
        13,
        51492
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1814.099967956543,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1812.099967956543,
      "temperature": 0.0,
      "text": " This course is not about AIDR, okay?",
      "tokens": [
        51492,
        639,
        1164,
        307,
        406,
        466,
        316,
        2777,
        49,
        11,
        1392,
        30,
        51592
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1815.479965209961,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1814.099967956543,
      "temperature": 0.0,
      "text": " So just to quickly mention that,",
      "tokens": [
        51592,
        407,
        445,
        281,
        2661,
        2152,
        300,
        11,
        51661
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.18325209617614746,
      "compression_ratio": 1.5992063283920288,
      "end": 1818.0399703979492,
      "no_speech_prob": 0.003707133000716567,
      "seek": 8576,
      "start": 1815.479965209961,
      "temperature": 0.0,
      "text": " and yeah, that's Principled AI Coding.",
      "tokens": [
        51661,
        293,
        1338,
        11,
        300,
        311,
        38372,
        15551,
        7318,
        383,
        8616,
        13,
        51789
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.2681009769439697,
      "compression_ratio": 1.4974359273910522,
      "end": 1820.3799667358398,
      "no_speech_prob": 0.5620678663253784,
      "seek": 11426,
      "start": 1818.0399703979492,
      "temperature": 0.0,
      "text": " I'm gonna hop in here before, you know,",
      "tokens": [
        50364,
        286,
        478,
        799,
        3818,
        294,
        510,
        949,
        11,
        291,
        458,
        11,
        50481
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.2681009769439697,
      "compression_ratio": 1.4974359273910522,
      "end": 1823.1799697875977,
      "no_speech_prob": 0.5620678663253784,
      "seek": 11426,
      "start": 1820.3799667358398,
      "temperature": 0.0,
      "text": " the next wave of coding comes,",
      "tokens": [
        50481,
        264,
        958,
        5772,
        295,
        17720,
        1487,
        11,
        50621
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.2681009769439697,
      "compression_ratio": 1.4974359273910522,
      "end": 1825.3799667358398,
      "no_speech_prob": 0.5620678663253784,
      "seek": 11426,
      "start": 1823.1799697875977,
      "temperature": 0.0,
      "text": " which I'm gonna be preparing everyone for,",
      "tokens": [
        50621,
        597,
        286,
        478,
        799,
        312,
        10075,
        1518,
        337,
        11,
        50731
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.2681009769439697,
      "compression_ratio": 1.4974359273910522,
      "end": 1826.8399658203125,
      "no_speech_prob": 0.5620678663253784,
      "seek": 11426,
      "start": 1825.3799667358398,
      "temperature": 0.0,
      "text": " again, inside this course.",
      "tokens": [
        50731,
        797,
        11,
        1854,
        341,
        1164,
        13,
        50804
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.2681009769439697,
      "compression_ratio": 1.4974359273910522,
      "end": 1829.5399703979492,
      "no_speech_prob": 0.5620678663253784,
      "seek": 11426,
      "start": 1826.8399658203125,
      "temperature": 0.0,
      "text": " Those lessons are in the works, they're in the queue,",
      "tokens": [
        50804,
        3950,
        8820,
        366,
        294,
        264,
        1985,
        11,
        436,
        434,
        294,
        264,
        18639,
        11,
        50939
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.2681009769439697,
      "compression_ratio": 1.4974359273910522,
      "end": 1832.1799621582031,
      "no_speech_prob": 0.5620678663253784,
      "seek": 11426,
      "start": 1829.5399703979492,
      "temperature": 0.0,
      "text": " but that's gonna be for later in this year.",
      "tokens": [
        50939,
        457,
        300,
        311,
        799,
        312,
        337,
        1780,
        294,
        341,
        1064,
        13,
        51071
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.2681009769439697,
      "compression_ratio": 1.4974359273910522,
      "end": 1833.9399719238281,
      "no_speech_prob": 0.5620678663253784,
      "seek": 11426,
      "start": 1832.1799621582031,
      "temperature": 0.0,
      "text": " Just to say it out loud here,",
      "tokens": [
        51071,
        1449,
        281,
        584,
        309,
        484,
        6588,
        510,
        11,
        51159
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.2681009769439697,
      "compression_ratio": 1.4974359273910522,
      "end": 1834.979965209961,
      "no_speech_prob": 0.5620678663253784,
      "seek": 11426,
      "start": 1833.9399719238281,
      "temperature": 0.0,
      "text": " right now, AI Coding...",
      "tokens": [
        51159,
        558,
        586,
        11,
        7318,
        383,
        8616,
        485,
        51211
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2029999941587448,
      "compression_ratio": 1.6724739074707031,
      "end": 1841.319965839386,
      "no_speech_prob": 0.014062593691051006,
      "seek": 0,
      "start": 1834.8399658203125,
      "temperature": 0.0,
      "text": " is the wave. The next wave that's upon us is agentic coding. When you fully close the loop,",
      "tokens": [
        50364,
        307,
        264,
        5772,
        13,
        440,
        958,
        5772,
        300,
        311,
        3564,
        505,
        307,
        9461,
        299,
        17720,
        13,
        1133,
        291,
        4498,
        1998,
        264,
        6367,
        11,
        50688
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2029999941587448,
      "compression_ratio": 1.6724739074707031,
      "end": 1847.0799655914307,
      "no_speech_prob": 0.014062593691051006,
      "seek": 0,
      "start": 1841.319965839386,
      "temperature": 0.0,
      "text": " what you end up with is systems that can operate on their own. So stay tuned, stay locked in. I",
      "tokens": [
        50688,
        437,
        291,
        917,
        493,
        365,
        307,
        3652,
        300,
        393,
        9651,
        322,
        641,
        1065,
        13,
        407,
        1754,
        10870,
        11,
        1754,
        9376,
        294,
        13,
        286,
        50976
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2029999941587448,
      "compression_ratio": 1.6724739074707031,
      "end": 1852.8399658203125,
      "no_speech_prob": 0.014062593691051006,
      "seek": 0,
      "start": 1847.0799655914307,
      "temperature": 0.0,
      "text": " hope you can understand why agents are so important in the age of AI. You first start with the prompt.",
      "tokens": [
        50976,
        1454,
        291,
        393,
        1223,
        983,
        12554,
        366,
        370,
        1021,
        294,
        264,
        3205,
        295,
        7318,
        13,
        509,
        700,
        722,
        365,
        264,
        12391,
        13,
        51264
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2029999941587448,
      "compression_ratio": 1.6724739074707031,
      "end": 1858.9199657440186,
      "no_speech_prob": 0.014062593691051006,
      "seek": 0,
      "start": 1852.8399658203125,
      "temperature": 0.0,
      "text": " You then move to prompt chains. You have a series of LLM-based calls that can do work on your behalf.",
      "tokens": [
        51264,
        509,
        550,
        1286,
        281,
        12391,
        12626,
        13,
        509,
        362,
        257,
        2638,
        295,
        441,
        43,
        44,
        12,
        6032,
        5498,
        300,
        393,
        360,
        589,
        322,
        428,
        9490,
        13,
        51568
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2029999941587448,
      "compression_ratio": 1.6724739074707031,
      "end": 1863.3999652862549,
      "no_speech_prob": 0.014062593691051006,
      "seek": 0,
      "start": 1858.9199657440186,
      "temperature": 0.0,
      "text": " And then you move to AI agents, right? The structure where you give them the tools they",
      "tokens": [
        51568,
        400,
        550,
        291,
        1286,
        281,
        7318,
        12554,
        11,
        558,
        30,
        440,
        3877,
        689,
        291,
        976,
        552,
        264,
        3873,
        436,
        51792
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.1725527048110962,
      "compression_ratio": 1.7106226682662964,
      "end": 1869.2399673461914,
      "no_speech_prob": 0.00446827569976449,
      "seek": 2856,
      "start": 1863.3999652862549,
      "temperature": 0.0,
      "text": " need to solve the problem. And then you let them learn, gather information, execute, get feedback.",
      "tokens": [
        50364,
        643,
        281,
        5039,
        264,
        1154,
        13,
        400,
        550,
        291,
        718,
        552,
        1466,
        11,
        5448,
        1589,
        11,
        14483,
        11,
        483,
        5824,
        13,
        50656
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.1725527048110962,
      "compression_ratio": 1.7106226682662964,
      "end": 1873.1599655151367,
      "no_speech_prob": 0.00446827569976449,
      "seek": 2856,
      "start": 1869.2399673461914,
      "temperature": 0.0,
      "text": " Agents is how we continue to scale our compute. This is where we're going to be focused on the",
      "tokens": [
        50656,
        2725,
        791,
        307,
        577,
        321,
        2354,
        281,
        4373,
        527,
        14722,
        13,
        639,
        307,
        689,
        321,
        434,
        516,
        281,
        312,
        5178,
        322,
        264,
        50852
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.1725527048110962,
      "compression_ratio": 1.7106226682662964,
      "end": 1879.1599655151367,
      "no_speech_prob": 0.00446827569976449,
      "seek": 2856,
      "start": 1873.1599655151367,
      "temperature": 0.0,
      "text": " channel. It's all about scaling compute usage, maximizing what you can do. It's all about AI",
      "tokens": [
        50852,
        2269,
        13,
        467,
        311,
        439,
        466,
        21589,
        14722,
        14924,
        11,
        5138,
        3319,
        437,
        291,
        393,
        360,
        13,
        467,
        311,
        439,
        466,
        7318,
        51152
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.1725527048110962,
      "compression_ratio": 1.7106226682662964,
      "end": 1884.4399642944336,
      "no_speech_prob": 0.00446827569976449,
      "seek": 2856,
      "start": 1879.1599655151367,
      "temperature": 0.0,
      "text": " coding so that you can write faster than ever, so that you can build out these agents fast,",
      "tokens": [
        51152,
        17720,
        370,
        300,
        291,
        393,
        2464,
        4663,
        813,
        1562,
        11,
        370,
        300,
        291,
        393,
        1322,
        484,
        613,
        12554,
        2370,
        11,
        51416
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.1725527048110962,
      "compression_ratio": 1.7106226682662964,
      "end": 1890.039966583252,
      "no_speech_prob": 0.00446827569976449,
      "seek": 2856,
      "start": 1884.4399642944336,
      "temperature": 0.0,
      "text": " just to come full circle here. That's why the single file agent pattern is so important,",
      "tokens": [
        51416,
        445,
        281,
        808,
        1577,
        6329,
        510,
        13,
        663,
        311,
        983,
        264,
        2167,
        3991,
        9461,
        5102,
        307,
        370,
        1021,
        11,
        51696
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.17392244935035706,
      "compression_ratio": 1.578723430633545,
      "end": 1896.4399642944336,
      "no_speech_prob": 0.00036258678301237524,
      "seek": 5520,
      "start": 1890.039966583252,
      "temperature": 0.0,
      "text": " because we meet at the intersection of three important innovations. We have Astral's UV,",
      "tokens": [
        50364,
        570,
        321,
        1677,
        412,
        264,
        15236,
        295,
        1045,
        1021,
        24283,
        13,
        492,
        362,
        12884,
        2155,
        311,
        17887,
        11,
        50684
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.17392244935035706,
      "compression_ratio": 1.578723430633545,
      "end": 1902.359962463379,
      "no_speech_prob": 0.00036258678301237524,
      "seek": 5520,
      "start": 1896.4399642944336,
      "temperature": 0.0,
      "text": " allowing us to bundle dependencies into a single file. We have self-validating agent patterns,",
      "tokens": [
        50684,
        8293,
        505,
        281,
        24438,
        36606,
        666,
        257,
        2167,
        3991,
        13,
        492,
        362,
        2698,
        12,
        3337,
        327,
        990,
        9461,
        8294,
        11,
        50980
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.17392244935035706,
      "compression_ratio": 1.578723430633545,
      "end": 1908.8399658203125,
      "no_speech_prob": 0.00036258678301237524,
      "seek": 5520,
      "start": 1902.359962463379,
      "temperature": 0.0,
      "text": " where we can write great tools and great prompts to allow the agent to self-verify before",
      "tokens": [
        50980,
        689,
        321,
        393,
        2464,
        869,
        3873,
        293,
        869,
        41095,
        281,
        2089,
        264,
        9461,
        281,
        2698,
        12,
        331,
        2505,
        949,
        51304
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.17392244935035706,
      "compression_ratio": 1.578723430633545,
      "end": 1915.2399673461914,
      "no_speech_prob": 0.00036258678301237524,
      "seek": 5520,
      "start": 1908.8399658203125,
      "temperature": 0.0,
      "text": " it returns the response to us. And then of course, we have powerful AI coding techniques. Many of",
      "tokens": [
        51304,
        309,
        11247,
        264,
        4134,
        281,
        505,
        13,
        400,
        550,
        295,
        1164,
        11,
        321,
        362,
        4005,
        7318,
        17720,
        7512,
        13,
        5126,
        295,
        51624
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.19840872287750244,
      "compression_ratio": 1.5738396644592285,
      "end": 1922.2799682617188,
      "no_speech_prob": 0.1096874549984932,
      "seek": 8040,
      "start": 1915.2399673461914,
      "temperature": 0.0,
      "text": " these we cover in principle AI coding. This lets us reuse, scale, clone, and duplicate our single",
      "tokens": [
        50364,
        613,
        321,
        2060,
        294,
        8665,
        7318,
        17720,
        13,
        639,
        6653,
        505,
        26225,
        11,
        4373,
        11,
        26506,
        11,
        293,
        23976,
        527,
        2167,
        50716
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.19840872287750244,
      "compression_ratio": 1.5738396644592285,
      "end": 1929.6399688720703,
      "no_speech_prob": 0.1096874549984932,
      "seek": 8040,
      "start": 1922.2799682617188,
      "temperature": 0.0,
      "text": " file AI agents into many different domains. You can imagine we have an agent that builds agents.",
      "tokens": [
        50716,
        3991,
        7318,
        12554,
        666,
        867,
        819,
        25514,
        13,
        509,
        393,
        3811,
        321,
        362,
        364,
        9461,
        300,
        15182,
        12554,
        13,
        51084
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.19840872287750244,
      "compression_ratio": 1.5738396644592285,
      "end": 1933.7999649047852,
      "no_speech_prob": 0.1096874549984932,
      "seek": 8040,
      "start": 1929.6399688720703,
      "temperature": 0.0,
      "text": " Okay. So we have a lot of big ideas to cover on the channel. If you're interested in this,",
      "tokens": [
        51084,
        1033,
        13,
        407,
        321,
        362,
        257,
        688,
        295,
        955,
        3487,
        281,
        2060,
        322,
        264,
        2269,
        13,
        759,
        291,
        434,
        3102,
        294,
        341,
        11,
        51292
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.19840872287750244,
      "compression_ratio": 1.5738396644592285,
      "end": 1937.8799667358398,
      "no_speech_prob": 0.1096874549984932,
      "seek": 8040,
      "start": 1933.7999649047852,
      "temperature": 0.0,
      "text": " if you made it this far in the video, you know what to do. Drop the like, drop the sub,",
      "tokens": [
        51292,
        498,
        291,
        1027,
        309,
        341,
        1400,
        294,
        264,
        960,
        11,
        291,
        458,
        437,
        281,
        360,
        13,
        17675,
        264,
        411,
        11,
        3270,
        264,
        1422,
        11,
        51496
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.19563037157058716,
      "compression_ratio": 1.1168831586837769,
      "end": 1947.8799667358398,
      "no_speech_prob": 0.05031327158212662,
      "seek": 10304,
      "start": 1937.8799667358398,
      "temperature": 0.0,
      "text": " leave a comment, stay connected, and whatever happens, stay focused and keep building.",
      "tokens": [
        50364,
        1856,
        257,
        2871,
        11,
        1754,
        4582,
        11,
        293,
        2035,
        2314,
        11,
        1754,
        5178,
        293,
        1066,
        2390,
        13,
        50864
      ],
      "chunk_source": "single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_015.mp3"
    }
  ],
  "created_at": 1742835076.445672,
  "num_chunks": 15,
  "language": "english"
}
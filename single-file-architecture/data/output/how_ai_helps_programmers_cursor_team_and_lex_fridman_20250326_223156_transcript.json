{
  "original_file": "data/audio/how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156.mp3",
  "text": "I'm really feeling the AGI with this editor. It feels like there's a lot of machine learning going on underneath. Tell me about some of the ML stuff that makes it all work. Cursor really works via this ensemble of custom models that we've trained alongside, you know, the frontier models that are fantastic at the reasoning intense things. And so cursor tab, for example, is a great example of where you can specialize this model to be even better than even frontier models. If you look at evils on the task, we set it at the other domain, which it's kind of surprising that it requires custom models, but it's kind of necessary and works quite well is in apply. So I think these models are like the frontier models are quite good at sketching out plans for code and generating like rough sketches of like the change, but actually creating diffs is quite hard for frontier models, for your training models. Like you try to do this with Sonnet, with O1, any frontier model, and it really messes up stupid things like counting line numbers, especially in super, super large files. And so what we've done to alleviate this is we let the model kind of sketch out this rough code block that indicates what the change will be. And we train a model to then apply that change to the file. And we should say that apply is the model looks at your code. It gives you a really damn good suggestion of what new things to do. And the seemingly for humans, trivial step of combining the two you're saying is not so trivial. Contrary to popular perception, it is not a deterministic algorithm. Yeah. I think like you see shallow copies of apply elsewhere. And it just breaks like most of the time because you think you can kind of try to do some deterministic matching and then it fails, you know, at least 40% of the time. And that just results in a terrible product experience. I think in general, this regime of you are going to get smarter and smarter models. And like, so one other thing that ApplyGit lets you do is it lets you use fewer tokens with the most intelligent models. This is both expensive in terms of latency for generating all these tokens and cost. So you can give this very, very rough sketch and then have your small models go and implement it because it's a much easier task to implement this very, very sketched out code. And I think that this regime will continue where you can use smarter and smarter models to do the planning. And then maybe the implementation details can be handled by the less intelligent ones. Perhaps you'll have, you know, maybe a one, maybe it'll be even more capable models given an even higher level plan that is kind of recursively applied by Sonnet and then the Apply model. Maybe we should talk about how to make it fast. Yeah. I feel like fast is always an interesting detail. Fast is good. Yeah. How do you make it fast? Yeah. So one big component of making it fast is speculative edits. So speculative edits are a variant of speculative decoding and maybe it'd be helpful to briefly describe speculative decoding. With speculative decoding, what you do is you can kind of take advantage of the fact that, you know, most of the time, and I'll add the caveat that it would be when you're memory bound in language model generation. If you process multiple tokens at once, it is faster than generating one token at a time. So this is like the same reason why if you look at tokens per second with prompt tokens versus generated tokens, it's much, much faster for prompt tokens. So what we do is instead of using what speculative decoding normally does, which is using a really small model to predict these draft tokens that your larger model will then go in and verify. With code edits, we have a very strong prior of what the existing code will look like. And that prior is literally the same exact code. So what you can do is you can just feed chunks of the original code back into the model. And then the model will just pretty much agree most of the time that, okay, I'm just going to... this code back out. And so you can process all of those lines in parallel. And you just do this with sufficiently many chunks and then eventually you'll reach a point of disagreement where the model will now predict text that is different from the ground truth original code. It'll generate those tokens and then we kind of will decide after enough tokens match the original code to restart speculating in chunks of code. What this actually ends up looking like is just a much faster version of normal editing code. So it's just like it looks like a much faster version of the model rewriting all the code. So just we can use the same exact interface that we use for diffs but it will just stream down a lot faster. And then the advantage is that while it's streaming you can just also be reviewing start reviewing the code before it's done so there's no big loading screen. So maybe that is part of the part of the advantage. So the human can start reading before the thing is done. I think the interesting riff here is something like like speculation is a fairly common idea nowadays. It's like not only in language models I mean there's obviously speculation in CPUs and there's like speculation for databases and speculation all over the place. you",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.303112655878067,
      "compression_ratio": 1.6188678741455078,
      "end": 5.0,
      "no_speech_prob": 0.0022168050054460764,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " I'm really feeling the AGI with this editor.",
      "tokens": [
        50364,
        286,
        478,
        534,
        2633,
        264,
        316,
        26252,
        365,
        341,
        9839,
        13,
        50614
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.303112655878067,
      "compression_ratio": 1.6188678741455078,
      "end": 10.359999656677246,
      "no_speech_prob": 0.0022168050054460764,
      "seek": 0,
      "start": 5.0,
      "temperature": 0.0,
      "text": " It feels like there's a lot of machine learning going on underneath.",
      "tokens": [
        50614,
        467,
        3417,
        411,
        456,
        311,
        257,
        688,
        295,
        3479,
        2539,
        516,
        322,
        7223,
        13,
        50882
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.303112655878067,
      "compression_ratio": 1.6188678741455078,
      "end": 14.039999961853027,
      "no_speech_prob": 0.0022168050054460764,
      "seek": 0,
      "start": 10.359999656677246,
      "temperature": 0.0,
      "text": " Tell me about some of the ML stuff that makes it all work.",
      "tokens": [
        50882,
        5115,
        385,
        466,
        512,
        295,
        264,
        21601,
        1507,
        300,
        1669,
        309,
        439,
        589,
        13,
        51066
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.303112655878067,
      "compression_ratio": 1.6188678741455078,
      "end": 20.1200008392334,
      "no_speech_prob": 0.0022168050054460764,
      "seek": 0,
      "start": 14.039999961853027,
      "temperature": 0.0,
      "text": " Cursor really works via this ensemble of custom models that we've trained alongside, you know,",
      "tokens": [
        51066,
        383,
        2156,
        284,
        534,
        1985,
        5766,
        341,
        19492,
        295,
        2375,
        5245,
        300,
        321,
        600,
        8895,
        12385,
        11,
        291,
        458,
        11,
        51370
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.303112655878067,
      "compression_ratio": 1.6188678741455078,
      "end": 23.479999542236328,
      "no_speech_prob": 0.0022168050054460764,
      "seek": 0,
      "start": 20.1200008392334,
      "temperature": 0.0,
      "text": " the frontier models that are fantastic at the reasoning intense things.",
      "tokens": [
        51370,
        264,
        35853,
        5245,
        300,
        366,
        5456,
        412,
        264,
        21577,
        9447,
        721,
        13,
        51538
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.303112655878067,
      "compression_ratio": 1.6188678741455078,
      "end": 27.920000076293945,
      "no_speech_prob": 0.0022168050054460764,
      "seek": 0,
      "start": 23.479999542236328,
      "temperature": 0.0,
      "text": " And so cursor tab, for example, is a great example of where you can specialize this model",
      "tokens": [
        51538,
        400,
        370,
        28169,
        4421,
        11,
        337,
        1365,
        11,
        307,
        257,
        869,
        1365,
        295,
        689,
        291,
        393,
        37938,
        341,
        2316,
        51760
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2702997922897339,
      "compression_ratio": 1.73305082321167,
      "end": 30.040000915527344,
      "no_speech_prob": 0.011868608184158802,
      "seek": 2792,
      "start": 27.920000076293945,
      "temperature": 0.0,
      "text": " to be even better than even frontier models.",
      "tokens": [
        50364,
        281,
        312,
        754,
        1101,
        813,
        754,
        35853,
        5245,
        13,
        50470
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2702997922897339,
      "compression_ratio": 1.73305082321167,
      "end": 35.52000045776367,
      "no_speech_prob": 0.011868608184158802,
      "seek": 2792,
      "start": 30.040000915527344,
      "temperature": 0.0,
      "text": " If you look at evils on the task, we set it at the other domain, which it's kind of surprising",
      "tokens": [
        50470,
        759,
        291,
        574,
        412,
        1073,
        4174,
        322,
        264,
        5633,
        11,
        321,
        992,
        309,
        412,
        264,
        661,
        9274,
        11,
        597,
        309,
        311,
        733,
        295,
        8830,
        50744
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2702997922897339,
      "compression_ratio": 1.73305082321167,
      "end": 41.880001068115234,
      "no_speech_prob": 0.011868608184158802,
      "seek": 2792,
      "start": 35.52000045776367,
      "temperature": 0.0,
      "text": " that it requires custom models, but it's kind of necessary and works quite well is in apply.",
      "tokens": [
        50744,
        300,
        309,
        7029,
        2375,
        5245,
        11,
        457,
        309,
        311,
        733,
        295,
        4818,
        293,
        1985,
        1596,
        731,
        307,
        294,
        3079,
        13,
        51062
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.2702997922897339,
      "compression_ratio": 1.73305082321167,
      "end": 47.31999969482422,
      "no_speech_prob": 0.011868608184158802,
      "seek": 2792,
      "start": 41.880001068115234,
      "temperature": 0.0,
      "text": " So I think these models are like the frontier models are quite good at sketching out plans",
      "tokens": [
        51062,
        407,
        286,
        519,
        613,
        5245,
        366,
        411,
        264,
        35853,
        5245,
        366,
        1596,
        665,
        412,
        12325,
        278,
        484,
        5482,
        51334
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.2702997922897339,
      "compression_ratio": 1.73305082321167,
      "end": 52.47999954223633,
      "no_speech_prob": 0.011868608184158802,
      "seek": 2792,
      "start": 47.31999969482422,
      "temperature": 0.0,
      "text": " for code and generating like rough sketches of like the change, but actually creating",
      "tokens": [
        51334,
        337,
        3089,
        293,
        17746,
        411,
        5903,
        34547,
        295,
        411,
        264,
        1319,
        11,
        457,
        767,
        4084,
        51592
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.269084095954895,
      "compression_ratio": 1.5966386795043945,
      "end": 59.36000061035156,
      "no_speech_prob": 0.009558944962918758,
      "seek": 5248,
      "start": 52.47999954223633,
      "temperature": 0.0,
      "text": " diffs is quite hard for frontier models, for your training models.",
      "tokens": [
        50364,
        7593,
        82,
        307,
        1596,
        1152,
        337,
        35853,
        5245,
        11,
        337,
        428,
        3097,
        5245,
        13,
        50708
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.269084095954895,
      "compression_ratio": 1.5966386795043945,
      "end": 65.80000305175781,
      "no_speech_prob": 0.009558944962918758,
      "seek": 5248,
      "start": 59.36000061035156,
      "temperature": 0.0,
      "text": " Like you try to do this with Sonnet, with O1, any frontier model, and it really messes",
      "tokens": [
        50708,
        1743,
        291,
        853,
        281,
        360,
        341,
        365,
        5185,
        7129,
        11,
        365,
        422,
        16,
        11,
        604,
        35853,
        2316,
        11,
        293,
        309,
        534,
        2082,
        279,
        51030
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.269084095954895,
      "compression_ratio": 1.5966386795043945,
      "end": 72.4000015258789,
      "no_speech_prob": 0.009558944962918758,
      "seek": 5248,
      "start": 65.80000305175781,
      "temperature": 0.0,
      "text": " up stupid things like counting line numbers, especially in super, super large files.",
      "tokens": [
        51030,
        493,
        6631,
        721,
        411,
        13251,
        1622,
        3547,
        11,
        2318,
        294,
        1687,
        11,
        1687,
        2416,
        7098,
        13,
        51360
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.269084095954895,
      "compression_ratio": 1.5966386795043945,
      "end": 77.0,
      "no_speech_prob": 0.009558944962918758,
      "seek": 5248,
      "start": 72.4000015258789,
      "temperature": 0.0,
      "text": " And so what we've done to alleviate this is we let the model kind of sketch out this rough",
      "tokens": [
        51360,
        400,
        370,
        437,
        321,
        600,
        1096,
        281,
        42701,
        341,
        307,
        321,
        718,
        264,
        2316,
        733,
        295,
        12325,
        484,
        341,
        5903,
        51590
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.269084095954895,
      "compression_ratio": 1.5966386795043945,
      "end": 80.76000213623047,
      "no_speech_prob": 0.009558944962918758,
      "seek": 5248,
      "start": 77.0,
      "temperature": 0.0,
      "text": " code block that indicates what the change will be.",
      "tokens": [
        51590,
        3089,
        3461,
        300,
        16203,
        437,
        264,
        1319,
        486,
        312,
        13,
        51778
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.24266602098941803,
      "compression_ratio": 1.608888864517212,
      "end": 85.04000091552734,
      "no_speech_prob": 0.015188601799309254,
      "seek": 8076,
      "start": 80.76000213623047,
      "temperature": 0.0,
      "text": " And we train a model to then apply that change to the file.",
      "tokens": [
        50364,
        400,
        321,
        3847,
        257,
        2316,
        281,
        550,
        3079,
        300,
        1319,
        281,
        264,
        3991,
        13,
        50578
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.24266602098941803,
      "compression_ratio": 1.608888864517212,
      "end": 90.0,
      "no_speech_prob": 0.015188601799309254,
      "seek": 8076,
      "start": 85.04000091552734,
      "temperature": 0.0,
      "text": " And we should say that apply is the model looks at your code.",
      "tokens": [
        50578,
        400,
        321,
        820,
        584,
        300,
        3079,
        307,
        264,
        2316,
        1542,
        412,
        428,
        3089,
        13,
        50826
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.24266602098941803,
      "compression_ratio": 1.608888864517212,
      "end": 95.08000183105469,
      "no_speech_prob": 0.015188601799309254,
      "seek": 8076,
      "start": 90.0,
      "temperature": 0.0,
      "text": " It gives you a really damn good suggestion of what new things to do.",
      "tokens": [
        50826,
        467,
        2709,
        291,
        257,
        534,
        8151,
        665,
        16541,
        295,
        437,
        777,
        721,
        281,
        360,
        13,
        51080
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.24266602098941803,
      "compression_ratio": 1.608888864517212,
      "end": 101.16000366210938,
      "no_speech_prob": 0.015188601799309254,
      "seek": 8076,
      "start": 95.08000183105469,
      "temperature": 0.0,
      "text": " And the seemingly for humans, trivial step of combining the two you're saying is not",
      "tokens": [
        51080,
        400,
        264,
        18709,
        337,
        6255,
        11,
        26703,
        1823,
        295,
        21928,
        264,
        732,
        291,
        434,
        1566,
        307,
        406,
        51384
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.24266602098941803,
      "compression_ratio": 1.608888864517212,
      "end": 102.16000366210938,
      "no_speech_prob": 0.015188601799309254,
      "seek": 8076,
      "start": 101.16000366210938,
      "temperature": 0.0,
      "text": " so trivial.",
      "tokens": [
        51384,
        370,
        26703,
        13,
        51434
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.24266602098941803,
      "compression_ratio": 1.608888864517212,
      "end": 105.80000305175781,
      "no_speech_prob": 0.015188601799309254,
      "seek": 8076,
      "start": 102.16000366210938,
      "temperature": 0.0,
      "text": " Contrary to popular perception, it is not a deterministic algorithm.",
      "tokens": [
        51434,
        4839,
        81,
        822,
        281,
        3743,
        12860,
        11,
        309,
        307,
        406,
        257,
        15957,
        3142,
        9284,
        13,
        51616
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.24266602098941803,
      "compression_ratio": 1.608888864517212,
      "end": 106.80000305175781,
      "no_speech_prob": 0.015188601799309254,
      "seek": 8076,
      "start": 105.80000305175781,
      "temperature": 0.0,
      "text": " Yeah.",
      "tokens": [
        51616,
        865,
        13,
        51666
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.2618679404258728,
      "compression_ratio": 1.508108139038086,
      "end": 112.19999694824219,
      "no_speech_prob": 0.007458364125341177,
      "seek": 10680,
      "start": 106.83999633789062,
      "temperature": 0.0,
      "text": " I think like you see shallow copies of apply elsewhere.",
      "tokens": [
        50366,
        286,
        519,
        411,
        291,
        536,
        20488,
        14341,
        295,
        3079,
        14517,
        13,
        50634
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.2618679404258728,
      "compression_ratio": 1.508108139038086,
      "end": 115.95999908447266,
      "no_speech_prob": 0.007458364125341177,
      "seek": 10680,
      "start": 112.19999694824219,
      "temperature": 0.0,
      "text": " And it just breaks like most of the time because you think you can kind of try to do some deterministic",
      "tokens": [
        50634,
        400,
        309,
        445,
        9857,
        411,
        881,
        295,
        264,
        565,
        570,
        291,
        519,
        291,
        393,
        733,
        295,
        853,
        281,
        360,
        512,
        15957,
        3142,
        50822
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.2618679404258728,
      "compression_ratio": 1.508108139038086,
      "end": 120.87999725341797,
      "no_speech_prob": 0.007458364125341177,
      "seek": 10680,
      "start": 115.95999908447266,
      "temperature": 0.0,
      "text": " matching and then it fails, you know, at least 40% of the time.",
      "tokens": [
        50822,
        14324,
        293,
        550,
        309,
        18199,
        11,
        291,
        458,
        11,
        412,
        1935,
        3356,
        4,
        295,
        264,
        565,
        13,
        51068
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.2618679404258728,
      "compression_ratio": 1.508108139038086,
      "end": 125.72000122070312,
      "no_speech_prob": 0.007458364125341177,
      "seek": 10680,
      "start": 120.87999725341797,
      "temperature": 0.0,
      "text": " And that just results in a terrible product experience.",
      "tokens": [
        51068,
        400,
        300,
        445,
        3542,
        294,
        257,
        6237,
        1674,
        1752,
        13,
        51310
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.3431689739227295,
      "compression_ratio": 1.0921052694320679,
      "end": 131.0,
      "no_speech_prob": 0.9524828791618347,
      "seek": 12572,
      "start": 125.72000122070312,
      "temperature": 0.0,
      "text": " I think in general, this regime of you are going to get smarter and smarter models.",
      "tokens": [
        50364,
        286,
        519,
        294,
        2674,
        11,
        341,
        13120,
        295,
        291,
        366,
        516,
        281,
        483,
        20294,
        293,
        20294,
        5245,
        13,
        50628
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_001.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 134.1999933719635,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 131.0399932861328,
      "temperature": 0.0,
      "text": " And like, so one other thing that ApplyGit lets you do",
      "tokens": [
        50364,
        400,
        411,
        11,
        370,
        472,
        661,
        551,
        300,
        25264,
        38,
        270,
        6653,
        291,
        360,
        50522
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 137.63999319076538,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 134.1999933719635,
      "temperature": 0.0,
      "text": " is it lets you use fewer tokens",
      "tokens": [
        50522,
        307,
        309,
        6653,
        291,
        764,
        13366,
        22667,
        50694
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 139.67999362945557,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 137.63999319076538,
      "temperature": 0.0,
      "text": " with the most intelligent models.",
      "tokens": [
        50694,
        365,
        264,
        881,
        13232,
        5245,
        13,
        50796
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 142.35999298095703,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 139.67999362945557,
      "temperature": 0.0,
      "text": " This is both expensive in terms of latency",
      "tokens": [
        50796,
        639,
        307,
        1293,
        5124,
        294,
        2115,
        295,
        27043,
        50930
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 146.63999366760254,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 142.35999298095703,
      "temperature": 0.0,
      "text": " for generating all these tokens and cost.",
      "tokens": [
        50930,
        337,
        17746,
        439,
        613,
        22667,
        293,
        2063,
        13,
        51144
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 149.55999374389648,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 146.63999366760254,
      "temperature": 0.0,
      "text": " So you can give this very, very rough sketch",
      "tokens": [
        51144,
        407,
        291,
        393,
        976,
        341,
        588,
        11,
        588,
        5903,
        12325,
        51290
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 152.31999397277832,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 149.55999374389648,
      "temperature": 0.0,
      "text": " and then have your small models go and implement it",
      "tokens": [
        51290,
        293,
        550,
        362,
        428,
        1359,
        5245,
        352,
        293,
        4445,
        309,
        51428
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 154.4399929046631,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 152.31999397277832,
      "temperature": 0.0,
      "text": " because it's a much easier task to implement",
      "tokens": [
        51428,
        570,
        309,
        311,
        257,
        709,
        3571,
        5633,
        281,
        4445,
        51534
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 156.7599925994873,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 154.4399929046631,
      "temperature": 0.0,
      "text": " this very, very sketched out code.",
      "tokens": [
        51534,
        341,
        588,
        11,
        588,
        12325,
        292,
        484,
        3089,
        13,
        51650
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 158.63999366760254,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 156.7599925994873,
      "temperature": 0.0,
      "text": " And I think that this regime will continue",
      "tokens": [
        51650,
        400,
        286,
        519,
        300,
        341,
        13120,
        486,
        2354,
        51744
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.25865185260772705,
      "compression_ratio": 1.7343173027038574,
      "end": 160.7199935913086,
      "no_speech_prob": 0.0007793423719704151,
      "seek": 0,
      "start": 158.63999366760254,
      "temperature": 0.0,
      "text": " where you can use smarter and smarter models",
      "tokens": [
        51744,
        689,
        291,
        393,
        764,
        20294,
        293,
        20294,
        5245,
        51848
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 161.55999374389648,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 160.7199935913086,
      "temperature": 0.0,
      "text": " to do the planning.",
      "tokens": [
        50364,
        281,
        360,
        264,
        5038,
        13,
        50406
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 164.0399932861328,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 161.55999374389648,
      "temperature": 0.0,
      "text": " And then maybe the implementation details",
      "tokens": [
        50406,
        400,
        550,
        1310,
        264,
        11420,
        4365,
        50530
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 165.99999237060547,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 164.0399932861328,
      "temperature": 0.0,
      "text": " can be handled by the less intelligent ones.",
      "tokens": [
        50530,
        393,
        312,
        18033,
        538,
        264,
        1570,
        13232,
        2306,
        13,
        50628
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 168.3199920654297,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 165.99999237060547,
      "temperature": 0.0,
      "text": " Perhaps you'll have, you know, maybe a one,",
      "tokens": [
        50628,
        10517,
        291,
        603,
        362,
        11,
        291,
        458,
        11,
        1310,
        257,
        472,
        11,
        50744
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 170.79999160766602,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 168.3199920654297,
      "temperature": 0.0,
      "text": " maybe it'll be even more capable models",
      "tokens": [
        50744,
        1310,
        309,
        603,
        312,
        754,
        544,
        8189,
        5245,
        50868
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 173.23999404907227,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 170.79999160766602,
      "temperature": 0.0,
      "text": " given an even higher level plan",
      "tokens": [
        50868,
        2212,
        364,
        754,
        2946,
        1496,
        1393,
        50990
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 178.07999420166016,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 173.23999404907227,
      "temperature": 0.0,
      "text": " that is kind of recursively applied by Sonnet",
      "tokens": [
        50990,
        300,
        307,
        733,
        295,
        20560,
        3413,
        6456,
        538,
        5185,
        7129,
        51232
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 179.07999420166016,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 178.07999420166016,
      "temperature": 0.0,
      "text": " and then the Apply model.",
      "tokens": [
        51232,
        293,
        550,
        264,
        25264,
        2316,
        13,
        51282
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 181.43999481201172,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 179.07999420166016,
      "temperature": 0.0,
      "text": " Maybe we should talk about how to make it fast.",
      "tokens": [
        51282,
        2704,
        321,
        820,
        751,
        466,
        577,
        281,
        652,
        309,
        2370,
        13,
        51400
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 182.2799949645996,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 181.43999481201172,
      "temperature": 0.0,
      "text": " Yeah.",
      "tokens": [
        51400,
        865,
        13,
        51442
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 184.1199951171875,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 182.2799949645996,
      "temperature": 0.0,
      "text": " I feel like fast is always an interesting detail.",
      "tokens": [
        51442,
        286,
        841,
        411,
        2370,
        307,
        1009,
        364,
        1880,
        2607,
        13,
        51534
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 185.23999404907227,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 184.1199951171875,
      "temperature": 0.0,
      "text": " Fast is good.",
      "tokens": [
        51534,
        15968,
        307,
        665,
        13,
        51590
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 186.07999420166016,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 185.23999404907227,
      "temperature": 0.0,
      "text": " Yeah.",
      "tokens": [
        51590,
        865,
        13,
        51632
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.2652750015258789,
      "compression_ratio": 1.6407407522201538,
      "end": 187.55999374389648,
      "no_speech_prob": 6.401947030099109e-05,
      "seek": 2968,
      "start": 186.07999420166016,
      "temperature": 0.0,
      "text": " How do you make it fast?",
      "tokens": [
        51632,
        1012,
        360,
        291,
        652,
        309,
        2370,
        30,
        51706
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 188.39999389648438,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 187.55999374389648,
      "temperature": 0.0,
      "text": " Yeah.",
      "tokens": [
        50364,
        865,
        13,
        50406
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 192.43999481201172,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 188.39999389648438,
      "temperature": 0.0,
      "text": " So one big component of making it fast is speculative edits.",
      "tokens": [
        50406,
        407,
        472,
        955,
        6542,
        295,
        1455,
        309,
        2370,
        307,
        49415,
        41752,
        13,
        50608
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 195.55998992919922,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 192.43999481201172,
      "temperature": 0.0,
      "text": " So speculative edits are a variant of speculative decoding",
      "tokens": [
        50608,
        407,
        49415,
        41752,
        366,
        257,
        17501,
        295,
        49415,
        979,
        8616,
        50764
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 198.1999969482422,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 195.55998992919922,
      "temperature": 0.0,
      "text": " and maybe it'd be helpful to briefly describe",
      "tokens": [
        50764,
        293,
        1310,
        309,
        1116,
        312,
        4961,
        281,
        10515,
        6786,
        50896
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 199.3199920654297,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 198.1999969482422,
      "temperature": 0.0,
      "text": " speculative decoding.",
      "tokens": [
        50896,
        49415,
        979,
        8616,
        13,
        50952
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 201.7199935913086,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 200.27999114990234,
      "temperature": 0.0,
      "text": " With speculative decoding,",
      "tokens": [
        51000,
        2022,
        49415,
        979,
        8616,
        11,
        51072
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 204.43999481201172,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 201.7199935913086,
      "temperature": 0.0,
      "text": " what you do is you can kind of take advantage",
      "tokens": [
        51072,
        437,
        291,
        360,
        307,
        291,
        393,
        733,
        295,
        747,
        5002,
        51208
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 207.7199935913086,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 204.43999481201172,
      "temperature": 0.0,
      "text": " of the fact that, you know, most of the time,",
      "tokens": [
        51208,
        295,
        264,
        1186,
        300,
        11,
        291,
        458,
        11,
        881,
        295,
        264,
        565,
        11,
        51372
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 210.1199951171875,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 207.7199935913086,
      "temperature": 0.0,
      "text": " and I'll add the caveat that it would be",
      "tokens": [
        51372,
        293,
        286,
        603,
        909,
        264,
        43012,
        300,
        309,
        576,
        312,
        51492
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.21865160763263702,
      "compression_ratio": 1.7662338018417358,
      "end": 213.07999420166016,
      "no_speech_prob": 6.108709203545004e-05,
      "seek": 5652,
      "start": 210.1199951171875,
      "temperature": 0.0,
      "text": " when you're memory bound in language model generation.",
      "tokens": [
        51492,
        562,
        291,
        434,
        4675,
        5472,
        294,
        2856,
        2316,
        5125,
        13,
        51640
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 218.07999420166016,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 214.0399932861328,
      "temperature": 0.0,
      "text": " If you process multiple tokens at once,",
      "tokens": [
        50412,
        759,
        291,
        1399,
        3866,
        22667,
        412,
        1564,
        11,
        50614
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 220.91999053955078,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 218.07999420166016,
      "temperature": 0.0,
      "text": " it is faster than generating one token at a time.",
      "tokens": [
        50614,
        309,
        307,
        4663,
        813,
        17746,
        472,
        14862,
        412,
        257,
        565,
        13,
        50756
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 222.6399917602539,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 220.91999053955078,
      "temperature": 0.0,
      "text": " So this is like the same reason why",
      "tokens": [
        50756,
        407,
        341,
        307,
        411,
        264,
        912,
        1778,
        983,
        50842
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 224.79999542236328,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 222.6399917602539,
      "temperature": 0.0,
      "text": " if you look at tokens per second",
      "tokens": [
        50842,
        498,
        291,
        574,
        412,
        22667,
        680,
        1150,
        50950
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 227.35999298095703,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 224.79999542236328,
      "temperature": 0.0,
      "text": " with prompt tokens versus generated tokens,",
      "tokens": [
        50950,
        365,
        12391,
        22667,
        5717,
        10833,
        22667,
        11,
        51078
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 229.67999267578125,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 227.35999298095703,
      "temperature": 0.0,
      "text": " it's much, much faster for prompt tokens.",
      "tokens": [
        51078,
        309,
        311,
        709,
        11,
        709,
        4663,
        337,
        12391,
        22667,
        13,
        51194
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 234.35999298095703,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 231.47999572753906,
      "temperature": 0.0,
      "text": " So what we do is instead of using",
      "tokens": [
        51284,
        407,
        437,
        321,
        360,
        307,
        2602,
        295,
        1228,
        51428
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 235.95999145507812,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 234.35999298095703,
      "temperature": 0.0,
      "text": " what speculative decoding normally does,",
      "tokens": [
        51428,
        437,
        49415,
        979,
        8616,
        5646,
        775,
        11,
        51508
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 237.91999053955078,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 235.95999145507812,
      "temperature": 0.0,
      "text": " which is using a really small model",
      "tokens": [
        51508,
        597,
        307,
        1228,
        257,
        534,
        1359,
        2316,
        51606
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 239.3199920654297,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 237.91999053955078,
      "temperature": 0.0,
      "text": " to predict these draft tokens",
      "tokens": [
        51606,
        281,
        6069,
        613,
        11206,
        22667,
        51676
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.19501006603240967,
      "compression_ratio": 1.7448559999465942,
      "end": 241.47999572753906,
      "no_speech_prob": 0.0001767414214555174,
      "seek": 8204,
      "start": 239.3199920654297,
      "temperature": 0.0,
      "text": " that your larger model will then go in",
      "tokens": [
        51676,
        300,
        428,
        4833,
        2316,
        486,
        550,
        352,
        294,
        51784
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.27406567335128784,
      "compression_ratio": 1.6323529481887817,
      "end": 243.0399932861328,
      "no_speech_prob": 0.001956833526492119,
      "seek": 11044,
      "start": 241.75999450683594,
      "temperature": 0.0,
      "text": " and verify.",
      "tokens": [
        50378,
        293,
        16888,
        13,
        50442
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.27406567335128784,
      "compression_ratio": 1.6323529481887817,
      "end": 246.43999481201172,
      "no_speech_prob": 0.001956833526492119,
      "seek": 11044,
      "start": 244.55998992919922,
      "temperature": 0.0,
      "text": " With code edits, we have a very strong prior",
      "tokens": [
        50518,
        2022,
        3089,
        41752,
        11,
        321,
        362,
        257,
        588,
        2068,
        4059,
        50612
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.27406567335128784,
      "compression_ratio": 1.6323529481887817,
      "end": 248.35999298095703,
      "no_speech_prob": 0.001956833526492119,
      "seek": 11044,
      "start": 246.43999481201172,
      "temperature": 0.0,
      "text": " of what the existing code will look like.",
      "tokens": [
        50612,
        295,
        437,
        264,
        6741,
        3089,
        486,
        574,
        411,
        13,
        50708
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.27406567335128784,
      "compression_ratio": 1.6323529481887817,
      "end": 252.0399932861328,
      "no_speech_prob": 0.001956833526492119,
      "seek": 11044,
      "start": 248.35999298095703,
      "temperature": 0.0,
      "text": " And that prior is literally the same exact code.",
      "tokens": [
        50708,
        400,
        300,
        4059,
        307,
        3736,
        264,
        912,
        1900,
        3089,
        13,
        50892
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.27406567335128784,
      "compression_ratio": 1.6323529481887817,
      "end": 253.99999237060547,
      "no_speech_prob": 0.001956833526492119,
      "seek": 11044,
      "start": 252.0399932861328,
      "temperature": 0.0,
      "text": " So what you can do is you can just feed chunks",
      "tokens": [
        50892,
        407,
        437,
        291,
        393,
        360,
        307,
        291,
        393,
        445,
        3154,
        24004,
        50990
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.27406567335128784,
      "compression_ratio": 1.6323529481887817,
      "end": 256.239990234375,
      "no_speech_prob": 0.001956833526492119,
      "seek": 11044,
      "start": 253.99999237060547,
      "temperature": 0.0,
      "text": " of the original code back into the model.",
      "tokens": [
        50990,
        295,
        264,
        3380,
        3089,
        646,
        666,
        264,
        2316,
        13,
        51102
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.27406567335128784,
      "compression_ratio": 1.6323529481887817,
      "end": 260.3199920654297,
      "no_speech_prob": 0.001956833526492119,
      "seek": 11044,
      "start": 257.3999938964844,
      "temperature": 0.0,
      "text": " And then the model will just pretty much agree",
      "tokens": [
        51160,
        400,
        550,
        264,
        2316,
        486,
        445,
        1238,
        709,
        3986,
        51306
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.27406567335128784,
      "compression_ratio": 1.6323529481887817,
      "end": 262.71998596191406,
      "no_speech_prob": 0.001956833526492119,
      "seek": 11044,
      "start": 260.3199920654297,
      "temperature": 0.0,
      "text": " most of the time that, okay, I'm just going to...",
      "tokens": [
        51306,
        881,
        295,
        264,
        565,
        300,
        11,
        1392,
        11,
        286,
        478,
        445,
        516,
        281,
        485,
        51426
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_002.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2444078028202057,
      "compression_ratio": 1.7167831659317017,
      "end": 266.47998666763306,
      "no_speech_prob": 0.01363564096391201,
      "seek": 0,
      "start": 262.0799865722656,
      "temperature": 0.0,
      "text": " this code back out. And so you can process all of those lines in parallel. And you just do this",
      "tokens": [
        50364,
        341,
        3089,
        646,
        484,
        13,
        400,
        370,
        291,
        393,
        1399,
        439,
        295,
        729,
        3876,
        294,
        8952,
        13,
        400,
        291,
        445,
        360,
        341,
        50584
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2444078028202057,
      "compression_ratio": 1.7167831659317017,
      "end": 270.6399869918823,
      "no_speech_prob": 0.01363564096391201,
      "seek": 0,
      "start": 266.47998666763306,
      "temperature": 0.0,
      "text": " with sufficiently many chunks and then eventually you'll reach a point of disagreement where the",
      "tokens": [
        50584,
        365,
        31868,
        867,
        24004,
        293,
        550,
        4728,
        291,
        603,
        2524,
        257,
        935,
        295,
        38947,
        689,
        264,
        50792
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2444078028202057,
      "compression_ratio": 1.7167831659317017,
      "end": 276.23998641967773,
      "no_speech_prob": 0.01363564096391201,
      "seek": 0,
      "start": 270.6399869918823,
      "temperature": 0.0,
      "text": " model will now predict text that is different from the ground truth original code. It'll generate",
      "tokens": [
        50792,
        2316,
        486,
        586,
        6069,
        2487,
        300,
        307,
        819,
        490,
        264,
        2727,
        3494,
        3380,
        3089,
        13,
        467,
        603,
        8460,
        51072
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2444078028202057,
      "compression_ratio": 1.7167831659317017,
      "end": 282.8799858093262,
      "no_speech_prob": 0.01363564096391201,
      "seek": 0,
      "start": 276.23998641967773,
      "temperature": 0.0,
      "text": " those tokens and then we kind of will decide after enough tokens match the original code to restart",
      "tokens": [
        51072,
        729,
        22667,
        293,
        550,
        321,
        733,
        295,
        486,
        4536,
        934,
        1547,
        22667,
        2995,
        264,
        3380,
        3089,
        281,
        21022,
        51404
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2444078028202057,
      "compression_ratio": 1.7167831659317017,
      "end": 289.9199867248535,
      "no_speech_prob": 0.01363564096391201,
      "seek": 0,
      "start": 282.8799858093262,
      "temperature": 0.0,
      "text": " speculating in chunks of code. What this actually ends up looking like is just a much faster version",
      "tokens": [
        51404,
        1608,
        12162,
        294,
        24004,
        295,
        3089,
        13,
        708,
        341,
        767,
        5314,
        493,
        1237,
        411,
        307,
        445,
        257,
        709,
        4663,
        3037,
        51756
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2495928555727005,
      "compression_ratio": 1.752293586730957,
      "end": 295.5999870300293,
      "no_speech_prob": 0.028434671461582184,
      "seek": 2784,
      "start": 289.9199867248535,
      "temperature": 0.0,
      "text": " of normal editing code. So it's just like it looks like a much faster version of the model rewriting",
      "tokens": [
        50364,
        295,
        2710,
        10000,
        3089,
        13,
        407,
        309,
        311,
        445,
        411,
        309,
        1542,
        411,
        257,
        709,
        4663,
        3037,
        295,
        264,
        2316,
        319,
        19868,
        50648
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2495928555727005,
      "compression_ratio": 1.752293586730957,
      "end": 302.39998626708984,
      "no_speech_prob": 0.028434671461582184,
      "seek": 2784,
      "start": 295.5999870300293,
      "temperature": 0.0,
      "text": " all the code. So just we can use the same exact interface that we use for diffs but it will just",
      "tokens": [
        50648,
        439,
        264,
        3089,
        13,
        407,
        445,
        321,
        393,
        764,
        264,
        912,
        1900,
        9226,
        300,
        321,
        764,
        337,
        7593,
        82,
        457,
        309,
        486,
        445,
        50988
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2495928555727005,
      "compression_ratio": 1.752293586730957,
      "end": 307.99998474121094,
      "no_speech_prob": 0.028434671461582184,
      "seek": 2784,
      "start": 302.39998626708984,
      "temperature": 0.0,
      "text": " stream down a lot faster. And then the advantage is that while it's streaming you can just also",
      "tokens": [
        50988,
        4309,
        760,
        257,
        688,
        4663,
        13,
        400,
        550,
        264,
        5002,
        307,
        300,
        1339,
        309,
        311,
        11791,
        291,
        393,
        445,
        611,
        51268
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2495928555727005,
      "compression_ratio": 1.752293586730957,
      "end": 313.2799873352051,
      "no_speech_prob": 0.028434671461582184,
      "seek": 2784,
      "start": 307.99998474121094,
      "temperature": 0.0,
      "text": " be reviewing start reviewing the code before it's done so there's no big loading screen.",
      "tokens": [
        51268,
        312,
        19576,
        722,
        19576,
        264,
        3089,
        949,
        309,
        311,
        1096,
        370,
        456,
        311,
        572,
        955,
        15114,
        2568,
        13,
        51532
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.2811690866947174,
      "compression_ratio": 1.7429906129837036,
      "end": 320.3199882507324,
      "no_speech_prob": 0.0031233648769557476,
      "seek": 5120,
      "start": 314.23998641967773,
      "temperature": 0.0,
      "text": " So maybe that is part of the part of the advantage. So the human can start reading",
      "tokens": [
        50412,
        407,
        1310,
        300,
        307,
        644,
        295,
        264,
        644,
        295,
        264,
        5002,
        13,
        407,
        264,
        1952,
        393,
        722,
        3760,
        50716
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.2811690866947174,
      "compression_ratio": 1.7429906129837036,
      "end": 323.6799850463867,
      "no_speech_prob": 0.0031233648769557476,
      "seek": 5120,
      "start": 320.3199882507324,
      "temperature": 0.0,
      "text": " before the thing is done. I think the interesting riff here is something like",
      "tokens": [
        50716,
        949,
        264,
        551,
        307,
        1096,
        13,
        286,
        519,
        264,
        1880,
        36798,
        510,
        307,
        746,
        411,
        50884
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.2811690866947174,
      "compression_ratio": 1.7429906129837036,
      "end": 329.6799850463867,
      "no_speech_prob": 0.0031233648769557476,
      "seek": 5120,
      "start": 324.39998626708984,
      "temperature": 0.0,
      "text": " like speculation is a fairly common idea nowadays. It's like not only in language models I mean",
      "tokens": [
        50920,
        411,
        27696,
        307,
        257,
        6457,
        2689,
        1558,
        13434,
        13,
        467,
        311,
        411,
        406,
        787,
        294,
        2856,
        5245,
        286,
        914,
        51184
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.2811690866947174,
      "compression_ratio": 1.7429906129837036,
      "end": 333.91998291015625,
      "no_speech_prob": 0.0031233648769557476,
      "seek": 5120,
      "start": 329.6799850463867,
      "temperature": 0.0,
      "text": " there's obviously speculation in CPUs and there's like speculation for databases and",
      "tokens": [
        51184,
        456,
        311,
        2745,
        27696,
        294,
        13199,
        82,
        293,
        456,
        311,
        411,
        27696,
        337,
        22380,
        293,
        51396
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.2811690866947174,
      "compression_ratio": 1.7429906129837036,
      "end": 336.1599884033203,
      "no_speech_prob": 0.0031233648769557476,
      "seek": 5120,
      "start": 334.79998779296875,
      "temperature": 0.0,
      "text": " speculation all over the place.",
      "tokens": [
        51440,
        27696,
        439,
        670,
        264,
        1081,
        13,
        51508
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.8692634105682373,
      "compression_ratio": 0.27272728085517883,
      "end": 344.31998443603516,
      "no_speech_prob": 0.9364514946937561,
      "seek": 8120,
      "start": 343.2799835205078,
      "temperature": 0.0,
      "text": " you",
      "tokens": [
        50412,
        291,
        50416
      ],
      "chunk_source": "how_ai_helps_programmers_cursor_team_and_lex_fridman_20250326_223156_chunk_003.mp3"
    }
  ],
  "created_at": 1743028348.432002,
  "num_chunks": 3,
  "language": "english"
}
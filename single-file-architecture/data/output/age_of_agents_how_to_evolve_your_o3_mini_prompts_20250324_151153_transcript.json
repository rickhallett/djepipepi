{
  "original_file": "data/audio/age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153.mp3",
  "text": "What's up, engineers? Indie Dev Dan here. We've entered the age of agents. Microsoft is rolling out co-pilot agent mode. OpenAI had back-to-back launches with Operator right into Deep Research. This is the most comprehensive Deep Research tool I've ever seen and used. Gemini has a version of Deep Research. More notably, they have their Notebook AI agent. Meanwhile, Anthropic created computer use and kind of set off this entire stream of generative AI companies, building agents on top of their own technology. The computer use, text editor, and Bash tools are still some of the most slept on tools to date. Check this out. Here's a simple bun logging script. I can open up the terminal. I have a file editing agent built on top of Anthropic's file editing tool. We can run this prompt and it'll make three distinct changes for us. It's going to read this file, update it, it's going to add the directory param just like we're asking, and then it's going to add a confirmation flag. You can see that just came in there. Then it's going to create two new versions, a shell script version and a PowerShell version. There it is. If I run that grep command again, you can see we now have those three individual files. Here's the updated bun version, clearlogs.sh. Here's the shell version, clearlogs.ps1. Here's the PowerShell version. With a single command, I was able to generate three changes thanks to my file AI agent. If it's not clear to you already, AI agents are extremely powerful. Why is that? It's because they turn your prompt, context, and model into actions at scale. It's important that you and I, the engineer, know how and when to build and deploy AI agents across your developer tooling projects and work. In this video, I want to take you through the prompt, the prompt chain, and the AI agent to help you understand which one you need to get the job done. We'll lean on Anthropic's incredible building effective agents post, and I'll share my distillation of what matters and mistakes I've made when building. AI agents so you can avoid making the same mistakes. Let me introduce you to my new video editing tool, Akka. Okay, so before we dive in to what exactly this tool does, let's go ahead and go over to the Akka agent file. And I'm going to kick off a benchmark that is going to run a series of problems for us using the prompt, the prompt chain, and the AI agent version. This benchmark is going to tell us which one of these levels we need to actually solve this problem. Spawn, run, Akka agent. And this benchmark is going to run in the background in parallel to us and we'll circle back to this to answer questions like, are reasoning models always better than base models? Do GPT-4 agents beat O3 mini prompts? Does a O3 mini prompt beat a O3 prompt chain? How much more expensive is an AI agent versus a prompt chain? And more importantly, is it worth it? So what's Akka, how does it work, and why did I build it? Akka is the fastest way to remove filler words, repeats, and nonsense out of your videos. So you can go from scripts that, you know, have stuttering in them, that have filler words and repeats, and then it'll end up looking like this. The scratchpad active memory pattern is going to be really important for rolling out useful personal AI assistance. The key here is that it focuses on the transcript. So let's walk through the process. It all starts out with word level transcript. You can use a whisper transcription tool to generate this type of JSON structure, right? We have all the text, and then we have the individual words at specific start and end times. This is the raw script, what I like to call the base edit, that we're going to have our AI agents edit for us. So if we scroll down here, you can see we have, you know, a couple sentences worth. Step two is create slices. So it is too much work to pass off an entire transcription for, you know, a 30, 40, 50 minute long video to any language model. If we open up a transcription here, you can see we have 350,000 tokens in this single transcript, and that includes all the text here. and then word level breakdowns, just as you saw before. And this is a real transcript from the DeepSeek personal AI assistant video. There's just too many tokens. Even if you hand this off to Gemini, it's not going to be able to solve this problem in any cohesive way at scale. How can we handle this? We can create slices. So a slice is a chunk of the transcript containing a few sentences each. From the transcription above, we could create two slices. In these two slices, there are a couple of key things that need to be edited out. Next, we're going to allocate our AI agents, right? So in our case, this is going to be our prompt, prompt chain, or our full-on AI agent, as we saw here, right? And we're going to walk through this in just a moment. I'm really excited to share with you how the prompt versus the prompt chain versus the AI agent performs for this use case. The results are not exactly as you would expect. This is the really cool part about creating slices, and it's a great part about breaking your large problem into smaller, more manageable chunks, right? If ever you're feeling overwhelmed with a specific problem, it's probably just too big, and you haven't broken it down into small enough chunks. Engineering 101. Slices give us this incredible ability to, for each slice, we'll create and allocate an AI agent and basically hand off this problem to compute at scale. So you can imagine we'll have hundreds of slices getting edited all at the same time in parallel. Now, step four is where all the magic happens. Slice one, you have this before text, and then you end up with this after text, right? So this is happening in parallel. Slice one and slice two and slice N are getting edited all at the same time with compute. And then finally, we combine the edits into the sequence of timeline edits. Every video editor has a different format. I use Final Cut Pro. So I'm gonna be converting these into FCP XML files. We're not gonna get into this too much, but there's what the format looks like. We're gonna go from prompt to prompt chain to AI agent, and we're gonna see across these three levels of abstraction, which one performs the best. Let's go ahead and run a prompt and really understand what this problem looks like. On run a cut agent, and then we can kick this off. Let's let this prompt run. So this is just running a single prompt. You can see it got the problem wrong. Let's go ahead and figure out why. So let's open up the logging and just look at this individual prompt. So we can open this up. I've been experimenting a lot lately with markdown based logging, just for a more easier to read logging experience. And let's go top to bottom here. So here's the original text and here's the target text. So every one of our benchmarking problems coming out of our benchmarking file, it looks like this, right? Here's the structure of it, right? So we have the problem ID, we have that slice. And remember the slice is a piece of the transcript. And then we have the correct text and the beginning text inside of the slice. Here's what a slice looks like. Most importantly, we have the words and we have the text. So let's look at what we're starting with and what we're ending up with. So a bunch of gibberish in the beginning. These are all real transcripts from videos, from previous videos, by the way. So yeah, this is me just, you know, stuttering and saying, ah, over and over. Turns out talking about technology can be sometimes harder than the technology itself. We then say the scratchpad active memory is going to be really important. So basically what we wanna do here is get rid of this intro, right? So that's the target text, right? It's everything remaining. This is what we want our model to edit down to, okay? So you can see we wrote the prompt. We'll look at what exactly this prompt looks like in just a moment. Our LLM created these deletions for us. Start time, end time, the duration, explanation. You can see the exact words that it removed. So it's gonna remove a, and then act the. Here's the original. Here's what we wanted to target. And then here's what the prediction was, right? Here's what our model output for us. You can see it didn't quite get the edit right. This is an example of where a prompt is not enough. And I'll link, just for fun, I'll link the original one prompt is not enough video that really kicked off the channel. Back then we were talking about the same concepts with much more primitive technology. It's incredible to think about how far we've come since that video. But you know, one prompt is not enough when you're trying to do more and more at scale and you're trying to accomplish and hand off a ton of work to your AI tooling. And here's the target text, right? So we can see here a simple prompt did not do the job. Let's look at what this prompt actually looks like. So if we open up this prompt, you can see here we have our classic clean XML-ish format. We have our. purpose, we have our instructions, and then we have our variables at the bottom. This was a dynamic variable and our application replaced it. So this, you know, looks like this in our code, right? So this is a, you know, variable that will be replaced. And what it ended up doing here was placing the iteration slice that we're operating on, right? And remember the slice is just a small piece of the entire transcript. So that's what the iteration slice is. You can see we have some instructions here, classic prompting, nothing new here that we haven't discussed on the channel before. Let's scale this up, right? This is the prompt. And if we open up our LLMs file, collapse everything, we have the intelligence comment here, and this is what that looks like in code, okay? So nothing too fancy, but it is important that I share it here because this tool is proprietary. Prompt up there, we have our XML slice that we're replacing with the incoming slice, and then we're doing some logging, reasoning effort check, and then we're just pulling out a bunch of auxiliary information from the response, right? That's the prompt. If we look at Anthropx building effective agents doc, it all starts with the prompt. What we've done here is we've given our language model access to an output structure so that we can pass in a prompt. Our LLM then makes a judgment call on the output. In the prompt version, we don't have anything fancy here. All we have is a structured outputs call that generates our deletions. And so that's all our prompt is doing. You can see here we have our response format that has our uncut deletion, and we are using Zodd response format for structured outputs. Let's go ahead and kick up our compute. There's two levers we can pull here right away. We can just do one of them for fun, right? We can quickly just take this, right? This is running GPT-40. We can go config, we can go LLM model, we can go O3 mini, and then we can just quickly, you know, kick this off again. And now O3 mini is going to take a hit at solving this problem. Let's take a look at the output that O3 mini gave us. Same deal. We have the original text, we have the target, there's the prompt for O3 mini, here's the deletion it created. And so if we scroll down here, you can see O3 mini got this problem right with just a prompt. Very cool to see this, right? So we have the original text and then we have the predicted final text coming out of our language model and then we have the target text. So that's us answering the problem successfully and incorrectly. So I'll comment this out and let's go ahead and look at the prompt chain. By looking at the log you'll understand exactly how it works. So let's kick this off. What we're doing here with the prompt chain is we're taking that same problem and we're throwing more compute at the problem. You can see here GPG 4.0 got this problem correct with a prompt chain. So let's go ahead and look at the log and then let's break down how the prompt chain worked. Let's go ahead and open up V2. This is the a cut prompt chain and let's look at how a prompt chain outperforms the single prompt, okay? So once again we have that exact same problem, right? Of this scratchpad kind of blah blah blah. So basically we have the starting text and then we have the ground truth, right? This is the end result we're looking to get to. And then we have this new piece of information. When you're using prompt chains and AI agents you'll always want to limit the amount of compute or loops that your AI tooling can run. You don't want it to run infinitely. You might have a bug, something might go wrong and there is nearly always a sweet spot or a perfect range for the problem that you're trying to solve. So you can see here for this prompt chain I'm allowing eight compute loops, eight iterations, okay? So we start with this one deletion here. This, the scratchpad kind of act um. And then if we scroll down here you can see, you know, that made a pretty good edit. Then we can scroll down and then you can see it only took out um. So it's taking another shot. It sees that, you know, after this first run that I made I still need to edit more, okay? So now it's just taking out um. Third compute loop, right? So it has, you know, five shots left. And so now it's telling us that no deletions were generated. So it's going to exit the loop. So inside of this prompt, which we'll look at in a moment, there is a condition that says if you're done return an empty list, okay? It created two deletions. Here's the first one with several words in the deletion. And then we have in a follow-up loop because it didn't create the perfect edit the first time. You can see here we have the words um edited that out. And then we have the final iteration slice. So this is what our final slice looks like. looks like with the edits made from the deletions. Okay. So there's that nice JSON object there. And then you can see here, here's the original, here's what our prompt chain output for us. And here's the target text. So you can see, we of course have the correct answer. This is really important because for this simple use case of effectively determining which words to remove that don't make sense, you can see here that having a little bit more compute, you know, quite literally, it just needed one additional run. Right. So we had one deletion and then we had another deletion. And then on our third compute loop, it said, there's nothing left for me to do here. I'm done by turning our prompt into a prompt chain, quite literally just saying, run it again. It was able to generate an improved answer for us. So, you know, that's the log and you can see here we have three prompts, right? So one prompt for our first run. So we have this first prompt here, and then we have our second prompt and then our third prompt. And it was in our third prompt where the prompt chain, you know, the language model returned no deletions. So that means we're done. Okay. Let's go ahead and just take a look at the prompt for a moment here. And you'll see a very similar structure, except for the primary difference that we have an original slice and current deletions. Okay. So in addition to the iteration slice, which is the small piece of the transcript that we're working on currently, we also have the current deletions. So when our model is looping, it needs to know what it's already edited and it needs to know the starting point. Okay. So this is where it started. This is the current deletions that it's made. And then the iteration slice is the result of those deletions on the original slice. So let me just show you the second prompt. You can see here, current deletions is empty. And in this version, our current deletions has some content, right? So in the second prompt, we have made edits, right? And you can see here, this corresponds to the edits we saw exactly in the log, the prompt chain, it allows us to keep track of the state, the original slice, the work that it's done and the work that it's doing that's iteration two. And then of course we have the third iteration. You can see here, same deal, except we have an additional current deletion, right? So we have two deletions in here. We can go ahead. and separate this just to make it a little bit more clear, right? So you can see those two removed words right there, okay? So this is our prompt chain and we can go ahead and dial into this code for a moment here, prompt chain. We can see here. We're just setting up logging, pulling out our model. We're pulling out the problem slice, starting text, and then we're actually running the code here. In the end, every one of these versions, right, every one of our prompt, our prompt chain, and our agent, it's just going to return deletions. It's really important to set up your workflows so that they're always returning consistent types, consistent formats. This allows you to operate on them at scale and create versions of them. So all we're doing here is outputting deletions and then some auxiliary information, right? In this case, we just have a cost. So let's go into generate a cut deletions v2. This is our prompt chain. So v1 is just a prompt, v2 is a prompt chain. So let's take a look at what this looks like and you can imagine it is, you know, effectively going to be a loop and you can see here we're passing in max compute and we're updating this to I think eight, but you can see here what's happening, right? We basically have the same thing and we're just looping this time, right? We're keeping track of some more state. This is our iteration slice. This is our original slice and here's our, you know, list of deletions that we're keeping track of and then of course, here's our loop, right? So just as you saw before, there's our instruction-rich prompt, purpose, and then our dynamic variables that get updated inside of our application, right? If we collapse the prompt, you can see we're always outputting our prompt file. We have our actual execution loop. This is the prompt chain. Let's go ahead and run the most exciting version, right? Let's run the AI agent. Let's kick this off. This agent has 16 compute loops. So I'm giving it 16 compute uses and unfortunately, GPT-40 got the problem wrong. So let's figure out why. Why did it edit this problem incorrectly, okay? Let's look at V3. You can see here it made four prompts in total and if we hop into this file, we can see a lot of the same things. The big difference here is that our AI agent now has access to a series of It has name and args. It's running make deletions here, just cutting out this one word. It's running another tool call here, editing out a few additional words, so on and so forth, right? You can see here it just continues to call make deletion. We run over and over and over and over, and then once we get to the bottom, it now calls an explicit tool. Instead of returning an empty list, it calls complete edit when it's done. So if we scroll all the way to the bottom, we'll get that exact same structure. So you can see the scratch pack active memory pattern is going to be really important for rolling out useful personal AI assistance. It just took out scratch pad. Didn't think scratch pad was important, so it edited that out, okay? So this is something that will just happen sometimes. You know, you can see here between the prompt chain and the AI assistant on this single use case, more compute isn't always better. And this is a really important thing to call out, okay? So this is our AI agent, and we can, of course, scale this up. Let's go ahead and let our O3 mini run the AI agent version, and let's go ahead and take a look at the AI agent code, okay? So we'll go ahead, kick this off, and let's dive into what the AI agent version of this looks like. So same deal on the top level, just logging and setup. And then this is where all the work happens, okay? So generate, cut, deletions, V3. So we'll hop in here, and let's open this up. Couple things are different right away. We have an entire class to support our AI agent. Why is that? Because we need to better manage state and tool calls. So just like the prompt chain, you can see there's our loop. And we'll go into the class in just a moment here, but you can see we're setting up the agent as a new class. We're passing in our starting state, and then the agent just gets updated with this one call, right? We just run prompt over and over, and then it just returns if it's done, right? Because our agents know what work to do. They know when to tell us when they're done. It's just a matter of letting them loop, letting them do the work, and then they'll let us know when they're done, right? This is kind of an interesting paradigm shift when we move into these longer-running assistants, these longer-running jobs. You know, a while back we put out this video called the two-way prompting, and that video really does set up the future of how we'll be operating with agentic technology. It might start out with us prompting them, but then they will prompt us, right? And we just saw this with deep research. it off it asks you questions right and I think we're going to see more of that as these tools progress but I digress let's jump into agent prompt and let me break down this class structure so I'll just collapse and we can look at it at a high level so this is the AI agent version you can see here we have state that we're keeping track of tool calls messages so on so forth we have our individual methods the most important thing is here inside the prompt you can see here more instructions I'm listing out the explicit tools it has access to you can see we just have three tools interestingly you know it doesn't take many tools to make your system an AI agent and then we have the state and this is really where the state becomes the environment okay if we open up anthropics building effective agents we're now in this state down here right so these are all different types of agentic workflows we have orchestrators parallelization we've talked about these on the channel before we'll bring them up again when they're relevant but we jumped all the way down here to agents okay and this is what's happening right we are prompting our AI agent it's going to run action and get feedback and the feedback that it's getting from its environment here is the edits that it's making right it's the edits and then the modifications to the original slice to the iteration slice okay so it's not far off at all from the prompt chain right that's something important to mention but this is a different design right we're not just looping over a structured output call we're now saying hey here's a bunch of instructions here's your purpose here's your tools here's your current environment solve the problem so it's quite a bit different even though the outcome here as you'll see is going to be relatively similar so now we have our AI agent and the action it takes updates its environment and then once again it tells us when it's done right it has access to this complete edit tool call and it also has a reset to original so if it decides that it's gotten itself into a bad state it can just reset okay and I personally don't care what tools it calls or what order it calls them I just want a good edit right I have an outcome that I'm looking for and then I'm packaging via this prompt context and model I'm packaging the work that I want done the right way and then I'm handing it off to this this AI agent, okay? So that's what this looks like. We then have a, you know, classic OpenAI call here. We have reasoning effort if we wanna go high. And then, you know, just classic stuff here, right? We're handling the tokens and making sure that we call the right tool. And so this is the AI agent version. So let's go ahead and take a look at the output, right? We just ran that with O3 mini. Let's see how it performed. So you can see it got the answer correct. Let's see what it did, okay? So I'll close this, O3 mini logging session. Top to bottom, make deletion. It's going to remove a. There's the before and after. So you can see it just pulled out that single a from the beginning, right? We have one deletion. And then if we scroll down here, so you can see these are all creating their own prompts. And then we have a nicer, larger edit. I did change it so that it is making a single edit, but you can still remove, you know, chunks of words, right? Chunks of words at a time, right? You wanna be able to remove phrases. Just like as if I were actually editing this. It's important to make the agent or the prompt chain or your AI tooling mirror the process you would take. It's always removing one idea of an edit at a time, right? One piece of an edit at a time. So you can see it removed a, and then removed this, the scratch pad. We can see here, this, the scratch pad, act, and then we have this, right? The scratch pad, act, and memory pattern is going to be really important. And then you can see, look at this. Once it got to this state, it said, perfect, right? The tool decided it was done. And this is really, really cool, right? It's not that different than the prompt chain, right? But it explicitly here called a different tool. There are all the deletions. There's the final transcript slice. And if we scroll to the bottom, we have the original, the final, and the target, okay? So this is correct. Fantastic. So now let's go ahead and look at the benchmark. Instead of just a single problem running against one model at a time, you know, just like in our previous benchmarking video, in order to understand and solve problems with generative AI at scale, you need to create tests. And tests are just another word for eval or benchmarks. For this tool, I'm starting to build up a suite of benchmarks. Right now, I only have 10 problems, but you can see here, I'm taking it. and I'm multiplying it by whatever models I wanna run against. So this ran in the background. Let's go ahead and just take a peek at the results from this. And let's see if we can answer some of the questions we put forth earlier in the video. So if we look at the logging, and if we open up logging underscore benchmark, you can see here, look at all these executions, right? You have to keep in mind, it's two models running against 10 problems for three different versions. We have the prompt, prompt chain, and AI agent. That's three times two times 10. So let's go ahead and just look at the top level benchmark session. So a benchmarking session is just gonna contain the kind of high level results. And so it's gonna tell us, you know, for the problem and for the model, what it got right and what it got wrong across the three levels. Is a prompt chain always better than a prompt? Is an AI agent always better than a prompt chain? Let's see if we can find some answers by looking at this benchmark. Here we have the prompt running GPT-4.0. It got the problem wrong. And you can see here, here's a start text. Here's our target text. It's incorrect. It left this. Our prompt chain has four remaining compute uses. So this is set at eight and our V3 AI agent, this is set at 16. We have a little bit more leeway for our AI agent because it can reset the entire state if it wants to. So we can see here with GPT-4.0, we have two correct and one wrong. Now we have that exact same problem running on O3 mini, right? So these are both problem zero. There's GPT-4.0. And here's problem zero with O3 mini. Same deal, except O3 mini, right? A powerful reasoning model gets every single version right. So what this individual test is telling us is that we don't need any more compute to solve this problem. A reasoning model and a prompt is enough, okay? But that is not always the case as we'll see here as we look at a few more problems, right? So GPT-4.0, problem two, here's a simple one. We're going to go right for, we're going to go. So how are we going to benchmark? And then if we scroll here, the correct edit is, so how are we going to benchmark the M4? This is from the M4 benchmarking video. If we scroll down here, you can see GPT-4.0 and every single variant gets this right. So prompt, prompt chain, agent, it's all good, okay? Interestingly, the O3 mini gets the individual prompt wrong, but you can see here the prompt chain and the AI agent get this problem correct. Okay, so very cool to see that. Now we're moving to problem two in GPT 4.0. So we can see here this problem, every single version of GPT 4.0 got it incorrect, right? False, false, false. So this is a longer, more interesting edit. Let's see how O3 mini has performed. True, true, and then interestingly, false. So this is a case where more compute is not better. Interesting to see that. And we can go on down the line here, right? I'm not gonna bore you with every single thing here. You can see here that this prompt chain over edited. So it ended up cutting out way too much text, right? It just kept going down. This is the, you know, one of the problems with just a prompt chain that just runs rampant. It just edited everything down, okay? And it didn't have the tools, right? It didn't have the tools available to reset or fix the edit. So if we continue down the line here, it's that same problem with O3 mini. You can see here, prompt was wrong. The chain was correct, but the AI agent was not correct. And so you can see here, it looks close, right? If we pull this text out, right? And we can just highlight this to see. So let's go ahead and open up everyone's favorite local model tool. We're going to be using Olama and here's where it branched. And we're going to be using a tool I'm building out called Benchy. And what we wanted was, and a tool I'm building out called Benchy, okay? So this is a better failure in the AI agent. You know, it made a clean edit, but it wasn't the exact edit we're looking for. And this is where making the prompt more specific to the exact editing decisions and subjective editing tastes is going to be more and more important, okay? There are many of these in here that could have been marked right, specifically with the O3 mini model that could be marked true, could be marked correct, but it doesn't exactly hit the target text, right? This is where something like 11 scene distance or some rough string comparison framework can come in, okay? So we're going to skip through these, right? There's a lot going on. If we just scroll all the way to the bottom, we can get some high level overarching benchmark results, okay? Here's everything. that was correct and incorrect for a raw prompt. We have across all models, eight correct. And if we break down by model, we can see GPT 4.0 got only two correct, while O3 Mini got eight of these problems correct with just a prompt. Even though O3 Mini is half the price of GPT 4.0, it uses thinking tokens, right? It has to reason. So the price is still, you know, something like almost four times as much, right? So there's just the raw prompt, right? So we have eight out of 12 correct. Now, when we move to the prompt chain, we see something interesting, right? You can see we have one more correct. And you can see here that the point is going to O3 Mini. So this is pretty good, right? So out of 10 problems, O3 Mini with a prompt chain solved 70% of them correctly. Okay. And it's very likely, like I mentioned, there are just some more subjective editing taste decisions in the language of, you know, what constitutes a correct edit. Maybe you can give a one or two point discount here if you wanted to, okay? That's the prompt chain. Interestingly here, we can see that the costs have jumped up quite a bit for GPT 4.0, okay? So for all 10 problems running on the prompt chain, you know, 30 cents. Now, when we move to the AI agent, we see something very interesting, right? The results don't improve, okay? The results get worse. So we have seven correct, 13 wrong for every AI agent version of this. So you can see here, GPT 4.0 has a really hard time operating the AI agent in a useful way. And O3 Mini, half the time it gets it right, half the time it gets it wrong. Again, we can give or take a couple points for editing decisions. So, you know, this leads me to kind of the big takeaway from the work I'm doing here and some, you know, potential advice and direction that you can take from this for your generative AI work. Very clearly, you likely don't need an AI agent. You know, whenever there's a new tool that comes out, we always want to use the tool and check out the tool and see what we can do with the tool. That's fine. But when you're really solving- some problems when you're really in the mindset of value creation, you find problems first and then you apply tools to them from your tool belt. You don't find tools first and then look for problems to solve. It's just the wrong way. It's the backward way to do things. I was really happy to see that Anthropic explicitly mentions this in their documentation. It's about building the right systems for your needs. Start with prompts, then optimize them with evals and then add multi-step agentic systems, AKA prompt chains, workflows, graphs, whatever you want to call it, it doesn't matter. You only do that when the simpler solutions fail. It looks like for my problem here, for the problem space of editing down words in a transcript, it looks like what I'm actually looking for here is for my step four, my AI agents, they actually don't need to be AI agents. They can just be prompt chains. These are concrete steps, predefined steps of executing a prompt and then updating some state and then running another prompt. It looks like for my intelligent editing system, I really only need prompt chains. And that means that inside of this, for my intelligence, I really only need to let my assistant run over and over on a series of steps. Now, of course, there are tons of caveats to that. I don't really have enough data, right? This is not significant data to make a complete decision to completely rule out AI agents. Obviously, that's not enough, but I think it's just really important to stress that point. If a prompt chain can do the job for you, use a prompt chain. I think to push a little bit further, you can experiment with an AI agent and see what that might look like to give your AI agent full autonomy over the system. But I think that what we're going to see moving forward is that a lot of the AI agents that are going to be built underneath the hood, they're not actually going to be AI agents. They're going to be agentic workflows. And more specifically, they're going to be just prompt chains. So just to recap, there are three levels to this. You have just the raw prompt, you have what are called workflows or prompt chains or graphs, and then you have much more autonomous. this agents that just have a bunch of tools, you give them a problem, you give the right context, and then you just say, go solve my problem. You know, under the hood, I think what's really going to happen is that we're going to see tons and tons of agentic workflows, right? Or put simply, prompt chains, right? There are many very interesting, very powerful ways to use prompt chains, right? And Anthropic has detailed a lot of them here. We have routing, we have parallelization. I like to call this the fusion chain. We put a video out on this in the past. And then we have orchestrators. There's definitely a good call for using an orchestrator for a cut, evaluator, optimizer. And then we can go down the line, right? All the way down to the AI agent. And the AI agent workflow is the most interesting because in a certain way, it's the most hands-off. I think there's a lot of value to be created here, but the trick is always benchmarking the performance of your AI agent versus a predefined series of steps that call prompts and tools, AKA prompt chains. A couple of improvements that I'm thinking about making for a cut. It's pretty clear that this super harsh, yes, no response framework that I have here, where we just have correct, true, or false, isn't going to be accurate enough to create comprehensive benchmarks. Rolling out something like Levenstein distance to allow for a five to 10 character difference is probably going to be a big win for improving these benchmarks going forward. You know, another big thing that piggybacks off this is that, you know, video editing, even when you're just editing out transcripts, it's a very subjective experience. Certain editing decisions that a model will make are totally valid and legit. And it might not match up with the exact target, even within the five or 10 characters using the Levenstein distance that could actually work. So I think a more concrete way to improve that is to add more comprehensive examples into the prompts themselves. You know, why is that important? How can that change the outcome? That's super important because, you know, when we add examples to our prompts to, you know, give us an idea about what types of edits we wanted to make, it'll pick up on the taste of our editing and what words we like to keep in and keep out, so on and so forth. So more work to be done on that, adding in examples. tag here, it's going to be really important for making the model more consistent with my personal editing style. So something to think about for your prompt chains and AI agents, examples that guide your model in these more creative, more subjective decision making domains is a great way to guide your model and to guide the outcome. And of course, the best way to do this is benchmarking, but also run this against real data and then in a reinforcement learning type of way, take the edits that are working coming out of the model and update the prompt that was feeling that model with those correct edits as examples, right? So more on that in the future, I have some pretty interesting ideas around automatic feedback looped prompts to add more auto self-improving behavior into the prompt. Another interesting problem that I'm running into is that idea of not solving the problem at all. I think one of the strongest signs of a high level problem solver, a senior level engineer is the ability to look at a problem and decide that it doesn't need to be solved at all. And this is tricky to teach or explain to an LLM because these are next token generators, not next token, not generators. For edits, I've run into this several times with this tool already, where the best thing to do is nothing, right? The slice in a real video will sometimes contain perfect script and nothing needs to be changed. So, you know, I think probably more prompt engineering and explicitly mentioning when things need to be edited will be helpful for solving that problem inside of prompts, prompt chains and AI agents. So, you know, the next time you want to solve a problem with generative AI, first start with a prompt, then move to a prompt chain. And only if your prompt chain and your, you know, graph of steps is not giving you the performance that you need, only then should you move to a full on AI agent that can operate in a domain for you automatically. I highly recommend, you know, throughout that process, the more important the problem you're trying to solve, the more important it is to set up benchmarks so that you can know for a fact that your prompt chain is outperforming your prompt and your AI agent is outperforming your prompt chain. Agents give us the ability. to scale our impact even further beyond. We're gonna be talking, and more importantly, building agents on the channel over 2025. Like, subscribe, and comment to stay connected to this content. And no matter what, stay focused and keep building.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 2.319999933242798,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " What's up, engineers? Indie Dev Dan here.",
      "tokens": [
        50364,
        708,
        311,
        493,
        11,
        11955,
        30,
        2333,
        414,
        9096,
        3394,
        510,
        13,
        50480
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 5.320000171661377,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 2.319999933242798,
      "temperature": 0.0,
      "text": " We've entered the age of agents.",
      "tokens": [
        50480,
        492,
        600,
        9065,
        264,
        3205,
        295,
        12554,
        13,
        50630
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 8.600000381469727,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 5.320000171661377,
      "temperature": 0.0,
      "text": " Microsoft is rolling out co-pilot agent mode.",
      "tokens": [
        50630,
        8116,
        307,
        9439,
        484,
        598,
        12,
        79,
        31516,
        9461,
        4391,
        13,
        50794
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 14.239999771118164,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 8.600000381469727,
      "temperature": 0.0,
      "text": " OpenAI had back-to-back launches with Operator right into Deep Research.",
      "tokens": [
        50794,
        7238,
        48698,
        632,
        646,
        12,
        1353,
        12,
        3207,
        31841,
        365,
        12480,
        1639,
        558,
        666,
        14895,
        10303,
        13,
        51076
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 19.559999465942383,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 14.239999771118164,
      "temperature": 0.0,
      "text": " This is the most comprehensive Deep Research tool I've ever seen and used.",
      "tokens": [
        51076,
        639,
        307,
        264,
        881,
        13914,
        14895,
        10303,
        2290,
        286,
        600,
        1562,
        1612,
        293,
        1143,
        13,
        51342
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 21.920000076293945,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 19.559999465942383,
      "temperature": 0.0,
      "text": " Gemini has a version of Deep Research.",
      "tokens": [
        51342,
        22894,
        3812,
        575,
        257,
        3037,
        295,
        14895,
        10303,
        13,
        51460
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 25.31999969482422,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 21.920000076293945,
      "temperature": 0.0,
      "text": " More notably, they have their Notebook AI agent.",
      "tokens": [
        51460,
        5048,
        31357,
        11,
        436,
        362,
        641,
        11633,
        2939,
        7318,
        9461,
        13,
        51630
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 29.68000030517578,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 25.31999969482422,
      "temperature": 0.0,
      "text": " Meanwhile, Anthropic created computer use and kind of set off",
      "tokens": [
        51630,
        13879,
        11,
        12727,
        39173,
        2942,
        3820,
        764,
        293,
        733,
        295,
        992,
        766,
        51848
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 32.84000015258789,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 29.68000030517578,
      "temperature": 0.0,
      "text": " this entire stream of generative AI companies,",
      "tokens": [
        50364,
        341,
        2302,
        4309,
        295,
        1337,
        1166,
        7318,
        3431,
        11,
        50522
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 35.36000061035156,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 32.84000015258789,
      "temperature": 0.0,
      "text": " building agents on top of their own technology.",
      "tokens": [
        50522,
        2390,
        12554,
        322,
        1192,
        295,
        641,
        1065,
        2899,
        13,
        50648
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 37.720001220703125,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 35.36000061035156,
      "temperature": 0.0,
      "text": " The computer use, text editor,",
      "tokens": [
        50648,
        440,
        3820,
        764,
        11,
        2487,
        9839,
        11,
        50766
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 42.560001373291016,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 37.720001220703125,
      "temperature": 0.0,
      "text": " and Bash tools are still some of the most slept on tools to date.",
      "tokens": [
        50766,
        293,
        43068,
        3873,
        366,
        920,
        512,
        295,
        264,
        881,
        17400,
        322,
        3873,
        281,
        4002,
        13,
        51008
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 45.52000045776367,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 42.560001373291016,
      "temperature": 0.0,
      "text": " Check this out. Here's a simple bun logging script.",
      "tokens": [
        51008,
        6881,
        341,
        484,
        13,
        1692,
        311,
        257,
        2199,
        6702,
        27991,
        5755,
        13,
        51156
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 46.84000015258789,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 45.52000045776367,
      "temperature": 0.0,
      "text": " I can open up the terminal.",
      "tokens": [
        51156,
        286,
        393,
        1269,
        493,
        264,
        14709,
        13,
        51222
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 51.52000045776367,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 46.84000015258789,
      "temperature": 0.0,
      "text": " I have a file editing agent built on top of Anthropic's file editing tool.",
      "tokens": [
        51222,
        286,
        362,
        257,
        3991,
        10000,
        9461,
        3094,
        322,
        1192,
        295,
        12727,
        39173,
        311,
        3991,
        10000,
        2290,
        13,
        51456
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 54.880001068115234,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 51.52000045776367,
      "temperature": 0.0,
      "text": " We can run this prompt and it'll make three distinct changes for us.",
      "tokens": [
        51456,
        492,
        393,
        1190,
        341,
        12391,
        293,
        309,
        603,
        652,
        1045,
        10644,
        2962,
        337,
        505,
        13,
        51624
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 56.31999969482422,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 54.880001068115234,
      "temperature": 0.0,
      "text": " It's going to read this file,",
      "tokens": [
        51624,
        467,
        311,
        516,
        281,
        1401,
        341,
        3991,
        11,
        51696
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 59.36000061035156,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 56.31999969482422,
      "temperature": 0.0,
      "text": " update it, it's going to add the directory param just like we're asking,",
      "tokens": [
        51696,
        5623,
        309,
        11,
        309,
        311,
        516,
        281,
        909,
        264,
        21120,
        6220,
        445,
        411,
        321,
        434,
        3365,
        11,
        51848
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 60.959999084472656,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 59.36000061035156,
      "temperature": 0.0,
      "text": " and then it's going to add a confirmation flag.",
      "tokens": [
        50364,
        293,
        550,
        309,
        311,
        516,
        281,
        909,
        257,
        21871,
        7166,
        13,
        50444
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 62.20000076293945,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 60.959999084472656,
      "temperature": 0.0,
      "text": " You can see that just came in there.",
      "tokens": [
        50444,
        509,
        393,
        536,
        300,
        445,
        1361,
        294,
        456,
        13,
        50506
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 64.0,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 62.20000076293945,
      "temperature": 0.0,
      "text": " Then it's going to create two new versions,",
      "tokens": [
        50506,
        1396,
        309,
        311,
        516,
        281,
        1884,
        732,
        777,
        9606,
        11,
        50596
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 67.0,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 64.0,
      "temperature": 0.0,
      "text": " a shell script version and a PowerShell version.",
      "tokens": [
        50596,
        257,
        8720,
        5755,
        3037,
        293,
        257,
        7086,
        9526,
        285,
        3037,
        13,
        50746
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 70.68000030517578,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 67.0,
      "temperature": 0.0,
      "text": " There it is. If I run that grep command again,",
      "tokens": [
        50746,
        821,
        309,
        307,
        13,
        759,
        286,
        1190,
        300,
        6066,
        79,
        5622,
        797,
        11,
        50930
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 74.12000274658203,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 70.68000030517578,
      "temperature": 0.0,
      "text": " you can see we now have those three individual files.",
      "tokens": [
        50930,
        291,
        393,
        536,
        321,
        586,
        362,
        729,
        1045,
        2609,
        7098,
        13,
        51102
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 75.80000305175781,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 74.12000274658203,
      "temperature": 0.0,
      "text": " Here's the updated bun version,",
      "tokens": [
        51102,
        1692,
        311,
        264,
        10588,
        6702,
        3037,
        11,
        51186
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 79.4000015258789,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 75.80000305175781,
      "temperature": 0.0,
      "text": " clearlogs.sh. Here's the shell version,",
      "tokens": [
        51186,
        1850,
        4987,
        82,
        13,
        2716,
        13,
        1692,
        311,
        264,
        8720,
        3037,
        11,
        51366
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 82.95999908447266,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 79.4000015258789,
      "temperature": 0.0,
      "text": " clearlogs.ps1. Here's the PowerShell version.",
      "tokens": [
        51366,
        1850,
        4987,
        82,
        13,
        1878,
        16,
        13,
        1692,
        311,
        264,
        7086,
        9526,
        285,
        3037,
        13,
        51544
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 84.5999984741211,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 82.95999908447266,
      "temperature": 0.0,
      "text": " With a single command,",
      "tokens": [
        51544,
        2022,
        257,
        2167,
        5622,
        11,
        51626
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 87.16000366210938,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 84.5999984741211,
      "temperature": 0.0,
      "text": " I was able to generate three changes",
      "tokens": [
        51626,
        286,
        390,
        1075,
        281,
        8460,
        1045,
        2962,
        51754
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 89.63999938964844,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 87.19999694824219,
      "temperature": 0.0,
      "text": " thanks to my file AI agent.",
      "tokens": [
        50366,
        3231,
        281,
        452,
        3991,
        7318,
        9461,
        13,
        50488
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 91.31999969482422,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 89.63999938964844,
      "temperature": 0.0,
      "text": " If it's not clear to you already,",
      "tokens": [
        50488,
        759,
        309,
        311,
        406,
        1850,
        281,
        291,
        1217,
        11,
        50572
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 94.80000305175781,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 91.31999969482422,
      "temperature": 0.0,
      "text": " AI agents are extremely powerful.",
      "tokens": [
        50572,
        7318,
        12554,
        366,
        4664,
        4005,
        13,
        50746
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 95.76000213623047,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 94.80000305175781,
      "temperature": 0.0,
      "text": " Why is that?",
      "tokens": [
        50746,
        1545,
        307,
        300,
        30,
        50794
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 97.63999938964844,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 95.76000213623047,
      "temperature": 0.0,
      "text": " It's because they turn your prompt,",
      "tokens": [
        50794,
        467,
        311,
        570,
        436,
        1261,
        428,
        12391,
        11,
        50888
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 101.76000213623047,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 97.63999938964844,
      "temperature": 0.0,
      "text": " context, and model into actions at scale.",
      "tokens": [
        50888,
        4319,
        11,
        293,
        2316,
        666,
        5909,
        412,
        4373,
        13,
        51094
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 103.55999755859375,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 101.76000213623047,
      "temperature": 0.0,
      "text": " It's important that you and I,",
      "tokens": [
        51094,
        467,
        311,
        1021,
        300,
        291,
        293,
        286,
        11,
        51184
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 107.4000015258789,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 103.55999755859375,
      "temperature": 0.0,
      "text": " the engineer, know how and when to build and deploy",
      "tokens": [
        51184,
        264,
        11403,
        11,
        458,
        577,
        293,
        562,
        281,
        1322,
        293,
        7274,
        51376
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 111.80000305175781,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 107.4000015258789,
      "temperature": 0.0,
      "text": " AI agents across your developer tooling projects and work.",
      "tokens": [
        51376,
        7318,
        12554,
        2108,
        428,
        10754,
        46593,
        4455,
        293,
        589,
        13,
        51596
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 114.36000061035156,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 111.80000305175781,
      "temperature": 0.0,
      "text": " In this video, I want to take you through the prompt,",
      "tokens": [
        51596,
        682,
        341,
        960,
        11,
        286,
        528,
        281,
        747,
        291,
        807,
        264,
        12391,
        11,
        51724
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 116.80000305175781,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 114.4800033569336,
      "temperature": 0.0,
      "text": " the prompt chain, and the AI agent",
      "tokens": [
        50370,
        264,
        12391,
        5021,
        11,
        293,
        264,
        7318,
        9461,
        50486
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 119.16000366210938,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 116.80000305175781,
      "temperature": 0.0,
      "text": " to help you understand which one you need",
      "tokens": [
        50486,
        281,
        854,
        291,
        1223,
        597,
        472,
        291,
        643,
        50604
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 120.95999908447266,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 119.16000366210938,
      "temperature": 0.0,
      "text": " to get the job done.",
      "tokens": [
        50604,
        281,
        483,
        264,
        1691,
        1096,
        13,
        50694
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 123.5199966430664,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 120.95999908447266,
      "temperature": 0.0,
      "text": " We'll lean on Anthropic's incredible",
      "tokens": [
        50694,
        492,
        603,
        11659,
        322,
        12727,
        39173,
        311,
        4651,
        50822
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 125.5999984741211,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 123.5199966430664,
      "temperature": 0.0,
      "text": " building effective agents post,",
      "tokens": [
        50822,
        2390,
        4942,
        12554,
        2183,
        11,
        50926
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 128.83999633789062,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 125.5999984741211,
      "temperature": 0.0,
      "text": " and I'll share my distillation of what matters",
      "tokens": [
        50926,
        293,
        286,
        603,
        2073,
        452,
        42923,
        399,
        295,
        437,
        7001,
        51088
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 131.0800018310547,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 128.83999633789062,
      "temperature": 0.0,
      "text": " and mistakes I've made when building.",
      "tokens": [
        51088,
        293,
        8038,
        286,
        600,
        1027,
        562,
        2390,
        13,
        51200
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.21875503659248352,
      "compression_ratio": 1.5862069129943848,
      "end": 137.45999765396118,
      "no_speech_prob": 0.007576774340122938,
      "seek": 0,
      "start": 131.05999755859375,
      "temperature": 0.0,
      "text": " AI agents so you can avoid making the same mistakes. Let me introduce you to my new video",
      "tokens": [
        50364,
        7318,
        12554,
        370,
        291,
        393,
        5042,
        1455,
        264,
        912,
        8038,
        13,
        961,
        385,
        5366,
        291,
        281,
        452,
        777,
        960,
        50684
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.21875503659248352,
      "compression_ratio": 1.5862069129943848,
      "end": 146.89999771118164,
      "no_speech_prob": 0.007576774340122938,
      "seek": 0,
      "start": 137.45999765396118,
      "temperature": 0.0,
      "text": " editing tool, Akka. Okay, so before we dive in to what exactly this tool does, let's go ahead and",
      "tokens": [
        50684,
        10000,
        2290,
        11,
        9629,
        2330,
        13,
        1033,
        11,
        370,
        949,
        321,
        9192,
        294,
        281,
        437,
        2293,
        341,
        2290,
        775,
        11,
        718,
        311,
        352,
        2286,
        293,
        51156
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.21875503659248352,
      "compression_ratio": 1.5862069129943848,
      "end": 152.49999809265137,
      "no_speech_prob": 0.007576774340122938,
      "seek": 0,
      "start": 146.89999771118164,
      "temperature": 0.0,
      "text": " go over to the Akka agent file. And I'm going to kick off a benchmark that is going to run",
      "tokens": [
        51156,
        352,
        670,
        281,
        264,
        9629,
        2330,
        9461,
        3991,
        13,
        400,
        286,
        478,
        516,
        281,
        4437,
        766,
        257,
        18927,
        300,
        307,
        516,
        281,
        1190,
        51436
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.21875503659248352,
      "compression_ratio": 1.5862069129943848,
      "end": 159.05999755859375,
      "no_speech_prob": 0.007576774340122938,
      "seek": 0,
      "start": 152.49999809265137,
      "temperature": 0.0,
      "text": " a series of problems for us using the prompt, the prompt chain, and the AI agent version.",
      "tokens": [
        51436,
        257,
        2638,
        295,
        2740,
        337,
        505,
        1228,
        264,
        12391,
        11,
        264,
        12391,
        5021,
        11,
        293,
        264,
        7318,
        9461,
        3037,
        13,
        51764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2188090682029724,
      "compression_ratio": 1.6130434274673462,
      "end": 163.93999862670898,
      "no_speech_prob": 0.0005192969110794365,
      "seek": 2800,
      "start": 159.05999755859375,
      "temperature": 0.0,
      "text": " This benchmark is going to tell us which one of these levels we need to actually solve this",
      "tokens": [
        50364,
        639,
        18927,
        307,
        516,
        281,
        980,
        505,
        597,
        472,
        295,
        613,
        4358,
        321,
        643,
        281,
        767,
        5039,
        341,
        50608
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2188090682029724,
      "compression_ratio": 1.6130434274673462,
      "end": 170.57999801635742,
      "no_speech_prob": 0.0005192969110794365,
      "seek": 2800,
      "start": 163.93999862670898,
      "temperature": 0.0,
      "text": " problem. Spawn, run, Akka agent. And this benchmark is going to run in the background in parallel to",
      "tokens": [
        50608,
        1154,
        13,
        1738,
        11251,
        11,
        1190,
        11,
        9629,
        2330,
        9461,
        13,
        400,
        341,
        18927,
        307,
        516,
        281,
        1190,
        294,
        264,
        3678,
        294,
        8952,
        281,
        50940
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2188090682029724,
      "compression_ratio": 1.6130434274673462,
      "end": 175.45999908447266,
      "no_speech_prob": 0.0005192969110794365,
      "seek": 2800,
      "start": 170.57999801635742,
      "temperature": 0.0,
      "text": " us and we'll circle back to this to answer questions like, are reasoning models always",
      "tokens": [
        50940,
        505,
        293,
        321,
        603,
        6329,
        646,
        281,
        341,
        281,
        1867,
        1651,
        411,
        11,
        366,
        21577,
        5245,
        1009,
        51184
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2188090682029724,
      "compression_ratio": 1.6130434274673462,
      "end": 183.61999893188477,
      "no_speech_prob": 0.0005192969110794365,
      "seek": 2800,
      "start": 175.45999908447266,
      "temperature": 0.0,
      "text": " better than base models? Do GPT-4 agents beat O3 mini prompts? Does a O3 mini prompt beat a",
      "tokens": [
        51184,
        1101,
        813,
        3096,
        5245,
        30,
        1144,
        26039,
        51,
        12,
        19,
        12554,
        4224,
        422,
        18,
        8382,
        41095,
        30,
        4402,
        257,
        422,
        18,
        8382,
        12391,
        4224,
        257,
        51592
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.19102822244167328,
      "compression_ratio": 1.6620689630508423,
      "end": 190.0999984741211,
      "no_speech_prob": 0.02096319943666458,
      "seek": 5256,
      "start": 183.61999893188477,
      "temperature": 0.0,
      "text": " O3 prompt chain? How much more expensive is an AI agent versus a prompt chain? And more importantly,",
      "tokens": [
        50364,
        422,
        18,
        12391,
        5021,
        30,
        1012,
        709,
        544,
        5124,
        307,
        364,
        7318,
        9461,
        5717,
        257,
        12391,
        5021,
        30,
        400,
        544,
        8906,
        11,
        50688
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.19102822244167328,
      "compression_ratio": 1.6620689630508423,
      "end": 197.13999938964844,
      "no_speech_prob": 0.02096319943666458,
      "seek": 5256,
      "start": 190.0999984741211,
      "temperature": 0.0,
      "text": " is it worth it? So what's Akka, how does it work, and why did I build it? Akka is the fastest way",
      "tokens": [
        50688,
        307,
        309,
        3163,
        309,
        30,
        407,
        437,
        311,
        9629,
        2330,
        11,
        577,
        775,
        309,
        589,
        11,
        293,
        983,
        630,
        286,
        1322,
        309,
        30,
        9629,
        2330,
        307,
        264,
        14573,
        636,
        51040
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.19102822244167328,
      "compression_ratio": 1.6620689630508423,
      "end": 204.5,
      "no_speech_prob": 0.02096319943666458,
      "seek": 5256,
      "start": 197.13999938964844,
      "temperature": 0.0,
      "text": " to remove filler words, repeats, and nonsense out of your videos. So you can go from scripts that,",
      "tokens": [
        51040,
        281,
        4159,
        34676,
        2283,
        11,
        35038,
        11,
        293,
        14925,
        484,
        295,
        428,
        2145,
        13,
        407,
        291,
        393,
        352,
        490,
        23294,
        300,
        11,
        51408
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.19102822244167328,
      "compression_ratio": 1.6620689630508423,
      "end": 208.65999603271484,
      "no_speech_prob": 0.02096319943666458,
      "seek": 5256,
      "start": 204.5,
      "temperature": 0.0,
      "text": " you know, have stuttering in them, that have filler words and repeats, and then it'll end up",
      "tokens": [
        51408,
        291,
        458,
        11,
        362,
        342,
        32224,
        294,
        552,
        11,
        300,
        362,
        34676,
        2283,
        293,
        35038,
        11,
        293,
        550,
        309,
        603,
        917,
        493,
        51616
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.19102822244167328,
      "compression_ratio": 1.6620689630508423,
      "end": 213.13999938964844,
      "no_speech_prob": 0.02096319943666458,
      "seek": 5256,
      "start": 208.65999603271484,
      "temperature": 0.0,
      "text": " looking like this. The scratchpad active memory pattern is going to be really important for",
      "tokens": [
        51616,
        1237,
        411,
        341,
        13,
        440,
        8459,
        13647,
        4967,
        4675,
        5102,
        307,
        516,
        281,
        312,
        534,
        1021,
        337,
        51840
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.17516165971755981,
      "compression_ratio": 1.6521738767623901,
      "end": 219.54000091552734,
      "no_speech_prob": 0.0008426300482824445,
      "seek": 8208,
      "start": 213.13999938964844,
      "temperature": 0.0,
      "text": " rolling out useful personal AI assistance. The key here is that it focuses on the transcript. So",
      "tokens": [
        50364,
        9439,
        484,
        4420,
        2973,
        7318,
        9683,
        13,
        440,
        2141,
        510,
        307,
        300,
        309,
        16109,
        322,
        264,
        24444,
        13,
        407,
        50684
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.17516165971755981,
      "compression_ratio": 1.6521738767623901,
      "end": 225.05999755859375,
      "no_speech_prob": 0.0008426300482824445,
      "seek": 8208,
      "start": 219.54000091552734,
      "temperature": 0.0,
      "text": " let's walk through the process. It all starts out with word level transcript. You can use a whisper",
      "tokens": [
        50684,
        718,
        311,
        1792,
        807,
        264,
        1399,
        13,
        467,
        439,
        3719,
        484,
        365,
        1349,
        1496,
        24444,
        13,
        509,
        393,
        764,
        257,
        26018,
        50960
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.17516165971755981,
      "compression_ratio": 1.6521738767623901,
      "end": 230.25999450683594,
      "no_speech_prob": 0.0008426300482824445,
      "seek": 8208,
      "start": 225.05999755859375,
      "temperature": 0.0,
      "text": " transcription tool to generate this type of JSON structure, right? We have all the text, and then",
      "tokens": [
        50960,
        35288,
        2290,
        281,
        8460,
        341,
        2010,
        295,
        31828,
        3877,
        11,
        558,
        30,
        492,
        362,
        439,
        264,
        2487,
        11,
        293,
        550,
        51220
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.17516165971755981,
      "compression_ratio": 1.6521738767623901,
      "end": 235.77999877929688,
      "no_speech_prob": 0.0008426300482824445,
      "seek": 8208,
      "start": 230.25999450683594,
      "temperature": 0.0,
      "text": " we have the individual words at specific start and end times. This is the raw script, what I like to",
      "tokens": [
        51220,
        321,
        362,
        264,
        2609,
        2283,
        412,
        2685,
        722,
        293,
        917,
        1413,
        13,
        639,
        307,
        264,
        8936,
        5755,
        11,
        437,
        286,
        411,
        281,
        51496
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.17516165971755981,
      "compression_ratio": 1.6521738767623901,
      "end": 240.33999633789062,
      "no_speech_prob": 0.0008426300482824445,
      "seek": 8208,
      "start": 235.77999877929688,
      "temperature": 0.0,
      "text": " call the base edit, that we're going to have our AI agents edit for us. So if we scroll down here,",
      "tokens": [
        51496,
        818,
        264,
        3096,
        8129,
        11,
        300,
        321,
        434,
        516,
        281,
        362,
        527,
        7318,
        12554,
        8129,
        337,
        505,
        13,
        407,
        498,
        321,
        11369,
        760,
        510,
        11,
        51724
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.18231964111328125,
      "compression_ratio": 1.6168224811553955,
      "end": 245.6999969482422,
      "no_speech_prob": 0.002148580737411976,
      "seek": 10928,
      "start": 240.33999633789062,
      "temperature": 0.0,
      "text": " you can see we have, you know, a couple sentences worth. Step two is create slices. So it is too",
      "tokens": [
        50364,
        291,
        393,
        536,
        321,
        362,
        11,
        291,
        458,
        11,
        257,
        1916,
        16579,
        3163,
        13,
        5470,
        732,
        307,
        1884,
        19793,
        13,
        407,
        309,
        307,
        886,
        50632
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.18231964111328125,
      "compression_ratio": 1.6168224811553955,
      "end": 251.45999908447266,
      "no_speech_prob": 0.002148580737411976,
      "seek": 10928,
      "start": 245.6999969482422,
      "temperature": 0.0,
      "text": " much work to pass off an entire transcription for, you know, a 30, 40, 50 minute long video",
      "tokens": [
        50632,
        709,
        589,
        281,
        1320,
        766,
        364,
        2302,
        35288,
        337,
        11,
        291,
        458,
        11,
        257,
        2217,
        11,
        3356,
        11,
        2625,
        3456,
        938,
        960,
        50920
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.18231964111328125,
      "compression_ratio": 1.6168224811553955,
      "end": 258.4199981689453,
      "no_speech_prob": 0.002148580737411976,
      "seek": 10928,
      "start": 251.45999908447266,
      "temperature": 0.0,
      "text": " to any language model. If we open up a transcription here, you can see we have 350,000",
      "tokens": [
        50920,
        281,
        604,
        2856,
        2316,
        13,
        759,
        321,
        1269,
        493,
        257,
        35288,
        510,
        11,
        291,
        393,
        536,
        321,
        362,
        18065,
        11,
        1360,
        51268
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.18231964111328125,
      "compression_ratio": 1.6168224811553955,
      "end": 262.09999084472656,
      "no_speech_prob": 0.002148580737411976,
      "seek": 10928,
      "start": 258.4199981689453,
      "temperature": 0.0,
      "text": " tokens in this single transcript, and that includes all the text here.",
      "tokens": [
        51268,
        22667,
        294,
        341,
        2167,
        24444,
        11,
        293,
        300,
        5974,
        439,
        264,
        2487,
        510,
        13,
        51452
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_002.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 265.55999517440796,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 262.1199951171875,
      "temperature": 0.0,
      "text": " and then word level breakdowns, just as you saw before.",
      "tokens": [
        50364,
        293,
        550,
        1349,
        1496,
        18188,
        82,
        11,
        445,
        382,
        291,
        1866,
        949,
        13,
        50536
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 267.31999492645264,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 265.55999517440796,
      "temperature": 0.0,
      "text": " And this is a real transcript",
      "tokens": [
        50536,
        400,
        341,
        307,
        257,
        957,
        24444,
        50624
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 270.0799951553345,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 267.31999492645264,
      "temperature": 0.0,
      "text": " from the DeepSeek personal AI assistant video.",
      "tokens": [
        50624,
        490,
        264,
        14895,
        10637,
        916,
        2973,
        7318,
        10994,
        960,
        13,
        50762
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 271.35999488830566,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 270.0799951553345,
      "temperature": 0.0,
      "text": " There's just too many tokens.",
      "tokens": [
        50762,
        821,
        311,
        445,
        886,
        867,
        22667,
        13,
        50826
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 273.1199951171875,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 271.35999488830566,
      "temperature": 0.0,
      "text": " Even if you hand this off to Gemini,",
      "tokens": [
        50826,
        2754,
        498,
        291,
        1011,
        341,
        766,
        281,
        22894,
        3812,
        11,
        50914
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 275.1199951171875,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 273.1199951171875,
      "temperature": 0.0,
      "text": " it's not going to be able to solve this problem",
      "tokens": [
        50914,
        309,
        311,
        406,
        516,
        281,
        312,
        1075,
        281,
        5039,
        341,
        1154,
        51014
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 277.2799949645996,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 275.1199951171875,
      "temperature": 0.0,
      "text": " in any cohesive way at scale.",
      "tokens": [
        51014,
        294,
        604,
        43025,
        636,
        412,
        4373,
        13,
        51122
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 278.1199951171875,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 277.2799949645996,
      "temperature": 0.0,
      "text": " How can we handle this?",
      "tokens": [
        51122,
        1012,
        393,
        321,
        4813,
        341,
        30,
        51164
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 279.5599956512451,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 278.1199951171875,
      "temperature": 0.0,
      "text": " We can create slices.",
      "tokens": [
        51164,
        492,
        393,
        1884,
        19793,
        13,
        51236
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 282.15999603271484,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 279.5599956512451,
      "temperature": 0.0,
      "text": " So a slice is a chunk of the transcript",
      "tokens": [
        51236,
        407,
        257,
        13153,
        307,
        257,
        16635,
        295,
        264,
        24444,
        51366
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 284.19999504089355,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 282.15999603271484,
      "temperature": 0.0,
      "text": " containing a few sentences each.",
      "tokens": [
        51366,
        19273,
        257,
        1326,
        16579,
        1184,
        13,
        51468
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 287.15999603271484,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 284.19999504089355,
      "temperature": 0.0,
      "text": " From the transcription above, we could create two slices.",
      "tokens": [
        51468,
        3358,
        264,
        35288,
        3673,
        11,
        321,
        727,
        1884,
        732,
        19793,
        13,
        51616
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 289.4599952697754,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 287.15999603271484,
      "temperature": 0.0,
      "text": " In these two slices, there are a couple of key things",
      "tokens": [
        51616,
        682,
        613,
        732,
        19793,
        11,
        456,
        366,
        257,
        1916,
        295,
        2141,
        721,
        51731
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.22358085215091705,
      "compression_ratio": 1.7015873193740845,
      "end": 290.7799949645996,
      "no_speech_prob": 0.05339203402400017,
      "seek": 0,
      "start": 289.4599952697754,
      "temperature": 0.0,
      "text": " that need to be edited out.",
      "tokens": [
        51731,
        300,
        643,
        281,
        312,
        23016,
        484,
        13,
        51797
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 293.4399948120117,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 290.7799949645996,
      "temperature": 0.0,
      "text": " Next, we're going to allocate our AI agents, right?",
      "tokens": [
        50364,
        3087,
        11,
        321,
        434,
        516,
        281,
        35713,
        527,
        7318,
        12554,
        11,
        558,
        30,
        50497
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 295.2799949645996,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 293.4399948120117,
      "temperature": 0.0,
      "text": " So in our case, this is going to be our prompt,",
      "tokens": [
        50497,
        407,
        294,
        527,
        1389,
        11,
        341,
        307,
        516,
        281,
        312,
        527,
        12391,
        11,
        50589
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 299.15999603271484,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 295.2799949645996,
      "temperature": 0.0,
      "text": " prompt chain, or our full-on AI agent, as we saw here, right?",
      "tokens": [
        50589,
        12391,
        5021,
        11,
        420,
        527,
        1577,
        12,
        266,
        7318,
        9461,
        11,
        382,
        321,
        1866,
        510,
        11,
        558,
        30,
        50783
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 300.9599952697754,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 299.15999603271484,
      "temperature": 0.0,
      "text": " And we're going to walk through this in just a moment.",
      "tokens": [
        50783,
        400,
        321,
        434,
        516,
        281,
        1792,
        807,
        341,
        294,
        445,
        257,
        1623,
        13,
        50873
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 302.2799949645996,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 300.9599952697754,
      "temperature": 0.0,
      "text": " I'm really excited to share with you",
      "tokens": [
        50873,
        286,
        478,
        534,
        2919,
        281,
        2073,
        365,
        291,
        50939
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 304.23999404907227,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 302.2799949645996,
      "temperature": 0.0,
      "text": " how the prompt versus the prompt chain",
      "tokens": [
        50939,
        577,
        264,
        12391,
        5717,
        264,
        12391,
        5021,
        51037
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 307.5599937438965,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 304.23999404907227,
      "temperature": 0.0,
      "text": " versus the AI agent performs for this use case.",
      "tokens": [
        51037,
        5717,
        264,
        7318,
        9461,
        26213,
        337,
        341,
        764,
        1389,
        13,
        51203
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 310.1199951171875,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 307.5599937438965,
      "temperature": 0.0,
      "text": " The results are not exactly as you would expect.",
      "tokens": [
        51203,
        440,
        3542,
        366,
        406,
        2293,
        382,
        291,
        576,
        2066,
        13,
        51331
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 312.5999946594238,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 310.1199951171875,
      "temperature": 0.0,
      "text": " This is the really cool part about creating slices,",
      "tokens": [
        51331,
        639,
        307,
        264,
        534,
        1627,
        644,
        466,
        4084,
        19793,
        11,
        51455
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 314.9599952697754,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 312.5999946594238,
      "temperature": 0.0,
      "text": " and it's a great part about breaking your large problem",
      "tokens": [
        51455,
        293,
        309,
        311,
        257,
        869,
        644,
        466,
        7697,
        428,
        2416,
        1154,
        51573
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 317.6799964904785,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 314.9599952697754,
      "temperature": 0.0,
      "text": " into smaller, more manageable chunks, right?",
      "tokens": [
        51573,
        666,
        4356,
        11,
        544,
        38798,
        24004,
        11,
        558,
        30,
        51709
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.18582940101623535,
      "compression_ratio": 1.8187310695648193,
      "end": 320.1999969482422,
      "no_speech_prob": 1.6442403648397885e-05,
      "seek": 2866,
      "start": 317.6799964904785,
      "temperature": 0.0,
      "text": " If ever you're feeling overwhelmed with a specific problem,",
      "tokens": [
        51709,
        759,
        1562,
        291,
        434,
        2633,
        19042,
        365,
        257,
        2685,
        1154,
        11,
        51835
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 321.5399932861328,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 320.2199935913086,
      "temperature": 0.0,
      "text": " it's probably just too big,",
      "tokens": [
        50365,
        309,
        311,
        1391,
        445,
        886,
        955,
        11,
        50431
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 324.65999603271484,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 321.5399932861328,
      "temperature": 0.0,
      "text": " and you haven't broken it down into small enough chunks.",
      "tokens": [
        50431,
        293,
        291,
        2378,
        380,
        5463,
        309,
        760,
        666,
        1359,
        1547,
        24004,
        13,
        50587
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 325.57999420166016,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 324.65999603271484,
      "temperature": 0.0,
      "text": " Engineering 101.",
      "tokens": [
        50587,
        16215,
        21055,
        13,
        50633
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 327.8199920654297,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 325.57999420166016,
      "temperature": 0.0,
      "text": " Slices give us this incredible ability to,",
      "tokens": [
        50633,
        318,
        1050,
        279,
        976,
        505,
        341,
        4651,
        3485,
        281,
        11,
        50745
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 330.9399948120117,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 327.8199920654297,
      "temperature": 0.0,
      "text": " for each slice, we'll create and allocate an AI agent",
      "tokens": [
        50745,
        337,
        1184,
        13153,
        11,
        321,
        603,
        1884,
        293,
        35713,
        364,
        7318,
        9461,
        50901
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 334.17999267578125,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 330.9399948120117,
      "temperature": 0.0,
      "text": " and basically hand off this problem to compute at scale.",
      "tokens": [
        50901,
        293,
        1936,
        1011,
        766,
        341,
        1154,
        281,
        14722,
        412,
        4373,
        13,
        51063
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 336.1399917602539,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 334.17999267578125,
      "temperature": 0.0,
      "text": " So you can imagine we'll have hundreds of slices",
      "tokens": [
        51063,
        407,
        291,
        393,
        3811,
        321,
        603,
        362,
        6779,
        295,
        19793,
        51161
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 339.0999984741211,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 336.1399917602539,
      "temperature": 0.0,
      "text": " getting edited all at the same time in parallel.",
      "tokens": [
        51161,
        1242,
        23016,
        439,
        412,
        264,
        912,
        565,
        294,
        8952,
        13,
        51309
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 341.9399948120117,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 339.0999984741211,
      "temperature": 0.0,
      "text": " Now, step four is where all the magic happens.",
      "tokens": [
        51309,
        823,
        11,
        1823,
        1451,
        307,
        689,
        439,
        264,
        5585,
        2314,
        13,
        51451
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 343.9399948120117,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 341.9399948120117,
      "temperature": 0.0,
      "text": " Slice one, you have this before text,",
      "tokens": [
        51451,
        6187,
        573,
        472,
        11,
        291,
        362,
        341,
        949,
        2487,
        11,
        51551
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 346.49999237060547,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 343.9399948120117,
      "temperature": 0.0,
      "text": " and then you end up with this after text, right?",
      "tokens": [
        51551,
        293,
        550,
        291,
        917,
        493,
        365,
        341,
        934,
        2487,
        11,
        558,
        30,
        51679
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.17465868592262268,
      "compression_ratio": 1.6806451082229614,
      "end": 347.8999938964844,
      "no_speech_prob": 0.00014883799303788692,
      "seek": 5808,
      "start": 346.49999237060547,
      "temperature": 0.0,
      "text": " So this is happening in parallel.",
      "tokens": [
        51679,
        407,
        341,
        307,
        2737,
        294,
        8952,
        13,
        51749
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 350.67999267578125,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 347.8999938964844,
      "temperature": 0.0,
      "text": " Slice one and slice two and slice N",
      "tokens": [
        50364,
        6187,
        573,
        472,
        293,
        13153,
        732,
        293,
        13153,
        426,
        50503
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 354.1999969482422,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 350.67999267578125,
      "temperature": 0.0,
      "text": " are getting edited all at the same time with compute.",
      "tokens": [
        50503,
        366,
        1242,
        23016,
        439,
        412,
        264,
        912,
        565,
        365,
        14722,
        13,
        50679
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 356.3999938964844,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 354.1999969482422,
      "temperature": 0.0,
      "text": " And then finally, we combine the edits",
      "tokens": [
        50679,
        400,
        550,
        2721,
        11,
        321,
        10432,
        264,
        41752,
        50789
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 359.5999984741211,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 356.3999938964844,
      "temperature": 0.0,
      "text": " into the sequence of timeline edits.",
      "tokens": [
        50789,
        666,
        264,
        8310,
        295,
        12933,
        41752,
        13,
        50949
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 361.2799987792969,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 359.5999984741211,
      "temperature": 0.0,
      "text": " Every video editor has a different format.",
      "tokens": [
        50949,
        2048,
        960,
        9839,
        575,
        257,
        819,
        7877,
        13,
        51033
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 362.3999938964844,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 361.2799987792969,
      "temperature": 0.0,
      "text": " I use Final Cut Pro.",
      "tokens": [
        51033,
        286,
        764,
        13443,
        9431,
        1705,
        13,
        51089
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 365.4399948120117,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 362.3999938964844,
      "temperature": 0.0,
      "text": " So I'm gonna be converting these into FCP XML files.",
      "tokens": [
        51089,
        407,
        286,
        478,
        799,
        312,
        29942,
        613,
        666,
        479,
        20049,
        43484,
        7098,
        13,
        51241
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 366.6999969482422,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 365.4399948120117,
      "temperature": 0.0,
      "text": " We're not gonna get into this too much,",
      "tokens": [
        51241,
        492,
        434,
        406,
        799,
        483,
        666,
        341,
        886,
        709,
        11,
        51304
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 368.5999984741211,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 366.6999969482422,
      "temperature": 0.0,
      "text": " but there's what the format looks like.",
      "tokens": [
        51304,
        457,
        456,
        311,
        437,
        264,
        7877,
        1542,
        411,
        13,
        51399
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 373.7999954223633,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 370.87999725341797,
      "temperature": 0.0,
      "text": " We're gonna go from prompt to prompt chain to AI agent,",
      "tokens": [
        51513,
        492,
        434,
        799,
        352,
        490,
        12391,
        281,
        12391,
        5021,
        281,
        7318,
        9461,
        11,
        51659
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.20915354788303375,
      "compression_ratio": 1.663082480430603,
      "end": 376.67999267578125,
      "no_speech_prob": 0.004538377746939659,
      "seek": 8578,
      "start": 373.7999954223633,
      "temperature": 0.0,
      "text": " and we're gonna see across these three levels",
      "tokens": [
        51659,
        293,
        321,
        434,
        799,
        536,
        2108,
        613,
        1045,
        4358,
        51803
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.24239203333854675,
      "compression_ratio": 1.6410256624221802,
      "end": 379.6199951171875,
      "no_speech_prob": 5.014671387471026e-06,
      "seek": 11456,
      "start": 376.67999267578125,
      "temperature": 0.0,
      "text": " of abstraction, which one performs the best.",
      "tokens": [
        50364,
        295,
        37765,
        11,
        597,
        472,
        26213,
        264,
        1151,
        13,
        50511
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.24239203333854675,
      "compression_ratio": 1.6410256624221802,
      "end": 381.8199920654297,
      "no_speech_prob": 5.014671387471026e-06,
      "seek": 11456,
      "start": 379.6199951171875,
      "temperature": 0.0,
      "text": " Let's go ahead and run a prompt",
      "tokens": [
        50511,
        961,
        311,
        352,
        2286,
        293,
        1190,
        257,
        12391,
        50621
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.24239203333854675,
      "compression_ratio": 1.6410256624221802,
      "end": 383.6199951171875,
      "no_speech_prob": 5.014671387471026e-06,
      "seek": 11456,
      "start": 381.8199920654297,
      "temperature": 0.0,
      "text": " and really understand what this problem looks like.",
      "tokens": [
        50621,
        293,
        534,
        1223,
        437,
        341,
        1154,
        1542,
        411,
        13,
        50711
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.24239203333854675,
      "compression_ratio": 1.6410256624221802,
      "end": 386.6999969482422,
      "no_speech_prob": 5.014671387471026e-06,
      "seek": 11456,
      "start": 383.6199951171875,
      "temperature": 0.0,
      "text": " On run a cut agent, and then we can kick this off.",
      "tokens": [
        50711,
        1282,
        1190,
        257,
        1723,
        9461,
        11,
        293,
        550,
        321,
        393,
        4437,
        341,
        766,
        13,
        50865
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.24239203333854675,
      "compression_ratio": 1.6410256624221802,
      "end": 388.8199920654297,
      "no_speech_prob": 5.014671387471026e-06,
      "seek": 11456,
      "start": 386.6999969482422,
      "temperature": 0.0,
      "text": " Let's let this prompt run.",
      "tokens": [
        50865,
        961,
        311,
        718,
        341,
        12391,
        1190,
        13,
        50971
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.24239203333854675,
      "compression_ratio": 1.6410256624221802,
      "end": 390.0199966430664,
      "no_speech_prob": 5.014671387471026e-06,
      "seek": 11456,
      "start": 388.8199920654297,
      "temperature": 0.0,
      "text": " So this is just running a single prompt.",
      "tokens": [
        50971,
        407,
        341,
        307,
        445,
        2614,
        257,
        2167,
        12391,
        13,
        51031
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.24239203333854675,
      "compression_ratio": 1.6410256624221802,
      "end": 391.5800018310547,
      "no_speech_prob": 5.014671387471026e-06,
      "seek": 11456,
      "start": 390.0199966430664,
      "temperature": 0.0,
      "text": " You can see it got the problem wrong.",
      "tokens": [
        51031,
        509,
        393,
        536,
        309,
        658,
        264,
        1154,
        2085,
        13,
        51109
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.24239203333854675,
      "compression_ratio": 1.6410256624221802,
      "end": 393.37998962402344,
      "no_speech_prob": 5.014671387471026e-06,
      "seek": 11456,
      "start": 391.5800018310547,
      "temperature": 0.0,
      "text": " Let's go ahead and figure out why.",
      "tokens": [
        51109,
        961,
        311,
        352,
        2286,
        293,
        2573,
        484,
        983,
        13,
        51199
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_003.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 395.29999256134033,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 393.17999267578125,
      "temperature": 0.0,
      "text": " So let's open up the logging",
      "tokens": [
        50364,
        407,
        718,
        311,
        1269,
        493,
        264,
        27991,
        50470
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 397.1399927139282,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 395.29999256134033,
      "temperature": 0.0,
      "text": " and just look at this individual prompt.",
      "tokens": [
        50470,
        293,
        445,
        574,
        412,
        341,
        2609,
        12391,
        13,
        50562
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 398.7399926185608,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 397.1399927139282,
      "temperature": 0.0,
      "text": " So we can open this up.",
      "tokens": [
        50562,
        407,
        321,
        393,
        1269,
        341,
        493,
        13,
        50642
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 400.2199926376343,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 398.7399926185608,
      "temperature": 0.0,
      "text": " I've been experimenting a lot lately",
      "tokens": [
        50642,
        286,
        600,
        668,
        29070,
        257,
        688,
        12881,
        50716
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 402.49999237060547,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 400.2199926376343,
      "temperature": 0.0,
      "text": " with markdown based logging,",
      "tokens": [
        50716,
        365,
        1491,
        5093,
        2361,
        27991,
        11,
        50830
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 405.49999237060547,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 402.49999237060547,
      "temperature": 0.0,
      "text": " just for a more easier to read logging experience.",
      "tokens": [
        50830,
        445,
        337,
        257,
        544,
        3571,
        281,
        1401,
        27991,
        1752,
        13,
        50980
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 406.6399927139282,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 405.49999237060547,
      "temperature": 0.0,
      "text": " And let's go top to bottom here.",
      "tokens": [
        50980,
        400,
        718,
        311,
        352,
        1192,
        281,
        2767,
        510,
        13,
        51037
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 410.0999927520752,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 406.6399927139282,
      "temperature": 0.0,
      "text": " So here's the original text and here's the target text.",
      "tokens": [
        51037,
        407,
        510,
        311,
        264,
        3380,
        2487,
        293,
        510,
        311,
        264,
        3779,
        2487,
        13,
        51210
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 413.0999927520752,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 410.0999927520752,
      "temperature": 0.0,
      "text": " So every one of our benchmarking problems",
      "tokens": [
        51210,
        407,
        633,
        472,
        295,
        527,
        18927,
        278,
        2740,
        51360
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 414.73999214172363,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 413.0999927520752,
      "temperature": 0.0,
      "text": " coming out of our benchmarking file,",
      "tokens": [
        51360,
        1348,
        484,
        295,
        527,
        18927,
        278,
        3991,
        11,
        51442
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 415.7199935913086,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 414.73999214172363,
      "temperature": 0.0,
      "text": " it looks like this, right?",
      "tokens": [
        51442,
        309,
        1542,
        411,
        341,
        11,
        558,
        30,
        51491
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 416.8199920654297,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 415.7199935913086,
      "temperature": 0.0,
      "text": " Here's the structure of it, right?",
      "tokens": [
        51491,
        1692,
        311,
        264,
        3877,
        295,
        309,
        11,
        558,
        30,
        51546
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 419.45999336242676,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 416.8199920654297,
      "temperature": 0.0,
      "text": " So we have the problem ID, we have that slice.",
      "tokens": [
        51546,
        407,
        321,
        362,
        264,
        1154,
        7348,
        11,
        321,
        362,
        300,
        13153,
        13,
        51678
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 422.17999267578125,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 419.45999336242676,
      "temperature": 0.0,
      "text": " And remember the slice is a piece of the transcript.",
      "tokens": [
        51678,
        400,
        1604,
        264,
        13153,
        307,
        257,
        2522,
        295,
        264,
        24444,
        13,
        51814
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 423.6999931335449,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 422.17999267578125,
      "temperature": 0.0,
      "text": " And then we have the correct text",
      "tokens": [
        50364,
        400,
        550,
        321,
        362,
        264,
        3006,
        2487,
        50440
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 427.09999084472656,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 423.6999931335449,
      "temperature": 0.0,
      "text": " and the beginning text inside of the slice.",
      "tokens": [
        50440,
        293,
        264,
        2863,
        2487,
        1854,
        295,
        264,
        13153,
        13,
        50610
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 428.299991607666,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 427.09999084472656,
      "temperature": 0.0,
      "text": " Here's what a slice looks like.",
      "tokens": [
        50610,
        1692,
        311,
        437,
        257,
        13153,
        1542,
        411,
        13,
        50670
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 431.17999267578125,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 428.299991607666,
      "temperature": 0.0,
      "text": " Most importantly, we have the words and we have the text.",
      "tokens": [
        50670,
        4534,
        8906,
        11,
        321,
        362,
        264,
        2283,
        293,
        321,
        362,
        264,
        2487,
        13,
        50814
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 432.41999435424805,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 431.17999267578125,
      "temperature": 0.0,
      "text": " So let's look at what we're starting with",
      "tokens": [
        50814,
        407,
        718,
        311,
        574,
        412,
        437,
        321,
        434,
        2891,
        365,
        50876
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 433.4599914550781,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 432.41999435424805,
      "temperature": 0.0,
      "text": " and what we're ending up with.",
      "tokens": [
        50876,
        293,
        437,
        321,
        434,
        8121,
        493,
        365,
        13,
        50928
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 435.85999298095703,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 433.4599914550781,
      "temperature": 0.0,
      "text": " So a bunch of gibberish in the beginning.",
      "tokens": [
        50928,
        407,
        257,
        3840,
        295,
        4553,
        43189,
        294,
        264,
        2863,
        13,
        51048
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 438.57999420166016,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 435.85999298095703,
      "temperature": 0.0,
      "text": " These are all real transcripts from videos,",
      "tokens": [
        51048,
        1981,
        366,
        439,
        957,
        24444,
        82,
        490,
        2145,
        11,
        51184
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 439.6399917602539,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 438.57999420166016,
      "temperature": 0.0,
      "text": " from previous videos, by the way.",
      "tokens": [
        51184,
        490,
        3894,
        2145,
        11,
        538,
        264,
        636,
        13,
        51237
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 440.93999099731445,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 439.6399917602539,
      "temperature": 0.0,
      "text": " So yeah, this is me just, you know,",
      "tokens": [
        51237,
        407,
        1338,
        11,
        341,
        307,
        385,
        445,
        11,
        291,
        458,
        11,
        51302
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 443.33999252319336,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 440.93999099731445,
      "temperature": 0.0,
      "text": " stuttering and saying, ah, over and over.",
      "tokens": [
        51302,
        342,
        32224,
        293,
        1566,
        11,
        3716,
        11,
        670,
        293,
        670,
        13,
        51422
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 444.8999938964844,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 443.33999252319336,
      "temperature": 0.0,
      "text": " Turns out talking about technology",
      "tokens": [
        51422,
        29524,
        484,
        1417,
        466,
        2899,
        51500
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 447.61999130249023,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 444.8999938964844,
      "temperature": 0.0,
      "text": " can be sometimes harder than the technology itself.",
      "tokens": [
        51500,
        393,
        312,
        2171,
        6081,
        813,
        264,
        2899,
        2564,
        13,
        51636
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 449.49999237060547,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 447.61999130249023,
      "temperature": 0.0,
      "text": " We then say the scratchpad active memory",
      "tokens": [
        51636,
        492,
        550,
        584,
        264,
        8459,
        13647,
        4967,
        4675,
        51730
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 450.7199935913086,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 449.49999237060547,
      "temperature": 0.0,
      "text": " is going to be really important.",
      "tokens": [
        51730,
        307,
        516,
        281,
        312,
        534,
        1021,
        13,
        51791
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 451.77999114990234,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 450.7199935913086,
      "temperature": 0.0,
      "text": " So basically what we wanna do here",
      "tokens": [
        51791,
        407,
        1936,
        437,
        321,
        1948,
        360,
        510,
        51844
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 453.17999267578125,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 452.33999252319336,
      "temperature": 0.0,
      "text": " is get rid of this intro, right?",
      "tokens": [
        50392,
        307,
        483,
        3973,
        295,
        341,
        12897,
        11,
        558,
        30,
        50434
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 454.8199920654297,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 453.17999267578125,
      "temperature": 0.0,
      "text": " So that's the target text, right?",
      "tokens": [
        50434,
        407,
        300,
        311,
        264,
        3779,
        2487,
        11,
        558,
        30,
        50516
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 455.77999114990234,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 454.8199920654297,
      "temperature": 0.0,
      "text": " It's everything remaining.",
      "tokens": [
        50516,
        467,
        311,
        1203,
        8877,
        13,
        50564
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 459.47999572753906,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 455.77999114990234,
      "temperature": 0.0,
      "text": " This is what we want our model to edit down to, okay?",
      "tokens": [
        50564,
        639,
        307,
        437,
        321,
        528,
        527,
        2316,
        281,
        8129,
        760,
        281,
        11,
        1392,
        30,
        50749
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 461.0399932861328,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 459.47999572753906,
      "temperature": 0.0,
      "text": " So you can see we wrote the prompt.",
      "tokens": [
        50749,
        407,
        291,
        393,
        536,
        321,
        4114,
        264,
        12391,
        13,
        50827
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 462.99999237060547,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 461.0399932861328,
      "temperature": 0.0,
      "text": " We'll look at what exactly this prompt looks like",
      "tokens": [
        50827,
        492,
        603,
        574,
        412,
        437,
        2293,
        341,
        12391,
        1542,
        411,
        50925
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 463.8399963378906,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 462.99999237060547,
      "temperature": 0.0,
      "text": " in just a moment.",
      "tokens": [
        50925,
        294,
        445,
        257,
        1623,
        13,
        50967
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 466.85999298095703,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 463.8399963378906,
      "temperature": 0.0,
      "text": " Our LLM created these deletions for us.",
      "tokens": [
        50967,
        2621,
        441,
        43,
        44,
        2942,
        613,
        1103,
        302,
        626,
        337,
        505,
        13,
        51118
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 469.7999954223633,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 466.85999298095703,
      "temperature": 0.0,
      "text": " Start time, end time, the duration, explanation.",
      "tokens": [
        51118,
        6481,
        565,
        11,
        917,
        565,
        11,
        264,
        16365,
        11,
        10835,
        13,
        51265
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 471.99999237060547,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 469.7999954223633,
      "temperature": 0.0,
      "text": " You can see the exact words that it removed.",
      "tokens": [
        51265,
        509,
        393,
        536,
        264,
        1900,
        2283,
        300,
        309,
        7261,
        13,
        51375
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 475.8199920654297,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 471.99999237060547,
      "temperature": 0.0,
      "text": " So it's gonna remove a, and then act the.",
      "tokens": [
        51375,
        407,
        309,
        311,
        799,
        4159,
        257,
        11,
        293,
        550,
        605,
        264,
        13,
        51566
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 477.25999450683594,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 475.8199920654297,
      "temperature": 0.0,
      "text": " Here's the original.",
      "tokens": [
        51566,
        1692,
        311,
        264,
        3380,
        13,
        51638
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 479.2199935913086,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 477.25999450683594,
      "temperature": 0.0,
      "text": " Here's what we wanted to target.",
      "tokens": [
        51638,
        1692,
        311,
        437,
        321,
        1415,
        281,
        3779,
        13,
        51736
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 481.59999084472656,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 479.2199935913086,
      "temperature": 0.0,
      "text": " And then here's what the prediction was, right?",
      "tokens": [
        51736,
        400,
        550,
        510,
        311,
        437,
        264,
        17630,
        390,
        11,
        558,
        30,
        51855
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 483.3199920654297,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 482.4199905395508,
      "temperature": 0.0,
      "text": " Here's what our model output for us.",
      "tokens": [
        50405,
        1692,
        311,
        437,
        527,
        2316,
        5598,
        337,
        505,
        13,
        50450
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 486.27999114990234,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 483.3199920654297,
      "temperature": 0.0,
      "text": " You can see it didn't quite get the edit right.",
      "tokens": [
        50450,
        509,
        393,
        536,
        309,
        994,
        380,
        1596,
        483,
        264,
        8129,
        558,
        13,
        50598
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 489.6399917602539,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 486.27999114990234,
      "temperature": 0.0,
      "text": " This is an example of where a prompt is not enough.",
      "tokens": [
        50598,
        639,
        307,
        364,
        1365,
        295,
        689,
        257,
        12391,
        307,
        406,
        1547,
        13,
        50766
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 492.4399948120117,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 489.6399917602539,
      "temperature": 0.0,
      "text": " And I'll link, just for fun, I'll link the original",
      "tokens": [
        50766,
        400,
        286,
        603,
        2113,
        11,
        445,
        337,
        1019,
        11,
        286,
        603,
        2113,
        264,
        3380,
        50906
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 494.1399917602539,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 492.4399948120117,
      "temperature": 0.0,
      "text": " one prompt is not enough video",
      "tokens": [
        50906,
        472,
        12391,
        307,
        406,
        1547,
        960,
        50991
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 495.97999572753906,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 494.1399917602539,
      "temperature": 0.0,
      "text": " that really kicked off the channel.",
      "tokens": [
        50991,
        300,
        534,
        14609,
        766,
        264,
        2269,
        13,
        51083
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 497.9599914550781,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 495.97999572753906,
      "temperature": 0.0,
      "text": " Back then we were talking about the same concepts",
      "tokens": [
        51083,
        5833,
        550,
        321,
        645,
        1417,
        466,
        264,
        912,
        10392,
        51182
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 499.87998962402344,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 497.9599914550781,
      "temperature": 0.0,
      "text": " with much more primitive technology.",
      "tokens": [
        51182,
        365,
        709,
        544,
        28540,
        2899,
        13,
        51278
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 501.75999450683594,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 499.87998962402344,
      "temperature": 0.0,
      "text": " It's incredible to think about how far we've come",
      "tokens": [
        51278,
        467,
        311,
        4651,
        281,
        519,
        466,
        577,
        1400,
        321,
        600,
        808,
        51372
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 502.59999084472656,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 501.75999450683594,
      "temperature": 0.0,
      "text": " since that video.",
      "tokens": [
        51372,
        1670,
        300,
        960,
        13,
        51414
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 504.7999954223633,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 502.59999084472656,
      "temperature": 0.0,
      "text": " But you know, one prompt is not enough",
      "tokens": [
        51414,
        583,
        291,
        458,
        11,
        472,
        12391,
        307,
        406,
        1547,
        51524
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 507.0399932861328,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 504.7999954223633,
      "temperature": 0.0,
      "text": " when you're trying to do more and more at scale",
      "tokens": [
        51524,
        562,
        291,
        434,
        1382,
        281,
        360,
        544,
        293,
        544,
        412,
        4373,
        51636
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 508.239990234375,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 507.0399932861328,
      "temperature": 0.0,
      "text": " and you're trying to accomplish",
      "tokens": [
        51636,
        293,
        291,
        434,
        1382,
        281,
        9021,
        51696
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 511.67999267578125,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 508.239990234375,
      "temperature": 0.0,
      "text": " and hand off a ton of work to your AI tooling.",
      "tokens": [
        50364,
        293,
        1011,
        766,
        257,
        2952,
        295,
        589,
        281,
        428,
        7318,
        46593,
        13,
        50536
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 58,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 513.0399932861328,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 511.67999267578125,
      "temperature": 0.0,
      "text": " And here's the target text, right?",
      "tokens": [
        50536,
        400,
        510,
        311,
        264,
        3779,
        2487,
        11,
        558,
        30,
        50604
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 59,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 516.359992980957,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 513.0399932861328,
      "temperature": 0.0,
      "text": " So we can see here a simple prompt did not do the job.",
      "tokens": [
        50604,
        407,
        321,
        393,
        536,
        510,
        257,
        2199,
        12391,
        630,
        406,
        360,
        264,
        1691,
        13,
        50770
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 60,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 518.7599945068359,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 516.359992980957,
      "temperature": 0.0,
      "text": " Let's look at what this prompt actually looks like.",
      "tokens": [
        50770,
        961,
        311,
        574,
        412,
        437,
        341,
        12391,
        767,
        1542,
        411,
        13,
        50890
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 61,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 520.8399963378906,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 518.7599945068359,
      "temperature": 0.0,
      "text": " So if we open up this prompt, you can see here",
      "tokens": [
        50890,
        407,
        498,
        321,
        1269,
        493,
        341,
        12391,
        11,
        291,
        393,
        536,
        510,
        50994
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 62,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 524.0399932861328,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 520.8399963378906,
      "temperature": 0.0,
      "text": " we have our classic clean XML-ish format.",
      "tokens": [
        50994,
        321,
        362,
        527,
        7230,
        2541,
        43484,
        12,
        742,
        7877,
        13,
        51154
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 63,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 524.8799896240234,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 524.0399932861328,
      "temperature": 0.0,
      "text": " We have our.",
      "tokens": [
        51154,
        492,
        362,
        527,
        13,
        51196
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2232224941253662,
      "compression_ratio": 1.864661693572998,
      "end": 531.0399904251099,
      "no_speech_prob": 0.008984766900539398,
      "seek": 0,
      "start": 524.239990234375,
      "temperature": 0.0,
      "text": " purpose, we have our instructions, and then we have our variables at the bottom. This was a dynamic",
      "tokens": [
        50364,
        4334,
        11,
        321,
        362,
        527,
        9415,
        11,
        293,
        550,
        321,
        362,
        527,
        9102,
        412,
        264,
        2767,
        13,
        639,
        390,
        257,
        8546,
        50704
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2232224941253662,
      "compression_ratio": 1.864661693572998,
      "end": 536.3999900817871,
      "no_speech_prob": 0.008984766900539398,
      "seek": 0,
      "start": 531.0399904251099,
      "temperature": 0.0,
      "text": " variable and our application replaced it. So this, you know, looks like this in our code, right? So",
      "tokens": [
        50704,
        7006,
        293,
        527,
        3861,
        10772,
        309,
        13,
        407,
        341,
        11,
        291,
        458,
        11,
        1542,
        411,
        341,
        294,
        527,
        3089,
        11,
        558,
        30,
        407,
        50972
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2232224941253662,
      "compression_ratio": 1.864661693572998,
      "end": 542.239990234375,
      "no_speech_prob": 0.008984766900539398,
      "seek": 0,
      "start": 536.3999900817871,
      "temperature": 0.0,
      "text": " this is a, you know, variable that will be replaced. And what it ended up doing here was placing the",
      "tokens": [
        50972,
        341,
        307,
        257,
        11,
        291,
        458,
        11,
        7006,
        300,
        486,
        312,
        10772,
        13,
        400,
        437,
        309,
        4590,
        493,
        884,
        510,
        390,
        17221,
        264,
        51264
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2232224941253662,
      "compression_ratio": 1.864661693572998,
      "end": 548.159990310669,
      "no_speech_prob": 0.008984766900539398,
      "seek": 0,
      "start": 542.239990234375,
      "temperature": 0.0,
      "text": " iteration slice that we're operating on, right? And remember the slice is just a small piece of",
      "tokens": [
        51264,
        24784,
        13153,
        300,
        321,
        434,
        7447,
        322,
        11,
        558,
        30,
        400,
        1604,
        264,
        13153,
        307,
        445,
        257,
        1359,
        2522,
        295,
        51560
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2232224941253662,
      "compression_ratio": 1.864661693572998,
      "end": 551.7599906921387,
      "no_speech_prob": 0.008984766900539398,
      "seek": 0,
      "start": 548.159990310669,
      "temperature": 0.0,
      "text": " the entire transcript. So that's what the iteration slice is. You can see we have some instructions",
      "tokens": [
        51560,
        264,
        2302,
        24444,
        13,
        407,
        300,
        311,
        437,
        264,
        24784,
        13153,
        307,
        13,
        509,
        393,
        536,
        321,
        362,
        512,
        9415,
        51740
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.17429576814174652,
      "compression_ratio": 1.7155425548553467,
      "end": 556.159990310669,
      "no_speech_prob": 0.011331046000123024,
      "seek": 2752,
      "start": 551.7599906921387,
      "temperature": 0.0,
      "text": " here, classic prompting, nothing new here that we haven't discussed on the channel before. Let's",
      "tokens": [
        50364,
        510,
        11,
        7230,
        12391,
        278,
        11,
        1825,
        777,
        510,
        300,
        321,
        2378,
        380,
        7152,
        322,
        264,
        2269,
        949,
        13,
        961,
        311,
        50584
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.17429576814174652,
      "compression_ratio": 1.7155425548553467,
      "end": 561.4399909973145,
      "no_speech_prob": 0.011331046000123024,
      "seek": 2752,
      "start": 556.159990310669,
      "temperature": 0.0,
      "text": " scale this up, right? This is the prompt. And if we open up our LLMs file, collapse everything,",
      "tokens": [
        50584,
        4373,
        341,
        493,
        11,
        558,
        30,
        639,
        307,
        264,
        12391,
        13,
        400,
        498,
        321,
        1269,
        493,
        527,
        441,
        43,
        26386,
        3991,
        11,
        15584,
        1203,
        11,
        50848
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.17429576814174652,
      "compression_ratio": 1.7155425548553467,
      "end": 566.799991607666,
      "no_speech_prob": 0.011331046000123024,
      "seek": 2752,
      "start": 561.4399909973145,
      "temperature": 0.0,
      "text": " we have the intelligence comment here, and this is what that looks like in code, okay? So nothing",
      "tokens": [
        50848,
        321,
        362,
        264,
        7599,
        2871,
        510,
        11,
        293,
        341,
        307,
        437,
        300,
        1542,
        411,
        294,
        3089,
        11,
        1392,
        30,
        407,
        1825,
        51116
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.17429576814174652,
      "compression_ratio": 1.7155425548553467,
      "end": 571.2799911499023,
      "no_speech_prob": 0.011331046000123024,
      "seek": 2752,
      "start": 566.799991607666,
      "temperature": 0.0,
      "text": " too fancy, but it is important that I share it here because this tool is proprietary. Prompt up",
      "tokens": [
        51116,
        886,
        10247,
        11,
        457,
        309,
        307,
        1021,
        300,
        286,
        2073,
        309,
        510,
        570,
        341,
        2290,
        307,
        38992,
        13,
        15833,
        662,
        493,
        51340
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.17429576814174652,
      "compression_ratio": 1.7155425548553467,
      "end": 576.239990234375,
      "no_speech_prob": 0.011331046000123024,
      "seek": 2752,
      "start": 571.2799911499023,
      "temperature": 0.0,
      "text": " there, we have our XML slice that we're replacing with the incoming slice, and then we're doing some",
      "tokens": [
        51340,
        456,
        11,
        321,
        362,
        527,
        43484,
        13153,
        300,
        321,
        434,
        19139,
        365,
        264,
        22341,
        13153,
        11,
        293,
        550,
        321,
        434,
        884,
        512,
        51588
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.17429576814174652,
      "compression_ratio": 1.7155425548553467,
      "end": 580.8799896240234,
      "no_speech_prob": 0.011331046000123024,
      "seek": 2752,
      "start": 576.239990234375,
      "temperature": 0.0,
      "text": " logging, reasoning effort check, and then we're just pulling out a bunch of auxiliary information",
      "tokens": [
        51588,
        27991,
        11,
        21577,
        4630,
        1520,
        11,
        293,
        550,
        321,
        434,
        445,
        8407,
        484,
        257,
        3840,
        295,
        43741,
        1589,
        51820
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.18597561120986938,
      "compression_ratio": 1.6971831321716309,
      "end": 586.6399917602539,
      "no_speech_prob": 0.0037653562612831593,
      "seek": 5664,
      "start": 580.9599914550781,
      "temperature": 0.0,
      "text": " from the response, right? That's the prompt. If we look at Anthropx building effective agents doc,",
      "tokens": [
        50368,
        490,
        264,
        4134,
        11,
        558,
        30,
        663,
        311,
        264,
        12391,
        13,
        759,
        321,
        574,
        412,
        12727,
        1513,
        87,
        2390,
        4942,
        12554,
        3211,
        11,
        50652
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.18597561120986938,
      "compression_ratio": 1.6971831321716309,
      "end": 593.359992980957,
      "no_speech_prob": 0.0037653562612831593,
      "seek": 5664,
      "start": 586.6399917602539,
      "temperature": 0.0,
      "text": " it all starts with the prompt. What we've done here is we've given our language model access to",
      "tokens": [
        50652,
        309,
        439,
        3719,
        365,
        264,
        12391,
        13,
        708,
        321,
        600,
        1096,
        510,
        307,
        321,
        600,
        2212,
        527,
        2856,
        2316,
        2105,
        281,
        50988
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.18597561120986938,
      "compression_ratio": 1.6971831321716309,
      "end": 599.5199890136719,
      "no_speech_prob": 0.0037653562612831593,
      "seek": 5664,
      "start": 593.359992980957,
      "temperature": 0.0,
      "text": " an output structure so that we can pass in a prompt. Our LLM then makes a judgment call on",
      "tokens": [
        50988,
        364,
        5598,
        3877,
        370,
        300,
        321,
        393,
        1320,
        294,
        257,
        12391,
        13,
        2621,
        441,
        43,
        44,
        550,
        1669,
        257,
        12216,
        818,
        322,
        51296
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.18597561120986938,
      "compression_ratio": 1.6971831321716309,
      "end": 604.239990234375,
      "no_speech_prob": 0.0037653562612831593,
      "seek": 5664,
      "start": 599.5199890136719,
      "temperature": 0.0,
      "text": " the output. In the prompt version, we don't have anything fancy here. All we have is a structured",
      "tokens": [
        51296,
        264,
        5598,
        13,
        682,
        264,
        12391,
        3037,
        11,
        321,
        500,
        380,
        362,
        1340,
        10247,
        510,
        13,
        1057,
        321,
        362,
        307,
        257,
        18519,
        51532
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.18597561120986938,
      "compression_ratio": 1.6971831321716309,
      "end": 610.239990234375,
      "no_speech_prob": 0.0037653562612831593,
      "seek": 5664,
      "start": 604.239990234375,
      "temperature": 0.0,
      "text": " outputs call that generates our deletions. And so that's all our prompt is doing. You can see here",
      "tokens": [
        51532,
        23930,
        818,
        300,
        23815,
        527,
        1103,
        302,
        626,
        13,
        400,
        370,
        300,
        311,
        439,
        527,
        12391,
        307,
        884,
        13,
        509,
        393,
        536,
        510,
        51832
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.18104620277881622,
      "compression_ratio": 1.695804238319397,
      "end": 616.3999938964844,
      "no_speech_prob": 0.00026530097238719463,
      "seek": 8600,
      "start": 610.239990234375,
      "temperature": 0.0,
      "text": " we have our response format that has our uncut deletion, and we are using Zodd response format",
      "tokens": [
        50364,
        321,
        362,
        527,
        4134,
        7877,
        300,
        575,
        527,
        6219,
        325,
        1103,
        302,
        313,
        11,
        293,
        321,
        366,
        1228,
        1176,
        378,
        67,
        4134,
        7877,
        50672
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.18104620277881622,
      "compression_ratio": 1.695804238319397,
      "end": 622.7999877929688,
      "no_speech_prob": 0.00026530097238719463,
      "seek": 8600,
      "start": 616.3999938964844,
      "temperature": 0.0,
      "text": " for structured outputs. Let's go ahead and kick up our compute. There's two levers we can pull here",
      "tokens": [
        50672,
        337,
        18519,
        23930,
        13,
        961,
        311,
        352,
        2286,
        293,
        4437,
        493,
        527,
        14722,
        13,
        821,
        311,
        732,
        45571,
        321,
        393,
        2235,
        510,
        50992
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.18104620277881622,
      "compression_ratio": 1.695804238319397,
      "end": 627.7599868774414,
      "no_speech_prob": 0.00026530097238719463,
      "seek": 8600,
      "start": 622.7999877929688,
      "temperature": 0.0,
      "text": " right away. We can just do one of them for fun, right? We can quickly just take this, right? This",
      "tokens": [
        50992,
        558,
        1314,
        13,
        492,
        393,
        445,
        360,
        472,
        295,
        552,
        337,
        1019,
        11,
        558,
        30,
        492,
        393,
        2661,
        445,
        747,
        341,
        11,
        558,
        30,
        639,
        51240
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.18104620277881622,
      "compression_ratio": 1.695804238319397,
      "end": 632.9599914550781,
      "no_speech_prob": 0.00026530097238719463,
      "seek": 8600,
      "start": 627.7599868774414,
      "temperature": 0.0,
      "text": " is running GPT-40. We can go config, we can go LLM model, we can go O3 mini, and then we can just",
      "tokens": [
        51240,
        307,
        2614,
        26039,
        51,
        12,
        5254,
        13,
        492,
        393,
        352,
        6662,
        11,
        321,
        393,
        352,
        441,
        43,
        44,
        2316,
        11,
        321,
        393,
        352,
        422,
        18,
        8382,
        11,
        293,
        550,
        321,
        393,
        445,
        51500
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.18104620277881622,
      "compression_ratio": 1.695804238319397,
      "end": 638.5599899291992,
      "no_speech_prob": 0.00026530097238719463,
      "seek": 8600,
      "start": 632.9599914550781,
      "temperature": 0.0,
      "text": " quickly, you know, kick this off again. And now O3 mini is going to take a hit at solving this",
      "tokens": [
        51500,
        2661,
        11,
        291,
        458,
        11,
        4437,
        341,
        766,
        797,
        13,
        400,
        586,
        422,
        18,
        8382,
        307,
        516,
        281,
        747,
        257,
        2045,
        412,
        12606,
        341,
        51780
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.16662892699241638,
      "compression_ratio": 1.54450261592865,
      "end": 644.1599884033203,
      "no_speech_prob": 0.012052685022354126,
      "seek": 11432,
      "start": 638.5599899291992,
      "temperature": 0.0,
      "text": " problem. Let's take a look at the output that O3 mini gave us. Same deal. We have the original text,",
      "tokens": [
        50364,
        1154,
        13,
        961,
        311,
        747,
        257,
        574,
        412,
        264,
        5598,
        300,
        422,
        18,
        8382,
        2729,
        505,
        13,
        10635,
        2028,
        13,
        492,
        362,
        264,
        3380,
        2487,
        11,
        50644
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.16662892699241638,
      "compression_ratio": 1.54450261592865,
      "end": 649.359992980957,
      "no_speech_prob": 0.012052685022354126,
      "seek": 11432,
      "start": 644.1599884033203,
      "temperature": 0.0,
      "text": " we have the target, there's the prompt for O3 mini, here's the deletion it created. And so if",
      "tokens": [
        50644,
        321,
        362,
        264,
        3779,
        11,
        456,
        311,
        264,
        12391,
        337,
        422,
        18,
        8382,
        11,
        510,
        311,
        264,
        1103,
        302,
        313,
        309,
        2942,
        13,
        400,
        370,
        498,
        50904
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.16662892699241638,
      "compression_ratio": 1.54450261592865,
      "end": 655.1999969482422,
      "no_speech_prob": 0.012052685022354126,
      "seek": 11432,
      "start": 649.359992980957,
      "temperature": 0.0,
      "text": " we scroll down here, you can see O3 mini got this problem right with just a prompt. Very cool to see",
      "tokens": [
        50904,
        321,
        11369,
        760,
        510,
        11,
        291,
        393,
        536,
        422,
        18,
        8382,
        658,
        341,
        1154,
        558,
        365,
        445,
        257,
        12391,
        13,
        4372,
        1627,
        281,
        536,
        51196
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_005.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.23724918067455292,
      "compression_ratio": 1.8228346109390259,
      "end": 659.6599879264832,
      "no_speech_prob": 0.07583343982696533,
      "seek": 0,
      "start": 655.2999877929688,
      "temperature": 0.0,
      "text": " this, right? So we have the original text and then we have the predicted final",
      "tokens": [
        50364,
        341,
        11,
        558,
        30,
        407,
        321,
        362,
        264,
        3380,
        2487,
        293,
        550,
        321,
        362,
        264,
        19147,
        2572,
        50582
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.23724918067455292,
      "compression_ratio": 1.8228346109390259,
      "end": 663.2999877929688,
      "no_speech_prob": 0.07583343982696533,
      "seek": 0,
      "start": 659.6599879264832,
      "temperature": 0.0,
      "text": " text coming out of our language model and then we have the target text. So",
      "tokens": [
        50582,
        2487,
        1348,
        484,
        295,
        527,
        2856,
        2316,
        293,
        550,
        321,
        362,
        264,
        3779,
        2487,
        13,
        407,
        50764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.23724918067455292,
      "compression_ratio": 1.8228346109390259,
      "end": 666.0999879837036,
      "no_speech_prob": 0.07583343982696533,
      "seek": 0,
      "start": 663.2999877929688,
      "temperature": 0.0,
      "text": " that's us answering the problem successfully and incorrectly. So I'll",
      "tokens": [
        50764,
        300,
        311,
        505,
        13430,
        264,
        1154,
        10727,
        293,
        42892,
        13,
        407,
        286,
        603,
        50904
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.23724918067455292,
      "compression_ratio": 1.8228346109390259,
      "end": 670.2199878692627,
      "no_speech_prob": 0.07583343982696533,
      "seek": 0,
      "start": 666.0999879837036,
      "temperature": 0.0,
      "text": " comment this out and let's go ahead and look at the prompt chain. By looking at",
      "tokens": [
        50904,
        2871,
        341,
        484,
        293,
        718,
        311,
        352,
        2286,
        293,
        574,
        412,
        264,
        12391,
        5021,
        13,
        3146,
        1237,
        412,
        51110
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.23724918067455292,
      "compression_ratio": 1.8228346109390259,
      "end": 676.699987411499,
      "no_speech_prob": 0.07583343982696533,
      "seek": 0,
      "start": 670.2199878692627,
      "temperature": 0.0,
      "text": " the log you'll understand exactly how it works. So let's kick this off. What we're",
      "tokens": [
        51110,
        264,
        3565,
        291,
        603,
        1223,
        2293,
        577,
        309,
        1985,
        13,
        407,
        718,
        311,
        4437,
        341,
        766,
        13,
        708,
        321,
        434,
        51434
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.23724918067455292,
      "compression_ratio": 1.8228346109390259,
      "end": 679.699987411499,
      "no_speech_prob": 0.07583343982696533,
      "seek": 0,
      "start": 676.699987411499,
      "temperature": 0.0,
      "text": " doing here with the prompt chain is we're taking that same problem and we're",
      "tokens": [
        51434,
        884,
        510,
        365,
        264,
        12391,
        5021,
        307,
        321,
        434,
        1940,
        300,
        912,
        1154,
        293,
        321,
        434,
        51584
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.243210569024086,
      "compression_ratio": 1.8695652484893799,
      "end": 685.3799877166748,
      "no_speech_prob": 0.024421392008662224,
      "seek": 2440,
      "start": 679.699987411499,
      "temperature": 0.0,
      "text": " throwing more compute at the problem. You can see here GPG 4.0 got this problem",
      "tokens": [
        50364,
        10238,
        544,
        14722,
        412,
        264,
        1154,
        13,
        509,
        393,
        536,
        510,
        26039,
        38,
        1017,
        13,
        15,
        658,
        341,
        1154,
        50648
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.243210569024086,
      "compression_ratio": 1.8695652484893799,
      "end": 689.0199890136719,
      "no_speech_prob": 0.024421392008662224,
      "seek": 2440,
      "start": 685.3799877166748,
      "temperature": 0.0,
      "text": " correct with a prompt chain. So let's go ahead and look at the log and then let's",
      "tokens": [
        50648,
        3006,
        365,
        257,
        12391,
        5021,
        13,
        407,
        718,
        311,
        352,
        2286,
        293,
        574,
        412,
        264,
        3565,
        293,
        550,
        718,
        311,
        50830
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.243210569024086,
      "compression_ratio": 1.8695652484893799,
      "end": 692.7399864196777,
      "no_speech_prob": 0.024421392008662224,
      "seek": 2440,
      "start": 689.0199890136719,
      "temperature": 0.0,
      "text": " break down how the prompt chain worked. Let's go ahead and open up V2. This is",
      "tokens": [
        50830,
        1821,
        760,
        577,
        264,
        12391,
        5021,
        2732,
        13,
        961,
        311,
        352,
        2286,
        293,
        1269,
        493,
        691,
        17,
        13,
        639,
        307,
        51016
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.243210569024086,
      "compression_ratio": 1.8695652484893799,
      "end": 696.8199882507324,
      "no_speech_prob": 0.024421392008662224,
      "seek": 2440,
      "start": 692.7399864196777,
      "temperature": 0.0,
      "text": " the a cut prompt chain and let's look at how a prompt chain outperforms the",
      "tokens": [
        51016,
        264,
        257,
        1723,
        12391,
        5021,
        293,
        718,
        311,
        574,
        412,
        577,
        257,
        12391,
        5021,
        484,
        26765,
        82,
        264,
        51220
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.243210569024086,
      "compression_ratio": 1.8695652484893799,
      "end": 701.2599868774414,
      "no_speech_prob": 0.024421392008662224,
      "seek": 2440,
      "start": 696.8199882507324,
      "temperature": 0.0,
      "text": " single prompt, okay? So once again we have that exact same problem, right? Of this",
      "tokens": [
        51220,
        2167,
        12391,
        11,
        1392,
        30,
        407,
        1564,
        797,
        321,
        362,
        300,
        1900,
        912,
        1154,
        11,
        558,
        30,
        2720,
        341,
        51442
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.243210569024086,
      "compression_ratio": 1.8695652484893799,
      "end": 704.6999893188477,
      "no_speech_prob": 0.024421392008662224,
      "seek": 2440,
      "start": 701.2599868774414,
      "temperature": 0.0,
      "text": " scratchpad kind of blah blah blah. So basically we have the starting text and",
      "tokens": [
        51442,
        8459,
        13647,
        733,
        295,
        12288,
        12288,
        12288,
        13,
        407,
        1936,
        321,
        362,
        264,
        2891,
        2487,
        293,
        51614
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.243210569024086,
      "compression_ratio": 1.8695652484893799,
      "end": 707.8199882507324,
      "no_speech_prob": 0.024421392008662224,
      "seek": 2440,
      "start": 704.6999893188477,
      "temperature": 0.0,
      "text": " then we have the ground truth, right? This is the end result we're looking to get",
      "tokens": [
        51614,
        550,
        321,
        362,
        264,
        2727,
        3494,
        11,
        558,
        30,
        639,
        307,
        264,
        917,
        1874,
        321,
        434,
        1237,
        281,
        483,
        51770
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.21672198176383972,
      "compression_ratio": 1.7142857313156128,
      "end": 711.4599876403809,
      "no_speech_prob": 0.03514304384589195,
      "seek": 5252,
      "start": 707.8199882507324,
      "temperature": 0.0,
      "text": " to. And then we have this new piece of information. When you're using prompt",
      "tokens": [
        50364,
        281,
        13,
        400,
        550,
        321,
        362,
        341,
        777,
        2522,
        295,
        1589,
        13,
        1133,
        291,
        434,
        1228,
        12391,
        50546
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.21672198176383972,
      "compression_ratio": 1.7142857313156128,
      "end": 715.8199882507324,
      "no_speech_prob": 0.03514304384589195,
      "seek": 5252,
      "start": 711.4599876403809,
      "temperature": 0.0,
      "text": " chains and AI agents you'll always want to limit the amount of compute or loops",
      "tokens": [
        50546,
        12626,
        293,
        7318,
        12554,
        291,
        603,
        1009,
        528,
        281,
        4948,
        264,
        2372,
        295,
        14722,
        420,
        16121,
        50764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.21672198176383972,
      "compression_ratio": 1.7142857313156128,
      "end": 720.3399887084961,
      "no_speech_prob": 0.03514304384589195,
      "seek": 5252,
      "start": 715.8199882507324,
      "temperature": 0.0,
      "text": " that your AI tooling can run. You don't want it to run infinitely. You might have",
      "tokens": [
        50764,
        300,
        428,
        7318,
        46593,
        393,
        1190,
        13,
        509,
        500,
        380,
        528,
        309,
        281,
        1190,
        36227,
        13,
        509,
        1062,
        362,
        50990
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.21672198176383972,
      "compression_ratio": 1.7142857313156128,
      "end": 725.0999908447266,
      "no_speech_prob": 0.03514304384589195,
      "seek": 5252,
      "start": 720.3399887084961,
      "temperature": 0.0,
      "text": " a bug, something might go wrong and there is nearly always a sweet spot or a",
      "tokens": [
        50990,
        257,
        7426,
        11,
        746,
        1062,
        352,
        2085,
        293,
        456,
        307,
        6217,
        1009,
        257,
        3844,
        4008,
        420,
        257,
        51228
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.21672198176383972,
      "compression_ratio": 1.7142857313156128,
      "end": 728.8999862670898,
      "no_speech_prob": 0.03514304384589195,
      "seek": 5252,
      "start": 725.0999908447266,
      "temperature": 0.0,
      "text": " perfect range for the problem that you're trying to solve. So you can see",
      "tokens": [
        51228,
        2176,
        3613,
        337,
        264,
        1154,
        300,
        291,
        434,
        1382,
        281,
        5039,
        13,
        407,
        291,
        393,
        536,
        51418
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.21672198176383972,
      "compression_ratio": 1.7142857313156128,
      "end": 732.8999862670898,
      "no_speech_prob": 0.03514304384589195,
      "seek": 5252,
      "start": 728.8999862670898,
      "temperature": 0.0,
      "text": " here for this prompt chain I'm allowing eight compute loops, eight iterations,",
      "tokens": [
        51418,
        510,
        337,
        341,
        12391,
        5021,
        286,
        478,
        8293,
        3180,
        14722,
        16121,
        11,
        3180,
        36540,
        11,
        51618
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.2511487305164337,
      "compression_ratio": 1.8441064357757568,
      "end": 738.5399856567383,
      "no_speech_prob": 0.268891304731369,
      "seek": 7760,
      "start": 732.8999862670898,
      "temperature": 0.0,
      "text": " okay? So we start with this one deletion here. This, the scratchpad kind of act",
      "tokens": [
        50364,
        1392,
        30,
        407,
        321,
        722,
        365,
        341,
        472,
        1103,
        302,
        313,
        510,
        13,
        639,
        11,
        264,
        8459,
        13647,
        733,
        295,
        605,
        50646
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2511487305164337,
      "compression_ratio": 1.8441064357757568,
      "end": 742.619987487793,
      "no_speech_prob": 0.268891304731369,
      "seek": 7760,
      "start": 738.5399856567383,
      "temperature": 0.0,
      "text": " um. And then if we scroll down here you can see, you know, that made a pretty good",
      "tokens": [
        50646,
        1105,
        13,
        400,
        550,
        498,
        321,
        11369,
        760,
        510,
        291,
        393,
        536,
        11,
        291,
        458,
        11,
        300,
        1027,
        257,
        1238,
        665,
        50850
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2511487305164337,
      "compression_ratio": 1.8441064357757568,
      "end": 746.739990234375,
      "no_speech_prob": 0.268891304731369,
      "seek": 7760,
      "start": 742.619987487793,
      "temperature": 0.0,
      "text": " edit. Then we can scroll down and then you can see it only took out um. So it's",
      "tokens": [
        50850,
        8129,
        13,
        1396,
        321,
        393,
        11369,
        760,
        293,
        550,
        291,
        393,
        536,
        309,
        787,
        1890,
        484,
        1105,
        13,
        407,
        309,
        311,
        51056
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2511487305164337,
      "compression_ratio": 1.8441064357757568,
      "end": 751.0599899291992,
      "no_speech_prob": 0.268891304731369,
      "seek": 7760,
      "start": 746.739990234375,
      "temperature": 0.0,
      "text": " taking another shot. It sees that, you know, after this first run that I made I",
      "tokens": [
        51056,
        1940,
        1071,
        3347,
        13,
        467,
        8194,
        300,
        11,
        291,
        458,
        11,
        934,
        341,
        700,
        1190,
        300,
        286,
        1027,
        286,
        51272
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.2511487305164337,
      "compression_ratio": 1.8441064357757568,
      "end": 755.5799865722656,
      "no_speech_prob": 0.268891304731369,
      "seek": 7760,
      "start": 751.0599899291992,
      "temperature": 0.0,
      "text": " still need to edit more, okay? So now it's just taking out um. Third compute loop,",
      "tokens": [
        51272,
        920,
        643,
        281,
        8129,
        544,
        11,
        1392,
        30,
        407,
        586,
        309,
        311,
        445,
        1940,
        484,
        1105,
        13,
        12548,
        14722,
        6367,
        11,
        51498
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.2511487305164337,
      "compression_ratio": 1.8441064357757568,
      "end": 760.0599899291992,
      "no_speech_prob": 0.268891304731369,
      "seek": 7760,
      "start": 755.5799865722656,
      "temperature": 0.0,
      "text": " right? So it has, you know, five shots left. And so now it's telling us that no",
      "tokens": [
        51498,
        558,
        30,
        407,
        309,
        575,
        11,
        291,
        458,
        11,
        1732,
        8305,
        1411,
        13,
        400,
        370,
        586,
        309,
        311,
        3585,
        505,
        300,
        572,
        51722
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.2335233986377716,
      "compression_ratio": 1.7560137510299683,
      "end": 763.6999893188477,
      "no_speech_prob": 0.000410838722018525,
      "seek": 10476,
      "start": 760.0999908447266,
      "temperature": 0.0,
      "text": " deletions were generated. So it's going to exit the loop. So inside of this",
      "tokens": [
        50366,
        1103,
        302,
        626,
        645,
        10833,
        13,
        407,
        309,
        311,
        516,
        281,
        11043,
        264,
        6367,
        13,
        407,
        1854,
        295,
        341,
        50546
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.2335233986377716,
      "compression_ratio": 1.7560137510299683,
      "end": 767.1799850463867,
      "no_speech_prob": 0.000410838722018525,
      "seek": 10476,
      "start": 763.6999893188477,
      "temperature": 0.0,
      "text": " prompt, which we'll look at in a moment, there is a condition that says if you're",
      "tokens": [
        50546,
        12391,
        11,
        597,
        321,
        603,
        574,
        412,
        294,
        257,
        1623,
        11,
        456,
        307,
        257,
        4188,
        300,
        1619,
        498,
        291,
        434,
        50720
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.2335233986377716,
      "compression_ratio": 1.7560137510299683,
      "end": 772.6999893188477,
      "no_speech_prob": 0.000410838722018525,
      "seek": 10476,
      "start": 767.1799850463867,
      "temperature": 0.0,
      "text": " done return an empty list, okay? It created two deletions. Here's the first",
      "tokens": [
        50720,
        1096,
        2736,
        364,
        6707,
        1329,
        11,
        1392,
        30,
        467,
        2942,
        732,
        1103,
        302,
        626,
        13,
        1692,
        311,
        264,
        700,
        50996
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.2335233986377716,
      "compression_ratio": 1.7560137510299683,
      "end": 776.9399871826172,
      "no_speech_prob": 0.000410838722018525,
      "seek": 10476,
      "start": 772.6999893188477,
      "temperature": 0.0,
      "text": " one with several words in the deletion. And then we have in a follow-up loop",
      "tokens": [
        50996,
        472,
        365,
        2940,
        2283,
        294,
        264,
        1103,
        302,
        313,
        13,
        400,
        550,
        321,
        362,
        294,
        257,
        1524,
        12,
        1010,
        6367,
        51208
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.2335233986377716,
      "compression_ratio": 1.7560137510299683,
      "end": 780.3799896240234,
      "no_speech_prob": 0.000410838722018525,
      "seek": 10476,
      "start": 776.9399871826172,
      "temperature": 0.0,
      "text": " because it didn't create the perfect edit the first time. You can see here we",
      "tokens": [
        51208,
        570,
        309,
        994,
        380,
        1884,
        264,
        2176,
        8129,
        264,
        700,
        565,
        13,
        509,
        393,
        536,
        510,
        321,
        51380
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.2335233986377716,
      "compression_ratio": 1.7560137510299683,
      "end": 784.8599853515625,
      "no_speech_prob": 0.000410838722018525,
      "seek": 10476,
      "start": 780.3799896240234,
      "temperature": 0.0,
      "text": " have the words um edited that out. And then we have the final iteration slice.",
      "tokens": [
        51380,
        362,
        264,
        2283,
        1105,
        23016,
        300,
        484,
        13,
        400,
        550,
        321,
        362,
        264,
        2572,
        24784,
        13153,
        13,
        51604
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.2335233986377716,
      "compression_ratio": 1.7560137510299683,
      "end": 788.3799896240234,
      "no_speech_prob": 0.000410838722018525,
      "seek": 10476,
      "start": 784.8599853515625,
      "temperature": 0.0,
      "text": " So this is what our final slice looks like.",
      "tokens": [
        51604,
        407,
        341,
        307,
        437,
        527,
        2572,
        13153,
        1542,
        411,
        13,
        51780
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_006.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 789.0199854373932,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 786.3599853515625,
      "temperature": 0.0,
      "text": " looks like with the edits made from the deletions.",
      "tokens": [
        50364,
        1542,
        411,
        365,
        264,
        41752,
        1027,
        490,
        264,
        1103,
        302,
        626,
        13,
        50497
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 789.2199852466583,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 789.0199854373932,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50497,
        1033,
        13,
        50507
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 791.2799854278564,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 789.2199852466583,
      "temperature": 0.0,
      "text": " So there's that nice JSON object there.",
      "tokens": [
        50507,
        407,
        456,
        311,
        300,
        1481,
        31828,
        2657,
        456,
        13,
        50610
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 793.8599853515625,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 791.379985332489,
      "temperature": 0.0,
      "text": " And then you can see here, here's the original, here's what our",
      "tokens": [
        50615,
        400,
        550,
        291,
        393,
        536,
        510,
        11,
        510,
        311,
        264,
        3380,
        11,
        510,
        311,
        437,
        527,
        50739
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 795.6199855804443,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 793.8599853515625,
      "temperature": 0.0,
      "text": " prompt chain output for us.",
      "tokens": [
        50739,
        12391,
        5021,
        5598,
        337,
        505,
        13,
        50827
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 796.6799850463867,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 795.7199850082397,
      "temperature": 0.0,
      "text": " And here's the target text.",
      "tokens": [
        50832,
        400,
        510,
        311,
        264,
        3779,
        2487,
        13,
        50880
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 799.2199850082397,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 796.6799850463867,
      "temperature": 0.0,
      "text": " So you can see, we of course have the correct answer.",
      "tokens": [
        50880,
        407,
        291,
        393,
        536,
        11,
        321,
        295,
        1164,
        362,
        264,
        3006,
        1867,
        13,
        51007
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 804.4999847412109,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 799.3399848937988,
      "temperature": 0.0,
      "text": " This is really important because for this simple use case of effectively",
      "tokens": [
        51013,
        639,
        307,
        534,
        1021,
        570,
        337,
        341,
        2199,
        764,
        1389,
        295,
        8659,
        51271
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 808.7999858856201,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 804.5999851226807,
      "temperature": 0.0,
      "text": " determining which words to remove that don't make sense, you can see here",
      "tokens": [
        51276,
        23751,
        597,
        2283,
        281,
        4159,
        300,
        500,
        380,
        652,
        2020,
        11,
        291,
        393,
        536,
        510,
        51486
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 811.5399856567383,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 808.7999858856201,
      "temperature": 0.0,
      "text": " that having a little bit more compute, you know, quite literally, it",
      "tokens": [
        51486,
        300,
        1419,
        257,
        707,
        857,
        544,
        14722,
        11,
        291,
        458,
        11,
        1596,
        3736,
        11,
        309,
        51623
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 813.7199859619141,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 811.5399856567383,
      "temperature": 0.0,
      "text": " just needed one additional run.",
      "tokens": [
        51623,
        445,
        2978,
        472,
        4497,
        1190,
        13,
        51732
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.2798928916454315,
      "compression_ratio": 1.6881028413772583,
      "end": 814.0199851989746,
      "no_speech_prob": 0.017710955813527107,
      "seek": 0,
      "start": 813.7799854278564,
      "temperature": 0.0,
      "text": " Right.",
      "tokens": [
        51735,
        1779,
        13,
        51747
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 816.9199848175049,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 814.0199851989746,
      "temperature": 0.0,
      "text": " So we had one deletion and then we had another deletion.",
      "tokens": [
        50364,
        407,
        321,
        632,
        472,
        1103,
        302,
        313,
        293,
        550,
        321,
        632,
        1071,
        1103,
        302,
        313,
        13,
        50509
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 820.559986114502,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 816.9599857330322,
      "temperature": 0.0,
      "text": " And then on our third compute loop, it said, there's nothing",
      "tokens": [
        50511,
        400,
        550,
        322,
        527,
        2636,
        14722,
        6367,
        11,
        309,
        848,
        11,
        456,
        311,
        1825,
        50691
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 821.3199844360352,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 820.559986114502,
      "temperature": 0.0,
      "text": " left for me to do here.",
      "tokens": [
        50691,
        1411,
        337,
        385,
        281,
        360,
        510,
        13,
        50729
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 824.5199851989746,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 821.3199844360352,
      "temperature": 0.0,
      "text": " I'm done by turning our prompt into a prompt chain, quite literally",
      "tokens": [
        50729,
        286,
        478,
        1096,
        538,
        6246,
        527,
        12391,
        666,
        257,
        12391,
        5021,
        11,
        1596,
        3736,
        50889
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 826.1999855041504,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 824.5199851989746,
      "temperature": 0.0,
      "text": " just saying, run it again.",
      "tokens": [
        50889,
        445,
        1566,
        11,
        1190,
        309,
        797,
        13,
        50973
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 828.7199859619141,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 826.2799835205078,
      "temperature": 0.0,
      "text": " It was able to generate an improved answer for us.",
      "tokens": [
        50977,
        467,
        390,
        1075,
        281,
        8460,
        364,
        9689,
        1867,
        337,
        505,
        13,
        51099
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 833.3999862670898,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 828.7199859619141,
      "temperature": 0.0,
      "text": " So, you know, that's the log and you can see here we have three prompts, right?",
      "tokens": [
        51099,
        407,
        11,
        291,
        458,
        11,
        300,
        311,
        264,
        3565,
        293,
        291,
        393,
        536,
        510,
        321,
        362,
        1045,
        41095,
        11,
        558,
        30,
        51333
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 835.9199867248535,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 833.5199851989746,
      "temperature": 0.0,
      "text": " So one prompt for our first run.",
      "tokens": [
        51339,
        407,
        472,
        12391,
        337,
        527,
        700,
        1190,
        13,
        51459
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 838.5999870300293,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 835.9799842834473,
      "temperature": 0.0,
      "text": " So we have this first prompt here, and then we have our second",
      "tokens": [
        51462,
        407,
        321,
        362,
        341,
        700,
        12391,
        510,
        11,
        293,
        550,
        321,
        362,
        527,
        1150,
        51593
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.24428415298461914,
      "compression_ratio": 1.8272058963775635,
      "end": 840.559986114502,
      "no_speech_prob": 0.00027802796103060246,
      "seek": 2766,
      "start": 838.5999870300293,
      "temperature": 0.0,
      "text": " prompt and then our third prompt.",
      "tokens": [
        51593,
        12391,
        293,
        550,
        527,
        2636,
        12391,
        13,
        51691
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 844.5399856567383,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 840.5799865722656,
      "temperature": 0.0,
      "text": " And it was in our third prompt where the prompt chain, you know, the",
      "tokens": [
        50365,
        400,
        309,
        390,
        294,
        527,
        2636,
        12391,
        689,
        264,
        12391,
        5021,
        11,
        291,
        458,
        11,
        264,
        50563
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 846.8199844360352,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 844.5399856567383,
      "temperature": 0.0,
      "text": " language model returned no deletions.",
      "tokens": [
        50563,
        2856,
        2316,
        8752,
        572,
        1103,
        302,
        626,
        13,
        50677
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 847.8199844360352,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 846.8199844360352,
      "temperature": 0.0,
      "text": " So that means we're done.",
      "tokens": [
        50677,
        407,
        300,
        1355,
        321,
        434,
        1096,
        13,
        50727
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 848.1799850463867,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 847.8599853515625,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50729,
        1033,
        13,
        50745
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 850.8599853515625,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 848.3399848937988,
      "temperature": 0.0,
      "text": " Let's go ahead and just take a look at the prompt for a moment here.",
      "tokens": [
        50753,
        961,
        311,
        352,
        2286,
        293,
        445,
        747,
        257,
        574,
        412,
        264,
        12391,
        337,
        257,
        1623,
        510,
        13,
        50879
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 854.7399826049805,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 850.9399871826172,
      "temperature": 0.0,
      "text": " And you'll see a very similar structure, except for the primary difference that",
      "tokens": [
        50883,
        400,
        291,
        603,
        536,
        257,
        588,
        2531,
        3877,
        11,
        3993,
        337,
        264,
        6194,
        2649,
        300,
        51073
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 858.2599868774414,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 854.8199844360352,
      "temperature": 0.0,
      "text": " we have an original slice and current deletions.",
      "tokens": [
        51077,
        321,
        362,
        364,
        3380,
        13153,
        293,
        2190,
        1103,
        302,
        626,
        13,
        51249
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 858.7399826049805,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 858.3199844360352,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51252,
        1033,
        13,
        51273
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 863.9799880981445,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 858.8999862670898,
      "temperature": 0.0,
      "text": " So in addition to the iteration slice, which is the small piece of the transcript",
      "tokens": [
        51281,
        407,
        294,
        4500,
        281,
        264,
        24784,
        13153,
        11,
        597,
        307,
        264,
        1359,
        2522,
        295,
        264,
        24444,
        51535
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.25094693899154663,
      "compression_ratio": 1.7420494556427002,
      "end": 867.4999847412109,
      "no_speech_prob": 0.00034062567283399403,
      "seek": 5420,
      "start": 863.9799880981445,
      "temperature": 0.0,
      "text": " that we're working on currently, we also have the current deletions.",
      "tokens": [
        51535,
        300,
        321,
        434,
        1364,
        322,
        4362,
        11,
        321,
        611,
        362,
        264,
        2190,
        1103,
        302,
        626,
        13,
        51711
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 872.119987487793,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 867.5599822998047,
      "temperature": 0.0,
      "text": " So when our model is looping, it needs to know what it's already edited and",
      "tokens": [
        50367,
        407,
        562,
        527,
        2316,
        307,
        6367,
        278,
        11,
        309,
        2203,
        281,
        458,
        437,
        309,
        311,
        1217,
        23016,
        293,
        50595
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 874.0799865722656,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 872.119987487793,
      "temperature": 0.0,
      "text": " it needs to know the starting point.",
      "tokens": [
        50595,
        309,
        2203,
        281,
        458,
        264,
        2891,
        935,
        13,
        50693
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 874.3999862670898,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 874.1599884033203,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50697,
        1033,
        13,
        50709
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 875.5199890136719,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 874.3999862670898,
      "temperature": 0.0,
      "text": " So this is where it started.",
      "tokens": [
        50709,
        407,
        341,
        307,
        689,
        309,
        1409,
        13,
        50765
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 878.5599822998047,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 875.5599822998047,
      "temperature": 0.0,
      "text": " This is the current deletions that it's made.",
      "tokens": [
        50767,
        639,
        307,
        264,
        2190,
        1103,
        302,
        626,
        300,
        309,
        311,
        1027,
        13,
        50917
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 882.1599884033203,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 878.7199859619141,
      "temperature": 0.0,
      "text": " And then the iteration slice is the result of those",
      "tokens": [
        50925,
        400,
        550,
        264,
        24784,
        13153,
        307,
        264,
        1874,
        295,
        729,
        51097
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 884.3599853515625,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 882.1599884033203,
      "temperature": 0.0,
      "text": " deletions on the original slice.",
      "tokens": [
        51097,
        1103,
        302,
        626,
        322,
        264,
        3380,
        13153,
        13,
        51207
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 885.8799819946289,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 884.3599853515625,
      "temperature": 0.0,
      "text": " So let me just show you the second prompt.",
      "tokens": [
        51207,
        407,
        718,
        385,
        445,
        855,
        291,
        264,
        1150,
        12391,
        13,
        51283
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 887.6399841308594,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 885.9199829101562,
      "temperature": 0.0,
      "text": " You can see here, current deletions is empty.",
      "tokens": [
        51285,
        509,
        393,
        536,
        510,
        11,
        2190,
        1103,
        302,
        626,
        307,
        6707,
        13,
        51371
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 892.5199890136719,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 887.9599838256836,
      "temperature": 0.0,
      "text": " And in this version, our current deletions has some content, right?",
      "tokens": [
        51387,
        400,
        294,
        341,
        3037,
        11,
        527,
        2190,
        1103,
        302,
        626,
        575,
        512,
        2701,
        11,
        558,
        30,
        51615
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.24546630680561066,
      "compression_ratio": 1.8803088665008545,
      "end": 895.7199859619141,
      "no_speech_prob": 0.000319995975587517,
      "seek": 8114,
      "start": 892.8799819946289,
      "temperature": 0.0,
      "text": " So in the second prompt, we have made edits, right?",
      "tokens": [
        51633,
        407,
        294,
        264,
        1150,
        12391,
        11,
        321,
        362,
        1027,
        41752,
        11,
        558,
        30,
        51775
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.2541390657424927,
      "compression_ratio": 1.7692307233810425,
      "end": 900.6599884033203,
      "no_speech_prob": 0.0009546919609420002,
      "seek": 10936,
      "start": 895.7399826049805,
      "temperature": 0.0,
      "text": " And you can see here, this corresponds to the edits we saw exactly in the log,",
      "tokens": [
        50365,
        400,
        291,
        393,
        536,
        510,
        11,
        341,
        23249,
        281,
        264,
        41752,
        321,
        1866,
        2293,
        294,
        264,
        3565,
        11,
        50611
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.2541390657424927,
      "compression_ratio": 1.7692307233810425,
      "end": 904.6999816894531,
      "no_speech_prob": 0.0009546919609420002,
      "seek": 10936,
      "start": 900.6999816894531,
      "temperature": 0.0,
      "text": " the prompt chain, it allows us to keep track of the state, the original slice,",
      "tokens": [
        50613,
        264,
        12391,
        5021,
        11,
        309,
        4045,
        505,
        281,
        1066,
        2837,
        295,
        264,
        1785,
        11,
        264,
        3380,
        13153,
        11,
        50813
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.2541390657424927,
      "compression_ratio": 1.7692307233810425,
      "end": 909.1399841308594,
      "no_speech_prob": 0.0009546919609420002,
      "seek": 10936,
      "start": 904.7799835205078,
      "temperature": 0.0,
      "text": " the work that it's done and the work that it's doing that's iteration two.",
      "tokens": [
        50817,
        264,
        589,
        300,
        309,
        311,
        1096,
        293,
        264,
        589,
        300,
        309,
        311,
        884,
        300,
        311,
        24784,
        732,
        13,
        51035
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.2541390657424927,
      "compression_ratio": 1.7692307233810425,
      "end": 911.099983215332,
      "no_speech_prob": 0.0009546919609420002,
      "seek": 10936,
      "start": 909.1399841308594,
      "temperature": 0.0,
      "text": " And then of course we have the third iteration.",
      "tokens": [
        51035,
        400,
        550,
        295,
        1164,
        321,
        362,
        264,
        2636,
        24784,
        13,
        51133
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.2541390657424927,
      "compression_ratio": 1.7692307233810425,
      "end": 915.6999816894531,
      "no_speech_prob": 0.0009546919609420002,
      "seek": 10936,
      "start": 911.1799850463867,
      "temperature": 0.0,
      "text": " You can see here, same deal, except we have an additional current deletion, right?",
      "tokens": [
        51137,
        509,
        393,
        536,
        510,
        11,
        912,
        2028,
        11,
        3993,
        321,
        362,
        364,
        4497,
        2190,
        1103,
        302,
        313,
        11,
        558,
        30,
        51363
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.2541390657424927,
      "compression_ratio": 1.7692307233810425,
      "end": 916.9399871826172,
      "no_speech_prob": 0.0009546919609420002,
      "seek": 10936,
      "start": 915.6999816894531,
      "temperature": 0.0,
      "text": " So we have two deletions in here.",
      "tokens": [
        51363,
        407,
        321,
        362,
        732,
        1103,
        302,
        626,
        294,
        510,
        13,
        51425
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.2541390657424927,
      "compression_ratio": 1.7692307233810425,
      "end": 917.4999847412109,
      "no_speech_prob": 0.0009546919609420002,
      "seek": 10936,
      "start": 916.9399871826172,
      "temperature": 0.0,
      "text": " We can go ahead.",
      "tokens": [
        51425,
        492,
        393,
        352,
        2286,
        13,
        51453
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_007.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 920.0199828147888,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 917.4199829101562,
      "temperature": 0.0,
      "text": " and separate this just to make it a little bit more clear, right?",
      "tokens": [
        50364,
        293,
        4994,
        341,
        445,
        281,
        652,
        309,
        257,
        707,
        857,
        544,
        1850,
        11,
        558,
        30,
        50494
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 924.5199828147888,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 920.0199828147888,
      "temperature": 0.0,
      "text": " So you can see those two removed words right there, okay?",
      "tokens": [
        50494,
        407,
        291,
        393,
        536,
        729,
        732,
        7261,
        2283,
        558,
        456,
        11,
        1392,
        30,
        50719
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 926.3199825286865,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 924.5199828147888,
      "temperature": 0.0,
      "text": " So this is our prompt chain",
      "tokens": [
        50719,
        407,
        341,
        307,
        527,
        12391,
        5021,
        50809
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 930.519983291626,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 926.3199825286865,
      "temperature": 0.0,
      "text": " and we can go ahead and dial into this code for a moment here, prompt chain.",
      "tokens": [
        50809,
        293,
        321,
        393,
        352,
        2286,
        293,
        5502,
        666,
        341,
        3089,
        337,
        257,
        1623,
        510,
        11,
        12391,
        5021,
        13,
        51019
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 931.4199829101562,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 930.519983291626,
      "temperature": 0.0,
      "text": " We can see here.",
      "tokens": [
        51019,
        492,
        393,
        536,
        510,
        13,
        51064
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 933.9199829101562,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 931.4199829101562,
      "temperature": 0.0,
      "text": " We're just setting up logging, pulling out our model.",
      "tokens": [
        51064,
        492,
        434,
        445,
        3287,
        493,
        27991,
        11,
        8407,
        484,
        527,
        2316,
        13,
        51189
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 936.3199825286865,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 933.9199829101562,
      "temperature": 0.0,
      "text": " We're pulling out the problem slice, starting text,",
      "tokens": [
        51189,
        492,
        434,
        8407,
        484,
        264,
        1154,
        13153,
        11,
        2891,
        2487,
        11,
        51309
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 938.3199825286865,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 936.3199825286865,
      "temperature": 0.0,
      "text": " and then we're actually running the code here.",
      "tokens": [
        51309,
        293,
        550,
        321,
        434,
        767,
        2614,
        264,
        3089,
        510,
        13,
        51409
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 941.1199836730957,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 938.3199825286865,
      "temperature": 0.0,
      "text": " In the end, every one of these versions, right,",
      "tokens": [
        51409,
        682,
        264,
        917,
        11,
        633,
        472,
        295,
        613,
        9606,
        11,
        558,
        11,
        51549
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 943.9199829101562,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 941.1199836730957,
      "temperature": 0.0,
      "text": " every one of our prompt, our prompt chain, and our agent,",
      "tokens": [
        51549,
        633,
        472,
        295,
        527,
        12391,
        11,
        527,
        12391,
        5021,
        11,
        293,
        527,
        9461,
        11,
        51689
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.2871677875518799,
      "compression_ratio": 1.8591065406799316,
      "end": 945.9199829101562,
      "no_speech_prob": 0.004007132723927498,
      "seek": 0,
      "start": 943.9199829101562,
      "temperature": 0.0,
      "text": " it's just going to return deletions.",
      "tokens": [
        51689,
        309,
        311,
        445,
        516,
        281,
        2736,
        1103,
        302,
        626,
        13,
        51789
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 948.7199821472168,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 945.9199829101562,
      "temperature": 0.0,
      "text": " It's really important to set up your workflows",
      "tokens": [
        50364,
        467,
        311,
        534,
        1021,
        281,
        992,
        493,
        428,
        43461,
        50504
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 952.6199836730957,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 948.7199821472168,
      "temperature": 0.0,
      "text": " so that they're always returning consistent types, consistent formats.",
      "tokens": [
        50504,
        370,
        300,
        436,
        434,
        1009,
        12678,
        8398,
        3467,
        11,
        8398,
        25879,
        13,
        50699
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 956.0199813842773,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 952.6199836730957,
      "temperature": 0.0,
      "text": " This allows you to operate on them at scale and create versions of them.",
      "tokens": [
        50699,
        639,
        4045,
        291,
        281,
        9651,
        322,
        552,
        412,
        4373,
        293,
        1884,
        9606,
        295,
        552,
        13,
        50869
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 958.9199829101562,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 956.0199813842773,
      "temperature": 0.0,
      "text": " So all we're doing here is outputting deletions",
      "tokens": [
        50869,
        407,
        439,
        321,
        434,
        884,
        510,
        307,
        5598,
        783,
        1103,
        302,
        626,
        51014
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 960.6199836730957,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 958.9199829101562,
      "temperature": 0.0,
      "text": " and then some auxiliary information, right?",
      "tokens": [
        51014,
        293,
        550,
        512,
        43741,
        1589,
        11,
        558,
        30,
        51099
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 962.1199836730957,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 960.6199836730957,
      "temperature": 0.0,
      "text": " In this case, we just have a cost.",
      "tokens": [
        51099,
        682,
        341,
        1389,
        11,
        321,
        445,
        362,
        257,
        2063,
        13,
        51174
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 965.3199844360352,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 962.1199836730957,
      "temperature": 0.0,
      "text": " So let's go into generate a cut deletions v2.",
      "tokens": [
        51174,
        407,
        718,
        311,
        352,
        666,
        8460,
        257,
        1723,
        1103,
        302,
        626,
        371,
        17,
        13,
        51334
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 966.5199813842773,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 965.3199844360352,
      "temperature": 0.0,
      "text": " This is our prompt chain.",
      "tokens": [
        51334,
        639,
        307,
        527,
        12391,
        5021,
        13,
        51394
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 971.2199821472168,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 966.5199813842773,
      "temperature": 0.0,
      "text": " So v1 is just a prompt, v2 is a prompt chain.",
      "tokens": [
        51394,
        407,
        371,
        16,
        307,
        445,
        257,
        12391,
        11,
        371,
        17,
        307,
        257,
        12391,
        5021,
        13,
        51629
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.17063140869140625,
      "compression_ratio": 1.7266186475753784,
      "end": 973.0199813842773,
      "no_speech_prob": 9.761468390934169e-05,
      "seek": 2850,
      "start": 971.2199821472168,
      "temperature": 0.0,
      "text": " So let's take a look at what this looks like",
      "tokens": [
        51629,
        407,
        718,
        311,
        747,
        257,
        574,
        412,
        437,
        341,
        1542,
        411,
        51719
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 976.6199836730957,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 973.1199836730957,
      "temperature": 0.0,
      "text": " and you can imagine it is, you know, effectively going to be a loop",
      "tokens": [
        50369,
        293,
        291,
        393,
        3811,
        309,
        307,
        11,
        291,
        458,
        11,
        8659,
        516,
        281,
        312,
        257,
        6367,
        50544
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 978.8199844360352,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 976.6199836730957,
      "temperature": 0.0,
      "text": " and you can see here we're passing in max compute",
      "tokens": [
        50544,
        293,
        291,
        393,
        536,
        510,
        321,
        434,
        8437,
        294,
        11469,
        14722,
        50654
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 980.5199813842773,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 978.8199844360352,
      "temperature": 0.0,
      "text": " and we're updating this to I think eight,",
      "tokens": [
        50654,
        293,
        321,
        434,
        25113,
        341,
        281,
        286,
        519,
        3180,
        11,
        50739
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 981.8199844360352,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 980.5199813842773,
      "temperature": 0.0,
      "text": " but you can see here what's happening, right?",
      "tokens": [
        50739,
        457,
        291,
        393,
        536,
        510,
        437,
        311,
        2737,
        11,
        558,
        30,
        50804
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 984.8199844360352,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 981.8199844360352,
      "temperature": 0.0,
      "text": " We basically have the same thing and we're just looping this time, right?",
      "tokens": [
        50804,
        492,
        1936,
        362,
        264,
        912,
        551,
        293,
        321,
        434,
        445,
        6367,
        278,
        341,
        565,
        11,
        558,
        30,
        50954
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 986.1199798583984,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 984.8199844360352,
      "temperature": 0.0,
      "text": " We're keeping track of some more state.",
      "tokens": [
        50954,
        492,
        434,
        5145,
        2837,
        295,
        512,
        544,
        1785,
        13,
        51019
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 987.2199859619141,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 986.1199798583984,
      "temperature": 0.0,
      "text": " This is our iteration slice.",
      "tokens": [
        51019,
        639,
        307,
        527,
        24784,
        13153,
        13,
        51074
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 988.6199798583984,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 987.2199859619141,
      "temperature": 0.0,
      "text": " This is our original slice",
      "tokens": [
        51074,
        639,
        307,
        527,
        3380,
        13153,
        51144
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 992.0199813842773,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 988.6199798583984,
      "temperature": 0.0,
      "text": " and here's our, you know, list of deletions that we're keeping track of",
      "tokens": [
        51144,
        293,
        510,
        311,
        527,
        11,
        291,
        458,
        11,
        1329,
        295,
        1103,
        302,
        626,
        300,
        321,
        434,
        5145,
        2837,
        295,
        51314
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 994.0199813842773,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 992.0199813842773,
      "temperature": 0.0,
      "text": " and then of course, here's our loop, right?",
      "tokens": [
        51314,
        293,
        550,
        295,
        1164,
        11,
        510,
        311,
        527,
        6367,
        11,
        558,
        30,
        51414
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 997.0199813842773,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 994.0199813842773,
      "temperature": 0.0,
      "text": " So just as you saw before, there's our instruction-rich prompt,",
      "tokens": [
        51414,
        407,
        445,
        382,
        291,
        1866,
        949,
        11,
        456,
        311,
        527,
        10951,
        12,
        10794,
        12391,
        11,
        51564
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 1000.0199813842773,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 997.0199813842773,
      "temperature": 0.0,
      "text": " purpose, and then our dynamic variables",
      "tokens": [
        51564,
        4334,
        11,
        293,
        550,
        527,
        8546,
        9102,
        51714
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.19727951288223267,
      "compression_ratio": 1.9635258913040161,
      "end": 1002.1199798583984,
      "no_speech_prob": 0.005301700439304113,
      "seek": 5560,
      "start": 1000.0199813842773,
      "temperature": 0.0,
      "text": " that get updated inside of our application, right?",
      "tokens": [
        51714,
        300,
        483,
        10588,
        1854,
        295,
        527,
        3861,
        11,
        558,
        30,
        51819
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1005.9199829101562,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1002.2199859619141,
      "temperature": 0.0,
      "text": " If we collapse the prompt, you can see we're always outputting our prompt file.",
      "tokens": [
        50369,
        759,
        321,
        15584,
        264,
        12391,
        11,
        291,
        393,
        536,
        321,
        434,
        1009,
        5598,
        783,
        527,
        12391,
        3991,
        13,
        50554
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1008.4199829101562,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1005.9199829101562,
      "temperature": 0.0,
      "text": " We have our actual execution loop.",
      "tokens": [
        50554,
        492,
        362,
        527,
        3539,
        15058,
        6367,
        13,
        50679
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1010.3199844360352,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1008.4199829101562,
      "temperature": 0.0,
      "text": " This is the prompt chain.",
      "tokens": [
        50679,
        639,
        307,
        264,
        12391,
        5021,
        13,
        50774
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1014.4199829101562,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1010.3199844360352,
      "temperature": 0.0,
      "text": " Let's go ahead and run the most exciting version, right?",
      "tokens": [
        50774,
        961,
        311,
        352,
        2286,
        293,
        1190,
        264,
        881,
        4670,
        3037,
        11,
        558,
        30,
        50979
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1016.9199829101562,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1014.4199829101562,
      "temperature": 0.0,
      "text": " Let's run the AI agent.",
      "tokens": [
        50979,
        961,
        311,
        1190,
        264,
        7318,
        9461,
        13,
        51104
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1020.4199829101562,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1019.4199829101562,
      "temperature": 0.0,
      "text": " Let's kick this off.",
      "tokens": [
        51229,
        961,
        311,
        4437,
        341,
        766,
        13,
        51279
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1024.4199829101562,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1021.4199829101562,
      "temperature": 0.0,
      "text": " This agent has 16 compute loops.",
      "tokens": [
        51329,
        639,
        9461,
        575,
        3165,
        14722,
        16121,
        13,
        51479
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1026.9199829101562,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1024.4199829101562,
      "temperature": 0.0,
      "text": " So I'm giving it 16 compute uses",
      "tokens": [
        51479,
        407,
        286,
        478,
        2902,
        309,
        3165,
        14722,
        4960,
        51604
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1031.0199813842773,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1026.9199829101562,
      "temperature": 0.0,
      "text": " and unfortunately, GPT-40 got the problem wrong.",
      "tokens": [
        51604,
        293,
        7015,
        11,
        26039,
        51,
        12,
        5254,
        658,
        264,
        1154,
        2085,
        13,
        51809
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.565573811531067,
      "end": 1032.0199813842773,
      "no_speech_prob": 0.00042388090514577925,
      "seek": 8470,
      "start": 1031.0199813842773,
      "temperature": 0.0,
      "text": " So let's figure out why.",
      "tokens": [
        51809,
        407,
        718,
        311,
        2573,
        484,
        983,
        13,
        51859
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.25334426760673523,
      "compression_ratio": 1.4269663095474243,
      "end": 1034.6199798583984,
      "no_speech_prob": 0.0012065675109624863,
      "seek": 11460,
      "start": 1032.0199813842773,
      "temperature": 0.0,
      "text": " Why did it edit this problem incorrectly, okay?",
      "tokens": [
        50364,
        1545,
        630,
        309,
        8129,
        341,
        1154,
        42892,
        11,
        1392,
        30,
        50494
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.25334426760673523,
      "compression_ratio": 1.4269663095474243,
      "end": 1036.219985961914,
      "no_speech_prob": 0.0012065675109624863,
      "seek": 11460,
      "start": 1034.6199798583984,
      "temperature": 0.0,
      "text": " Let's look at V3.",
      "tokens": [
        50494,
        961,
        311,
        574,
        412,
        691,
        18,
        13,
        50574
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.25334426760673523,
      "compression_ratio": 1.4269663095474243,
      "end": 1039.0199813842773,
      "no_speech_prob": 0.0012065675109624863,
      "seek": 11460,
      "start": 1036.219985961914,
      "temperature": 0.0,
      "text": " You can see here it made four prompts in total",
      "tokens": [
        50574,
        509,
        393,
        536,
        510,
        309,
        1027,
        1451,
        41095,
        294,
        3217,
        50714
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.25334426760673523,
      "compression_ratio": 1.4269663095474243,
      "end": 1042.719985961914,
      "no_speech_prob": 0.0012065675109624863,
      "seek": 11460,
      "start": 1039.0199813842773,
      "temperature": 0.0,
      "text": " and if we hop into this file, we can see a lot of the same things.",
      "tokens": [
        50714,
        293,
        498,
        321,
        3818,
        666,
        341,
        3991,
        11,
        321,
        393,
        536,
        257,
        688,
        295,
        264,
        912,
        721,
        13,
        50899
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.25334426760673523,
      "compression_ratio": 1.4269663095474243,
      "end": 1048.3199768066406,
      "no_speech_prob": 0.0012065675109624863,
      "seek": 11460,
      "start": 1042.719985961914,
      "temperature": 0.0,
      "text": " The big difference here is that our AI agent now has access to a series of",
      "tokens": [
        50899,
        440,
        955,
        2649,
        510,
        307,
        300,
        527,
        7318,
        9461,
        586,
        575,
        2105,
        281,
        257,
        2638,
        295,
        51179
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_008.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1050.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1048.47998046875,
      "temperature": 0.0,
      "text": " It has name and args.",
      "tokens": [
        50364,
        467,
        575,
        1315,
        293,
        3882,
        82,
        13,
        50464
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1052.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1050.47998046875,
      "temperature": 0.0,
      "text": " It's running make deletions here,",
      "tokens": [
        50464,
        467,
        311,
        2614,
        652,
        1103,
        302,
        626,
        510,
        11,
        50564
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1054.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1052.47998046875,
      "temperature": 0.0,
      "text": " just cutting out this one word.",
      "tokens": [
        50564,
        445,
        6492,
        484,
        341,
        472,
        1349,
        13,
        50664
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1056.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1054.47998046875,
      "temperature": 0.0,
      "text": " It's running another tool call here,",
      "tokens": [
        50664,
        467,
        311,
        2614,
        1071,
        2290,
        818,
        510,
        11,
        50764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1058.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1056.47998046875,
      "temperature": 0.0,
      "text": " editing out a few additional words,",
      "tokens": [
        50764,
        10000,
        484,
        257,
        1326,
        4497,
        2283,
        11,
        50864
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1059.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1058.47998046875,
      "temperature": 0.0,
      "text": " so on and so forth, right?",
      "tokens": [
        50864,
        370,
        322,
        293,
        370,
        5220,
        11,
        558,
        30,
        50914
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1061.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1059.47998046875,
      "temperature": 0.0,
      "text": " You can see here it just continues to call make deletion.",
      "tokens": [
        50914,
        509,
        393,
        536,
        510,
        309,
        445,
        6515,
        281,
        818,
        652,
        1103,
        302,
        313,
        13,
        51014
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1063.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1061.47998046875,
      "temperature": 0.0,
      "text": " We run over and over and over and over,",
      "tokens": [
        51014,
        492,
        1190,
        670,
        293,
        670,
        293,
        670,
        293,
        670,
        11,
        51114
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1064.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1063.47998046875,
      "temperature": 0.0,
      "text": " and then once we get to the bottom,",
      "tokens": [
        51114,
        293,
        550,
        1564,
        321,
        483,
        281,
        264,
        2767,
        11,
        51164
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1066.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1064.47998046875,
      "temperature": 0.0,
      "text": " it now calls an explicit tool.",
      "tokens": [
        51164,
        309,
        586,
        5498,
        364,
        13691,
        2290,
        13,
        51264
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1068.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1066.47998046875,
      "temperature": 0.0,
      "text": " Instead of returning an empty list,",
      "tokens": [
        51264,
        7156,
        295,
        12678,
        364,
        6707,
        1329,
        11,
        51364
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1070.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1068.47998046875,
      "temperature": 0.0,
      "text": " it calls complete edit when it's done.",
      "tokens": [
        51364,
        309,
        5498,
        3566,
        8129,
        562,
        309,
        311,
        1096,
        13,
        51464
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1072.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1070.47998046875,
      "temperature": 0.0,
      "text": " So if we scroll all the way to the bottom,",
      "tokens": [
        51464,
        407,
        498,
        321,
        11369,
        439,
        264,
        636,
        281,
        264,
        2767,
        11,
        51564
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1074.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1072.47998046875,
      "temperature": 0.0,
      "text": " we'll get that exact same structure.",
      "tokens": [
        51564,
        321,
        603,
        483,
        300,
        1900,
        912,
        3877,
        13,
        51664
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 1076.47998046875,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 1074.47998046875,
      "temperature": 0.0,
      "text": " So you can see the scratch pack active memory pattern",
      "tokens": [
        51664,
        407,
        291,
        393,
        536,
        264,
        8459,
        2844,
        4967,
        4675,
        5102,
        51764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1078.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1076.47998046875,
      "temperature": 0.0,
      "text": " is going to be really important for rolling out",
      "tokens": [
        50364,
        307,
        516,
        281,
        312,
        534,
        1021,
        337,
        9439,
        484,
        50464
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1079.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1078.47998046875,
      "temperature": 0.0,
      "text": " useful personal AI assistance.",
      "tokens": [
        50464,
        4420,
        2973,
        7318,
        9683,
        13,
        50514
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1081.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1079.47998046875,
      "temperature": 0.0,
      "text": " It just took out scratch pad.",
      "tokens": [
        50514,
        467,
        445,
        1890,
        484,
        8459,
        6887,
        13,
        50614
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1082.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1081.47998046875,
      "temperature": 0.0,
      "text": " Didn't think scratch pad was important,",
      "tokens": [
        50614,
        11151,
        380,
        519,
        8459,
        6887,
        390,
        1021,
        11,
        50664
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1084.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1082.47998046875,
      "temperature": 0.0,
      "text": " so it edited that out, okay?",
      "tokens": [
        50664,
        370,
        309,
        23016,
        300,
        484,
        11,
        1392,
        30,
        50764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1086.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1084.47998046875,
      "temperature": 0.0,
      "text": " So this is something that will just happen sometimes.",
      "tokens": [
        50764,
        407,
        341,
        307,
        746,
        300,
        486,
        445,
        1051,
        2171,
        13,
        50864
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1088.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1086.47998046875,
      "temperature": 0.0,
      "text": " You know, you can see here between the prompt chain",
      "tokens": [
        50864,
        509,
        458,
        11,
        291,
        393,
        536,
        510,
        1296,
        264,
        12391,
        5021,
        50964
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1090.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1088.47998046875,
      "temperature": 0.0,
      "text": " and the AI assistant on this single use case,",
      "tokens": [
        50964,
        293,
        264,
        7318,
        10994,
        322,
        341,
        2167,
        764,
        1389,
        11,
        51064
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1092.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1090.47998046875,
      "temperature": 0.0,
      "text": " more compute isn't always better.",
      "tokens": [
        51064,
        544,
        14722,
        1943,
        380,
        1009,
        1101,
        13,
        51164
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1094.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1092.47998046875,
      "temperature": 0.0,
      "text": " And this is a really important thing to call out, okay?",
      "tokens": [
        51164,
        400,
        341,
        307,
        257,
        534,
        1021,
        551,
        281,
        818,
        484,
        11,
        1392,
        30,
        51264
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1097.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1094.47998046875,
      "temperature": 0.0,
      "text": " So this is our AI agent,",
      "tokens": [
        51264,
        407,
        341,
        307,
        527,
        7318,
        9461,
        11,
        51414
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1099.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1097.47998046875,
      "temperature": 0.0,
      "text": " and we can, of course, scale this up.",
      "tokens": [
        51414,
        293,
        321,
        393,
        11,
        295,
        1164,
        11,
        4373,
        341,
        493,
        13,
        51514
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1102.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1099.47998046875,
      "temperature": 0.0,
      "text": " Let's go ahead and let our O3 mini",
      "tokens": [
        51514,
        961,
        311,
        352,
        2286,
        293,
        718,
        527,
        422,
        18,
        8382,
        51664
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 1104.47998046875,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 1102.47998046875,
      "temperature": 0.0,
      "text": " run the AI agent version,",
      "tokens": [
        51664,
        1190,
        264,
        7318,
        9461,
        3037,
        11,
        51764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1106.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1104.47998046875,
      "temperature": 0.0,
      "text": " and let's go ahead and take a look at the AI agent code, okay?",
      "tokens": [
        50364,
        293,
        718,
        311,
        352,
        2286,
        293,
        747,
        257,
        574,
        412,
        264,
        7318,
        9461,
        3089,
        11,
        1392,
        30,
        50464
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1108.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1106.47998046875,
      "temperature": 0.0,
      "text": " So we'll go ahead, kick this off,",
      "tokens": [
        50464,
        407,
        321,
        603,
        352,
        2286,
        11,
        4437,
        341,
        766,
        11,
        50564
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1112.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1108.47998046875,
      "temperature": 0.0,
      "text": " and let's dive into what the AI agent version of this looks like.",
      "tokens": [
        50564,
        293,
        718,
        311,
        9192,
        666,
        437,
        264,
        7318,
        9461,
        3037,
        295,
        341,
        1542,
        411,
        13,
        50764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1115.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1112.47998046875,
      "temperature": 0.0,
      "text": " So same deal on the top level, just logging and setup.",
      "tokens": [
        50764,
        407,
        912,
        2028,
        322,
        264,
        1192,
        1496,
        11,
        445,
        27991,
        293,
        8657,
        13,
        50914
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1117.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1115.47998046875,
      "temperature": 0.0,
      "text": " And then this is where all the work happens, okay?",
      "tokens": [
        50914,
        400,
        550,
        341,
        307,
        689,
        439,
        264,
        589,
        2314,
        11,
        1392,
        30,
        51014
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1120.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1117.47998046875,
      "temperature": 0.0,
      "text": " So generate, cut, deletions, V3.",
      "tokens": [
        51014,
        407,
        8460,
        11,
        1723,
        11,
        1103,
        302,
        626,
        11,
        691,
        18,
        13,
        51164
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1122.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1120.47998046875,
      "temperature": 0.0,
      "text": " So we'll hop in here, and let's open this up.",
      "tokens": [
        51164,
        407,
        321,
        603,
        3818,
        294,
        510,
        11,
        293,
        718,
        311,
        1269,
        341,
        493,
        13,
        51264
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1124.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1122.47998046875,
      "temperature": 0.0,
      "text": " Couple things are different right away.",
      "tokens": [
        51264,
        38266,
        721,
        366,
        819,
        558,
        1314,
        13,
        51364
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1127.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1124.47998046875,
      "temperature": 0.0,
      "text": " We have an entire class to support our AI agent.",
      "tokens": [
        51364,
        492,
        362,
        364,
        2302,
        1508,
        281,
        1406,
        527,
        7318,
        9461,
        13,
        51514
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1128.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1127.47998046875,
      "temperature": 0.0,
      "text": " Why is that?",
      "tokens": [
        51514,
        1545,
        307,
        300,
        30,
        51564
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1131.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1128.47998046875,
      "temperature": 0.0,
      "text": " Because we need to better manage state and tool calls.",
      "tokens": [
        51564,
        1436,
        321,
        643,
        281,
        1101,
        3067,
        1785,
        293,
        2290,
        5498,
        13,
        51714
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 1133.47998046875,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 1131.47998046875,
      "temperature": 0.0,
      "text": " So just like the prompt chain, you can see there's our loop.",
      "tokens": [
        51714,
        407,
        445,
        411,
        264,
        12391,
        5021,
        11,
        291,
        393,
        536,
        456,
        311,
        527,
        6367,
        13,
        51814
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1135.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1133.47998046875,
      "temperature": 0.0,
      "text": " And we'll go into the class in just a moment here,",
      "tokens": [
        50364,
        400,
        321,
        603,
        352,
        666,
        264,
        1508,
        294,
        445,
        257,
        1623,
        510,
        11,
        50464
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1138.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1135.47998046875,
      "temperature": 0.0,
      "text": " but you can see we're setting up the agent as a new class.",
      "tokens": [
        50464,
        457,
        291,
        393,
        536,
        321,
        434,
        3287,
        493,
        264,
        9461,
        382,
        257,
        777,
        1508,
        13,
        50614
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1140.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1138.47998046875,
      "temperature": 0.0,
      "text": " We're passing in our starting state,",
      "tokens": [
        50614,
        492,
        434,
        8437,
        294,
        527,
        2891,
        1785,
        11,
        50714
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1143.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1140.47998046875,
      "temperature": 0.0,
      "text": " and then the agent just gets updated with this one call, right?",
      "tokens": [
        50714,
        293,
        550,
        264,
        9461,
        445,
        2170,
        10588,
        365,
        341,
        472,
        818,
        11,
        558,
        30,
        50864
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1145.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1143.47998046875,
      "temperature": 0.0,
      "text": " We just run prompt over and over,",
      "tokens": [
        50864,
        492,
        445,
        1190,
        12391,
        670,
        293,
        670,
        11,
        50964
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1147.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1145.47998046875,
      "temperature": 0.0,
      "text": " and then it just returns if it's done, right?",
      "tokens": [
        50964,
        293,
        550,
        309,
        445,
        11247,
        498,
        309,
        311,
        1096,
        11,
        558,
        30,
        51064
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1149.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1147.47998046875,
      "temperature": 0.0,
      "text": " Because our agents know what work to do.",
      "tokens": [
        51064,
        1436,
        527,
        12554,
        458,
        437,
        589,
        281,
        360,
        13,
        51164
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1151.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1149.47998046875,
      "temperature": 0.0,
      "text": " They know when to tell us when they're done.",
      "tokens": [
        51164,
        814,
        458,
        562,
        281,
        980,
        505,
        562,
        436,
        434,
        1096,
        13,
        51264
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1153.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1151.47998046875,
      "temperature": 0.0,
      "text": " It's just a matter of letting them loop,",
      "tokens": [
        51264,
        467,
        311,
        445,
        257,
        1871,
        295,
        8295,
        552,
        6367,
        11,
        51364
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1154.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1153.47998046875,
      "temperature": 0.0,
      "text": " letting them do the work,",
      "tokens": [
        51364,
        8295,
        552,
        360,
        264,
        589,
        11,
        51414
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1157.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1154.47998046875,
      "temperature": 0.0,
      "text": " and then they'll let us know when they're done, right?",
      "tokens": [
        51414,
        293,
        550,
        436,
        603,
        718,
        505,
        458,
        562,
        436,
        434,
        1096,
        11,
        558,
        30,
        51564
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1159.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1157.47998046875,
      "temperature": 0.0,
      "text": " This is kind of an interesting paradigm shift",
      "tokens": [
        51564,
        639,
        307,
        733,
        295,
        364,
        1880,
        24709,
        5513,
        51664
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 1162.47998046875,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 1159.47998046875,
      "temperature": 0.0,
      "text": " when we move into these longer-running assistants,",
      "tokens": [
        51664,
        562,
        321,
        1286,
        666,
        613,
        2854,
        12,
        45482,
        34949,
        11,
        51814
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 1163.47998046875,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 1162.47998046875,
      "temperature": 0.0,
      "text": " these longer-running jobs.",
      "tokens": [
        50364,
        613,
        2854,
        12,
        45482,
        4782,
        13,
        50414
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 1165.47998046875,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 1163.47998046875,
      "temperature": 0.0,
      "text": " You know, a while back we put out this video",
      "tokens": [
        50414,
        509,
        458,
        11,
        257,
        1339,
        646,
        321,
        829,
        484,
        341,
        960,
        50514
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 1167.47998046875,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 1165.47998046875,
      "temperature": 0.0,
      "text": " called the two-way prompting,",
      "tokens": [
        50514,
        1219,
        264,
        732,
        12,
        676,
        12391,
        278,
        11,
        50614
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 1169.47998046875,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 1167.47998046875,
      "temperature": 0.0,
      "text": " and that video really does set up the future",
      "tokens": [
        50614,
        293,
        300,
        960,
        534,
        775,
        992,
        493,
        264,
        2027,
        50714
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 58,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 1173.47998046875,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 1169.47998046875,
      "temperature": 0.0,
      "text": " of how we'll be operating with agentic technology.",
      "tokens": [
        50714,
        295,
        577,
        321,
        603,
        312,
        7447,
        365,
        9461,
        299,
        2899,
        13,
        50914
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 59,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 1175.47998046875,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 1173.47998046875,
      "temperature": 0.0,
      "text": " It might start out with us prompting them,",
      "tokens": [
        50914,
        467,
        1062,
        722,
        484,
        365,
        505,
        12391,
        278,
        552,
        11,
        51014
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 60,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 1177.47998046875,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 1175.47998046875,
      "temperature": 0.0,
      "text": " but then they will prompt us, right?",
      "tokens": [
        51014,
        457,
        550,
        436,
        486,
        12391,
        505,
        11,
        558,
        30,
        51114
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 61,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 1179.47998046875,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 1177.47998046875,
      "temperature": 0.0,
      "text": " And we just saw this with deep research.",
      "tokens": [
        51114,
        400,
        321,
        445,
        1866,
        341,
        365,
        2452,
        2132,
        13,
        51214
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.23291778564453125,
      "compression_ratio": 1.7759740352630615,
      "end": 1184.9799780845642,
      "no_speech_prob": 0.03308319300413132,
      "seek": 0,
      "start": 1179.5399780273438,
      "temperature": 0.0,
      "text": " it off it asks you questions right and I think we're going to see more of that as these tools",
      "tokens": [
        50364,
        309,
        766,
        309,
        8962,
        291,
        1651,
        558,
        293,
        286,
        519,
        321,
        434,
        516,
        281,
        536,
        544,
        295,
        300,
        382,
        613,
        3873,
        50636
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.23291778564453125,
      "compression_ratio": 1.7759740352630615,
      "end": 1190.2999782562256,
      "no_speech_prob": 0.03308319300413132,
      "seek": 0,
      "start": 1184.9799780845642,
      "temperature": 0.0,
      "text": " progress but I digress let's jump into agent prompt and let me break down this class structure",
      "tokens": [
        50636,
        4205,
        457,
        286,
        2528,
        735,
        718,
        311,
        3012,
        666,
        9461,
        12391,
        293,
        718,
        385,
        1821,
        760,
        341,
        1508,
        3877,
        50902
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.23291778564453125,
      "compression_ratio": 1.7759740352630615,
      "end": 1194.2199783325195,
      "no_speech_prob": 0.03308319300413132,
      "seek": 0,
      "start": 1190.2999782562256,
      "temperature": 0.0,
      "text": " so I'll just collapse and we can look at it at a high level so this is the AI agent version",
      "tokens": [
        50902,
        370,
        286,
        603,
        445,
        15584,
        293,
        321,
        393,
        574,
        412,
        309,
        412,
        257,
        1090,
        1496,
        370,
        341,
        307,
        264,
        7318,
        9461,
        3037,
        51098
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.23291778564453125,
      "compression_ratio": 1.7759740352630615,
      "end": 1198.0599784851074,
      "no_speech_prob": 0.03308319300413132,
      "seek": 0,
      "start": 1194.2199783325195,
      "temperature": 0.0,
      "text": " you can see here we have state that we're keeping track of tool calls messages so on",
      "tokens": [
        51098,
        291,
        393,
        536,
        510,
        321,
        362,
        1785,
        300,
        321,
        434,
        5145,
        2837,
        295,
        2290,
        5498,
        7897,
        370,
        322,
        51290
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.23291778564453125,
      "compression_ratio": 1.7759740352630615,
      "end": 1203.4799785614014,
      "no_speech_prob": 0.03308319300413132,
      "seek": 0,
      "start": 1198.0599784851074,
      "temperature": 0.0,
      "text": " so forth we have our individual methods the most important thing is here inside the prompt",
      "tokens": [
        51290,
        370,
        5220,
        321,
        362,
        527,
        2609,
        7150,
        264,
        881,
        1021,
        551,
        307,
        510,
        1854,
        264,
        12391,
        51561
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.23291778564453125,
      "compression_ratio": 1.7759740352630615,
      "end": 1208.0999774932861,
      "no_speech_prob": 0.03308319300413132,
      "seek": 0,
      "start": 1203.4799785614014,
      "temperature": 0.0,
      "text": " you can see here more instructions I'm listing out the explicit tools it has access to you",
      "tokens": [
        51561,
        291,
        393,
        536,
        510,
        544,
        9415,
        286,
        478,
        22161,
        484,
        264,
        13691,
        3873,
        309,
        575,
        2105,
        281,
        291,
        51792
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2523331046104431,
      "compression_ratio": 1.720149278640747,
      "end": 1213.0399780273438,
      "no_speech_prob": 0.007576823700219393,
      "seek": 2856,
      "start": 1208.0999774932861,
      "temperature": 0.0,
      "text": " can see we just have three tools interestingly you know it doesn't take many tools to make",
      "tokens": [
        50364,
        393,
        536,
        321,
        445,
        362,
        1045,
        3873,
        25873,
        291,
        458,
        309,
        1177,
        380,
        747,
        867,
        3873,
        281,
        652,
        50611
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2523331046104431,
      "compression_ratio": 1.720149278640747,
      "end": 1219.8399772644043,
      "no_speech_prob": 0.007576823700219393,
      "seek": 2856,
      "start": 1213.0399780273438,
      "temperature": 0.0,
      "text": " your system an AI agent and then we have the state and this is really where the state becomes",
      "tokens": [
        50611,
        428,
        1185,
        364,
        7318,
        9461,
        293,
        550,
        321,
        362,
        264,
        1785,
        293,
        341,
        307,
        534,
        689,
        264,
        1785,
        3643,
        50951
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2523331046104431,
      "compression_ratio": 1.720149278640747,
      "end": 1224.9799766540527,
      "no_speech_prob": 0.007576823700219393,
      "seek": 2856,
      "start": 1219.8399772644043,
      "temperature": 0.0,
      "text": " the environment okay if we open up anthropics building effective agents we're now in this",
      "tokens": [
        50951,
        264,
        2823,
        1392,
        498,
        321,
        1269,
        493,
        25820,
        1513,
        1167,
        2390,
        4942,
        12554,
        321,
        434,
        586,
        294,
        341,
        51208
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.2523331046104431,
      "compression_ratio": 1.720149278640747,
      "end": 1230.6199798583984,
      "no_speech_prob": 0.007576823700219393,
      "seek": 2856,
      "start": 1224.9799766540527,
      "temperature": 0.0,
      "text": " state down here right so these are all different types of agentic workflows we have orchestrators",
      "tokens": [
        51208,
        1785,
        760,
        510,
        558,
        370,
        613,
        366,
        439,
        819,
        3467,
        295,
        9461,
        299,
        43461,
        321,
        362,
        14161,
        34886,
        51490
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.2523331046104431,
      "compression_ratio": 1.720149278640747,
      "end": 1234.299976348877,
      "no_speech_prob": 0.007576823700219393,
      "seek": 2856,
      "start": 1230.6199798583984,
      "temperature": 0.0,
      "text": " parallelization we've talked about these on the channel before we'll bring them up again",
      "tokens": [
        51490,
        8952,
        2144,
        321,
        600,
        2825,
        466,
        613,
        322,
        264,
        2269,
        949,
        321,
        603,
        1565,
        552,
        493,
        797,
        51674
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.20564515888690948,
      "compression_ratio": 1.8958333730697632,
      "end": 1239.7799797058105,
      "no_speech_prob": 0.30068469047546387,
      "seek": 5476,
      "start": 1234.299976348877,
      "temperature": 0.0,
      "text": " when they're relevant but we jumped all the way down here to agents okay and this is what's",
      "tokens": [
        50364,
        562,
        436,
        434,
        7340,
        457,
        321,
        13864,
        439,
        264,
        636,
        760,
        510,
        281,
        12554,
        1392,
        293,
        341,
        307,
        437,
        311,
        50638
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.20564515888690948,
      "compression_ratio": 1.8958333730697632,
      "end": 1245.1999816894531,
      "no_speech_prob": 0.30068469047546387,
      "seek": 5476,
      "start": 1239.7799797058105,
      "temperature": 0.0,
      "text": " happening right we are prompting our AI agent it's going to run action and get feedback",
      "tokens": [
        50638,
        2737,
        558,
        321,
        366,
        12391,
        278,
        527,
        7318,
        9461,
        309,
        311,
        516,
        281,
        1190,
        3069,
        293,
        483,
        5824,
        50909
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.20564515888690948,
      "compression_ratio": 1.8958333730697632,
      "end": 1249.579978942871,
      "no_speech_prob": 0.30068469047546387,
      "seek": 5476,
      "start": 1245.1999816894531,
      "temperature": 0.0,
      "text": " and the feedback that it's getting from its environment here is the edits that it's making",
      "tokens": [
        50909,
        293,
        264,
        5824,
        300,
        309,
        311,
        1242,
        490,
        1080,
        2823,
        510,
        307,
        264,
        41752,
        300,
        309,
        311,
        1455,
        51128
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.20564515888690948,
      "compression_ratio": 1.8958333730697632,
      "end": 1254.8199768066406,
      "no_speech_prob": 0.30068469047546387,
      "seek": 5476,
      "start": 1249.579978942871,
      "temperature": 0.0,
      "text": " right it's the edits and then the modifications to the original slice to the iteration slice",
      "tokens": [
        51128,
        558,
        309,
        311,
        264,
        41752,
        293,
        550,
        264,
        26881,
        281,
        264,
        3380,
        13153,
        281,
        264,
        24784,
        13153,
        51390
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.20564515888690948,
      "compression_ratio": 1.8958333730697632,
      "end": 1259.1799774169922,
      "no_speech_prob": 0.30068469047546387,
      "seek": 5476,
      "start": 1254.8199768066406,
      "temperature": 0.0,
      "text": " okay so it's not far off at all from the prompt chain right that's something important to",
      "tokens": [
        51390,
        1392,
        370,
        309,
        311,
        406,
        1400,
        766,
        412,
        439,
        490,
        264,
        12391,
        5021,
        558,
        300,
        311,
        746,
        1021,
        281,
        51608
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.20564515888690948,
      "compression_ratio": 1.8958333730697632,
      "end": 1264.2199783325195,
      "no_speech_prob": 0.30068469047546387,
      "seek": 5476,
      "start": 1259.1799774169922,
      "temperature": 0.0,
      "text": " mention but this is a different design right we're not just looping over a structured output",
      "tokens": [
        51608,
        2152,
        457,
        341,
        307,
        257,
        819,
        1715,
        558,
        321,
        434,
        406,
        445,
        6367,
        278,
        670,
        257,
        18519,
        5598,
        51860
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.2223467081785202,
      "compression_ratio": 1.8047945499420166,
      "end": 1268.459976196289,
      "no_speech_prob": 0.006289540324360132,
      "seek": 8468,
      "start": 1264.2199783325195,
      "temperature": 0.0,
      "text": " call we're now saying hey here's a bunch of instructions here's your purpose here's",
      "tokens": [
        50364,
        818,
        321,
        434,
        586,
        1566,
        4177,
        510,
        311,
        257,
        3840,
        295,
        9415,
        510,
        311,
        428,
        4334,
        510,
        311,
        50576
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.2223467081785202,
      "compression_ratio": 1.8047945499420166,
      "end": 1272.5399780273438,
      "no_speech_prob": 0.006289540324360132,
      "seek": 8468,
      "start": 1268.459976196289,
      "temperature": 0.0,
      "text": " your tools here's your current environment solve the problem so it's quite a bit different",
      "tokens": [
        50576,
        428,
        3873,
        510,
        311,
        428,
        2190,
        2823,
        5039,
        264,
        1154,
        370,
        309,
        311,
        1596,
        257,
        857,
        819,
        50780
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.2223467081785202,
      "compression_ratio": 1.8047945499420166,
      "end": 1276.2599792480469,
      "no_speech_prob": 0.006289540324360132,
      "seek": 8468,
      "start": 1272.5399780273438,
      "temperature": 0.0,
      "text": " even though the outcome here as you'll see is going to be relatively similar so now we",
      "tokens": [
        50780,
        754,
        1673,
        264,
        9700,
        510,
        382,
        291,
        603,
        536,
        307,
        516,
        281,
        312,
        7226,
        2531,
        370,
        586,
        321,
        50966
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2223467081785202,
      "compression_ratio": 1.8047945499420166,
      "end": 1280.8999786376953,
      "no_speech_prob": 0.006289540324360132,
      "seek": 8468,
      "start": 1276.2599792480469,
      "temperature": 0.0,
      "text": " have our AI agent and the action it takes updates its environment and then once again",
      "tokens": [
        50966,
        362,
        527,
        7318,
        9461,
        293,
        264,
        3069,
        309,
        2516,
        9205,
        1080,
        2823,
        293,
        550,
        1564,
        797,
        51198
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2223467081785202,
      "compression_ratio": 1.8047945499420166,
      "end": 1286.4399795532227,
      "no_speech_prob": 0.006289540324360132,
      "seek": 8468,
      "start": 1280.8999786376953,
      "temperature": 0.0,
      "text": " it tells us when it's done right it has access to this complete edit tool call and it also",
      "tokens": [
        51198,
        309,
        5112,
        505,
        562,
        309,
        311,
        1096,
        558,
        309,
        575,
        2105,
        281,
        341,
        3566,
        8129,
        2290,
        818,
        293,
        309,
        611,
        51475
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2223467081785202,
      "compression_ratio": 1.8047945499420166,
      "end": 1291.6999816894531,
      "no_speech_prob": 0.006289540324360132,
      "seek": 8468,
      "start": 1286.4399795532227,
      "temperature": 0.0,
      "text": " has a reset to original so if it decides that it's gotten itself into a bad state it can",
      "tokens": [
        51475,
        575,
        257,
        14322,
        281,
        3380,
        370,
        498,
        309,
        14898,
        300,
        309,
        311,
        5768,
        2564,
        666,
        257,
        1578,
        1785,
        309,
        393,
        51738
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.22334007918834686,
      "compression_ratio": 1.7055555582046509,
      "end": 1298.2599792480469,
      "no_speech_prob": 0.14025922119617462,
      "seek": 11216,
      "start": 1291.6999816894531,
      "temperature": 0.0,
      "text": " just reset okay and I personally don't care what tools it calls or what order it calls",
      "tokens": [
        50364,
        445,
        14322,
        1392,
        293,
        286,
        5665,
        500,
        380,
        1127,
        437,
        3873,
        309,
        5498,
        420,
        437,
        1668,
        309,
        5498,
        50692
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.22334007918834686,
      "compression_ratio": 1.7055555582046509,
      "end": 1302.459976196289,
      "no_speech_prob": 0.14025922119617462,
      "seek": 11216,
      "start": 1298.2599792480469,
      "temperature": 0.0,
      "text": " them I just want a good edit right I have an outcome that I'm looking for and then I'm",
      "tokens": [
        50692,
        552,
        286,
        445,
        528,
        257,
        665,
        8129,
        558,
        286,
        362,
        364,
        9700,
        300,
        286,
        478,
        1237,
        337,
        293,
        550,
        286,
        478,
        50902
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.22334007918834686,
      "compression_ratio": 1.7055555582046509,
      "end": 1307.9399719238281,
      "no_speech_prob": 0.14025922119617462,
      "seek": 11216,
      "start": 1302.459976196289,
      "temperature": 0.0,
      "text": " packaging via this prompt context and model I'm packaging the work that I want done the",
      "tokens": [
        50902,
        16836,
        5766,
        341,
        12391,
        4319,
        293,
        2316,
        286,
        478,
        16836,
        264,
        589,
        300,
        286,
        528,
        1096,
        264,
        51176
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.22334007918834686,
      "compression_ratio": 1.7055555582046509,
      "end": 1310.5399780273438,
      "no_speech_prob": 0.14025922119617462,
      "seek": 11216,
      "start": 1307.9399719238281,
      "temperature": 0.0,
      "text": " right way and then I'm handing it off to this",
      "tokens": [
        51176,
        558,
        636,
        293,
        550,
        286,
        478,
        34774,
        309,
        766,
        281,
        341,
        51306
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_010.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1312.039975643158,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1310.5999755859375,
      "temperature": 0.0,
      "text": " this AI agent, okay?",
      "tokens": [
        50364,
        341,
        7318,
        9461,
        11,
        1392,
        30,
        50436
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1313.3399755954742,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1312.039975643158,
      "temperature": 0.0,
      "text": " So that's what this looks like.",
      "tokens": [
        50436,
        407,
        300,
        311,
        437,
        341,
        1542,
        411,
        13,
        50501
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1316.4199757575989,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1313.3399755954742,
      "temperature": 0.0,
      "text": " We then have a, you know, classic OpenAI call here.",
      "tokens": [
        50501,
        492,
        550,
        362,
        257,
        11,
        291,
        458,
        11,
        7230,
        7238,
        48698,
        818,
        510,
        13,
        50655
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1318.6799755096436,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1316.4199757575989,
      "temperature": 0.0,
      "text": " We have reasoning effort if we wanna go high.",
      "tokens": [
        50655,
        492,
        362,
        21577,
        4630,
        498,
        321,
        1948,
        352,
        1090,
        13,
        50768
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1320.4399757385254,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1318.6799755096436,
      "temperature": 0.0,
      "text": " And then, you know, just classic stuff here, right?",
      "tokens": [
        50768,
        400,
        550,
        11,
        291,
        458,
        11,
        445,
        7230,
        1507,
        510,
        11,
        558,
        30,
        50856
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1321.9599752426147,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1320.4399757385254,
      "temperature": 0.0,
      "text": " We're handling the tokens",
      "tokens": [
        50856,
        492,
        434,
        13175,
        264,
        22667,
        50932
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1323.5199756622314,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1321.9599752426147,
      "temperature": 0.0,
      "text": " and making sure that we call the right tool.",
      "tokens": [
        50932,
        293,
        1455,
        988,
        300,
        321,
        818,
        264,
        558,
        2290,
        13,
        51010
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1325.9599752426147,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1323.5199756622314,
      "temperature": 0.0,
      "text": " And so this is the AI agent version.",
      "tokens": [
        51010,
        400,
        370,
        341,
        307,
        264,
        7318,
        9461,
        3037,
        13,
        51132
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1328.4399757385254,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1325.9599752426147,
      "temperature": 0.0,
      "text": " So let's go ahead and take a look at the output, right?",
      "tokens": [
        51132,
        407,
        718,
        311,
        352,
        2286,
        293,
        747,
        257,
        574,
        412,
        264,
        5598,
        11,
        558,
        30,
        51256
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1330.479974746704,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1328.4399757385254,
      "temperature": 0.0,
      "text": " We just ran that with O3 mini.",
      "tokens": [
        51256,
        492,
        445,
        5872,
        300,
        365,
        422,
        18,
        8382,
        13,
        51358
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1331.5199756622314,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1330.479974746704,
      "temperature": 0.0,
      "text": " Let's see how it performed.",
      "tokens": [
        51358,
        961,
        311,
        536,
        577,
        309,
        10332,
        13,
        51410
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1333.3399753570557,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1331.5199756622314,
      "temperature": 0.0,
      "text": " So you can see it got the answer correct.",
      "tokens": [
        51410,
        407,
        291,
        393,
        536,
        309,
        658,
        264,
        1867,
        3006,
        13,
        51501
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1335.399974822998,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1333.3399753570557,
      "temperature": 0.0,
      "text": " Let's see what it did, okay?",
      "tokens": [
        51501,
        961,
        311,
        536,
        437,
        309,
        630,
        11,
        1392,
        30,
        51604
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.21769393980503082,
      "compression_ratio": 1.7796052694320679,
      "end": 1339.3399753570557,
      "no_speech_prob": 0.07475928962230682,
      "seek": 0,
      "start": 1335.399974822998,
      "temperature": 0.0,
      "text": " So I'll close this, O3 mini logging session.",
      "tokens": [
        51604,
        407,
        286,
        603,
        1998,
        341,
        11,
        422,
        18,
        8382,
        27991,
        5481,
        13,
        51801
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1341.1799755096436,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1339.3399753570557,
      "temperature": 0.0,
      "text": " Top to bottom, make deletion.",
      "tokens": [
        50364,
        8840,
        281,
        2767,
        11,
        652,
        1103,
        302,
        313,
        13,
        50456
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1342.6199760437012,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1341.1799755096436,
      "temperature": 0.0,
      "text": " It's going to remove a.",
      "tokens": [
        50456,
        467,
        311,
        516,
        281,
        4159,
        257,
        13,
        50528
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1343.8199768066406,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1342.6199760437012,
      "temperature": 0.0,
      "text": " There's the before and after.",
      "tokens": [
        50528,
        821,
        311,
        264,
        949,
        293,
        934,
        13,
        50588
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1346.739974975586,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1343.8199768066406,
      "temperature": 0.0,
      "text": " So you can see it just pulled out that single a",
      "tokens": [
        50588,
        407,
        291,
        393,
        536,
        309,
        445,
        7373,
        484,
        300,
        2167,
        257,
        50734
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1347.6999740600586,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1346.739974975586,
      "temperature": 0.0,
      "text": " from the beginning, right?",
      "tokens": [
        50734,
        490,
        264,
        2863,
        11,
        558,
        30,
        50782
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1349.239974975586,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1347.6999740600586,
      "temperature": 0.0,
      "text": " We have one deletion.",
      "tokens": [
        50782,
        492,
        362,
        472,
        1103,
        302,
        313,
        13,
        50859
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1351.0599746704102,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1349.239974975586,
      "temperature": 0.0,
      "text": " And then if we scroll down here,",
      "tokens": [
        50859,
        400,
        550,
        498,
        321,
        11369,
        760,
        510,
        11,
        50950
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1353.299976348877,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1351.0599746704102,
      "temperature": 0.0,
      "text": " so you can see these are all creating their own prompts.",
      "tokens": [
        50950,
        370,
        291,
        393,
        536,
        613,
        366,
        439,
        4084,
        641,
        1065,
        41095,
        13,
        51062
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1355.899974822998,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1353.299976348877,
      "temperature": 0.0,
      "text": " And then we have a nicer, larger edit.",
      "tokens": [
        51062,
        400,
        550,
        321,
        362,
        257,
        22842,
        11,
        4833,
        8129,
        13,
        51192
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1358.1999740600586,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1355.899974822998,
      "temperature": 0.0,
      "text": " I did change it so that it is making a single edit,",
      "tokens": [
        51192,
        286,
        630,
        1319,
        309,
        370,
        300,
        309,
        307,
        1455,
        257,
        2167,
        8129,
        11,
        51307
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1361.3399772644043,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1358.1999740600586,
      "temperature": 0.0,
      "text": " but you can still remove, you know, chunks of words, right?",
      "tokens": [
        51307,
        457,
        291,
        393,
        920,
        4159,
        11,
        291,
        458,
        11,
        24004,
        295,
        2283,
        11,
        558,
        30,
        51464
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1362.5799751281738,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1361.3399772644043,
      "temperature": 0.0,
      "text": " Chunks of words at a time, right?",
      "tokens": [
        51464,
        761,
        17627,
        295,
        2283,
        412,
        257,
        565,
        11,
        558,
        30,
        51526
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1363.9799766540527,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1362.5799751281738,
      "temperature": 0.0,
      "text": " You wanna be able to remove phrases.",
      "tokens": [
        51526,
        509,
        1948,
        312,
        1075,
        281,
        4159,
        20312,
        13,
        51596
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.18802152574062347,
      "compression_ratio": 1.769736886024475,
      "end": 1366.5799751281738,
      "no_speech_prob": 0.1943558156490326,
      "seek": 2874,
      "start": 1363.9799766540527,
      "temperature": 0.0,
      "text": " Just like as if I were actually editing this.",
      "tokens": [
        51596,
        1449,
        411,
        382,
        498,
        286,
        645,
        767,
        10000,
        341,
        13,
        51726
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1369.8199768066406,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1366.5799751281738,
      "temperature": 0.0,
      "text": " It's important to make the agent or the prompt chain",
      "tokens": [
        50364,
        467,
        311,
        1021,
        281,
        652,
        264,
        9461,
        420,
        264,
        12391,
        5021,
        50526
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1373.1799774169922,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1369.8199768066406,
      "temperature": 0.0,
      "text": " or your AI tooling mirror the process you would take.",
      "tokens": [
        50526,
        420,
        428,
        7318,
        46593,
        8013,
        264,
        1399,
        291,
        576,
        747,
        13,
        50694
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1377.2999725341797,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1373.1799774169922,
      "temperature": 0.0,
      "text": " It's always removing one idea of an edit at a time, right?",
      "tokens": [
        50694,
        467,
        311,
        1009,
        12720,
        472,
        1558,
        295,
        364,
        8129,
        412,
        257,
        565,
        11,
        558,
        30,
        50900
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1379.0199737548828,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1377.2999725341797,
      "temperature": 0.0,
      "text": " One piece of an edit at a time.",
      "tokens": [
        50900,
        1485,
        2522,
        295,
        364,
        8129,
        412,
        257,
        565,
        13,
        50986
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1380.6599731445312,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1379.0199737548828,
      "temperature": 0.0,
      "text": " So you can see it removed a,",
      "tokens": [
        50986,
        407,
        291,
        393,
        536,
        309,
        7261,
        257,
        11,
        51068
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1383.0999755859375,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1380.6599731445312,
      "temperature": 0.0,
      "text": " and then removed this, the scratch pad.",
      "tokens": [
        51068,
        293,
        550,
        7261,
        341,
        11,
        264,
        8459,
        6887,
        13,
        51190
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1385.0999755859375,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1383.0999755859375,
      "temperature": 0.0,
      "text": " We can see here, this, the scratch pad,",
      "tokens": [
        51190,
        492,
        393,
        536,
        510,
        11,
        341,
        11,
        264,
        8459,
        6887,
        11,
        51290
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1387.7999725341797,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1385.0999755859375,
      "temperature": 0.0,
      "text": " act, and then we have this, right?",
      "tokens": [
        51290,
        605,
        11,
        293,
        550,
        321,
        362,
        341,
        11,
        558,
        30,
        51425
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1389.0599746704102,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1387.7999725341797,
      "temperature": 0.0,
      "text": " The scratch pad, act, and memory pattern",
      "tokens": [
        51425,
        440,
        8459,
        6887,
        11,
        605,
        11,
        293,
        4675,
        5102,
        51488
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1390.2199783325195,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1389.0599746704102,
      "temperature": 0.0,
      "text": " is going to be really important.",
      "tokens": [
        51488,
        307,
        516,
        281,
        312,
        534,
        1021,
        13,
        51546
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1392.2199783325195,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1390.2199783325195,
      "temperature": 0.0,
      "text": " And then you can see, look at this.",
      "tokens": [
        51546,
        400,
        550,
        291,
        393,
        536,
        11,
        574,
        412,
        341,
        13,
        51646
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.22940762341022491,
      "compression_ratio": 1.9125474691390991,
      "end": 1395.0599746704102,
      "no_speech_prob": 0.0003353485371917486,
      "seek": 5598,
      "start": 1392.2199783325195,
      "temperature": 0.0,
      "text": " Once it got to this state, it said, perfect, right?",
      "tokens": [
        51646,
        3443,
        309,
        658,
        281,
        341,
        1785,
        11,
        309,
        848,
        11,
        2176,
        11,
        558,
        30,
        51788
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1397.2199783325195,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1395.0599746704102,
      "temperature": 0.0,
      "text": " The tool decided it was done.",
      "tokens": [
        50364,
        440,
        2290,
        3047,
        309,
        390,
        1096,
        13,
        50472
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1399.5399780273438,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1397.2199783325195,
      "temperature": 0.0,
      "text": " And this is really, really cool, right?",
      "tokens": [
        50472,
        400,
        341,
        307,
        534,
        11,
        534,
        1627,
        11,
        558,
        30,
        50588
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1401.4399719238281,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1399.5399780273438,
      "temperature": 0.0,
      "text": " It's not that different than the prompt chain, right?",
      "tokens": [
        50588,
        467,
        311,
        406,
        300,
        819,
        813,
        264,
        12391,
        5021,
        11,
        558,
        30,
        50683
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1404.2999725341797,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1401.4399719238281,
      "temperature": 0.0,
      "text": " But it explicitly here called a different tool.",
      "tokens": [
        50683,
        583,
        309,
        20803,
        510,
        1219,
        257,
        819,
        2290,
        13,
        50826
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1405.839973449707,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1404.2999725341797,
      "temperature": 0.0,
      "text": " There are all the deletions.",
      "tokens": [
        50826,
        821,
        366,
        439,
        264,
        1103,
        302,
        626,
        13,
        50903
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1407.619972229004,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1405.839973449707,
      "temperature": 0.0,
      "text": " There's the final transcript slice.",
      "tokens": [
        50903,
        821,
        311,
        264,
        2572,
        24444,
        13153,
        13,
        50992
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1409.0599746704102,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1407.619972229004,
      "temperature": 0.0,
      "text": " And if we scroll to the bottom,",
      "tokens": [
        50992,
        400,
        498,
        321,
        11369,
        281,
        264,
        2767,
        11,
        51064
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1412.2599792480469,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1409.0599746704102,
      "temperature": 0.0,
      "text": " we have the original, the final, and the target, okay?",
      "tokens": [
        51064,
        321,
        362,
        264,
        3380,
        11,
        264,
        2572,
        11,
        293,
        264,
        3779,
        11,
        1392,
        30,
        51224
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1413.1799774169922,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1412.2599792480469,
      "temperature": 0.0,
      "text": " So this is correct.",
      "tokens": [
        51224,
        407,
        341,
        307,
        3006,
        13,
        51270
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1414.0199737548828,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1413.1799774169922,
      "temperature": 0.0,
      "text": " Fantastic.",
      "tokens": [
        51270,
        21320,
        13,
        51312
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1417.4399719238281,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1414.0199737548828,
      "temperature": 0.0,
      "text": " So now let's go ahead and look at the benchmark.",
      "tokens": [
        51312,
        407,
        586,
        718,
        311,
        352,
        2286,
        293,
        574,
        412,
        264,
        18927,
        13,
        51483
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1421.5399780273438,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1419.9399719238281,
      "temperature": 0.0,
      "text": " Instead of just a single problem",
      "tokens": [
        51608,
        7156,
        295,
        445,
        257,
        2167,
        1154,
        51688
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.19399572908878326,
      "compression_ratio": 1.6829267740249634,
      "end": 1423.5199737548828,
      "no_speech_prob": 0.0005884025013074279,
      "seek": 8446,
      "start": 1421.5399780273438,
      "temperature": 0.0,
      "text": " running against one model at a time, you know,",
      "tokens": [
        51688,
        2614,
        1970,
        472,
        2316,
        412,
        257,
        565,
        11,
        291,
        458,
        11,
        51787
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.23130349814891815,
      "compression_ratio": 1.539170503616333,
      "end": 1425.6799774169922,
      "no_speech_prob": 0.0031235332135111094,
      "seek": 11292,
      "start": 1423.5199737548828,
      "temperature": 0.20000000298023224,
      "text": " just like in our previous benchmarking video,",
      "tokens": [
        50364,
        445,
        411,
        294,
        527,
        3894,
        18927,
        278,
        960,
        11,
        50472
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.23130349814891815,
      "compression_ratio": 1.539170503616333,
      "end": 1428.239974975586,
      "no_speech_prob": 0.0031235332135111094,
      "seek": 11292,
      "start": 1425.6799774169922,
      "temperature": 0.20000000298023224,
      "text": " in order to understand and solve problems",
      "tokens": [
        50472,
        294,
        1668,
        281,
        1223,
        293,
        5039,
        2740,
        50600
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.23130349814891815,
      "compression_ratio": 1.539170503616333,
      "end": 1431.8999786376953,
      "no_speech_prob": 0.0031235332135111094,
      "seek": 11292,
      "start": 1428.239974975586,
      "temperature": 0.20000000298023224,
      "text": " with generative AI at scale, you need to create tests.",
      "tokens": [
        50600,
        365,
        1337,
        1166,
        7318,
        412,
        4373,
        11,
        291,
        643,
        281,
        1884,
        6921,
        13,
        50783
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.23130349814891815,
      "compression_ratio": 1.539170503616333,
      "end": 1436.079978942871,
      "no_speech_prob": 0.0031235332135111094,
      "seek": 11292,
      "start": 1431.8999786376953,
      "temperature": 0.20000000298023224,
      "text": " And tests are just another word for eval or benchmarks.",
      "tokens": [
        50783,
        400,
        6921,
        366,
        445,
        1071,
        1349,
        337,
        1073,
        304,
        420,
        43751,
        13,
        50992
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.23130349814891815,
      "compression_ratio": 1.539170503616333,
      "end": 1436.9199752807617,
      "no_speech_prob": 0.0031235332135111094,
      "seek": 11292,
      "start": 1436.079978942871,
      "temperature": 0.20000000298023224,
      "text": " For this tool,",
      "tokens": [
        50992,
        1171,
        341,
        2290,
        11,
        51034
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 58,
      "avg_logprob": -0.23130349814891815,
      "compression_ratio": 1.539170503616333,
      "end": 1438.719970703125,
      "no_speech_prob": 0.0031235332135111094,
      "seek": 11292,
      "start": 1436.9199752807617,
      "temperature": 0.20000000298023224,
      "text": " I'm starting to build up a suite of benchmarks.",
      "tokens": [
        51034,
        286,
        478,
        2891,
        281,
        1322,
        493,
        257,
        14205,
        295,
        43751,
        13,
        51124
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 59,
      "avg_logprob": -0.23130349814891815,
      "compression_ratio": 1.539170503616333,
      "end": 1440.3599700927734,
      "no_speech_prob": 0.0031235332135111094,
      "seek": 11292,
      "start": 1438.719970703125,
      "temperature": 0.20000000298023224,
      "text": " Right now, I only have 10 problems,",
      "tokens": [
        51124,
        1779,
        586,
        11,
        286,
        787,
        362,
        1266,
        2740,
        11,
        51206
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 60,
      "avg_logprob": -0.23130349814891815,
      "compression_ratio": 1.539170503616333,
      "end": 1442.3999786376953,
      "no_speech_prob": 0.0031235332135111094,
      "seek": 11292,
      "start": 1440.3599700927734,
      "temperature": 0.20000000298023224,
      "text": " but you can see here, I'm taking it.",
      "tokens": [
        51206,
        457,
        291,
        393,
        536,
        510,
        11,
        286,
        478,
        1940,
        309,
        13,
        51308
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_011.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1443.939973115921,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1441.6599731445312,
      "temperature": 0.0,
      "text": " and I'm multiplying it by whatever models",
      "tokens": [
        50364,
        293,
        286,
        478,
        30955,
        309,
        538,
        2035,
        5245,
        50478
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1444.7799730300903,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1443.939973115921,
      "temperature": 0.0,
      "text": " I wanna run against.",
      "tokens": [
        50478,
        286,
        1948,
        1190,
        1970,
        13,
        50520
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1446.0199732780457,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1444.7799730300903,
      "temperature": 0.0,
      "text": " So this ran in the background.",
      "tokens": [
        50520,
        407,
        341,
        5872,
        294,
        264,
        3678,
        13,
        50582
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1447.8999729156494,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1446.0199732780457,
      "temperature": 0.0,
      "text": " Let's go ahead and just take a peek",
      "tokens": [
        50582,
        961,
        311,
        352,
        2286,
        293,
        445,
        747,
        257,
        19604,
        50676
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1449.8199729919434,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1447.8999729156494,
      "temperature": 0.0,
      "text": " at the results from this.",
      "tokens": [
        50676,
        412,
        264,
        3542,
        490,
        341,
        13,
        50772
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1451.799973487854,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1449.8199729919434,
      "temperature": 0.0,
      "text": " And let's see if we can answer some of the questions",
      "tokens": [
        50772,
        400,
        718,
        311,
        536,
        498,
        321,
        393,
        1867,
        512,
        295,
        264,
        1651,
        50871
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1453.7399730682373,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1451.799973487854,
      "temperature": 0.0,
      "text": " we put forth earlier in the video.",
      "tokens": [
        50871,
        321,
        829,
        5220,
        3071,
        294,
        264,
        960,
        13,
        50968
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1455.419973373413,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1453.7399730682373,
      "temperature": 0.0,
      "text": " So if we look at the logging,",
      "tokens": [
        50968,
        407,
        498,
        321,
        574,
        412,
        264,
        27991,
        11,
        51052
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1458.3799724578857,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1455.419973373413,
      "temperature": 0.0,
      "text": " and if we open up logging underscore benchmark,",
      "tokens": [
        51052,
        293,
        498,
        321,
        1269,
        493,
        27991,
        37556,
        18927,
        11,
        51200
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1462.7799739837646,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1458.3799724578857,
      "temperature": 0.0,
      "text": " you can see here, look at all these executions, right?",
      "tokens": [
        51200,
        291,
        393,
        536,
        510,
        11,
        574,
        412,
        439,
        613,
        4454,
        3666,
        11,
        558,
        30,
        51420
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1463.9399738311768,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1462.7799739837646,
      "temperature": 0.0,
      "text": " You have to keep in mind,",
      "tokens": [
        51420,
        509,
        362,
        281,
        1066,
        294,
        1575,
        11,
        51478
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1468.1399726867676,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1463.9399738311768,
      "temperature": 0.0,
      "text": " it's two models running against 10 problems",
      "tokens": [
        51478,
        309,
        311,
        732,
        5245,
        2614,
        1970,
        1266,
        2740,
        51688
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.1891324669122696,
      "compression_ratio": 1.6190476417541504,
      "end": 1471.259973526001,
      "no_speech_prob": 0.004399188328534365,
      "seek": 0,
      "start": 1468.1399726867676,
      "temperature": 0.0,
      "text": " for three different versions.",
      "tokens": [
        51688,
        337,
        1045,
        819,
        9606,
        13,
        51844
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1473.2999725341797,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1471.259973526001,
      "temperature": 0.0,
      "text": " We have the prompt, prompt chain, and AI agent.",
      "tokens": [
        50364,
        492,
        362,
        264,
        12391,
        11,
        12391,
        5021,
        11,
        293,
        7318,
        9461,
        13,
        50466
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1476.0999717712402,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1473.2999725341797,
      "temperature": 0.0,
      "text": " That's three times two times 10.",
      "tokens": [
        50466,
        663,
        311,
        1045,
        1413,
        732,
        1413,
        1266,
        13,
        50606
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1477.0999717712402,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1476.0999717712402,
      "temperature": 0.0,
      "text": " So let's go ahead and just look",
      "tokens": [
        50606,
        407,
        718,
        311,
        352,
        2286,
        293,
        445,
        574,
        50656
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1478.4599723815918,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1477.0999717712402,
      "temperature": 0.0,
      "text": " at the top level benchmark session.",
      "tokens": [
        50656,
        412,
        264,
        1192,
        1496,
        18927,
        5481,
        13,
        50724
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1480.4599723815918,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1478.4599723815918,
      "temperature": 0.0,
      "text": " So a benchmarking session is just gonna contain",
      "tokens": [
        50724,
        407,
        257,
        18927,
        278,
        5481,
        307,
        445,
        799,
        5304,
        50824
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1482.3799743652344,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1480.4599723815918,
      "temperature": 0.0,
      "text": " the kind of high level results.",
      "tokens": [
        50824,
        264,
        733,
        295,
        1090,
        1496,
        3542,
        13,
        50920
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1484.2199745178223,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1482.3799743652344,
      "temperature": 0.0,
      "text": " And so it's gonna tell us, you know,",
      "tokens": [
        50920,
        400,
        370,
        309,
        311,
        799,
        980,
        505,
        11,
        291,
        458,
        11,
        51012
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1486.6599731445312,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1484.2199745178223,
      "temperature": 0.0,
      "text": " for the problem and for the model,",
      "tokens": [
        51012,
        337,
        264,
        1154,
        293,
        337,
        264,
        2316,
        11,
        51134
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1487.9799728393555,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1486.6599731445312,
      "temperature": 0.0,
      "text": " what it got right and what it got wrong",
      "tokens": [
        51134,
        437,
        309,
        658,
        558,
        293,
        437,
        309,
        658,
        2085,
        51200
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1489.5799713134766,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1487.9799728393555,
      "temperature": 0.0,
      "text": " across the three levels.",
      "tokens": [
        51200,
        2108,
        264,
        1045,
        4358,
        13,
        51280
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1491.6599731445312,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1489.5799713134766,
      "temperature": 0.0,
      "text": " Is a prompt chain always better than a prompt?",
      "tokens": [
        51280,
        1119,
        257,
        12391,
        5021,
        1009,
        1101,
        813,
        257,
        12391,
        30,
        51384
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1494.339973449707,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1491.6599731445312,
      "temperature": 0.0,
      "text": " Is an AI agent always better than a prompt chain?",
      "tokens": [
        51384,
        1119,
        364,
        7318,
        9461,
        1009,
        1101,
        813,
        257,
        12391,
        5021,
        30,
        51518
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1496.239974975586,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1494.339973449707,
      "temperature": 0.0,
      "text": " Let's see if we can find some answers",
      "tokens": [
        51518,
        961,
        311,
        536,
        498,
        321,
        393,
        915,
        512,
        6338,
        51613
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1497.8199729919434,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1496.239974975586,
      "temperature": 0.0,
      "text": " by looking at this benchmark.",
      "tokens": [
        51613,
        538,
        1237,
        412,
        341,
        18927,
        13,
        51692
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.20057706534862518,
      "compression_ratio": 1.853896141052246,
      "end": 1500.3799743652344,
      "no_speech_prob": 0.0001511805021436885,
      "seek": 2960,
      "start": 1497.8199729919434,
      "temperature": 0.0,
      "text": " Here we have the prompt running GPT-4.0.",
      "tokens": [
        51692,
        1692,
        321,
        362,
        264,
        12391,
        2614,
        26039,
        51,
        12,
        19,
        13,
        15,
        13,
        51820
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1501.5599746704102,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1500.3799743652344,
      "temperature": 0.0,
      "text": " It got the problem wrong.",
      "tokens": [
        50364,
        467,
        658,
        264,
        1154,
        2085,
        13,
        50423
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1503.4999732971191,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1501.5599746704102,
      "temperature": 0.0,
      "text": " And you can see here, here's a start text.",
      "tokens": [
        50423,
        400,
        291,
        393,
        536,
        510,
        11,
        510,
        311,
        257,
        722,
        2487,
        13,
        50520
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1504.739974975586,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1503.4999732971191,
      "temperature": 0.0,
      "text": " Here's our target text.",
      "tokens": [
        50520,
        1692,
        311,
        527,
        3779,
        2487,
        13,
        50582
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1505.5799713134766,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1504.739974975586,
      "temperature": 0.0,
      "text": " It's incorrect.",
      "tokens": [
        50582,
        467,
        311,
        18424,
        13,
        50624
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1506.459976196289,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1505.5799713134766,
      "temperature": 0.0,
      "text": " It left this.",
      "tokens": [
        50624,
        467,
        1411,
        341,
        13,
        50668
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1510.0599746704102,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1506.459976196289,
      "temperature": 0.0,
      "text": " Our prompt chain has four remaining compute uses.",
      "tokens": [
        50668,
        2621,
        12391,
        5021,
        575,
        1451,
        8877,
        14722,
        4960,
        13,
        50848
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1512.9799728393555,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1510.0599746704102,
      "temperature": 0.0,
      "text": " So this is set at eight and our V3 AI agent,",
      "tokens": [
        50848,
        407,
        341,
        307,
        992,
        412,
        3180,
        293,
        527,
        691,
        18,
        7318,
        9461,
        11,
        50994
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1514.4199752807617,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1512.9799728393555,
      "temperature": 0.0,
      "text": " this is set at 16.",
      "tokens": [
        50994,
        341,
        307,
        992,
        412,
        3165,
        13,
        51066
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1516.7799758911133,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1514.4199752807617,
      "temperature": 0.0,
      "text": " We have a little bit more leeway for our AI agent",
      "tokens": [
        51066,
        492,
        362,
        257,
        707,
        857,
        544,
        46571,
        676,
        337,
        527,
        7318,
        9461,
        51184
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1519.3799743652344,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1516.7799758911133,
      "temperature": 0.0,
      "text": " because it can reset the entire state if it wants to.",
      "tokens": [
        51184,
        570,
        309,
        393,
        14322,
        264,
        2302,
        1785,
        498,
        309,
        2738,
        281,
        13,
        51314
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1521.8599700927734,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1519.3799743652344,
      "temperature": 0.0,
      "text": " So we can see here with GPT-4.0,",
      "tokens": [
        51314,
        407,
        321,
        393,
        536,
        510,
        365,
        26039,
        51,
        12,
        19,
        13,
        15,
        11,
        51438
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1524.4199752807617,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1521.8599700927734,
      "temperature": 0.0,
      "text": " we have two correct and one wrong.",
      "tokens": [
        51438,
        321,
        362,
        732,
        3006,
        293,
        472,
        2085,
        13,
        51566
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1527.8999710083008,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1524.4199752807617,
      "temperature": 0.0,
      "text": " Now we have that exact same problem running on O3 mini,",
      "tokens": [
        51566,
        823,
        321,
        362,
        300,
        1900,
        912,
        1154,
        2614,
        322,
        422,
        18,
        8382,
        11,
        51740
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1528.739974975586,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1527.8999710083008,
      "temperature": 0.0,
      "text": " right?",
      "tokens": [
        51740,
        558,
        30,
        51782
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.7050848007202148,
      "end": 1529.739974975586,
      "no_speech_prob": 0.0010987237328663468,
      "seek": 5872,
      "start": 1528.739974975586,
      "temperature": 0.0,
      "text": " So these are both problem zero.",
      "tokens": [
        51782,
        407,
        613,
        366,
        1293,
        1154,
        4018,
        13,
        51832
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1530.8999710083008,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1530.0599746704102,
      "temperature": 0.0,
      "text": " There's GPT-4.0.",
      "tokens": [
        50380,
        821,
        311,
        26039,
        51,
        12,
        19,
        13,
        15,
        13,
        50422
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1533.6599731445312,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1530.8999710083008,
      "temperature": 0.0,
      "text": " And here's problem zero with O3 mini.",
      "tokens": [
        50422,
        400,
        510,
        311,
        1154,
        4018,
        365,
        422,
        18,
        8382,
        13,
        50560
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1535.6599731445312,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1533.6599731445312,
      "temperature": 0.0,
      "text": " Same deal, except O3 mini, right?",
      "tokens": [
        50560,
        10635,
        2028,
        11,
        3993,
        422,
        18,
        8382,
        11,
        558,
        30,
        50660
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1538.9399719238281,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1535.6599731445312,
      "temperature": 0.0,
      "text": " A powerful reasoning model gets every single version right.",
      "tokens": [
        50660,
        316,
        4005,
        21577,
        2316,
        2170,
        633,
        2167,
        3037,
        558,
        13,
        50824
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1541.2599716186523,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1538.9399719238281,
      "temperature": 0.0,
      "text": " So what this individual test is telling us",
      "tokens": [
        50824,
        407,
        437,
        341,
        2609,
        1500,
        307,
        3585,
        505,
        50940
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1544.459976196289,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1541.2599716186523,
      "temperature": 0.0,
      "text": " is that we don't need any more compute to solve this problem.",
      "tokens": [
        50940,
        307,
        300,
        321,
        500,
        380,
        643,
        604,
        544,
        14722,
        281,
        5039,
        341,
        1154,
        13,
        51100
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1546.9799728393555,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1544.459976196289,
      "temperature": 0.0,
      "text": " A reasoning model and a prompt is enough, okay?",
      "tokens": [
        51100,
        316,
        21577,
        2316,
        293,
        257,
        12391,
        307,
        1547,
        11,
        1392,
        30,
        51226
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1549.2999725341797,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1546.9799728393555,
      "temperature": 0.0,
      "text": " But that is not always the case as we'll see here",
      "tokens": [
        51226,
        583,
        300,
        307,
        406,
        1009,
        264,
        1389,
        382,
        321,
        603,
        536,
        510,
        51342
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1550.7799758911133,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1549.2999725341797,
      "temperature": 0.0,
      "text": " as we look at a few more problems, right?",
      "tokens": [
        51342,
        382,
        321,
        574,
        412,
        257,
        1326,
        544,
        2740,
        11,
        558,
        30,
        51416
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1553.8199768066406,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1550.7799758911133,
      "temperature": 0.0,
      "text": " So GPT-4.0, problem two, here's a simple one.",
      "tokens": [
        51416,
        407,
        26039,
        51,
        12,
        19,
        13,
        15,
        11,
        1154,
        732,
        11,
        510,
        311,
        257,
        2199,
        472,
        13,
        51568
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1556.219970703125,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1553.8199768066406,
      "temperature": 0.0,
      "text": " We're going to go right for, we're going to go.",
      "tokens": [
        51568,
        492,
        434,
        516,
        281,
        352,
        558,
        337,
        11,
        321,
        434,
        516,
        281,
        352,
        13,
        51688
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.20820419490337372,
      "compression_ratio": 1.730897068977356,
      "end": 1557.9399719238281,
      "no_speech_prob": 0.0007096666959114373,
      "seek": 8808,
      "start": 1556.219970703125,
      "temperature": 0.0,
      "text": " So how are we going to benchmark?",
      "tokens": [
        51688,
        407,
        577,
        366,
        321,
        516,
        281,
        18927,
        30,
        51774
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.18061865866184235,
      "compression_ratio": 1.4408602714538574,
      "end": 1560.8199768066406,
      "no_speech_prob": 0.008846733719110489,
      "seek": 11628,
      "start": 1557.9399719238281,
      "temperature": 0.0,
      "text": " And then if we scroll here, the correct edit is,",
      "tokens": [
        50364,
        400,
        550,
        498,
        321,
        11369,
        510,
        11,
        264,
        3006,
        8129,
        307,
        11,
        50508
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.18061865866184235,
      "compression_ratio": 1.4408602714538574,
      "end": 1562.8199768066406,
      "no_speech_prob": 0.008846733719110489,
      "seek": 11628,
      "start": 1560.8199768066406,
      "temperature": 0.0,
      "text": " so how are we going to benchmark the M4?",
      "tokens": [
        50508,
        370,
        577,
        366,
        321,
        516,
        281,
        18927,
        264,
        376,
        19,
        30,
        50608
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.18061865866184235,
      "compression_ratio": 1.4408602714538574,
      "end": 1564.8199768066406,
      "no_speech_prob": 0.008846733719110489,
      "seek": 11628,
      "start": 1562.8199768066406,
      "temperature": 0.0,
      "text": " This is from the M4 benchmarking video.",
      "tokens": [
        50608,
        639,
        307,
        490,
        264,
        376,
        19,
        18927,
        278,
        960,
        13,
        50708
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 58,
      "avg_logprob": -0.18061865866184235,
      "compression_ratio": 1.4408602714538574,
      "end": 1565.6599731445312,
      "no_speech_prob": 0.008846733719110489,
      "seek": 11628,
      "start": 1564.8199768066406,
      "temperature": 0.0,
      "text": " If we scroll down here,",
      "tokens": [
        50708,
        759,
        321,
        11369,
        760,
        510,
        11,
        50750
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 59,
      "avg_logprob": -0.18061865866184235,
      "compression_ratio": 1.4408602714538574,
      "end": 1568.5399703979492,
      "no_speech_prob": 0.008846733719110489,
      "seek": 11628,
      "start": 1565.6599731445312,
      "temperature": 0.0,
      "text": " you can see GPT-4.0 and every single variant",
      "tokens": [
        50750,
        291,
        393,
        536,
        26039,
        51,
        12,
        19,
        13,
        15,
        293,
        633,
        2167,
        17501,
        50894
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 60,
      "avg_logprob": -0.18061865866184235,
      "compression_ratio": 1.4408602714538574,
      "end": 1569.3799743652344,
      "no_speech_prob": 0.008846733719110489,
      "seek": 11628,
      "start": 1568.5399703979492,
      "temperature": 0.0,
      "text": " gets this right.",
      "tokens": [
        50894,
        2170,
        341,
        558,
        13,
        50936
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 61,
      "avg_logprob": -0.18061865866184235,
      "compression_ratio": 1.4408602714538574,
      "end": 1572.6599731445312,
      "no_speech_prob": 0.008846733719110489,
      "seek": 11628,
      "start": 1569.3799743652344,
      "temperature": 0.0,
      "text": " So prompt, prompt chain, agent, it's all good, okay?",
      "tokens": [
        50936,
        407,
        12391,
        11,
        12391,
        5021,
        11,
        9461,
        11,
        309,
        311,
        439,
        665,
        11,
        1392,
        30,
        51100
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_012.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1577.719970703125,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1572.719970703125,
      "temperature": 0.0,
      "text": " Interestingly, the O3 mini gets the individual prompt wrong,",
      "tokens": [
        50364,
        30564,
        11,
        264,
        422,
        18,
        8382,
        2170,
        264,
        2609,
        12391,
        2085,
        11,
        50614
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1579.8599705696106,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1578.2399706840515,
      "temperature": 0.0,
      "text": " but you can see here the prompt chain",
      "tokens": [
        50640,
        457,
        291,
        393,
        536,
        510,
        264,
        12391,
        5021,
        50721
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1582.559970855713,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1579.8599705696106,
      "temperature": 0.0,
      "text": " and the AI agent get this problem correct.",
      "tokens": [
        50721,
        293,
        264,
        7318,
        9461,
        483,
        341,
        1154,
        3006,
        13,
        50856
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1584.5199708938599,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1582.559970855713,
      "temperature": 0.0,
      "text": " Okay, so very cool to see that.",
      "tokens": [
        50856,
        1033,
        11,
        370,
        588,
        1627,
        281,
        536,
        300,
        13,
        50954
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1587.3599710464478,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1584.5199708938599,
      "temperature": 0.0,
      "text": " Now we're moving to problem two in GPT 4.0.",
      "tokens": [
        50954,
        823,
        321,
        434,
        2684,
        281,
        1154,
        732,
        294,
        26039,
        51,
        1017,
        13,
        15,
        13,
        51096
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1589.639970779419,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1587.3599710464478,
      "temperature": 0.0,
      "text": " So we can see here this problem,",
      "tokens": [
        51096,
        407,
        321,
        393,
        536,
        510,
        341,
        1154,
        11,
        51210
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1592.879970550537,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1589.639970779419,
      "temperature": 0.0,
      "text": " every single version of GPT 4.0 got it incorrect, right?",
      "tokens": [
        51210,
        633,
        2167,
        3037,
        295,
        26039,
        51,
        1017,
        13,
        15,
        658,
        309,
        18424,
        11,
        558,
        30,
        51372
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1595.1599712371826,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1592.879970550537,
      "temperature": 0.0,
      "text": " False, false, false.",
      "tokens": [
        51372,
        50040,
        11,
        7908,
        11,
        7908,
        13,
        51486
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1597.1599712371826,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1595.1599712371826,
      "temperature": 0.0,
      "text": " So this is a longer, more interesting edit.",
      "tokens": [
        51486,
        407,
        341,
        307,
        257,
        2854,
        11,
        544,
        1880,
        8129,
        13,
        51586
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1599.879970550537,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1597.1599712371826,
      "temperature": 0.0,
      "text": " Let's see how O3 mini has performed.",
      "tokens": [
        51586,
        961,
        311,
        536,
        577,
        422,
        18,
        8382,
        575,
        10332,
        13,
        51722
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.2537037134170532,
      "compression_ratio": 1.7186311483383179,
      "end": 1602.4799709320068,
      "no_speech_prob": 0.0850805938243866,
      "seek": 0,
      "start": 1599.879970550537,
      "temperature": 0.0,
      "text": " True, true, and then interestingly, false.",
      "tokens": [
        51722,
        13587,
        11,
        2074,
        11,
        293,
        550,
        25873,
        11,
        7908,
        13,
        51852
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1604.639970779419,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1602.4799709320068,
      "temperature": 0.0,
      "text": " So this is a case where more compute is not better.",
      "tokens": [
        50364,
        407,
        341,
        307,
        257,
        1389,
        689,
        544,
        14722,
        307,
        406,
        1101,
        13,
        50472
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1605.619972229004,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1604.639970779419,
      "temperature": 0.0,
      "text": " Interesting to see that.",
      "tokens": [
        50472,
        14711,
        281,
        536,
        300,
        13,
        50521
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1608.1999702453613,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1605.619972229004,
      "temperature": 0.0,
      "text": " And we can go on down the line here, right?",
      "tokens": [
        50521,
        400,
        321,
        393,
        352,
        322,
        760,
        264,
        1622,
        510,
        11,
        558,
        30,
        50650
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1610.4399719238281,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1608.1999702453613,
      "temperature": 0.0,
      "text": " I'm not gonna bore you with every single thing here.",
      "tokens": [
        50650,
        286,
        478,
        406,
        799,
        26002,
        291,
        365,
        633,
        2167,
        551,
        510,
        13,
        50762
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1614.319969177246,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1610.4399719238281,
      "temperature": 0.0,
      "text": " You can see here that this prompt chain over edited.",
      "tokens": [
        50762,
        509,
        393,
        536,
        510,
        300,
        341,
        12391,
        5021,
        670,
        23016,
        13,
        50956
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1617.7999725341797,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1614.319969177246,
      "temperature": 0.0,
      "text": " So it ended up cutting out way too much text, right?",
      "tokens": [
        50956,
        407,
        309,
        4590,
        493,
        6492,
        484,
        636,
        886,
        709,
        2487,
        11,
        558,
        30,
        51130
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1619.0999717712402,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1617.7999725341797,
      "temperature": 0.0,
      "text": " It just kept going down.",
      "tokens": [
        51130,
        467,
        445,
        4305,
        516,
        760,
        13,
        51195
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1621.0799713134766,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1619.0999717712402,
      "temperature": 0.0,
      "text": " This is the, you know, one of the problems",
      "tokens": [
        51195,
        639,
        307,
        264,
        11,
        291,
        458,
        11,
        472,
        295,
        264,
        2740,
        51294
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1623.3999710083008,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1621.0799713134766,
      "temperature": 0.0,
      "text": " with just a prompt chain that just runs rampant.",
      "tokens": [
        51294,
        365,
        445,
        257,
        12391,
        5021,
        300,
        445,
        6676,
        12428,
        394,
        13,
        51410
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1625.4199714660645,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1623.3999710083008,
      "temperature": 0.0,
      "text": " It just edited everything down, okay?",
      "tokens": [
        51410,
        467,
        445,
        23016,
        1203,
        760,
        11,
        1392,
        30,
        51511
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1627.1999702453613,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1625.4199714660645,
      "temperature": 0.0,
      "text": " And it didn't have the tools, right?",
      "tokens": [
        51511,
        400,
        309,
        994,
        380,
        362,
        264,
        3873,
        11,
        558,
        30,
        51600
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1630.119972229004,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1627.1999702453613,
      "temperature": 0.0,
      "text": " It didn't have the tools available to reset or fix the edit.",
      "tokens": [
        51600,
        467,
        994,
        380,
        362,
        264,
        3873,
        2435,
        281,
        14322,
        420,
        3191,
        264,
        8129,
        13,
        51746
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.21431326866149902,
      "compression_ratio": 1.850649356842041,
      "end": 1631.9999694824219,
      "no_speech_prob": 6.922166357981041e-05,
      "seek": 2976,
      "start": 1630.119972229004,
      "temperature": 0.0,
      "text": " So if we continue down the line here,",
      "tokens": [
        51746,
        407,
        498,
        321,
        2354,
        760,
        264,
        1622,
        510,
        11,
        51840
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1633.9199714660645,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1632.4799690246582,
      "temperature": 0.0,
      "text": " it's that same problem with O3 mini.",
      "tokens": [
        50388,
        309,
        311,
        300,
        912,
        1154,
        365,
        422,
        18,
        8382,
        13,
        50460
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1635.879970550537,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1633.9199714660645,
      "temperature": 0.0,
      "text": " You can see here, prompt was wrong.",
      "tokens": [
        50460,
        509,
        393,
        536,
        510,
        11,
        12391,
        390,
        2085,
        13,
        50558
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1640.5199737548828,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1635.879970550537,
      "temperature": 0.0,
      "text": " The chain was correct, but the AI agent was not correct.",
      "tokens": [
        50558,
        440,
        5021,
        390,
        3006,
        11,
        457,
        264,
        7318,
        9461,
        390,
        406,
        3006,
        13,
        50790
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1643.0799713134766,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1640.5199737548828,
      "temperature": 0.0,
      "text": " And so you can see here, it looks close, right?",
      "tokens": [
        50790,
        400,
        370,
        291,
        393,
        536,
        510,
        11,
        309,
        1542,
        1998,
        11,
        558,
        30,
        50918
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1644.9199676513672,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1643.0799713134766,
      "temperature": 0.0,
      "text": " If we pull this text out, right?",
      "tokens": [
        50918,
        759,
        321,
        2235,
        341,
        2487,
        484,
        11,
        558,
        30,
        51010
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1646.1999740600586,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1644.9199676513672,
      "temperature": 0.0,
      "text": " And we can just highlight this to see.",
      "tokens": [
        51010,
        400,
        321,
        393,
        445,
        5078,
        341,
        281,
        536,
        13,
        51074
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1648.9599685668945,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1646.1999740600586,
      "temperature": 0.0,
      "text": " So let's go ahead and open up everyone's favorite",
      "tokens": [
        51074,
        407,
        718,
        311,
        352,
        2286,
        293,
        1269,
        493,
        1518,
        311,
        2954,
        51212
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1649.7999725341797,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1648.9599685668945,
      "temperature": 0.0,
      "text": " local model tool.",
      "tokens": [
        51212,
        2654,
        2316,
        2290,
        13,
        51254
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1653.8599700927734,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1649.7999725341797,
      "temperature": 0.0,
      "text": " We're going to be using Olama and here's where it branched.",
      "tokens": [
        51254,
        492,
        434,
        516,
        281,
        312,
        1228,
        6141,
        2404,
        293,
        510,
        311,
        689,
        309,
        9819,
        292,
        13,
        51457
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1655.1599731445312,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1653.8599700927734,
      "temperature": 0.0,
      "text": " And we're going to be using a tool",
      "tokens": [
        51457,
        400,
        321,
        434,
        516,
        281,
        312,
        1228,
        257,
        2290,
        51522
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1656.7999725341797,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1655.1599731445312,
      "temperature": 0.0,
      "text": " I'm building out called Benchy.",
      "tokens": [
        51522,
        286,
        478,
        2390,
        484,
        1219,
        3964,
        28629,
        13,
        51604
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1657.9199676513672,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1656.7999725341797,
      "temperature": 0.0,
      "text": " And what we wanted was,",
      "tokens": [
        51604,
        400,
        437,
        321,
        1415,
        390,
        11,
        51660
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.20788419246673584,
      "compression_ratio": 1.7827585935592651,
      "end": 1660.9999694824219,
      "no_speech_prob": 0.0020829332061111927,
      "seek": 5928,
      "start": 1657.9199676513672,
      "temperature": 0.0,
      "text": " and a tool I'm building out called Benchy, okay?",
      "tokens": [
        51660,
        293,
        257,
        2290,
        286,
        478,
        2390,
        484,
        1219,
        3964,
        28629,
        11,
        1392,
        30,
        51814
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1664.7999725341797,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1661.5199737548828,
      "temperature": 0.0,
      "text": " So this is a better failure in the AI agent.",
      "tokens": [
        50390,
        407,
        341,
        307,
        257,
        1101,
        7763,
        294,
        264,
        7318,
        9461,
        13,
        50554
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1666.1999740600586,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1664.7999725341797,
      "temperature": 0.0,
      "text": " You know, it made a clean edit,",
      "tokens": [
        50554,
        509,
        458,
        11,
        309,
        1027,
        257,
        2541,
        8129,
        11,
        50624
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1668.1599731445312,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1666.1999740600586,
      "temperature": 0.0,
      "text": " but it wasn't the exact edit we're looking for.",
      "tokens": [
        50624,
        457,
        309,
        2067,
        380,
        264,
        1900,
        8129,
        321,
        434,
        1237,
        337,
        13,
        50722
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1671.4399719238281,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1668.1599731445312,
      "temperature": 0.0,
      "text": " And this is where making the prompt more specific",
      "tokens": [
        50722,
        400,
        341,
        307,
        689,
        1455,
        264,
        12391,
        544,
        2685,
        50886
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1675.6599731445312,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1671.4399719238281,
      "temperature": 0.0,
      "text": " to the exact editing decisions and subjective editing tastes",
      "tokens": [
        50886,
        281,
        264,
        1900,
        10000,
        5327,
        293,
        25972,
        10000,
        8666,
        51097
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1677.4799728393555,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1675.6599731445312,
      "temperature": 0.0,
      "text": " is going to be more and more important, okay?",
      "tokens": [
        51097,
        307,
        516,
        281,
        312,
        544,
        293,
        544,
        1021,
        11,
        1392,
        30,
        51188
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1679.0799713134766,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1677.4799728393555,
      "temperature": 0.0,
      "text": " There are many of these in here",
      "tokens": [
        51188,
        821,
        366,
        867,
        295,
        613,
        294,
        510,
        51268
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1681.1999740600586,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1679.0799713134766,
      "temperature": 0.0,
      "text": " that could have been marked right,",
      "tokens": [
        51268,
        300,
        727,
        362,
        668,
        12658,
        558,
        11,
        51374
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1683.119972229004,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1681.1999740600586,
      "temperature": 0.0,
      "text": " specifically with the O3 mini model",
      "tokens": [
        51374,
        4682,
        365,
        264,
        422,
        18,
        8382,
        2316,
        51470
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1685.839973449707,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1683.119972229004,
      "temperature": 0.0,
      "text": " that could be marked true, could be marked correct,",
      "tokens": [
        51470,
        300,
        727,
        312,
        12658,
        2074,
        11,
        727,
        312,
        12658,
        3006,
        11,
        51606
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1688.719970703125,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1685.839973449707,
      "temperature": 0.0,
      "text": " but it doesn't exactly hit the target text, right?",
      "tokens": [
        51606,
        457,
        309,
        1177,
        380,
        2293,
        2045,
        264,
        3779,
        2487,
        11,
        558,
        30,
        51750
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.20649729669094086,
      "compression_ratio": 1.791946291923523,
      "end": 1690.719970703125,
      "no_speech_prob": 0.00013135100016370416,
      "seek": 8828,
      "start": 1688.719970703125,
      "temperature": 0.0,
      "text": " This is where something like 11 scene distance",
      "tokens": [
        51750,
        639,
        307,
        689,
        746,
        411,
        2975,
        4145,
        4560,
        51850
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.2548559308052063,
      "compression_ratio": 1.4855490922927856,
      "end": 1694.319969177246,
      "no_speech_prob": 0.020963406190276146,
      "seek": 11800,
      "start": 1691.4399719238281,
      "temperature": 0.0,
      "text": " or some rough string comparison framework can come in, okay?",
      "tokens": [
        50400,
        420,
        512,
        5903,
        6798,
        9660,
        8388,
        393,
        808,
        294,
        11,
        1392,
        30,
        50544
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.2548559308052063,
      "compression_ratio": 1.4855490922927856,
      "end": 1695.9199676513672,
      "no_speech_prob": 0.020963406190276146,
      "seek": 11800,
      "start": 1694.319969177246,
      "temperature": 0.0,
      "text": " So we're going to skip through these, right?",
      "tokens": [
        50544,
        407,
        321,
        434,
        516,
        281,
        10023,
        807,
        613,
        11,
        558,
        30,
        50624
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.2548559308052063,
      "compression_ratio": 1.4855490922927856,
      "end": 1696.7599716186523,
      "no_speech_prob": 0.020963406190276146,
      "seek": 11800,
      "start": 1695.9199676513672,
      "temperature": 0.0,
      "text": " There's a lot going on.",
      "tokens": [
        50624,
        821,
        311,
        257,
        688,
        516,
        322,
        13,
        50666
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.2548559308052063,
      "compression_ratio": 1.4855490922927856,
      "end": 1698.599967956543,
      "no_speech_prob": 0.020963406190276146,
      "seek": 11800,
      "start": 1696.7599716186523,
      "temperature": 0.0,
      "text": " If we just scroll all the way to the bottom,",
      "tokens": [
        50666,
        759,
        321,
        445,
        11369,
        439,
        264,
        636,
        281,
        264,
        2767,
        11,
        50758
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.2548559308052063,
      "compression_ratio": 1.4855490922927856,
      "end": 1702.0799713134766,
      "no_speech_prob": 0.020963406190276146,
      "seek": 11800,
      "start": 1698.599967956543,
      "temperature": 0.0,
      "text": " we can get some high level overarching benchmark results,",
      "tokens": [
        50758,
        321,
        393,
        483,
        512,
        1090,
        1496,
        45501,
        18927,
        3542,
        11,
        50932
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.2548559308052063,
      "compression_ratio": 1.4855490922927856,
      "end": 1702.9199676513672,
      "no_speech_prob": 0.020963406190276146,
      "seek": 11800,
      "start": 1702.0799713134766,
      "temperature": 0.0,
      "text": " okay?",
      "tokens": [
        50932,
        1392,
        30,
        50974
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.2548559308052063,
      "compression_ratio": 1.4855490922927856,
      "end": 1703.7599639892578,
      "no_speech_prob": 0.020963406190276146,
      "seek": 11800,
      "start": 1702.9199676513672,
      "temperature": 0.0,
      "text": " Here's everything.",
      "tokens": [
        50974,
        1692,
        311,
        1203,
        13,
        51016
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_013.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1708.2599682807922,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1703.7799682617188,
      "temperature": 0.0,
      "text": " that was correct and incorrect for a raw prompt.",
      "tokens": [
        50364,
        300,
        390,
        3006,
        293,
        18424,
        337,
        257,
        8936,
        12391,
        13,
        50588
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1711.5799684524536,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1708.2599682807922,
      "temperature": 0.0,
      "text": " We have across all models, eight correct.",
      "tokens": [
        50588,
        492,
        362,
        2108,
        439,
        5245,
        11,
        3180,
        3006,
        13,
        50754
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1713.6199684143066,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1711.5799684524536,
      "temperature": 0.0,
      "text": " And if we break down by model,",
      "tokens": [
        50754,
        400,
        498,
        321,
        1821,
        760,
        538,
        2316,
        11,
        50856
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1716.6199684143066,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1713.6199684143066,
      "temperature": 0.0,
      "text": " we can see GPT 4.0 got only two correct,",
      "tokens": [
        50856,
        321,
        393,
        536,
        26039,
        51,
        1017,
        13,
        15,
        658,
        787,
        732,
        3006,
        11,
        51006
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1719.7799682617188,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1716.6199684143066,
      "temperature": 0.0,
      "text": " while O3 Mini got eight of these problems correct",
      "tokens": [
        51006,
        1339,
        422,
        18,
        18239,
        658,
        3180,
        295,
        613,
        2740,
        3006,
        51164
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1721.7799682617188,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1719.7799682617188,
      "temperature": 0.0,
      "text": " with just a prompt.",
      "tokens": [
        51164,
        365,
        445,
        257,
        12391,
        13,
        51264
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1726.4199676513672,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1721.7799682617188,
      "temperature": 0.0,
      "text": " Even though O3 Mini is half the price of GPT 4.0,",
      "tokens": [
        51264,
        2754,
        1673,
        422,
        18,
        18239,
        307,
        1922,
        264,
        3218,
        295,
        26039,
        51,
        1017,
        13,
        15,
        11,
        51496
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1728.0599689483643,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1726.4199676513672,
      "temperature": 0.0,
      "text": " it uses thinking tokens, right?",
      "tokens": [
        51496,
        309,
        4960,
        1953,
        22667,
        11,
        558,
        30,
        51578
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1729.0599689483643,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1728.0599689483643,
      "temperature": 0.0,
      "text": " It has to reason.",
      "tokens": [
        51578,
        467,
        575,
        281,
        1778,
        13,
        51628
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1731.019968032837,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1729.0599689483643,
      "temperature": 0.0,
      "text": " So the price is still, you know,",
      "tokens": [
        51628,
        407,
        264,
        3218,
        307,
        920,
        11,
        291,
        458,
        11,
        51726
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.1951884925365448,
      "compression_ratio": 1.629921317100525,
      "end": 1733.2999687194824,
      "no_speech_prob": 0.0034294549841433764,
      "seek": 0,
      "start": 1731.019968032837,
      "temperature": 0.0,
      "text": " something like almost four times as much, right?",
      "tokens": [
        51726,
        746,
        411,
        1920,
        1451,
        1413,
        382,
        709,
        11,
        558,
        30,
        51840
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1735.5399684906006,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1733.2999687194824,
      "temperature": 0.0,
      "text": " So there's just the raw prompt, right?",
      "tokens": [
        50364,
        407,
        456,
        311,
        445,
        264,
        8936,
        12391,
        11,
        558,
        30,
        50476
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1737.2199668884277,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1735.5399684906006,
      "temperature": 0.0,
      "text": " So we have eight out of 12 correct.",
      "tokens": [
        50476,
        407,
        321,
        362,
        3180,
        484,
        295,
        2272,
        3006,
        13,
        50560
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1739.259967803955,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1737.2199668884277,
      "temperature": 0.0,
      "text": " Now, when we move to the prompt chain,",
      "tokens": [
        50560,
        823,
        11,
        562,
        321,
        1286,
        281,
        264,
        12391,
        5021,
        11,
        50662
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1740.539966583252,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1739.259967803955,
      "temperature": 0.0,
      "text": " we see something interesting, right?",
      "tokens": [
        50662,
        321,
        536,
        746,
        1880,
        11,
        558,
        30,
        50726
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1742.4199676513672,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1740.539966583252,
      "temperature": 0.0,
      "text": " You can see we have one more correct.",
      "tokens": [
        50726,
        509,
        393,
        536,
        321,
        362,
        472,
        544,
        3006,
        13,
        50820
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1745.7399673461914,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1742.4199676513672,
      "temperature": 0.0,
      "text": " And you can see here that the point is going to O3 Mini.",
      "tokens": [
        50820,
        400,
        291,
        393,
        536,
        510,
        300,
        264,
        935,
        307,
        516,
        281,
        422,
        18,
        18239,
        13,
        50986
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1747.659969329834,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1745.7399673461914,
      "temperature": 0.0,
      "text": " So this is pretty good, right?",
      "tokens": [
        50986,
        407,
        341,
        307,
        1238,
        665,
        11,
        558,
        30,
        51082
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1749.4199676513672,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1747.659969329834,
      "temperature": 0.0,
      "text": " So out of 10 problems,",
      "tokens": [
        51082,
        407,
        484,
        295,
        1266,
        2740,
        11,
        51170
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1754.0599670410156,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1749.4199676513672,
      "temperature": 0.0,
      "text": " O3 Mini with a prompt chain solved 70% of them correctly.",
      "tokens": [
        51170,
        422,
        18,
        18239,
        365,
        257,
        12391,
        5021,
        13041,
        5285,
        4,
        295,
        552,
        8944,
        13,
        51402
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1754.8999671936035,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1754.0599670410156,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51402,
        1033,
        13,
        51444
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1756.4599685668945,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1754.8999671936035,
      "temperature": 0.0,
      "text": " And it's very likely, like I mentioned,",
      "tokens": [
        51444,
        400,
        309,
        311,
        588,
        3700,
        11,
        411,
        286,
        2835,
        11,
        51522
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2055579572916031,
      "compression_ratio": 1.7084870338439941,
      "end": 1760.1799697875977,
      "no_speech_prob": 7.60245748097077e-05,
      "seek": 2952,
      "start": 1756.4599685668945,
      "temperature": 0.0,
      "text": " there are just some more subjective editing taste decisions",
      "tokens": [
        51522,
        456,
        366,
        445,
        512,
        544,
        25972,
        10000,
        3939,
        5327,
        51708
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1761.699966430664,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1760.2199668884277,
      "temperature": 0.0,
      "text": " in the language of, you know,",
      "tokens": [
        50366,
        294,
        264,
        2856,
        295,
        11,
        291,
        458,
        11,
        50440
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1764.0199699401855,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1761.699966430664,
      "temperature": 0.0,
      "text": " what constitutes a correct edit.",
      "tokens": [
        50440,
        437,
        44204,
        257,
        3006,
        8129,
        13,
        50556
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1766.8599700927734,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1764.0199699401855,
      "temperature": 0.0,
      "text": " Maybe you can give a one or two point discount here",
      "tokens": [
        50556,
        2704,
        291,
        393,
        976,
        257,
        472,
        420,
        732,
        935,
        11635,
        510,
        50698
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1767.7799682617188,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1766.8599700927734,
      "temperature": 0.0,
      "text": " if you wanted to, okay?",
      "tokens": [
        50698,
        498,
        291,
        1415,
        281,
        11,
        1392,
        30,
        50744
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1768.6199645996094,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1767.7799682617188,
      "temperature": 0.0,
      "text": " That's the prompt chain.",
      "tokens": [
        50744,
        663,
        311,
        264,
        12391,
        5021,
        13,
        50786
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1770.3399658203125,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1768.6199645996094,
      "temperature": 0.0,
      "text": " Interestingly here, we can see that the costs",
      "tokens": [
        50786,
        30564,
        510,
        11,
        321,
        393,
        536,
        300,
        264,
        5497,
        50872
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1773.819969177246,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1770.3399658203125,
      "temperature": 0.0,
      "text": " have jumped up quite a bit for GPT 4.0, okay?",
      "tokens": [
        50872,
        362,
        13864,
        493,
        1596,
        257,
        857,
        337,
        26039,
        51,
        1017,
        13,
        15,
        11,
        1392,
        30,
        51046
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1777.0599670410156,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1773.819969177246,
      "temperature": 0.0,
      "text": " So for all 10 problems running on the prompt chain,",
      "tokens": [
        51046,
        407,
        337,
        439,
        1266,
        2740,
        2614,
        322,
        264,
        12391,
        5021,
        11,
        51208
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1778.8599700927734,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1777.0599670410156,
      "temperature": 0.0,
      "text": " you know, 30 cents.",
      "tokens": [
        51208,
        291,
        458,
        11,
        2217,
        14941,
        13,
        51298
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1781.9399719238281,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1778.8599700927734,
      "temperature": 0.0,
      "text": " Now, when we move to the AI agent,",
      "tokens": [
        51298,
        823,
        11,
        562,
        321,
        1286,
        281,
        264,
        7318,
        9461,
        11,
        51452
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1784.699966430664,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1781.9399719238281,
      "temperature": 0.0,
      "text": " we see something very interesting, right?",
      "tokens": [
        51452,
        321,
        536,
        746,
        588,
        1880,
        11,
        558,
        30,
        51590
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1787.0599670410156,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1784.699966430664,
      "temperature": 0.0,
      "text": " The results don't improve, okay?",
      "tokens": [
        51590,
        440,
        3542,
        500,
        380,
        3470,
        11,
        1392,
        30,
        51708
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.1885702759027481,
      "compression_ratio": 1.6370106935501099,
      "end": 1788.2999649047852,
      "no_speech_prob": 0.3106222450733185,
      "seek": 5640,
      "start": 1787.0599670410156,
      "temperature": 0.0,
      "text": " The results get worse.",
      "tokens": [
        51708,
        440,
        3542,
        483,
        5324,
        13,
        51770
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1791.5399703979492,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1788.2999649047852,
      "temperature": 0.0,
      "text": " So we have seven correct, 13 wrong",
      "tokens": [
        50364,
        407,
        321,
        362,
        3407,
        3006,
        11,
        3705,
        2085,
        50526
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1794.4999694824219,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1791.5399703979492,
      "temperature": 0.0,
      "text": " for every AI agent version of this.",
      "tokens": [
        50526,
        337,
        633,
        7318,
        9461,
        3037,
        295,
        341,
        13,
        50674
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1796.1799697875977,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1794.4999694824219,
      "temperature": 0.0,
      "text": " So you can see here,",
      "tokens": [
        50674,
        407,
        291,
        393,
        536,
        510,
        11,
        50758
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1800.7399673461914,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1796.1799697875977,
      "temperature": 0.0,
      "text": " GPT 4.0 has a really hard time operating the AI agent",
      "tokens": [
        50758,
        26039,
        51,
        1017,
        13,
        15,
        575,
        257,
        534,
        1152,
        565,
        7447,
        264,
        7318,
        9461,
        50986
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1801.819969177246,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1800.7399673461914,
      "temperature": 0.0,
      "text": " in a useful way.",
      "tokens": [
        50986,
        294,
        257,
        4420,
        636,
        13,
        51040
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1804.1799697875977,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1801.819969177246,
      "temperature": 0.0,
      "text": " And O3 Mini, half the time it gets it right,",
      "tokens": [
        51040,
        400,
        422,
        18,
        18239,
        11,
        1922,
        264,
        565,
        309,
        2170,
        309,
        558,
        11,
        51158
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1805.4599685668945,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1804.1799697875977,
      "temperature": 0.0,
      "text": " half the time it gets it wrong.",
      "tokens": [
        51158,
        1922,
        264,
        565,
        309,
        2170,
        309,
        2085,
        13,
        51222
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1807.6599655151367,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1805.4599685668945,
      "temperature": 0.0,
      "text": " Again, we can give or take a couple points",
      "tokens": [
        51222,
        3764,
        11,
        321,
        393,
        976,
        420,
        747,
        257,
        1916,
        2793,
        51332
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1809.1399688720703,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1807.6599655151367,
      "temperature": 0.0,
      "text": " for editing decisions.",
      "tokens": [
        51332,
        337,
        10000,
        5327,
        13,
        51406
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1812.1399688720703,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1809.1399688720703,
      "temperature": 0.0,
      "text": " So, you know, this leads me to kind of the big takeaway",
      "tokens": [
        51406,
        407,
        11,
        291,
        458,
        11,
        341,
        6689,
        385,
        281,
        733,
        295,
        264,
        955,
        30681,
        51556
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1814.819969177246,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1812.1399688720703,
      "temperature": 0.0,
      "text": " from the work I'm doing here and some, you know,",
      "tokens": [
        51556,
        490,
        264,
        589,
        286,
        478,
        884,
        510,
        293,
        512,
        11,
        291,
        458,
        11,
        51690
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.18401528894901276,
      "compression_ratio": 1.6870503425598145,
      "end": 1817.6599655151367,
      "no_speech_prob": 0.0007096632616594434,
      "seek": 8452,
      "start": 1814.819969177246,
      "temperature": 0.0,
      "text": " potential advice and direction that you can take from this",
      "tokens": [
        51690,
        3995,
        5192,
        293,
        3513,
        300,
        291,
        393,
        747,
        490,
        341,
        51832
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.25401657819747925,
      "compression_ratio": 1.4888888597488403,
      "end": 1819.699966430664,
      "no_speech_prob": 0.024796171113848686,
      "seek": 11388,
      "start": 1817.699966430664,
      "temperature": 0.0,
      "text": " for your generative AI work.",
      "tokens": [
        50366,
        337,
        428,
        1337,
        1166,
        7318,
        589,
        13,
        50466
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.25401657819747925,
      "compression_ratio": 1.4888888597488403,
      "end": 1826.4199676513672,
      "no_speech_prob": 0.024796171113848686,
      "seek": 11388,
      "start": 1822.2599716186523,
      "temperature": 0.0,
      "text": " Very clearly, you likely don't need an AI agent.",
      "tokens": [
        50594,
        4372,
        4448,
        11,
        291,
        3700,
        500,
        380,
        643,
        364,
        7318,
        9461,
        13,
        50802
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.25401657819747925,
      "compression_ratio": 1.4888888597488403,
      "end": 1828.6599655151367,
      "no_speech_prob": 0.024796171113848686,
      "seek": 11388,
      "start": 1826.4199676513672,
      "temperature": 0.0,
      "text": " You know, whenever there's a new tool that comes out,",
      "tokens": [
        50802,
        509,
        458,
        11,
        5699,
        456,
        311,
        257,
        777,
        2290,
        300,
        1487,
        484,
        11,
        50914
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.25401657819747925,
      "compression_ratio": 1.4888888597488403,
      "end": 1832.1399688720703,
      "no_speech_prob": 0.024796171113848686,
      "seek": 11388,
      "start": 1828.6599655151367,
      "temperature": 0.0,
      "text": " we always want to use the tool and check out the tool",
      "tokens": [
        50914,
        321,
        1009,
        528,
        281,
        764,
        264,
        2290,
        293,
        1520,
        484,
        264,
        2290,
        51088
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.25401657819747925,
      "compression_ratio": 1.4888888597488403,
      "end": 1833.0199737548828,
      "no_speech_prob": 0.024796171113848686,
      "seek": 11388,
      "start": 1832.1399688720703,
      "temperature": 0.0,
      "text": " and see what we can do with the tool.",
      "tokens": [
        51088,
        293,
        536,
        437,
        321,
        393,
        360,
        365,
        264,
        2290,
        13,
        51132
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.25401657819747925,
      "compression_ratio": 1.4888888597488403,
      "end": 1833.8599700927734,
      "no_speech_prob": 0.024796171113848686,
      "seek": 11388,
      "start": 1833.0199737548828,
      "temperature": 0.0,
      "text": " That's fine.",
      "tokens": [
        51132,
        663,
        311,
        2489,
        13,
        51174
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.25401657819747925,
      "compression_ratio": 1.4888888597488403,
      "end": 1834.699966430664,
      "no_speech_prob": 0.024796171113848686,
      "seek": 11388,
      "start": 1833.8599700927734,
      "temperature": 0.0,
      "text": " But when you're really solving-",
      "tokens": [
        51174,
        583,
        562,
        291,
        434,
        534,
        12606,
        12,
        51216
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_014.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1836.5999658107758,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1834.8399658203125,
      "temperature": 0.0,
      "text": " some problems when you're really in the mindset",
      "tokens": [
        50364,
        512,
        2740,
        562,
        291,
        434,
        534,
        294,
        264,
        12543,
        50452
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1839.1599659919739,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1836.5999658107758,
      "temperature": 0.0,
      "text": " of value creation, you find problems first",
      "tokens": [
        50452,
        295,
        2158,
        8016,
        11,
        291,
        915,
        2740,
        700,
        50580
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1842.359965801239,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1839.1599659919739,
      "temperature": 0.0,
      "text": " and then you apply tools to them from your tool belt.",
      "tokens": [
        50580,
        293,
        550,
        291,
        3079,
        3873,
        281,
        552,
        490,
        428,
        2290,
        10750,
        13,
        50740
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1844.1199655532837,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1842.359965801239,
      "temperature": 0.0,
      "text": " You don't find tools first",
      "tokens": [
        50740,
        509,
        500,
        380,
        915,
        3873,
        700,
        50828
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1846.0399656295776,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1844.1199655532837,
      "temperature": 0.0,
      "text": " and then look for problems to solve.",
      "tokens": [
        50828,
        293,
        550,
        574,
        337,
        2740,
        281,
        5039,
        13,
        50924
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1846.9599657058716,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1846.0399656295776,
      "temperature": 0.0,
      "text": " It's just the wrong way.",
      "tokens": [
        50924,
        467,
        311,
        445,
        264,
        2085,
        636,
        13,
        50970
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1848.4799661636353,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1846.9599657058716,
      "temperature": 0.0,
      "text": " It's the backward way to do things.",
      "tokens": [
        50970,
        467,
        311,
        264,
        23897,
        636,
        281,
        360,
        721,
        13,
        51046
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1850.9199657440186,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1848.4799661636353,
      "temperature": 0.0,
      "text": " I was really happy to see that Anthropic",
      "tokens": [
        51046,
        286,
        390,
        534,
        2055,
        281,
        536,
        300,
        12727,
        39173,
        51168
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1854.0999660491943,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1850.9199657440186,
      "temperature": 0.0,
      "text": " explicitly mentions this in their documentation.",
      "tokens": [
        51168,
        20803,
        23844,
        341,
        294,
        641,
        14333,
        13,
        51327
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1857.3199653625488,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1854.0999660491943,
      "temperature": 0.0,
      "text": " It's about building the right systems for your needs.",
      "tokens": [
        51327,
        467,
        311,
        466,
        2390,
        264,
        558,
        3652,
        337,
        428,
        2203,
        13,
        51488
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.2244783490896225,
      "compression_ratio": 1.7406015396118164,
      "end": 1861.0199661254883,
      "no_speech_prob": 0.003824355313554406,
      "seek": 0,
      "start": 1857.3199653625488,
      "temperature": 0.0,
      "text": " Start with prompts, then optimize them with evals",
      "tokens": [
        51488,
        6481,
        365,
        41095,
        11,
        550,
        19719,
        552,
        365,
        1073,
        1124,
        51673
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1863.8199653625488,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1861.0199661254883,
      "temperature": 0.0,
      "text": " and then add multi-step agentic systems,",
      "tokens": [
        50364,
        293,
        550,
        909,
        4825,
        12,
        16792,
        9461,
        299,
        3652,
        11,
        50504
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1867.9399642944336,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1863.8199653625488,
      "temperature": 0.0,
      "text": " AKA prompt chains, workflows, graphs,",
      "tokens": [
        50504,
        45933,
        12391,
        12626,
        11,
        43461,
        11,
        24877,
        11,
        50710
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1869.8199653625488,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1867.9399642944336,
      "temperature": 0.0,
      "text": " whatever you want to call it, it doesn't matter.",
      "tokens": [
        50710,
        2035,
        291,
        528,
        281,
        818,
        309,
        11,
        309,
        1177,
        380,
        1871,
        13,
        50804
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1872.539966583252,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1869.8199653625488,
      "temperature": 0.0,
      "text": " You only do that when the simpler solutions fail.",
      "tokens": [
        50804,
        509,
        787,
        360,
        300,
        562,
        264,
        18587,
        6547,
        3061,
        13,
        50940
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1876.0199661254883,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1872.539966583252,
      "temperature": 0.0,
      "text": " It looks like for my problem here,",
      "tokens": [
        50940,
        467,
        1542,
        411,
        337,
        452,
        1154,
        510,
        11,
        51114
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1881.0199661254883,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1876.0199661254883,
      "temperature": 0.0,
      "text": " for the problem space of editing down words in a transcript,",
      "tokens": [
        51114,
        337,
        264,
        1154,
        1901,
        295,
        10000,
        760,
        2283,
        294,
        257,
        24444,
        11,
        51364
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1884.4599647521973,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1881.7799644470215,
      "temperature": 0.0,
      "text": " it looks like what I'm actually looking for here",
      "tokens": [
        51402,
        309,
        1542,
        411,
        437,
        286,
        478,
        767,
        1237,
        337,
        510,
        51536
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1887.6199645996094,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1884.4599647521973,
      "temperature": 0.0,
      "text": " is for my step four, my AI agents,",
      "tokens": [
        51536,
        307,
        337,
        452,
        1823,
        1451,
        11,
        452,
        7318,
        12554,
        11,
        51694
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.23027345538139343,
      "compression_ratio": 1.615384578704834,
      "end": 1889.3399658203125,
      "no_speech_prob": 0.01150780450552702,
      "seek": 2618,
      "start": 1887.6199645996094,
      "temperature": 0.0,
      "text": " they actually don't need to be AI agents.",
      "tokens": [
        51694,
        436,
        767,
        500,
        380,
        643,
        281,
        312,
        7318,
        12554,
        13,
        51780
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1891.6599655151367,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1889.3399658203125,
      "temperature": 0.0,
      "text": " They can just be prompt chains.",
      "tokens": [
        50364,
        814,
        393,
        445,
        312,
        12391,
        12626,
        13,
        50480
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1894.8599662780762,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1891.6599655151367,
      "temperature": 0.0,
      "text": " These are concrete steps, predefined steps",
      "tokens": [
        50480,
        1981,
        366,
        9859,
        4439,
        11,
        659,
        37716,
        4439,
        50640
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1898.0199661254883,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1894.8599662780762,
      "temperature": 0.0,
      "text": " of executing a prompt and then updating some state",
      "tokens": [
        50640,
        295,
        32368,
        257,
        12391,
        293,
        550,
        25113,
        512,
        1785,
        50798
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1899.7399673461914,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1898.0199661254883,
      "temperature": 0.0,
      "text": " and then running another prompt.",
      "tokens": [
        50798,
        293,
        550,
        2614,
        1071,
        12391,
        13,
        50884
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1902.859962463379,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1899.7399673461914,
      "temperature": 0.0,
      "text": " It looks like for my intelligent editing system,",
      "tokens": [
        50884,
        467,
        1542,
        411,
        337,
        452,
        13232,
        10000,
        1185,
        11,
        51040
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1905.859962463379,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1902.859962463379,
      "temperature": 0.0,
      "text": " I really only need prompt chains.",
      "tokens": [
        51040,
        286,
        534,
        787,
        643,
        12391,
        12626,
        13,
        51190
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1909.3799667358398,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1905.859962463379,
      "temperature": 0.0,
      "text": " And that means that inside of this, for my intelligence,",
      "tokens": [
        51190,
        400,
        300,
        1355,
        300,
        1854,
        295,
        341,
        11,
        337,
        452,
        7599,
        11,
        51366
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1913.8999633789062,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1909.3799667358398,
      "temperature": 0.0,
      "text": " I really only need to let my assistant run over and over",
      "tokens": [
        51366,
        286,
        534,
        787,
        643,
        281,
        718,
        452,
        10994,
        1190,
        670,
        293,
        670,
        51592
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1915.2999649047852,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1913.8999633789062,
      "temperature": 0.0,
      "text": " on a series of steps.",
      "tokens": [
        51592,
        322,
        257,
        2638,
        295,
        4439,
        13,
        51662
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.19119501113891602,
      "compression_ratio": 1.7833333015441895,
      "end": 1917.699966430664,
      "no_speech_prob": 0.0002694784780032933,
      "seek": 5450,
      "start": 1915.2999649047852,
      "temperature": 0.0,
      "text": " Now, of course, there are tons of caveats to that.",
      "tokens": [
        51662,
        823,
        11,
        295,
        1164,
        11,
        456,
        366,
        9131,
        295,
        11730,
        1720,
        281,
        300,
        13,
        51782
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1919.5399627685547,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1917.699966430664,
      "temperature": 0.0,
      "text": " I don't really have enough data, right?",
      "tokens": [
        50364,
        286,
        500,
        380,
        534,
        362,
        1547,
        1412,
        11,
        558,
        30,
        50456
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1923.2599639892578,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1919.5399627685547,
      "temperature": 0.0,
      "text": " This is not significant data to make a complete decision",
      "tokens": [
        50456,
        639,
        307,
        406,
        4776,
        1412,
        281,
        652,
        257,
        3566,
        3537,
        50642
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1924.699966430664,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1923.2599639892578,
      "temperature": 0.0,
      "text": " to completely rule out AI agents.",
      "tokens": [
        50642,
        281,
        2584,
        4978,
        484,
        7318,
        12554,
        13,
        50714
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1926.2199630737305,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1924.699966430664,
      "temperature": 0.0,
      "text": " Obviously, that's not enough,",
      "tokens": [
        50714,
        7580,
        11,
        300,
        311,
        406,
        1547,
        11,
        50790
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1929.0199661254883,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1926.2199630737305,
      "temperature": 0.0,
      "text": " but I think it's just really important to stress that point.",
      "tokens": [
        50790,
        457,
        286,
        519,
        309,
        311,
        445,
        534,
        1021,
        281,
        4244,
        300,
        935,
        13,
        50930
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1931.6599655151367,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1929.0199661254883,
      "temperature": 0.0,
      "text": " If a prompt chain can do the job for you,",
      "tokens": [
        50930,
        759,
        257,
        12391,
        5021,
        393,
        360,
        264,
        1691,
        337,
        291,
        11,
        51062
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1932.8999633789062,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1931.6599655151367,
      "temperature": 0.0,
      "text": " use a prompt chain.",
      "tokens": [
        51062,
        764,
        257,
        12391,
        5021,
        13,
        51124
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1935.0599670410156,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1932.8999633789062,
      "temperature": 0.0,
      "text": " I think to push a little bit further,",
      "tokens": [
        51124,
        286,
        519,
        281,
        2944,
        257,
        707,
        857,
        3052,
        11,
        51232
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1937.2199630737305,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1935.0599670410156,
      "temperature": 0.0,
      "text": " you can experiment with an AI agent",
      "tokens": [
        51232,
        291,
        393,
        5120,
        365,
        364,
        7318,
        9461,
        51340
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1938.979965209961,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1937.2199630737305,
      "temperature": 0.0,
      "text": " and see what that might look like",
      "tokens": [
        51340,
        293,
        536,
        437,
        300,
        1062,
        574,
        411,
        51428
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1941.859962463379,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1938.979965209961,
      "temperature": 0.0,
      "text": " to give your AI agent full autonomy over the system.",
      "tokens": [
        51428,
        281,
        976,
        428,
        7318,
        9461,
        1577,
        27278,
        670,
        264,
        1185,
        13,
        51572
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.1687486320734024,
      "compression_ratio": 1.7006802558898926,
      "end": 1944.4199676513672,
      "no_speech_prob": 0.0009849963244050741,
      "seek": 8286,
      "start": 1941.859962463379,
      "temperature": 0.0,
      "text": " But I think that what we're going to see moving forward",
      "tokens": [
        51572,
        583,
        286,
        519,
        300,
        437,
        321,
        434,
        516,
        281,
        536,
        2684,
        2128,
        51700
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1947.819969177246,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1944.4599685668945,
      "temperature": 0.0,
      "text": " is that a lot of the AI agents that are going to be built",
      "tokens": [
        50366,
        307,
        300,
        257,
        688,
        295,
        264,
        7318,
        12554,
        300,
        366,
        516,
        281,
        312,
        3094,
        50534
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1948.6599655151367,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1947.819969177246,
      "temperature": 0.0,
      "text": " underneath the hood,",
      "tokens": [
        50534,
        7223,
        264,
        13376,
        11,
        50576
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1950.579963684082,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1948.6599655151367,
      "temperature": 0.0,
      "text": " they're not actually going to be AI agents.",
      "tokens": [
        50576,
        436,
        434,
        406,
        767,
        516,
        281,
        312,
        7318,
        12554,
        13,
        50672
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1952.5399627685547,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1950.579963684082,
      "temperature": 0.0,
      "text": " They're going to be agentic workflows.",
      "tokens": [
        50672,
        814,
        434,
        516,
        281,
        312,
        9461,
        299,
        43461,
        13,
        50770
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1953.6599655151367,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1952.5399627685547,
      "temperature": 0.0,
      "text": " And more specifically,",
      "tokens": [
        50770,
        400,
        544,
        4682,
        11,
        50826
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1956.1399688720703,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1953.6599655151367,
      "temperature": 0.0,
      "text": " they're going to be just prompt chains.",
      "tokens": [
        50826,
        436,
        434,
        516,
        281,
        312,
        445,
        12391,
        12626,
        13,
        50950
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1958.2199630737305,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1956.1399688720703,
      "temperature": 0.0,
      "text": " So just to recap, there are three levels to this.",
      "tokens": [
        50950,
        407,
        445,
        281,
        20928,
        11,
        456,
        366,
        1045,
        4358,
        281,
        341,
        13,
        51054
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1959.6199645996094,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1958.2199630737305,
      "temperature": 0.0,
      "text": " You have just the raw prompt,",
      "tokens": [
        51054,
        509,
        362,
        445,
        264,
        8936,
        12391,
        11,
        51124
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1963.9399719238281,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1959.6199645996094,
      "temperature": 0.0,
      "text": " you have what are called workflows or prompt chains or graphs,",
      "tokens": [
        51124,
        291,
        362,
        437,
        366,
        1219,
        43461,
        420,
        12391,
        12626,
        420,
        24877,
        11,
        51340
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.22231127321720123,
      "compression_ratio": 1.8584474325180054,
      "end": 1966.0999603271484,
      "no_speech_prob": 0.26272350549697876,
      "seek": 10958,
      "start": 1963.9399719238281,
      "temperature": 0.0,
      "text": " and then you have much more autonomous.",
      "tokens": [
        51340,
        293,
        550,
        291,
        362,
        709,
        544,
        23797,
        13,
        51448
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_015.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1968.139963388443,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1965.8999633789062,
      "temperature": 0.0,
      "text": " this agents that just have a bunch of tools,",
      "tokens": [
        50364,
        341,
        12554,
        300,
        445,
        362,
        257,
        3840,
        295,
        3873,
        11,
        50476
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1970.8599634170532,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1968.139963388443,
      "temperature": 0.0,
      "text": " you give them a problem, you give the right context,",
      "tokens": [
        50476,
        291,
        976,
        552,
        257,
        1154,
        11,
        291,
        976,
        264,
        558,
        4319,
        11,
        50612
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1972.8999633789062,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1970.8599634170532,
      "temperature": 0.0,
      "text": " and then you just say, go solve my problem.",
      "tokens": [
        50612,
        293,
        550,
        291,
        445,
        584,
        11,
        352,
        5039,
        452,
        1154,
        13,
        50714
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1973.8999633789062,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1972.8999633789062,
      "temperature": 0.0,
      "text": " You know, under the hood,",
      "tokens": [
        50714,
        509,
        458,
        11,
        833,
        264,
        13376,
        11,
        50764
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1976.3199634552002,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1973.8999633789062,
      "temperature": 0.0,
      "text": " I think what's really going to happen",
      "tokens": [
        50764,
        286,
        519,
        437,
        311,
        534,
        516,
        281,
        1051,
        50885
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1978.2799634933472,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1976.3199634552002,
      "temperature": 0.0,
      "text": " is that we're going to see tons and tons",
      "tokens": [
        50885,
        307,
        300,
        321,
        434,
        516,
        281,
        536,
        9131,
        293,
        9131,
        50983
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1980.039963722229,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1978.2799634933472,
      "temperature": 0.0,
      "text": " of agentic workflows, right?",
      "tokens": [
        50983,
        295,
        9461,
        299,
        43461,
        11,
        558,
        30,
        51071
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1982.2799625396729,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1980.039963722229,
      "temperature": 0.0,
      "text": " Or put simply, prompt chains, right?",
      "tokens": [
        51071,
        1610,
        829,
        2935,
        11,
        12391,
        12626,
        11,
        558,
        30,
        51183
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1983.8199634552002,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1982.2799625396729,
      "temperature": 0.0,
      "text": " There are many very interesting,",
      "tokens": [
        51183,
        821,
        366,
        867,
        588,
        1880,
        11,
        51260
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1986.8399639129639,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1983.8199634552002,
      "temperature": 0.0,
      "text": " very powerful ways to use prompt chains, right?",
      "tokens": [
        51260,
        588,
        4005,
        2098,
        281,
        764,
        12391,
        12626,
        11,
        558,
        30,
        51411
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1989.0999641418457,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1986.8399639129639,
      "temperature": 0.0,
      "text": " And Anthropic has detailed a lot of them here.",
      "tokens": [
        51411,
        400,
        12727,
        39173,
        575,
        9942,
        257,
        688,
        295,
        552,
        510,
        13,
        51524
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1991.4399642944336,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1989.0999641418457,
      "temperature": 0.0,
      "text": " We have routing, we have parallelization.",
      "tokens": [
        51524,
        492,
        362,
        32722,
        11,
        321,
        362,
        8952,
        2144,
        13,
        51641
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1993.5999641418457,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1991.4399642944336,
      "temperature": 0.0,
      "text": " I like to call this the fusion chain.",
      "tokens": [
        51641,
        286,
        411,
        281,
        818,
        341,
        264,
        23100,
        5021,
        13,
        51749
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.22714844346046448,
      "compression_ratio": 1.7337461709976196,
      "end": 1995.7999629974365,
      "no_speech_prob": 0.13474483788013458,
      "seek": 0,
      "start": 1993.5999641418457,
      "temperature": 0.0,
      "text": " We put a video out on this in the past.",
      "tokens": [
        51749,
        492,
        829,
        257,
        960,
        484,
        322,
        341,
        294,
        264,
        1791,
        13,
        51859
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 1997.5999641418457,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 1996.6199626922607,
      "temperature": 0.0,
      "text": " And then we have orchestrators.",
      "tokens": [
        50405,
        400,
        550,
        321,
        362,
        14161,
        34886,
        13,
        50454
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2000.3999633789062,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 1997.5999641418457,
      "temperature": 0.0,
      "text": " There's definitely a good call for using an orchestrator",
      "tokens": [
        50454,
        821,
        311,
        2138,
        257,
        665,
        818,
        337,
        1228,
        364,
        14161,
        19802,
        50594
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2002.4999618530273,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2000.3999633789062,
      "temperature": 0.0,
      "text": " for a cut, evaluator, optimizer.",
      "tokens": [
        50594,
        337,
        257,
        1723,
        11,
        6133,
        1639,
        11,
        5028,
        6545,
        13,
        50699
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2003.639965057373,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2002.4999618530273,
      "temperature": 0.0,
      "text": " And then we can go down the line, right?",
      "tokens": [
        50699,
        400,
        550,
        321,
        393,
        352,
        760,
        264,
        1622,
        11,
        558,
        30,
        50756
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2005.3399620056152,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2003.639965057373,
      "temperature": 0.0,
      "text": " All the way down to the AI agent.",
      "tokens": [
        50756,
        1057,
        264,
        636,
        760,
        281,
        264,
        7318,
        9461,
        13,
        50841
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2007.3199615478516,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2005.3399620056152,
      "temperature": 0.0,
      "text": " And the AI agent workflow is the most interesting",
      "tokens": [
        50841,
        400,
        264,
        7318,
        9461,
        20993,
        307,
        264,
        881,
        1880,
        50940
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2009.639965057373,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2007.3199615478516,
      "temperature": 0.0,
      "text": " because in a certain way, it's the most hands-off.",
      "tokens": [
        50940,
        570,
        294,
        257,
        1629,
        636,
        11,
        309,
        311,
        264,
        881,
        2377,
        12,
        4506,
        13,
        51056
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2012.079963684082,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2009.639965057373,
      "temperature": 0.0,
      "text": " I think there's a lot of value to be created here,",
      "tokens": [
        51056,
        286,
        519,
        456,
        311,
        257,
        688,
        295,
        2158,
        281,
        312,
        2942,
        510,
        11,
        51178
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2015.639965057373,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2012.079963684082,
      "temperature": 0.0,
      "text": " but the trick is always benchmarking the performance",
      "tokens": [
        51178,
        457,
        264,
        4282,
        307,
        1009,
        18927,
        278,
        264,
        3389,
        51356
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2020.519962310791,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2015.639965057373,
      "temperature": 0.0,
      "text": " of your AI agent versus a predefined series of steps",
      "tokens": [
        51356,
        295,
        428,
        7318,
        9461,
        5717,
        257,
        659,
        37716,
        2638,
        295,
        4439,
        51600
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.2555289566516876,
      "compression_ratio": 1.7250858545303345,
      "end": 2023.7599639892578,
      "no_speech_prob": 0.00012148063979111612,
      "seek": 2990,
      "start": 2020.519962310791,
      "temperature": 0.0,
      "text": " that call prompts and tools, AKA prompt chains.",
      "tokens": [
        51600,
        300,
        818,
        41095,
        293,
        3873,
        11,
        45933,
        12391,
        12626,
        13,
        51762
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2025.359962463379,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2023.7599639892578,
      "temperature": 0.0,
      "text": " A couple of improvements",
      "tokens": [
        50364,
        316,
        1916,
        295,
        13797,
        50444
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2027.0399627685547,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2025.359962463379,
      "temperature": 0.0,
      "text": " that I'm thinking about making for a cut.",
      "tokens": [
        50444,
        300,
        286,
        478,
        1953,
        466,
        1455,
        337,
        257,
        1723,
        13,
        50528
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2029.8399620056152,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2027.0399627685547,
      "temperature": 0.0,
      "text": " It's pretty clear that this super harsh,",
      "tokens": [
        50528,
        467,
        311,
        1238,
        1850,
        300,
        341,
        1687,
        14897,
        11,
        50668
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2032.9599609375,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2029.8399620056152,
      "temperature": 0.0,
      "text": " yes, no response framework that I have here,",
      "tokens": [
        50668,
        2086,
        11,
        572,
        4134,
        8388,
        300,
        286,
        362,
        510,
        11,
        50824
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2035.3999633789062,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2032.9599609375,
      "temperature": 0.0,
      "text": " where we just have correct, true, or false,",
      "tokens": [
        50824,
        689,
        321,
        445,
        362,
        3006,
        11,
        2074,
        11,
        420,
        7908,
        11,
        50946
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2036.9599609375,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2035.3999633789062,
      "temperature": 0.0,
      "text": " isn't going to be accurate enough",
      "tokens": [
        50946,
        1943,
        380,
        516,
        281,
        312,
        8559,
        1547,
        51024
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2038.7199630737305,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2036.9599609375,
      "temperature": 0.0,
      "text": " to create comprehensive benchmarks.",
      "tokens": [
        51024,
        281,
        1884,
        13914,
        43751,
        13,
        51112
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2040.5599670410156,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2038.7199630737305,
      "temperature": 0.0,
      "text": " Rolling out something like Levenstein distance",
      "tokens": [
        51112,
        36457,
        484,
        746,
        411,
        1456,
        553,
        9089,
        4560,
        51204
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 33,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2043.359962463379,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2040.5599670410156,
      "temperature": 0.0,
      "text": " to allow for a five to 10 character difference",
      "tokens": [
        51204,
        281,
        2089,
        337,
        257,
        1732,
        281,
        1266,
        2517,
        2649,
        51344
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 34,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2045.2799606323242,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2043.359962463379,
      "temperature": 0.0,
      "text": " is probably going to be a big win",
      "tokens": [
        51344,
        307,
        1391,
        516,
        281,
        312,
        257,
        955,
        1942,
        51440
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 35,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2048.079963684082,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2045.2799606323242,
      "temperature": 0.0,
      "text": " for improving these benchmarks going forward.",
      "tokens": [
        51440,
        337,
        11470,
        613,
        43751,
        516,
        2128,
        13,
        51580
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 36,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2051.1199645996094,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2048.079963684082,
      "temperature": 0.0,
      "text": " You know, another big thing that piggybacks off this",
      "tokens": [
        51580,
        509,
        458,
        11,
        1071,
        955,
        551,
        300,
        39349,
        17758,
        766,
        341,
        51732
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 37,
      "avg_logprob": -0.2177339792251587,
      "compression_ratio": 1.6837060451507568,
      "end": 2052.779960632324,
      "no_speech_prob": 0.017985593527555466,
      "seek": 5786,
      "start": 2051.1199645996094,
      "temperature": 0.0,
      "text": " is that, you know, video editing,",
      "tokens": [
        51732,
        307,
        300,
        11,
        291,
        458,
        11,
        960,
        10000,
        11,
        51815
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 38,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2055.259963989258,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2052.779960632324,
      "temperature": 0.0,
      "text": " even when you're just editing out transcripts,",
      "tokens": [
        50364,
        754,
        562,
        291,
        434,
        445,
        10000,
        484,
        24444,
        82,
        11,
        50488
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 39,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2057.8999633789062,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2055.259963989258,
      "temperature": 0.0,
      "text": " it's a very subjective experience.",
      "tokens": [
        50488,
        309,
        311,
        257,
        588,
        25972,
        1752,
        13,
        50620
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 40,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2061.479965209961,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2057.8999633789062,
      "temperature": 0.0,
      "text": " Certain editing decisions that a model will make",
      "tokens": [
        50620,
        13407,
        10000,
        5327,
        300,
        257,
        2316,
        486,
        652,
        50799
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 41,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2063.0599670410156,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2061.479965209961,
      "temperature": 0.0,
      "text": " are totally valid and legit.",
      "tokens": [
        50799,
        366,
        3879,
        7363,
        293,
        10275,
        13,
        50878
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 42,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2065.9199600219727,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2063.0599670410156,
      "temperature": 0.0,
      "text": " And it might not match up with the exact target,",
      "tokens": [
        50878,
        400,
        309,
        1062,
        406,
        2995,
        493,
        365,
        264,
        1900,
        3779,
        11,
        51021
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 43,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2067.779960632324,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2065.9199600219727,
      "temperature": 0.0,
      "text": " even within the five or 10 characters",
      "tokens": [
        51021,
        754,
        1951,
        264,
        1732,
        420,
        1266,
        4342,
        51114
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 44,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2070.299964904785,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2067.779960632324,
      "temperature": 0.0,
      "text": " using the Levenstein distance that could actually work.",
      "tokens": [
        51114,
        1228,
        264,
        1456,
        553,
        9089,
        4560,
        300,
        727,
        767,
        589,
        13,
        51240
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 45,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2072.4599609375,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2070.299964904785,
      "temperature": 0.0,
      "text": " So I think a more concrete way to improve that",
      "tokens": [
        51240,
        407,
        286,
        519,
        257,
        544,
        9859,
        636,
        281,
        3470,
        300,
        51348
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 46,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2075.9999618530273,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2072.4599609375,
      "temperature": 0.0,
      "text": " is to add more comprehensive examples",
      "tokens": [
        51348,
        307,
        281,
        909,
        544,
        13914,
        5110,
        51525
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 47,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2078.37996673584,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2075.9999618530273,
      "temperature": 0.0,
      "text": " into the prompts themselves.",
      "tokens": [
        51525,
        666,
        264,
        41095,
        2969,
        13,
        51644
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 48,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2079.5399627685547,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2078.37996673584,
      "temperature": 0.0,
      "text": " You know, why is that important?",
      "tokens": [
        51644,
        509,
        458,
        11,
        983,
        307,
        300,
        1021,
        30,
        51702
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 49,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2081.179962158203,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2079.5399627685547,
      "temperature": 0.0,
      "text": " How can that change the outcome?",
      "tokens": [
        51702,
        1012,
        393,
        300,
        1319,
        264,
        9700,
        30,
        51784
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 50,
      "avg_logprob": -0.19102443754673004,
      "compression_ratio": 1.6172839403152466,
      "end": 2082.679962158203,
      "no_speech_prob": 0.001032222993671894,
      "seek": 8688,
      "start": 2081.179962158203,
      "temperature": 0.0,
      "text": " That's super important because, you know,",
      "tokens": [
        51784,
        663,
        311,
        1687,
        1021,
        570,
        11,
        291,
        458,
        11,
        51859
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 51,
      "avg_logprob": -0.27171802520751953,
      "compression_ratio": 1.559999942779541,
      "end": 2085.3999633789062,
      "no_speech_prob": 0.01115746796131134,
      "seek": 11678,
      "start": 2083.4599609375,
      "temperature": 0.0,
      "text": " when we add examples to our prompts to, you know,",
      "tokens": [
        50403,
        562,
        321,
        909,
        5110,
        281,
        527,
        41095,
        281,
        11,
        291,
        458,
        11,
        50500
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 52,
      "avg_logprob": -0.27171802520751953,
      "compression_ratio": 1.559999942779541,
      "end": 2088.479965209961,
      "no_speech_prob": 0.01115746796131134,
      "seek": 11678,
      "start": 2085.3999633789062,
      "temperature": 0.0,
      "text": " give us an idea about what types of edits we wanted to make,",
      "tokens": [
        50500,
        976,
        505,
        364,
        1558,
        466,
        437,
        3467,
        295,
        41752,
        321,
        1415,
        281,
        652,
        11,
        50654
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 53,
      "avg_logprob": -0.27171802520751953,
      "compression_ratio": 1.559999942779541,
      "end": 2090.4399642944336,
      "no_speech_prob": 0.01115746796131134,
      "seek": 11678,
      "start": 2088.479965209961,
      "temperature": 0.0,
      "text": " it'll pick up on the taste of our editing",
      "tokens": [
        50654,
        309,
        603,
        1888,
        493,
        322,
        264,
        3939,
        295,
        527,
        10000,
        50752
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 54,
      "avg_logprob": -0.27171802520751953,
      "compression_ratio": 1.559999942779541,
      "end": 2092.5399627685547,
      "no_speech_prob": 0.01115746796131134,
      "seek": 11678,
      "start": 2090.4399642944336,
      "temperature": 0.0,
      "text": " and what words we like to keep in and keep out,",
      "tokens": [
        50752,
        293,
        437,
        2283,
        321,
        411,
        281,
        1066,
        294,
        293,
        1066,
        484,
        11,
        50857
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 55,
      "avg_logprob": -0.27171802520751953,
      "compression_ratio": 1.559999942779541,
      "end": 2093.37996673584,
      "no_speech_prob": 0.01115746796131134,
      "seek": 11678,
      "start": 2092.5399627685547,
      "temperature": 0.0,
      "text": " so on and so forth.",
      "tokens": [
        50857,
        370,
        322,
        293,
        370,
        5220,
        13,
        50899
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 56,
      "avg_logprob": -0.27171802520751953,
      "compression_ratio": 1.559999942779541,
      "end": 2095.159957885742,
      "no_speech_prob": 0.01115746796131134,
      "seek": 11678,
      "start": 2093.37996673584,
      "temperature": 0.0,
      "text": " So more work to be done on that,",
      "tokens": [
        50899,
        407,
        544,
        589,
        281,
        312,
        1096,
        322,
        300,
        11,
        50988
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 57,
      "avg_logprob": -0.27171802520751953,
      "compression_ratio": 1.559999942779541,
      "end": 2096.9599609375,
      "no_speech_prob": 0.01115746796131134,
      "seek": 11678,
      "start": 2095.159957885742,
      "temperature": 0.0,
      "text": " adding in examples.",
      "tokens": [
        50988,
        5127,
        294,
        5110,
        13,
        51078
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_016.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2589476406574249,
      "compression_ratio": 1.7638888359069824,
      "end": 2101.159960746765,
      "no_speech_prob": 0.06463973969221115,
      "seek": 0,
      "start": 2096.9599609375,
      "temperature": 0.0,
      "text": " tag here, it's going to be really important for making the model more consistent with",
      "tokens": [
        50364,
        6162,
        510,
        11,
        309,
        311,
        516,
        281,
        312,
        534,
        1021,
        337,
        1455,
        264,
        2316,
        544,
        8398,
        365,
        50574
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2589476406574249,
      "compression_ratio": 1.7638888359069824,
      "end": 2103.119960784912,
      "no_speech_prob": 0.06463973969221115,
      "seek": 0,
      "start": 2101.159960746765,
      "temperature": 0.0,
      "text": " my personal editing style.",
      "tokens": [
        50574,
        452,
        2973,
        10000,
        3758,
        13,
        50672
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2589476406574249,
      "compression_ratio": 1.7638888359069824,
      "end": 2108.039960861206,
      "no_speech_prob": 0.06463973969221115,
      "seek": 0,
      "start": 2103.119960784912,
      "temperature": 0.0,
      "text": " So something to think about for your prompt chains and AI agents, examples that guide",
      "tokens": [
        50672,
        407,
        746,
        281,
        519,
        466,
        337,
        428,
        12391,
        12626,
        293,
        7318,
        12554,
        11,
        5110,
        300,
        5934,
        50918
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2589476406574249,
      "compression_ratio": 1.7638888359069824,
      "end": 2115.3199615478516,
      "no_speech_prob": 0.06463973969221115,
      "seek": 0,
      "start": 2108.039960861206,
      "temperature": 0.0,
      "text": " your model in these more creative, more subjective decision making domains is a great way to",
      "tokens": [
        50918,
        428,
        2316,
        294,
        613,
        544,
        5880,
        11,
        544,
        25972,
        3537,
        1455,
        25514,
        307,
        257,
        869,
        636,
        281,
        51282
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2589476406574249,
      "compression_ratio": 1.7638888359069824,
      "end": 2118.0599613189697,
      "no_speech_prob": 0.06463973969221115,
      "seek": 0,
      "start": 2115.3199615478516,
      "temperature": 0.0,
      "text": " guide your model and to guide the outcome.",
      "tokens": [
        51282,
        5934,
        428,
        2316,
        293,
        281,
        5934,
        264,
        9700,
        13,
        51419
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2589476406574249,
      "compression_ratio": 1.7638888359069824,
      "end": 2121.719961166382,
      "no_speech_prob": 0.06463973969221115,
      "seek": 0,
      "start": 2118.0599613189697,
      "temperature": 0.0,
      "text": " And of course, the best way to do this is benchmarking, but also run this against real",
      "tokens": [
        51419,
        400,
        295,
        1164,
        11,
        264,
        1151,
        636,
        281,
        360,
        341,
        307,
        18927,
        278,
        11,
        457,
        611,
        1190,
        341,
        1970,
        957,
        51602
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 6,
      "avg_logprob": -0.2589476406574249,
      "compression_ratio": 1.7638888359069824,
      "end": 2126.6599617004395,
      "no_speech_prob": 0.06463973969221115,
      "seek": 0,
      "start": 2121.719961166382,
      "temperature": 0.0,
      "text": " data and then in a reinforcement learning type of way, take the edits that are working",
      "tokens": [
        51602,
        1412,
        293,
        550,
        294,
        257,
        29280,
        2539,
        2010,
        295,
        636,
        11,
        747,
        264,
        41752,
        300,
        366,
        1364,
        51849
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 7,
      "avg_logprob": -0.2315772920846939,
      "compression_ratio": 1.7426470518112183,
      "end": 2131.2599601745605,
      "no_speech_prob": 0.01150767132639885,
      "seek": 2970,
      "start": 2126.6599617004395,
      "temperature": 0.0,
      "text": " coming out of the model and update the prompt that was feeling that model with those correct",
      "tokens": [
        50364,
        1348,
        484,
        295,
        264,
        2316,
        293,
        5623,
        264,
        12391,
        300,
        390,
        2633,
        300,
        2316,
        365,
        729,
        3006,
        50594
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 8,
      "avg_logprob": -0.2315772920846939,
      "compression_ratio": 1.7426470518112183,
      "end": 2132.6599617004395,
      "no_speech_prob": 0.01150767132639885,
      "seek": 2970,
      "start": 2131.2599601745605,
      "temperature": 0.0,
      "text": " edits as examples, right?",
      "tokens": [
        50594,
        41752,
        382,
        5110,
        11,
        558,
        30,
        50664
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 9,
      "avg_logprob": -0.2315772920846939,
      "compression_ratio": 1.7426470518112183,
      "end": 2136.6599617004395,
      "no_speech_prob": 0.01150767132639885,
      "seek": 2970,
      "start": 2132.6599617004395,
      "temperature": 0.0,
      "text": " So more on that in the future, I have some pretty interesting ideas around automatic",
      "tokens": [
        50664,
        407,
        544,
        322,
        300,
        294,
        264,
        2027,
        11,
        286,
        362,
        512,
        1238,
        1880,
        3487,
        926,
        12509,
        50864
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 10,
      "avg_logprob": -0.2315772920846939,
      "compression_ratio": 1.7426470518112183,
      "end": 2142.4599609375,
      "no_speech_prob": 0.01150767132639885,
      "seek": 2970,
      "start": 2136.6599617004395,
      "temperature": 0.0,
      "text": " feedback looped prompts to add more auto self-improving behavior into the prompt.",
      "tokens": [
        50864,
        5824,
        6367,
        292,
        41095,
        281,
        909,
        544,
        8399,
        2698,
        12,
        332,
        4318,
        798,
        5223,
        666,
        264,
        12391,
        13,
        51154
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 11,
      "avg_logprob": -0.2315772920846939,
      "compression_ratio": 1.7426470518112183,
      "end": 2147.4599609375,
      "no_speech_prob": 0.01150767132639885,
      "seek": 2970,
      "start": 2142.4599609375,
      "temperature": 0.0,
      "text": " Another interesting problem that I'm running into is that idea of not solving the problem",
      "tokens": [
        51154,
        3996,
        1880,
        1154,
        300,
        286,
        478,
        2614,
        666,
        307,
        300,
        1558,
        295,
        406,
        12606,
        264,
        1154,
        51404
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 12,
      "avg_logprob": -0.2315772920846939,
      "compression_ratio": 1.7426470518112183,
      "end": 2148.4599609375,
      "no_speech_prob": 0.01150767132639885,
      "seek": 2970,
      "start": 2147.4599609375,
      "temperature": 0.0,
      "text": " at all.",
      "tokens": [
        51404,
        412,
        439,
        13,
        51454
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 13,
      "avg_logprob": -0.2315772920846939,
      "compression_ratio": 1.7426470518112183,
      "end": 2154.059959411621,
      "no_speech_prob": 0.01150767132639885,
      "seek": 2970,
      "start": 2148.4599609375,
      "temperature": 0.0,
      "text": " I think one of the strongest signs of a high level problem solver, a senior level engineer",
      "tokens": [
        51454,
        286,
        519,
        472,
        295,
        264,
        16595,
        7880,
        295,
        257,
        1090,
        1496,
        1154,
        1404,
        331,
        11,
        257,
        7965,
        1496,
        11403,
        51734
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 14,
      "avg_logprob": -0.23152877390384674,
      "compression_ratio": 1.6254826784133911,
      "end": 2160.7599601745605,
      "no_speech_prob": 0.09008479118347168,
      "seek": 5710,
      "start": 2154.059959411621,
      "temperature": 0.0,
      "text": " is the ability to look at a problem and decide that it doesn't need to be solved at all.",
      "tokens": [
        50364,
        307,
        264,
        3485,
        281,
        574,
        412,
        257,
        1154,
        293,
        4536,
        300,
        309,
        1177,
        380,
        643,
        281,
        312,
        13041,
        412,
        439,
        13,
        50699
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 15,
      "avg_logprob": -0.23152877390384674,
      "compression_ratio": 1.6254826784133911,
      "end": 2165.859962463379,
      "no_speech_prob": 0.09008479118347168,
      "seek": 5710,
      "start": 2160.7599601745605,
      "temperature": 0.0,
      "text": " And this is tricky to teach or explain to an LLM because these are next token generators,",
      "tokens": [
        50699,
        400,
        341,
        307,
        12414,
        281,
        2924,
        420,
        2903,
        281,
        364,
        441,
        43,
        44,
        570,
        613,
        366,
        958,
        14862,
        38662,
        11,
        50954
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 16,
      "avg_logprob": -0.23152877390384674,
      "compression_ratio": 1.6254826784133911,
      "end": 2168.4199600219727,
      "no_speech_prob": 0.09008479118347168,
      "seek": 5710,
      "start": 2165.859962463379,
      "temperature": 0.0,
      "text": " not next token, not generators.",
      "tokens": [
        50954,
        406,
        958,
        14862,
        11,
        406,
        38662,
        13,
        51082
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 17,
      "avg_logprob": -0.23152877390384674,
      "compression_ratio": 1.6254826784133911,
      "end": 2172.4799575805664,
      "no_speech_prob": 0.09008479118347168,
      "seek": 5710,
      "start": 2168.4199600219727,
      "temperature": 0.0,
      "text": " For edits, I've run into this several times with this tool already, where the best thing",
      "tokens": [
        51082,
        1171,
        41752,
        11,
        286,
        600,
        1190,
        666,
        341,
        2940,
        1413,
        365,
        341,
        2290,
        1217,
        11,
        689,
        264,
        1151,
        551,
        51285
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 18,
      "avg_logprob": -0.23152877390384674,
      "compression_ratio": 1.6254826784133911,
      "end": 2174.5399627685547,
      "no_speech_prob": 0.09008479118347168,
      "seek": 5710,
      "start": 2172.4799575805664,
      "temperature": 0.0,
      "text": " to do is nothing, right?",
      "tokens": [
        51285,
        281,
        360,
        307,
        1825,
        11,
        558,
        30,
        51388
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 19,
      "avg_logprob": -0.23152877390384674,
      "compression_ratio": 1.6254826784133911,
      "end": 2180.2999572753906,
      "no_speech_prob": 0.09008479118347168,
      "seek": 5710,
      "start": 2174.5399627685547,
      "temperature": 0.0,
      "text": " The slice in a real video will sometimes contain perfect script and nothing needs to be changed.",
      "tokens": [
        51388,
        440,
        13153,
        294,
        257,
        957,
        960,
        486,
        2171,
        5304,
        2176,
        5755,
        293,
        1825,
        2203,
        281,
        312,
        3105,
        13,
        51676
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 20,
      "avg_logprob": -0.2401713728904724,
      "compression_ratio": 1.8819187879562378,
      "end": 2184.859962463379,
      "no_speech_prob": 0.039045050740242004,
      "seek": 8334,
      "start": 2180.2999572753906,
      "temperature": 0.0,
      "text": " So, you know, I think probably more prompt engineering and explicitly mentioning when",
      "tokens": [
        50364,
        407,
        11,
        291,
        458,
        11,
        286,
        519,
        1391,
        544,
        12391,
        7043,
        293,
        20803,
        18315,
        562,
        50592
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 21,
      "avg_logprob": -0.2401713728904724,
      "compression_ratio": 1.8819187879562378,
      "end": 2189.859962463379,
      "no_speech_prob": 0.039045050740242004,
      "seek": 8334,
      "start": 2184.859962463379,
      "temperature": 0.0,
      "text": " things need to be edited will be helpful for solving that problem inside of prompts, prompt",
      "tokens": [
        50592,
        721,
        643,
        281,
        312,
        23016,
        486,
        312,
        4961,
        337,
        12606,
        300,
        1154,
        1854,
        295,
        41095,
        11,
        12391,
        50842
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 22,
      "avg_logprob": -0.2401713728904724,
      "compression_ratio": 1.8819187879562378,
      "end": 2191.6999588012695,
      "no_speech_prob": 0.039045050740242004,
      "seek": 8334,
      "start": 2189.859962463379,
      "temperature": 0.0,
      "text": " chains and AI agents.",
      "tokens": [
        50842,
        12626,
        293,
        7318,
        12554,
        13,
        50934
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 23,
      "avg_logprob": -0.2401713728904724,
      "compression_ratio": 1.8819187879562378,
      "end": 2197.259963989258,
      "no_speech_prob": 0.039045050740242004,
      "seek": 8334,
      "start": 2191.6999588012695,
      "temperature": 0.0,
      "text": " So, you know, the next time you want to solve a problem with generative AI, first start",
      "tokens": [
        50934,
        407,
        11,
        291,
        458,
        11,
        264,
        958,
        565,
        291,
        528,
        281,
        5039,
        257,
        1154,
        365,
        1337,
        1166,
        7318,
        11,
        700,
        722,
        51212
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 24,
      "avg_logprob": -0.2401713728904724,
      "compression_ratio": 1.8819187879562378,
      "end": 2199.779960632324,
      "no_speech_prob": 0.039045050740242004,
      "seek": 8334,
      "start": 2197.259963989258,
      "temperature": 0.0,
      "text": " with a prompt, then move to a prompt chain.",
      "tokens": [
        51212,
        365,
        257,
        12391,
        11,
        550,
        1286,
        281,
        257,
        12391,
        5021,
        13,
        51338
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 25,
      "avg_logprob": -0.2401713728904724,
      "compression_ratio": 1.8819187879562378,
      "end": 2203.9399642944336,
      "no_speech_prob": 0.039045050740242004,
      "seek": 8334,
      "start": 2199.779960632324,
      "temperature": 0.0,
      "text": " And only if your prompt chain and your, you know, graph of steps is not giving you the",
      "tokens": [
        51338,
        400,
        787,
        498,
        428,
        12391,
        5021,
        293,
        428,
        11,
        291,
        458,
        11,
        4295,
        295,
        4439,
        307,
        406,
        2902,
        291,
        264,
        51546
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 26,
      "avg_logprob": -0.2401713728904724,
      "compression_ratio": 1.8819187879562378,
      "end": 2209.9399642944336,
      "no_speech_prob": 0.039045050740242004,
      "seek": 8334,
      "start": 2203.9399642944336,
      "temperature": 0.0,
      "text": " performance that you need, only then should you move to a full on AI agent that can operate",
      "tokens": [
        51546,
        3389,
        300,
        291,
        643,
        11,
        787,
        550,
        820,
        291,
        1286,
        281,
        257,
        1577,
        322,
        7318,
        9461,
        300,
        393,
        9651,
        51846
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 27,
      "avg_logprob": -0.2624400854110718,
      "compression_ratio": 1.7889447212219238,
      "end": 2212.0999603271484,
      "no_speech_prob": 0.06559734046459198,
      "seek": 11298,
      "start": 2209.9799575805664,
      "temperature": 0.0,
      "text": " in a domain for you automatically.",
      "tokens": [
        50366,
        294,
        257,
        9274,
        337,
        291,
        6772,
        13,
        50472
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 28,
      "avg_logprob": -0.2624400854110718,
      "compression_ratio": 1.7889447212219238,
      "end": 2216.2199630737305,
      "no_speech_prob": 0.06559734046459198,
      "seek": 11298,
      "start": 2212.0999603271484,
      "temperature": 0.0,
      "text": " I highly recommend, you know, throughout that process, the more important the problem you're",
      "tokens": [
        50472,
        286,
        5405,
        2748,
        11,
        291,
        458,
        11,
        3710,
        300,
        1399,
        11,
        264,
        544,
        1021,
        264,
        1154,
        291,
        434,
        50678
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 29,
      "avg_logprob": -0.2624400854110718,
      "compression_ratio": 1.7889447212219238,
      "end": 2219.779960632324,
      "no_speech_prob": 0.06559734046459198,
      "seek": 11298,
      "start": 2216.2199630737305,
      "temperature": 0.0,
      "text": " trying to solve, the more important it is to set up benchmarks so that you can know",
      "tokens": [
        50678,
        1382,
        281,
        5039,
        11,
        264,
        544,
        1021,
        309,
        307,
        281,
        992,
        493,
        43751,
        370,
        300,
        291,
        393,
        458,
        50856
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 30,
      "avg_logprob": -0.2624400854110718,
      "compression_ratio": 1.7889447212219238,
      "end": 2225.5799560546875,
      "no_speech_prob": 0.06559734046459198,
      "seek": 11298,
      "start": 2219.779960632324,
      "temperature": 0.0,
      "text": " for a fact that your prompt chain is outperforming your prompt and your AI agent is outperforming",
      "tokens": [
        50856,
        337,
        257,
        1186,
        300,
        428,
        12391,
        5021,
        307,
        484,
        26765,
        278,
        428,
        12391,
        293,
        428,
        7318,
        9461,
        307,
        484,
        26765,
        278,
        51146
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 31,
      "avg_logprob": -0.2624400854110718,
      "compression_ratio": 1.7889447212219238,
      "end": 2227.259963989258,
      "no_speech_prob": 0.06559734046459198,
      "seek": 11298,
      "start": 2225.5799560546875,
      "temperature": 0.0,
      "text": " your prompt chain.",
      "tokens": [
        51146,
        428,
        12391,
        5021,
        13,
        51230
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 32,
      "avg_logprob": -0.2624400854110718,
      "compression_ratio": 1.7889447212219238,
      "end": 2228.0999603271484,
      "no_speech_prob": 0.06559734046459198,
      "seek": 11298,
      "start": 2227.259963989258,
      "temperature": 0.0,
      "text": " Agents give us the ability.",
      "tokens": [
        51230,
        2725,
        791,
        976,
        505,
        264,
        3485,
        13,
        51272
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_017.mp3"
    },
    {
      "id": 0,
      "avg_logprob": -0.2425750195980072,
      "compression_ratio": 1.4186046123504639,
      "end": 2231.3799583911896,
      "no_speech_prob": 0.06840977072715759,
      "seek": 0,
      "start": 2228.0199584960938,
      "temperature": 0.0,
      "text": " to scale our impact even further beyond.",
      "tokens": [
        50364,
        281,
        4373,
        527,
        2712,
        754,
        3052,
        4399,
        13,
        50532
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_018.mp3"
    },
    {
      "id": 1,
      "avg_logprob": -0.2425750195980072,
      "compression_ratio": 1.4186046123504639,
      "end": 2232.9999585151672,
      "no_speech_prob": 0.06840977072715759,
      "seek": 0,
      "start": 2231.3799583911896,
      "temperature": 0.0,
      "text": " We're gonna be talking, and more importantly,",
      "tokens": [
        50532,
        492,
        434,
        799,
        312,
        1417,
        11,
        293,
        544,
        8906,
        11,
        50613
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_018.mp3"
    },
    {
      "id": 2,
      "avg_logprob": -0.2425750195980072,
      "compression_ratio": 1.4186046123504639,
      "end": 2236.2399587631226,
      "no_speech_prob": 0.06840977072715759,
      "seek": 0,
      "start": 2232.9999585151672,
      "temperature": 0.0,
      "text": " building agents on the channel over 2025.",
      "tokens": [
        50613,
        2390,
        12554,
        322,
        264,
        2269,
        670,
        39209,
        13,
        50775
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_018.mp3"
    },
    {
      "id": 3,
      "avg_logprob": -0.2425750195980072,
      "compression_ratio": 1.4186046123504639,
      "end": 2238.1999588012695,
      "no_speech_prob": 0.06840977072715759,
      "seek": 0,
      "start": 2236.2399587631226,
      "temperature": 0.0,
      "text": " Like, subscribe, and comment",
      "tokens": [
        50775,
        1743,
        11,
        3022,
        11,
        293,
        2871,
        50873
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_018.mp3"
    },
    {
      "id": 4,
      "avg_logprob": -0.2425750195980072,
      "compression_ratio": 1.4186046123504639,
      "end": 2240.1199588775635,
      "no_speech_prob": 0.06840977072715759,
      "seek": 0,
      "start": 2238.1999588012695,
      "temperature": 0.0,
      "text": " to stay connected to this content.",
      "tokens": [
        50873,
        281,
        1754,
        4582,
        281,
        341,
        2701,
        13,
        50969
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_018.mp3"
    },
    {
      "id": 5,
      "avg_logprob": -0.2425750195980072,
      "compression_ratio": 1.4186046123504639,
      "end": 2243.879958152771,
      "no_speech_prob": 0.06840977072715759,
      "seek": 0,
      "start": 2240.1199588775635,
      "temperature": 0.0,
      "text": " And no matter what, stay focused and keep building.",
      "tokens": [
        50969,
        400,
        572,
        1871,
        437,
        11,
        1754,
        5178,
        293,
        1066,
        2390,
        13,
        51157
      ],
      "chunk_source": "age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_018.mp3"
    }
  ],
  "created_at": 1742835517.7476742,
  "num_chunks": 18,
  "language": "english"
}
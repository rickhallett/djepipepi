{
  "audio_path": "data/chunks/single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_003.mp3",
  "text": "the results to us. We're using multiple libraries inside of a single file. So how is this possible? We have to give credit to Astral's UV. You can think of this as bun for Python. It's the all-in-one Python ecosystem manager. It basically replaces every other Python tool. And most importantly for us, for these powerful single file agents, it gives us this ability, run scripts with support for inline dependency metadata. Let's dive into this feature right now so we can see how we're building out these powerful single file agents. So if we open up our DuckDB OpenAI agent here, you can see right at the top of this file, something fascinating, right? We have dependencies. You know, you saw with this single command here, right? We had UV run. This creates a sandbox environment. This allows us to run the script as a standalone file with these dependencies included. So we have OpenAI, Rich, and Pydantic. So this is the first key aspect of the single file agent structure. We need to be able to load and use dependencies from any Python library. Most importantly, we need a model provider, right? So now we have this, we have access to this and our single file agent. Now, what does the agentic structure look like for this agent? You can see we're using Pydantic to create our argument structure. So for instance, for our list table args, we have the model pass and reasoning. This is a powerful pattern to help you understand what your language model was thinking at every single step. If we open up every one of these tool argument structures, I'm always requesting reasoning. You can see it there, you can see it there, so on and so forth, right? So that's a super important pattern you can use when building your agents, always passing reasoning, and then always log the reasoning. So you can see we have tools, we have the agent prompt, but the most important thing is the agentic loop down here. So let's go ahead and break this down. And then let's go ahead and look at how we can distribute this pattern with AI coding to scale it up to an entirely new AI agent. So at the start here, we're pulling up the agentic loop. So we're pulling up the agentic loop, and then we're pulling up the reasoning loop. So we're pulling up the reasoning loop, and then we're pulling up the agentic loop.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 2.0199999809265137,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " the results to us.",
      "tokens": [
        50364,
        264,
        3542,
        281,
        505,
        13,
        50465
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 5.260000228881836,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 2.0199999809265137,
      "temperature": 0.0,
      "text": " We're using multiple libraries inside of a single file.",
      "tokens": [
        50465,
        492,
        434,
        1228,
        3866,
        15148,
        1854,
        295,
        257,
        2167,
        3991,
        13,
        50627
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 6.179999828338623,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 5.260000228881836,
      "temperature": 0.0,
      "text": " So how is this possible?",
      "tokens": [
        50627,
        407,
        577,
        307,
        341,
        1944,
        30,
        50673
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 9.579999923706055,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 6.179999828338623,
      "temperature": 0.0,
      "text": " We have to give credit to Astral's UV.",
      "tokens": [
        50673,
        492,
        362,
        281,
        976,
        5397,
        281,
        12884,
        2155,
        311,
        17887,
        13,
        50843
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 12.539999961853027,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 9.579999923706055,
      "temperature": 0.0,
      "text": " You can think of this as bun for Python.",
      "tokens": [
        50843,
        509,
        393,
        519,
        295,
        341,
        382,
        6702,
        337,
        15329,
        13,
        50991
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 15.760000228881836,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 12.539999961853027,
      "temperature": 0.0,
      "text": " It's the all-in-one Python ecosystem manager.",
      "tokens": [
        50991,
        467,
        311,
        264,
        439,
        12,
        259,
        12,
        546,
        15329,
        11311,
        6598,
        13,
        51152
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 18.940000534057617,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 15.760000228881836,
      "temperature": 0.0,
      "text": " It basically replaces every other Python tool.",
      "tokens": [
        51152,
        467,
        1936,
        46734,
        633,
        661,
        15329,
        2290,
        13,
        51311
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 20.780000686645508,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 18.940000534057617,
      "temperature": 0.0,
      "text": " And most importantly for us,",
      "tokens": [
        51311,
        400,
        881,
        8906,
        337,
        505,
        11,
        51403
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 23.139999389648438,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 20.780000686645508,
      "temperature": 0.0,
      "text": " for these powerful single file agents,",
      "tokens": [
        51403,
        337,
        613,
        4005,
        2167,
        3991,
        12554,
        11,
        51521
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.24623902142047882,
      "compression_ratio": 1.5313807725906372,
      "end": 25.020000457763672,
      "no_speech_prob": 0.07368456572294235,
      "seek": 0,
      "start": 23.139999389648438,
      "temperature": 0.0,
      "text": " it gives us this ability,",
      "tokens": [
        51521,
        309,
        2709,
        505,
        341,
        3485,
        11,
        51615
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 30.020000457763672,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 25.020000457763672,
      "temperature": 0.0,
      "text": " run scripts with support for inline dependency metadata.",
      "tokens": [
        50364,
        1190,
        23294,
        365,
        1406,
        337,
        294,
        1889,
        33621,
        26603,
        13,
        50614
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 32.279998779296875,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 30.360000610351562,
      "temperature": 0.0,
      "text": " Let's dive into this feature right now",
      "tokens": [
        50631,
        961,
        311,
        9192,
        666,
        341,
        4111,
        558,
        586,
        50727
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 34.08000183105469,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 32.279998779296875,
      "temperature": 0.0,
      "text": " so we can see how we're building out",
      "tokens": [
        50727,
        370,
        321,
        393,
        536,
        577,
        321,
        434,
        2390,
        484,
        50817
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 35.880001068115234,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 34.08000183105469,
      "temperature": 0.0,
      "text": " these powerful single file agents.",
      "tokens": [
        50817,
        613,
        4005,
        2167,
        3991,
        12554,
        13,
        50907
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 44.34000015258789,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 40.459999084472656,
      "temperature": 0.0,
      "text": " So if we open up our DuckDB OpenAI agent here,",
      "tokens": [
        51136,
        407,
        498,
        321,
        1269,
        493,
        527,
        29266,
        27735,
        7238,
        48698,
        9461,
        510,
        11,
        51330
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 46.599998474121094,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 44.34000015258789,
      "temperature": 0.0,
      "text": " you can see right at the top of this file,",
      "tokens": [
        51330,
        291,
        393,
        536,
        558,
        412,
        264,
        1192,
        295,
        341,
        3991,
        11,
        51443
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 48.439998626708984,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 46.599998474121094,
      "temperature": 0.0,
      "text": " something fascinating, right?",
      "tokens": [
        51443,
        746,
        10343,
        11,
        558,
        30,
        51535
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 50.36000061035156,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 48.439998626708984,
      "temperature": 0.0,
      "text": " We have dependencies.",
      "tokens": [
        51535,
        492,
        362,
        36606,
        13,
        51631
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.24025101959705353,
      "compression_ratio": 1.566523551940918,
      "end": 53.47999954223633,
      "no_speech_prob": 0.09945682436227798,
      "seek": 2502,
      "start": 50.36000061035156,
      "temperature": 0.0,
      "text": " You know, you saw with this single command here, right?",
      "tokens": [
        51631,
        509,
        458,
        11,
        291,
        1866,
        365,
        341,
        2167,
        5622,
        510,
        11,
        558,
        30,
        51787
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 55.119998931884766,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 53.47999954223633,
      "temperature": 0.0,
      "text": " We had UV run.",
      "tokens": [
        50364,
        492,
        632,
        17887,
        1190,
        13,
        50446
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 58.060001373291016,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 55.119998931884766,
      "temperature": 0.0,
      "text": " This creates a sandbox environment.",
      "tokens": [
        50446,
        639,
        7829,
        257,
        42115,
        2823,
        13,
        50593
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 61.400001525878906,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 58.060001373291016,
      "temperature": 0.0,
      "text": " This allows us to run the script as a standalone file",
      "tokens": [
        50593,
        639,
        4045,
        505,
        281,
        1190,
        264,
        5755,
        382,
        257,
        37454,
        3991,
        50760
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 63.540000915527344,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 61.400001525878906,
      "temperature": 0.0,
      "text": " with these dependencies included.",
      "tokens": [
        50760,
        365,
        613,
        36606,
        5556,
        13,
        50867
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 65.9000015258789,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 63.540000915527344,
      "temperature": 0.0,
      "text": " So we have OpenAI, Rich, and Pydantic.",
      "tokens": [
        50867,
        407,
        321,
        362,
        7238,
        48698,
        11,
        6781,
        11,
        293,
        430,
        6655,
        7128,
        13,
        50985
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 68.08000183105469,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 65.9000015258789,
      "temperature": 0.0,
      "text": " So this is the first key aspect",
      "tokens": [
        50985,
        407,
        341,
        307,
        264,
        700,
        2141,
        4171,
        51094
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 70.0999984741211,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 68.08000183105469,
      "temperature": 0.0,
      "text": " of the single file agent structure.",
      "tokens": [
        51094,
        295,
        264,
        2167,
        3991,
        9461,
        3877,
        13,
        51195
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 72.31999969482422,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 70.0999984741211,
      "temperature": 0.0,
      "text": " We need to be able to load and use dependencies",
      "tokens": [
        51195,
        492,
        643,
        281,
        312,
        1075,
        281,
        3677,
        293,
        764,
        36606,
        51306
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 74.83999633789062,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 72.31999969482422,
      "temperature": 0.0,
      "text": " from any Python library.",
      "tokens": [
        51306,
        490,
        604,
        15329,
        6405,
        13,
        51432
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 77.55999755859375,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 74.83999633789062,
      "temperature": 0.0,
      "text": " Most importantly, we need a model provider, right?",
      "tokens": [
        51432,
        4534,
        8906,
        11,
        321,
        643,
        257,
        2316,
        12398,
        11,
        558,
        30,
        51568
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 78.44000244140625,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 77.55999755859375,
      "temperature": 0.0,
      "text": " So now we have this,",
      "tokens": [
        51568,
        407,
        586,
        321,
        362,
        341,
        11,
        51612
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 80.5999984741211,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 78.44000244140625,
      "temperature": 0.0,
      "text": " we have access to this and our single file agent.",
      "tokens": [
        51612,
        321,
        362,
        2105,
        281,
        341,
        293,
        527,
        2167,
        3991,
        9461,
        13,
        51720
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.19976851344108582,
      "compression_ratio": 1.6851210594177246,
      "end": 83.19999694824219,
      "no_speech_prob": 9.314585622632876e-05,
      "seek": 5348,
      "start": 80.5999984741211,
      "temperature": 0.0,
      "text": " Now, what does the agentic structure look like",
      "tokens": [
        51720,
        823,
        11,
        437,
        775,
        264,
        9461,
        299,
        3877,
        574,
        411,
        51850
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 84.76000213623047,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 83.91999816894531,
      "temperature": 0.0,
      "text": " for this agent?",
      "tokens": [
        50400,
        337,
        341,
        9461,
        30,
        50442
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 85.58000183105469,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 84.76000213623047,
      "temperature": 0.0,
      "text": " You can see we're using Pydantic",
      "tokens": [
        50442,
        509,
        393,
        536,
        321,
        434,
        1228,
        430,
        6655,
        7128,
        50483
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 87.83999633789062,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 85.58000183105469,
      "temperature": 0.0,
      "text": " to create our argument structure.",
      "tokens": [
        50483,
        281,
        1884,
        527,
        6770,
        3877,
        13,
        50596
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 90.94000244140625,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 87.83999633789062,
      "temperature": 0.0,
      "text": " So for instance, for our list table args,",
      "tokens": [
        50596,
        407,
        337,
        5197,
        11,
        337,
        527,
        1329,
        3199,
        3882,
        82,
        11,
        50751
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 93.27999877929688,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 90.94000244140625,
      "temperature": 0.0,
      "text": " we have the model pass and reasoning.",
      "tokens": [
        50751,
        321,
        362,
        264,
        2316,
        1320,
        293,
        21577,
        13,
        50868
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 95.87999725341797,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 93.27999877929688,
      "temperature": 0.0,
      "text": " This is a powerful pattern to help you understand",
      "tokens": [
        50868,
        639,
        307,
        257,
        4005,
        5102,
        281,
        854,
        291,
        1223,
        50998
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 98.87999725341797,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 95.87999725341797,
      "temperature": 0.0,
      "text": " what your language model was thinking at every single step.",
      "tokens": [
        50998,
        437,
        428,
        2856,
        2316,
        390,
        1953,
        412,
        633,
        2167,
        1823,
        13,
        51148
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 102.0999984741211,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 98.87999725341797,
      "temperature": 0.0,
      "text": " If we open up every one of these tool argument structures,",
      "tokens": [
        51148,
        759,
        321,
        1269,
        493,
        633,
        472,
        295,
        613,
        2290,
        6770,
        9227,
        11,
        51309
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 104.5199966430664,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 102.0999984741211,
      "temperature": 0.0,
      "text": " I'm always requesting reasoning.",
      "tokens": [
        51309,
        286,
        478,
        1009,
        31937,
        21577,
        13,
        51430
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 106.63999938964844,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 104.5199966430664,
      "temperature": 0.0,
      "text": " You can see it there, you can see it there,",
      "tokens": [
        51430,
        509,
        393,
        536,
        309,
        456,
        11,
        291,
        393,
        536,
        309,
        456,
        11,
        51536
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 107.58000183105469,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 106.63999938964844,
      "temperature": 0.0,
      "text": " so on and so forth, right?",
      "tokens": [
        51536,
        370,
        322,
        293,
        370,
        5220,
        11,
        558,
        30,
        51583
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 109.4000015258789,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 107.58000183105469,
      "temperature": 0.0,
      "text": " So that's a super important pattern",
      "tokens": [
        51583,
        407,
        300,
        311,
        257,
        1687,
        1021,
        5102,
        51674
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 111.55999755859375,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 109.4000015258789,
      "temperature": 0.0,
      "text": " you can use when building your agents,",
      "tokens": [
        51674,
        291,
        393,
        764,
        562,
        2390,
        428,
        12554,
        11,
        51782
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.23275862634181976,
      "compression_ratio": 1.8047138452529907,
      "end": 112.95999908447266,
      "no_speech_prob": 0.007577013690024614,
      "seek": 8320,
      "start": 111.55999755859375,
      "temperature": 0.0,
      "text": " always passing reasoning,",
      "tokens": [
        51782,
        1009,
        8437,
        21577,
        11,
        51852
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 115.0999984741211,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 113.72000122070312,
      "temperature": 0.0,
      "text": " and then always log the reasoning.",
      "tokens": [
        50402,
        293,
        550,
        1009,
        3565,
        264,
        21577,
        13,
        50471
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 116.23999786376953,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 115.0999984741211,
      "temperature": 0.0,
      "text": " So you can see we have tools,",
      "tokens": [
        50471,
        407,
        291,
        393,
        536,
        321,
        362,
        3873,
        11,
        50528
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 117.23999786376953,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 116.23999786376953,
      "temperature": 0.0,
      "text": " we have the agent prompt,",
      "tokens": [
        50528,
        321,
        362,
        264,
        9461,
        12391,
        11,
        50578
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 120.16000366210938,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 117.23999786376953,
      "temperature": 0.0,
      "text": " but the most important thing is the agentic loop down here.",
      "tokens": [
        50578,
        457,
        264,
        881,
        1021,
        551,
        307,
        264,
        9461,
        299,
        6367,
        760,
        510,
        13,
        50724
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 121.5999984741211,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 120.16000366210938,
      "temperature": 0.0,
      "text": " So let's go ahead and break this down.",
      "tokens": [
        50724,
        407,
        718,
        311,
        352,
        2286,
        293,
        1821,
        341,
        760,
        13,
        50796
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 122.44000244140625,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 121.5999984741211,
      "temperature": 0.0,
      "text": " And then let's go ahead",
      "tokens": [
        50796,
        400,
        550,
        718,
        311,
        352,
        2286,
        50838
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 125.19999694824219,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 122.44000244140625,
      "temperature": 0.0,
      "text": " and look at how we can distribute this pattern",
      "tokens": [
        50838,
        293,
        574,
        412,
        577,
        321,
        393,
        20594,
        341,
        5102,
        50976
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 129.9199981689453,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 125.19999694824219,
      "temperature": 0.0,
      "text": " with AI coding to scale it up to an entirely new AI agent.",
      "tokens": [
        50976,
        365,
        7318,
        17720,
        281,
        4373,
        309,
        493,
        281,
        364,
        7696,
        777,
        7318,
        9461,
        13,
        51212
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 130.8800048828125,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 129.9199981689453,
      "temperature": 0.0,
      "text": " So at the start here,",
      "tokens": [
        51212,
        407,
        412,
        264,
        722,
        510,
        11,
        51260
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 132.72000122070312,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 130.8800048828125,
      "temperature": 0.0,
      "text": " we're pulling up the agentic loop.",
      "tokens": [
        51260,
        321,
        434,
        8407,
        493,
        264,
        9461,
        299,
        6367,
        13,
        51352
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 134.52000427246094,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 132.72000122070312,
      "temperature": 0.0,
      "text": " So we're pulling up the agentic loop,",
      "tokens": [
        51352,
        407,
        321,
        434,
        8407,
        493,
        264,
        9461,
        299,
        6367,
        11,
        51442
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 136.72000122070312,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 134.52000427246094,
      "temperature": 0.0,
      "text": " and then we're pulling up the reasoning loop.",
      "tokens": [
        51442,
        293,
        550,
        321,
        434,
        8407,
        493,
        264,
        21577,
        6367,
        13,
        51552
      ]
    },
    {
      "id": 58,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 138.52000427246094,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 136.72000122070312,
      "temperature": 0.0,
      "text": " So we're pulling up the reasoning loop,",
      "tokens": [
        51552,
        407,
        321,
        434,
        8407,
        493,
        264,
        21577,
        6367,
        11,
        51642
      ]
    },
    {
      "id": 59,
      "avg_logprob": -0.5081544518470764,
      "compression_ratio": 2.295358657836914,
      "end": 140.72000122070312,
      "no_speech_prob": 0.004829466808587313,
      "seek": 11296,
      "start": 138.52000427246094,
      "temperature": 0.0,
      "text": " and then we're pulling up the agentic loop.",
      "tokens": [
        51642,
        293,
        550,
        321,
        434,
        8407,
        493,
        264,
        9461,
        299,
        6367,
        13,
        51752
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834927.4845812
}
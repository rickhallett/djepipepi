{
  "audio_path": "data/chunks/best_codebase_architecture_for_ai_coding_and_ai_20250324_143507_chunk_006.mp3",
  "text": "your product inside your application. So we have the users feature slice and it contains API model service. We have the images feature and it contains you know API model and FFmpeg. Just to kind of make it clear you don't need the same file structure although this will definitely help your AI coding tools if you have you know similar api.py across all your features. And then we have the messaging feature at the bottom right. So you can see here how this can be super super clean super concise for AI coding tools. All you do is import this entire directory you context prime with this single directory and we're off to the races. You can even do a couple features if you're working on two features at once. So I hope you can see why this is a very very interesting codebase architecture to pay attention to. Pros things are organized by feature rather than some arbitrary technical layer. Okay and you know the arbitrary layer is some logical layer right it's there for a reason. But by organizing into a feature it's a lot easier to collect everything you need into a collection of context. A beautiful thing you can do here this is all one prompt context priming. So when you're setting up your AI coding tools it's just a single shot to get this working. Okay and I can show this off here very very quickly if we open up cursor and let's go into the single file agents codebase. I have this new directory here codebase architectures. If we open up a terminal cd into this codebase architecture vertical slice. So you know this is what vertical slice looks like. We have our features and then we have you know products tasks users. If we do ader dash dash no git and if we just do slash add features slash users slash we just set up all the codebase context we need right. This is it we're done. So you know ask what does this do and you know we're off to the races. Our AI coding assistant is primed it's good to go right. We can do the exact same thing if we want to boot up cloud code. We can cd codebase architectures vertical.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.2506793439388275,
      "compression_ratio": 1.7655677795410156,
      "end": 6.960000038146973,
      "no_speech_prob": 0.0900774598121643,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " your product inside your application. So we have the users feature slice and it contains API model",
      "tokens": [
        50364,
        428,
        447,
        5020,
        1854,
        428,
        3861,
        13,
        407,
        321,
        362,
        264,
        5022,
        4111,
        13153,
        293,
        309,
        8306,
        9362,
        2316,
        50712
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.2506793439388275,
      "compression_ratio": 1.7655677795410156,
      "end": 13.760000228881836,
      "no_speech_prob": 0.0900774598121643,
      "seek": 0,
      "start": 6.960000038146973,
      "temperature": 0.0,
      "text": " service. We have the images feature and it contains you know API model and FFmpeg. Just to kind of",
      "tokens": [
        50712,
        2643,
        13,
        492,
        362,
        264,
        5267,
        4111,
        293,
        309,
        8306,
        291,
        458,
        9362,
        2316,
        293,
        479,
        37,
        76,
        494,
        70,
        13,
        1449,
        281,
        733,
        295,
        51052
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.2506793439388275,
      "compression_ratio": 1.7655677795410156,
      "end": 17.520000457763672,
      "no_speech_prob": 0.0900774598121643,
      "seek": 0,
      "start": 13.760000228881836,
      "temperature": 0.0,
      "text": " make it clear you don't need the same file structure although this will definitely help",
      "tokens": [
        51052,
        652,
        309,
        1850,
        291,
        500,
        380,
        643,
        264,
        912,
        3991,
        3877,
        4878,
        341,
        486,
        2138,
        854,
        51240
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.2506793439388275,
      "compression_ratio": 1.7655677795410156,
      "end": 23.280000686645508,
      "no_speech_prob": 0.0900774598121643,
      "seek": 0,
      "start": 17.520000457763672,
      "temperature": 0.0,
      "text": " your AI coding tools if you have you know similar api.py across all your features. And then we have",
      "tokens": [
        51240,
        428,
        7318,
        17720,
        3873,
        498,
        291,
        362,
        291,
        458,
        2531,
        1882,
        72,
        13,
        8200,
        2108,
        439,
        428,
        4122,
        13,
        400,
        550,
        321,
        362,
        51528
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.2506793439388275,
      "compression_ratio": 1.7655677795410156,
      "end": 27.84000015258789,
      "no_speech_prob": 0.0900774598121643,
      "seek": 0,
      "start": 23.280000686645508,
      "temperature": 0.0,
      "text": " the messaging feature at the bottom right. So you can see here how this can be super super clean",
      "tokens": [
        51528,
        264,
        21812,
        4111,
        412,
        264,
        2767,
        558,
        13,
        407,
        291,
        393,
        536,
        510,
        577,
        341,
        393,
        312,
        1687,
        1687,
        2541,
        51756
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.2146192491054535,
      "compression_ratio": 1.618644118309021,
      "end": 37.119998931884766,
      "no_speech_prob": 0.0007096649496816099,
      "seek": 2784,
      "start": 28.559999465942383,
      "temperature": 0.0,
      "text": " super concise for AI coding tools. All you do is import this entire directory you context prime",
      "tokens": [
        50400,
        1687,
        44882,
        337,
        7318,
        17720,
        3873,
        13,
        1057,
        291,
        360,
        307,
        974,
        341,
        2302,
        21120,
        291,
        4319,
        5835,
        50828
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.2146192491054535,
      "compression_ratio": 1.618644118309021,
      "end": 42.720001220703125,
      "no_speech_prob": 0.0007096649496816099,
      "seek": 2784,
      "start": 37.119998931884766,
      "temperature": 0.0,
      "text": " with this single directory and we're off to the races. You can even do a couple features if you're",
      "tokens": [
        50828,
        365,
        341,
        2167,
        21120,
        293,
        321,
        434,
        766,
        281,
        264,
        15484,
        13,
        509,
        393,
        754,
        360,
        257,
        1916,
        4122,
        498,
        291,
        434,
        51108
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.2146192491054535,
      "compression_ratio": 1.618644118309021,
      "end": 48.63999938964844,
      "no_speech_prob": 0.0007096649496816099,
      "seek": 2784,
      "start": 42.720001220703125,
      "temperature": 0.0,
      "text": " working on two features at once. So I hope you can see why this is a very very interesting",
      "tokens": [
        51108,
        1364,
        322,
        732,
        4122,
        412,
        1564,
        13,
        407,
        286,
        1454,
        291,
        393,
        536,
        983,
        341,
        307,
        257,
        588,
        588,
        1880,
        51404
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.2146192491054535,
      "compression_ratio": 1.618644118309021,
      "end": 55.279998779296875,
      "no_speech_prob": 0.0007096649496816099,
      "seek": 2784,
      "start": 48.63999938964844,
      "temperature": 0.0,
      "text": " codebase architecture to pay attention to. Pros things are organized by feature rather than some",
      "tokens": [
        51404,
        3089,
        17429,
        9482,
        281,
        1689,
        3202,
        281,
        13,
        26024,
        721,
        366,
        9983,
        538,
        4111,
        2831,
        813,
        512,
        51736
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.7318840026855469,
      "end": 60.880001068115234,
      "no_speech_prob": 0.011157875880599022,
      "seek": 5528,
      "start": 55.279998779296875,
      "temperature": 0.0,
      "text": " arbitrary technical layer. Okay and you know the arbitrary layer is some logical layer right it's",
      "tokens": [
        50364,
        23211,
        6191,
        4583,
        13,
        1033,
        293,
        291,
        458,
        264,
        23211,
        4583,
        307,
        512,
        14978,
        4583,
        558,
        309,
        311,
        50644
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.7318840026855469,
      "end": 66.23999786376953,
      "no_speech_prob": 0.011157875880599022,
      "seek": 5528,
      "start": 60.880001068115234,
      "temperature": 0.0,
      "text": " there for a reason. But by organizing into a feature it's a lot easier to collect everything",
      "tokens": [
        50644,
        456,
        337,
        257,
        1778,
        13,
        583,
        538,
        17608,
        666,
        257,
        4111,
        309,
        311,
        257,
        688,
        3571,
        281,
        2500,
        1203,
        50912
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.7318840026855469,
      "end": 72.72000122070312,
      "no_speech_prob": 0.011157875880599022,
      "seek": 5528,
      "start": 66.23999786376953,
      "temperature": 0.0,
      "text": " you need into a collection of context. A beautiful thing you can do here this is all one prompt",
      "tokens": [
        50912,
        291,
        643,
        666,
        257,
        5765,
        295,
        4319,
        13,
        316,
        2238,
        551,
        291,
        393,
        360,
        510,
        341,
        307,
        439,
        472,
        12391,
        51236
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.7318840026855469,
      "end": 77.36000061035156,
      "no_speech_prob": 0.011157875880599022,
      "seek": 5528,
      "start": 72.72000122070312,
      "temperature": 0.0,
      "text": " context priming. So when you're setting up your AI coding tools it's just a single shot to get",
      "tokens": [
        51236,
        4319,
        2886,
        278,
        13,
        407,
        562,
        291,
        434,
        3287,
        493,
        428,
        7318,
        17720,
        3873,
        309,
        311,
        445,
        257,
        2167,
        3347,
        281,
        483,
        51468
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.19621127843856812,
      "compression_ratio": 1.7318840026855469,
      "end": 83.5199966430664,
      "no_speech_prob": 0.011157875880599022,
      "seek": 5528,
      "start": 77.36000061035156,
      "temperature": 0.0,
      "text": " this working. Okay and I can show this off here very very quickly if we open up cursor and let's",
      "tokens": [
        51468,
        341,
        1364,
        13,
        1033,
        293,
        286,
        393,
        855,
        341,
        766,
        510,
        588,
        588,
        2661,
        498,
        321,
        1269,
        493,
        28169,
        293,
        718,
        311,
        51776
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.24764886498451233,
      "compression_ratio": 1.8317307233810425,
      "end": 89.76000213623047,
      "no_speech_prob": 0.0029809661209583282,
      "seek": 8352,
      "start": 83.5199966430664,
      "temperature": 0.0,
      "text": " go into the single file agents codebase. I have this new directory here codebase architectures.",
      "tokens": [
        50364,
        352,
        666,
        264,
        2167,
        3991,
        12554,
        3089,
        17429,
        13,
        286,
        362,
        341,
        777,
        21120,
        510,
        3089,
        17429,
        6331,
        1303,
        13,
        50676
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.24764886498451233,
      "compression_ratio": 1.8317307233810425,
      "end": 95.27999877929688,
      "no_speech_prob": 0.0029809661209583282,
      "seek": 8352,
      "start": 89.76000213623047,
      "temperature": 0.0,
      "text": " If we open up a terminal cd into this codebase architecture vertical slice. So you know this",
      "tokens": [
        50676,
        759,
        321,
        1269,
        493,
        257,
        14709,
        269,
        67,
        666,
        341,
        3089,
        17429,
        9482,
        9429,
        13153,
        13,
        407,
        291,
        458,
        341,
        50952
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.24764886498451233,
      "compression_ratio": 1.8317307233810425,
      "end": 99.5199966430664,
      "no_speech_prob": 0.0029809661209583282,
      "seek": 8352,
      "start": 95.27999877929688,
      "temperature": 0.0,
      "text": " is what vertical slice looks like. We have our features and then we have you know products tasks",
      "tokens": [
        50952,
        307,
        437,
        9429,
        13153,
        1542,
        411,
        13,
        492,
        362,
        527,
        4122,
        293,
        550,
        321,
        362,
        291,
        458,
        3383,
        9608,
        51164
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.24764886498451233,
      "compression_ratio": 1.8317307233810425,
      "end": 109.12000274658203,
      "no_speech_prob": 0.0029809661209583282,
      "seek": 8352,
      "start": 99.5199966430664,
      "temperature": 0.0,
      "text": " users. If we do ader dash dash no git and if we just do slash add features slash users slash we",
      "tokens": [
        51164,
        5022,
        13,
        759,
        321,
        360,
        257,
        1068,
        8240,
        8240,
        572,
        18331,
        293,
        498,
        321,
        445,
        360,
        17330,
        909,
        4122,
        17330,
        5022,
        17330,
        321,
        51644
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.25629717111587524,
      "compression_ratio": 1.5499999523162842,
      "end": 115.04000091552734,
      "no_speech_prob": 0.0002913672069553286,
      "seek": 10912,
      "start": 109.12000274658203,
      "temperature": 0.0,
      "text": " just set up all the codebase context we need right. This is it we're done. So you know ask",
      "tokens": [
        50364,
        445,
        992,
        493,
        439,
        264,
        3089,
        17429,
        4319,
        321,
        643,
        558,
        13,
        639,
        307,
        309,
        321,
        434,
        1096,
        13,
        407,
        291,
        458,
        1029,
        50660
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.25629717111587524,
      "compression_ratio": 1.5499999523162842,
      "end": 122.80000305175781,
      "no_speech_prob": 0.0002913672069553286,
      "seek": 10912,
      "start": 116.0,
      "temperature": 0.0,
      "text": " what does this do and you know we're off to the races. Our AI coding assistant is primed it's good",
      "tokens": [
        50708,
        437,
        775,
        341,
        360,
        293,
        291,
        458,
        321,
        434,
        766,
        281,
        264,
        15484,
        13,
        2621,
        7318,
        17720,
        10994,
        307,
        2886,
        292,
        309,
        311,
        665,
        51048
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.25629717111587524,
      "compression_ratio": 1.5499999523162842,
      "end": 129.36000061035156,
      "no_speech_prob": 0.0002913672069553286,
      "seek": 10912,
      "start": 122.80000305175781,
      "temperature": 0.0,
      "text": " to go right. We can do the exact same thing if we want to boot up cloud code. We can cd codebase",
      "tokens": [
        51048,
        281,
        352,
        558,
        13,
        492,
        393,
        360,
        264,
        1900,
        912,
        551,
        498,
        321,
        528,
        281,
        11450,
        493,
        4588,
        3089,
        13,
        492,
        393,
        269,
        67,
        3089,
        17429,
        51376
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.25629717111587524,
      "compression_ratio": 1.5499999523162842,
      "end": 130.72000122070312,
      "no_speech_prob": 0.0002913672069553286,
      "seek": 10912,
      "start": 129.36000061035156,
      "temperature": 0.0,
      "text": " architectures vertical.",
      "tokens": [
        51376,
        6331,
        1303,
        9429,
        13,
        51444
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835167.056022
}
{
  "audio_path": "data/chunks/gpt_4_5_flop_claude_3_7_sonnet_starter_pack_what_20250324_151153_chunk_014.mp3",
  "text": "As Robert mentioned, I found this to be really useful. Basically, you just start with the bare minimum and track your token usage as we are here. If you never hit the 1K mark, you never need to go to 2K. All right, so this is really cool. So we just finished and you can see here our output tokens chewed up 6K, right? So we really, really pushed it. We really got that. Wow, look at that up. You can really see that this model pushed really hard here. My word calculation is likely off. We're likely not counting. It likely got a lot closer here than we think. When you're really pushing the output tokens, this is when you're gonna boost up the costs. So this is really powerful, right? So this is an example of using both the streaming with the extended 128K token output. And we can just go ahead and search this so you can see exactly what that looks like. Right, so if we hop down here, you can see we're enabling that beta flag to enable these longer outputs. This is gonna be in the description for you to hop in and play with so you can really understand the capabilities. You can also just give this to a model, give this to your AI coding assistant and have it generate whatever you're looking for. So last thing I wanna show off here is an agent. You can be building your own agents to solve your domain specific problem right now. And I'm kind of giving you a quick start here with the single file agent, showcasing how exactly you can do this. So before the cloud code release, we built a bash and editor agent on top of cloud's bash and editor tools. And what we can do is this. So I'm gonna copy this and run this agent here. So agent loop one out of 10, it has 10 compute uses. I asked it to do this, right? The user asked me to create a file called hello.txt with the content hello world inside it. I can use the create file tool to accomplish this task. It sees the parameters of that tool, right? So you can see the tool call right here, reasoning, path and file text. You can see the thinking budget, right? The thinking tokens, walking through what it needs to do to call the tool. You can see there's a tool call and then there's the file created response, right? So this is what that response looks like. You can see we have.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 2.559999942779541,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " As Robert mentioned, I found this to be really useful.",
      "tokens": [
        50364,
        1018,
        5424,
        911,
        2835,
        11,
        286,
        1352,
        341,
        281,
        312,
        534,
        4420,
        13,
        50492
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 4.320000171661377,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 2.559999942779541,
      "temperature": 0.0,
      "text": " Basically, you just start with the bare minimum",
      "tokens": [
        50492,
        8537,
        11,
        291,
        445,
        722,
        365,
        264,
        6949,
        7285,
        50580
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 7.199999809265137,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 4.320000171661377,
      "temperature": 0.0,
      "text": " and track your token usage as we are here.",
      "tokens": [
        50580,
        293,
        2837,
        428,
        14862,
        14924,
        382,
        321,
        366,
        510,
        13,
        50724
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 10.720000267028809,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 7.199999809265137,
      "temperature": 0.0,
      "text": " If you never hit the 1K mark, you never need to go to 2K.",
      "tokens": [
        50724,
        759,
        291,
        1128,
        2045,
        264,
        502,
        42,
        1491,
        11,
        291,
        1128,
        643,
        281,
        352,
        281,
        568,
        42,
        13,
        50900
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 11.779999732971191,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 10.720000267028809,
      "temperature": 0.0,
      "text": " All right, so this is really cool.",
      "tokens": [
        50900,
        1057,
        558,
        11,
        370,
        341,
        307,
        534,
        1627,
        13,
        50953
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 14.960000038146973,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 11.779999732971191,
      "temperature": 0.0,
      "text": " So we just finished and you can see here",
      "tokens": [
        50953,
        407,
        321,
        445,
        4335,
        293,
        291,
        393,
        536,
        510,
        51112
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 18.68000030517578,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 14.960000038146973,
      "temperature": 0.0,
      "text": " our output tokens chewed up 6K, right?",
      "tokens": [
        51112,
        527,
        5598,
        22667,
        21200,
        292,
        493,
        1386,
        42,
        11,
        558,
        30,
        51298
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 20.200000762939453,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 18.68000030517578,
      "temperature": 0.0,
      "text": " So we really, really pushed it.",
      "tokens": [
        51298,
        407,
        321,
        534,
        11,
        534,
        9152,
        309,
        13,
        51374
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 21.84000015258789,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 20.200000762939453,
      "temperature": 0.0,
      "text": " We really got that.",
      "tokens": [
        51374,
        492,
        534,
        658,
        300,
        13,
        51456
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 23.200000762939453,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 21.84000015258789,
      "temperature": 0.0,
      "text": " Wow, look at that up.",
      "tokens": [
        51456,
        3153,
        11,
        574,
        412,
        300,
        493,
        13,
        51524
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 24.8799991607666,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 23.200000762939453,
      "temperature": 0.0,
      "text": " You can really see that this model",
      "tokens": [
        51524,
        509,
        393,
        534,
        536,
        300,
        341,
        2316,
        51608
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 27.079999923706055,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 24.8799991607666,
      "temperature": 0.0,
      "text": " pushed really hard here.",
      "tokens": [
        51608,
        9152,
        534,
        1152,
        510,
        13,
        51718
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.23030821979045868,
      "compression_ratio": 1.696864128112793,
      "end": 29.639999389648438,
      "no_speech_prob": 0.2478541135787964,
      "seek": 0,
      "start": 27.079999923706055,
      "temperature": 0.0,
      "text": " My word calculation is likely off.",
      "tokens": [
        51718,
        1222,
        1349,
        17108,
        307,
        3700,
        766,
        13,
        51846
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 30.899999618530273,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 29.639999389648438,
      "temperature": 0.0,
      "text": " We're likely not counting.",
      "tokens": [
        50364,
        492,
        434,
        3700,
        406,
        13251,
        13,
        50427
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 33.29999923706055,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 30.899999618530273,
      "temperature": 0.0,
      "text": " It likely got a lot closer here than we think.",
      "tokens": [
        50427,
        467,
        3700,
        658,
        257,
        688,
        4966,
        510,
        813,
        321,
        519,
        13,
        50547
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 34.720001220703125,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 33.29999923706055,
      "temperature": 0.0,
      "text": " When you're really pushing the output tokens,",
      "tokens": [
        50547,
        1133,
        291,
        434,
        534,
        7380,
        264,
        5598,
        22667,
        11,
        50618
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 37.2599983215332,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 34.720001220703125,
      "temperature": 0.0,
      "text": " this is when you're gonna boost up the costs.",
      "tokens": [
        50618,
        341,
        307,
        562,
        291,
        434,
        799,
        9194,
        493,
        264,
        5497,
        13,
        50745
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 38.2400016784668,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 37.2599983215332,
      "temperature": 0.0,
      "text": " So this is really powerful, right?",
      "tokens": [
        50745,
        407,
        341,
        307,
        534,
        4005,
        11,
        558,
        30,
        50794
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 41.880001068115234,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 38.2400016784668,
      "temperature": 0.0,
      "text": " So this is an example of using both the streaming",
      "tokens": [
        50794,
        407,
        341,
        307,
        364,
        1365,
        295,
        1228,
        1293,
        264,
        11791,
        50976
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 45.720001220703125,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 41.880001068115234,
      "temperature": 0.0,
      "text": " with the extended 128K token output.",
      "tokens": [
        50976,
        365,
        264,
        10913,
        29810,
        42,
        14862,
        5598,
        13,
        51168
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 47.040000915527344,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 45.720001220703125,
      "temperature": 0.0,
      "text": " And we can just go ahead and search this",
      "tokens": [
        51168,
        400,
        321,
        393,
        445,
        352,
        2286,
        293,
        3164,
        341,
        51234
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 49.13999938964844,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 47.040000915527344,
      "temperature": 0.0,
      "text": " so you can see exactly what that looks like.",
      "tokens": [
        51234,
        370,
        291,
        393,
        536,
        2293,
        437,
        300,
        1542,
        411,
        13,
        51339
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 51.79999923706055,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 50.20000076293945,
      "temperature": 0.0,
      "text": " Right, so if we hop down here,",
      "tokens": [
        51392,
        1779,
        11,
        370,
        498,
        321,
        3818,
        760,
        510,
        11,
        51472
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 54.040000915527344,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 51.79999923706055,
      "temperature": 0.0,
      "text": " you can see we're enabling that beta flag",
      "tokens": [
        51472,
        291,
        393,
        536,
        321,
        434,
        23148,
        300,
        9861,
        7166,
        51584
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 55.959999084472656,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 54.040000915527344,
      "temperature": 0.0,
      "text": " to enable these longer outputs.",
      "tokens": [
        51584,
        281,
        9528,
        613,
        2854,
        23930,
        13,
        51680
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 57.099998474121094,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 55.959999084472656,
      "temperature": 0.0,
      "text": " This is gonna be in the description",
      "tokens": [
        51680,
        639,
        307,
        799,
        312,
        294,
        264,
        3855,
        51737
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.2213311642408371,
      "compression_ratio": 1.75,
      "end": 58.7599983215332,
      "no_speech_prob": 0.00037997981416992843,
      "seek": 2964,
      "start": 57.099998474121094,
      "temperature": 0.0,
      "text": " for you to hop in and play with",
      "tokens": [
        51737,
        337,
        291,
        281,
        3818,
        294,
        293,
        862,
        365,
        51820
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 60.15999984741211,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 58.7599983215332,
      "temperature": 0.0,
      "text": " so you can really understand the capabilities.",
      "tokens": [
        50364,
        370,
        291,
        393,
        534,
        1223,
        264,
        10862,
        13,
        50434
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 62.52000045776367,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 60.15999984741211,
      "temperature": 0.0,
      "text": " You can also just give this to a model,",
      "tokens": [
        50434,
        509,
        393,
        611,
        445,
        976,
        341,
        281,
        257,
        2316,
        11,
        50552
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 63.91999816894531,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 62.52000045776367,
      "temperature": 0.0,
      "text": " give this to your AI coding assistant",
      "tokens": [
        50552,
        976,
        341,
        281,
        428,
        7318,
        17720,
        10994,
        50622
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 66.5199966430664,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 63.91999816894531,
      "temperature": 0.0,
      "text": " and have it generate whatever you're looking for.",
      "tokens": [
        50622,
        293,
        362,
        309,
        8460,
        2035,
        291,
        434,
        1237,
        337,
        13,
        50752
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 69.68000030517578,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 66.5199966430664,
      "temperature": 0.0,
      "text": " So last thing I wanna show off here is an agent.",
      "tokens": [
        50752,
        407,
        1036,
        551,
        286,
        1948,
        855,
        766,
        510,
        307,
        364,
        9461,
        13,
        50910
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 74.95999908447266,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 73.19999694824219,
      "temperature": 0.0,
      "text": " You can be building your own agents",
      "tokens": [
        51086,
        509,
        393,
        312,
        2390,
        428,
        1065,
        12554,
        51174
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 78.0,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 74.95999908447266,
      "temperature": 0.0,
      "text": " to solve your domain specific problem right now.",
      "tokens": [
        51174,
        281,
        5039,
        428,
        9274,
        2685,
        1154,
        558,
        586,
        13,
        51326
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 80.9800033569336,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 78.0,
      "temperature": 0.0,
      "text": " And I'm kind of giving you a quick start here",
      "tokens": [
        51326,
        400,
        286,
        478,
        733,
        295,
        2902,
        291,
        257,
        1702,
        722,
        510,
        51475
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 82.12000274658203,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 80.9800033569336,
      "temperature": 0.0,
      "text": " with the single file agent,",
      "tokens": [
        51475,
        365,
        264,
        2167,
        3991,
        9461,
        11,
        51532
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 83.95999908447266,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 82.12000274658203,
      "temperature": 0.0,
      "text": " showcasing how exactly you can do this.",
      "tokens": [
        51532,
        29794,
        3349,
        577,
        2293,
        291,
        393,
        360,
        341,
        13,
        51624
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.23226647078990936,
      "compression_ratio": 1.6764706373214722,
      "end": 85.87999725341797,
      "no_speech_prob": 0.0017274325946345925,
      "seek": 5876,
      "start": 83.95999908447266,
      "temperature": 0.0,
      "text": " So before the cloud code release,",
      "tokens": [
        51624,
        407,
        949,
        264,
        4588,
        3089,
        4374,
        11,
        51720
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 88.91999816894531,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 85.87999725341797,
      "temperature": 0.0,
      "text": " we built a bash and editor agent",
      "tokens": [
        50364,
        321,
        3094,
        257,
        46183,
        293,
        9839,
        9461,
        50516
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 91.68000030517578,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 88.91999816894531,
      "temperature": 0.0,
      "text": " on top of cloud's bash and editor tools.",
      "tokens": [
        50516,
        322,
        1192,
        295,
        4588,
        311,
        46183,
        293,
        9839,
        3873,
        13,
        50654
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 93.12000274658203,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 91.68000030517578,
      "temperature": 0.0,
      "text": " And what we can do is this.",
      "tokens": [
        50654,
        400,
        437,
        321,
        393,
        360,
        307,
        341,
        13,
        50726
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 96.12000274658203,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 93.12000274658203,
      "temperature": 0.0,
      "text": " So I'm gonna copy this and run this agent here.",
      "tokens": [
        50726,
        407,
        286,
        478,
        799,
        5055,
        341,
        293,
        1190,
        341,
        9461,
        510,
        13,
        50876
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 100.27999877929688,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 96.12000274658203,
      "temperature": 0.0,
      "text": " So agent loop one out of 10, it has 10 compute uses.",
      "tokens": [
        50876,
        407,
        9461,
        6367,
        472,
        484,
        295,
        1266,
        11,
        309,
        575,
        1266,
        14722,
        4960,
        13,
        51084
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 102.83999633789062,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 100.27999877929688,
      "temperature": 0.0,
      "text": " I asked it to do this, right?",
      "tokens": [
        51084,
        286,
        2351,
        309,
        281,
        360,
        341,
        11,
        558,
        30,
        51212
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 106.4000015258789,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 102.83999633789062,
      "temperature": 0.0,
      "text": " The user asked me to create a file called hello.txt",
      "tokens": [
        51212,
        440,
        4195,
        2351,
        385,
        281,
        1884,
        257,
        3991,
        1219,
        7751,
        13,
        83,
        734,
        51390
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 108.36000061035156,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 106.4000015258789,
      "temperature": 0.0,
      "text": " with the content hello world inside it.",
      "tokens": [
        51390,
        365,
        264,
        2701,
        7751,
        1002,
        1854,
        309,
        13,
        51488
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 111.18000030517578,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 108.36000061035156,
      "temperature": 0.0,
      "text": " I can use the create file tool to accomplish this task.",
      "tokens": [
        51488,
        286,
        393,
        764,
        264,
        1884,
        3991,
        2290,
        281,
        9021,
        341,
        5633,
        13,
        51629
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 113.76000213623047,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 111.18000030517578,
      "temperature": 0.0,
      "text": " It sees the parameters of that tool, right?",
      "tokens": [
        51629,
        467,
        8194,
        264,
        9834,
        295,
        300,
        2290,
        11,
        558,
        30,
        51758
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.22011861205101013,
      "compression_ratio": 1.7816091775894165,
      "end": 115.36000061035156,
      "no_speech_prob": 0.007460440509021282,
      "seek": 8588,
      "start": 113.76000213623047,
      "temperature": 0.0,
      "text": " So you can see the tool call right here,",
      "tokens": [
        51758,
        407,
        291,
        393,
        536,
        264,
        2290,
        818,
        558,
        510,
        11,
        51838
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.2943349778652191,
      "compression_ratio": 1.7321428060531616,
      "end": 117.76000213623047,
      "no_speech_prob": 0.009412098675966263,
      "seek": 11536,
      "start": 116.19999694824219,
      "temperature": 0.0,
      "text": " reasoning, path and file text.",
      "tokens": [
        50406,
        21577,
        11,
        3100,
        293,
        3991,
        2487,
        13,
        50484
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.2943349778652191,
      "compression_ratio": 1.7321428060531616,
      "end": 119.80000305175781,
      "no_speech_prob": 0.009412098675966263,
      "seek": 11536,
      "start": 117.76000213623047,
      "temperature": 0.0,
      "text": " You can see the thinking budget, right?",
      "tokens": [
        50484,
        509,
        393,
        536,
        264,
        1953,
        4706,
        11,
        558,
        30,
        50586
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.2943349778652191,
      "compression_ratio": 1.7321428060531616,
      "end": 121.5199966430664,
      "no_speech_prob": 0.009412098675966263,
      "seek": 11536,
      "start": 119.80000305175781,
      "temperature": 0.0,
      "text": " The thinking tokens,",
      "tokens": [
        50586,
        440,
        1953,
        22667,
        11,
        50672
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.2943349778652191,
      "compression_ratio": 1.7321428060531616,
      "end": 124.55999755859375,
      "no_speech_prob": 0.009412098675966263,
      "seek": 11536,
      "start": 121.5199966430664,
      "temperature": 0.0,
      "text": " walking through what it needs to do to call the tool.",
      "tokens": [
        50672,
        4494,
        807,
        437,
        309,
        2203,
        281,
        360,
        281,
        818,
        264,
        2290,
        13,
        50824
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.2943349778652191,
      "compression_ratio": 1.7321428060531616,
      "end": 126.12000274658203,
      "no_speech_prob": 0.009412098675966263,
      "seek": 11536,
      "start": 124.55999755859375,
      "temperature": 0.0,
      "text": " You can see there's a tool call",
      "tokens": [
        50824,
        509,
        393,
        536,
        456,
        311,
        257,
        2290,
        818,
        50902
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.2943349778652191,
      "compression_ratio": 1.7321428060531616,
      "end": 129.13999938964844,
      "no_speech_prob": 0.009412098675966263,
      "seek": 11536,
      "start": 126.12000274658203,
      "temperature": 0.0,
      "text": " and then there's the file created response, right?",
      "tokens": [
        50902,
        293,
        550,
        456,
        311,
        264,
        3991,
        2942,
        4134,
        11,
        558,
        30,
        51053
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.2943349778652191,
      "compression_ratio": 1.7321428060531616,
      "end": 130.63999938964844,
      "no_speech_prob": 0.009412098675966263,
      "seek": 11536,
      "start": 129.13999938964844,
      "temperature": 0.0,
      "text": " So this is what that response looks like.",
      "tokens": [
        51053,
        407,
        341,
        307,
        437,
        300,
        4134,
        1542,
        411,
        13,
        51128
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.2943349778652191,
      "compression_ratio": 1.7321428060531616,
      "end": 131.63999938964844,
      "no_speech_prob": 0.009412098675966263,
      "seek": 11536,
      "start": 130.63999938964844,
      "temperature": 0.0,
      "text": " You can see we have.",
      "tokens": [
        51128,
        509,
        393,
        536,
        321,
        362,
        13,
        51178
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835709.748936
}
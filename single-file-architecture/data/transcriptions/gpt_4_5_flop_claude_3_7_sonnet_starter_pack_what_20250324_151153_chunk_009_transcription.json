{
  "audio_path": "data/chunks/gpt_4_5_flop_claude_3_7_sonnet_starter_pack_what_20250324_151153_chunk_009.mp3",
  "text": "that new file created there. Let's open that up. Here's all the lesson names and the description. Okay, so all I wanna do here is dial in the point, the idea that this is an AI agent with a slew of tools that you can call in any order as long as your prompt communicates that to the agent. And if you're using this tool, you understand that, you're working through that, but this is just such an important point. Why? Because Cloud Code is just a single agent, all right? It's one agent. There are going to be many, many, many more agents and you, as an engineer, can build and harness the capabilities of these agents. The really key important part is that you understand that these agents are a series of tools powered by a great prompt, fueled by a great language model. And this is part of why this release is so great. Cloud 3.7 is exceptional at calling the right tool when you need it. I'm super impressed with the coding capabilities of Cloud Code. We'll dive a lot more into actually using this tool. You know, there's a lot of chatter right now, you know, does this replace Cursor, Aider, Devon? In their release, they explicitly mentioned, you know, Cursor mentioned Cloud Cognition, right? So Devon, far better than any other model at planning code changes and handling full stack updates, right? Basically what they're saying here, what everyone is saying is that this model powers my agents very well, all right? And then of course, you know, it's great at coding too, right? It's kind of expected. This is the, you know, Cloud 3.5, Sonnet was the best in class base model for coding. 3.7 takes it to the next level. And again, I'm super, super mind blown that they only gave us two points here, right? They only incremented the minor version here by two points, 3.7. What else do they have in the bag? So let's go ahead and run my local MCP server. All this is going to do is just call a weather endpoint, but this really showcases how quickly you can set up a MCP server when you have the right tooling. So basically you just run this and then you fire up Cloud.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 1.1200000047683716,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " that new file created there.",
      "tokens": [
        50364,
        300,
        777,
        3991,
        2942,
        456,
        13,
        50420
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 1.940000057220459,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 1.1200000047683716,
      "temperature": 0.0,
      "text": " Let's open that up.",
      "tokens": [
        50420,
        961,
        311,
        1269,
        300,
        493,
        13,
        50461
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 5.260000228881836,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 1.940000057220459,
      "temperature": 0.0,
      "text": " Here's all the lesson names and the description.",
      "tokens": [
        50461,
        1692,
        311,
        439,
        264,
        6898,
        5288,
        293,
        264,
        3855,
        13,
        50627
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 8.020000457763672,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 5.260000228881836,
      "temperature": 0.0,
      "text": " Okay, so all I wanna do here is dial in the point,",
      "tokens": [
        50627,
        1033,
        11,
        370,
        439,
        286,
        1948,
        360,
        510,
        307,
        5502,
        294,
        264,
        935,
        11,
        50765
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 12.260000228881836,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 8.020000457763672,
      "temperature": 0.0,
      "text": " the idea that this is an AI agent with a slew of tools",
      "tokens": [
        50765,
        264,
        1558,
        300,
        341,
        307,
        364,
        7318,
        9461,
        365,
        257,
        2426,
        86,
        295,
        3873,
        50977
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 14.260000228881836,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 12.260000228881836,
      "temperature": 0.0,
      "text": " that you can call in any order",
      "tokens": [
        50977,
        300,
        291,
        393,
        818,
        294,
        604,
        1668,
        51077
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 18.100000381469727,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 14.260000228881836,
      "temperature": 0.0,
      "text": " as long as your prompt communicates that to the agent.",
      "tokens": [
        51077,
        382,
        938,
        382,
        428,
        12391,
        3363,
        1024,
        300,
        281,
        264,
        9461,
        13,
        51269
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 20.700000762939453,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 18.100000381469727,
      "temperature": 0.0,
      "text": " And if you're using this tool, you understand that,",
      "tokens": [
        51269,
        400,
        498,
        291,
        434,
        1228,
        341,
        2290,
        11,
        291,
        1223,
        300,
        11,
        51399
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 21.65999984741211,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 20.700000762939453,
      "temperature": 0.0,
      "text": " you're working through that,",
      "tokens": [
        51399,
        291,
        434,
        1364,
        807,
        300,
        11,
        51447
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 23.5,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 21.65999984741211,
      "temperature": 0.0,
      "text": " but this is just such an important point.",
      "tokens": [
        51447,
        457,
        341,
        307,
        445,
        1270,
        364,
        1021,
        935,
        13,
        51539
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 24.34000015258789,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 23.5,
      "temperature": 0.0,
      "text": " Why?",
      "tokens": [
        51539,
        1545,
        30,
        51581
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 27.700000762939453,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 24.34000015258789,
      "temperature": 0.0,
      "text": " Because Cloud Code is just a single agent, all right?",
      "tokens": [
        51581,
        1436,
        8061,
        15549,
        307,
        445,
        257,
        2167,
        9461,
        11,
        439,
        558,
        30,
        51749
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.2220279723405838,
      "compression_ratio": 1.7027971744537354,
      "end": 29.18000030517578,
      "no_speech_prob": 0.008061667904257774,
      "seek": 0,
      "start": 27.700000762939453,
      "temperature": 0.0,
      "text": " It's one agent.",
      "tokens": [
        51749,
        467,
        311,
        472,
        9461,
        13,
        51823
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 32.459999084472656,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 29.18000030517578,
      "temperature": 0.0,
      "text": " There are going to be many, many, many more agents",
      "tokens": [
        50364,
        821,
        366,
        516,
        281,
        312,
        867,
        11,
        867,
        11,
        867,
        544,
        12554,
        50528
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 36.81999969482422,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 32.459999084472656,
      "temperature": 0.0,
      "text": " and you, as an engineer, can build and harness",
      "tokens": [
        50528,
        293,
        291,
        11,
        382,
        364,
        11403,
        11,
        393,
        1322,
        293,
        19700,
        50746
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 39.13999938964844,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 36.81999969482422,
      "temperature": 0.0,
      "text": " the capabilities of these agents.",
      "tokens": [
        50746,
        264,
        10862,
        295,
        613,
        12554,
        13,
        50862
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 42.380001068115234,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 39.13999938964844,
      "temperature": 0.0,
      "text": " The really key important part is that you understand",
      "tokens": [
        50862,
        440,
        534,
        2141,
        1021,
        644,
        307,
        300,
        291,
        1223,
        51024
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 45.400001525878906,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 42.380001068115234,
      "temperature": 0.0,
      "text": " that these agents are a series of tools",
      "tokens": [
        51024,
        300,
        613,
        12554,
        366,
        257,
        2638,
        295,
        3873,
        51175
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 50.29999923706055,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 45.400001525878906,
      "temperature": 0.0,
      "text": " powered by a great prompt, fueled by a great language model.",
      "tokens": [
        51175,
        17786,
        538,
        257,
        869,
        12391,
        11,
        45446,
        538,
        257,
        869,
        2856,
        2316,
        13,
        51420
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 53.5,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 50.29999923706055,
      "temperature": 0.0,
      "text": " And this is part of why this release is so great.",
      "tokens": [
        51420,
        400,
        341,
        307,
        644,
        295,
        983,
        341,
        4374,
        307,
        370,
        869,
        13,
        51580
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 57.84000015258789,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 53.5,
      "temperature": 0.0,
      "text": " Cloud 3.7 is exceptional at calling the right tool",
      "tokens": [
        51580,
        8061,
        805,
        13,
        22,
        307,
        19279,
        412,
        5141,
        264,
        558,
        2290,
        51797
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2259053736925125,
      "compression_ratio": 1.697479009628296,
      "end": 58.68000030517578,
      "no_speech_prob": 3.480782106635161e-05,
      "seek": 2918,
      "start": 57.84000015258789,
      "temperature": 0.0,
      "text": " when you need it.",
      "tokens": [
        51797,
        562,
        291,
        643,
        309,
        13,
        51839
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 61.880001068115234,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 59.18000030517578,
      "temperature": 0.0,
      "text": " I'm super impressed with the coding capabilities",
      "tokens": [
        50389,
        286,
        478,
        1687,
        11679,
        365,
        264,
        17720,
        10862,
        50524
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 62.91999816894531,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 61.880001068115234,
      "temperature": 0.0,
      "text": " of Cloud Code.",
      "tokens": [
        50524,
        295,
        8061,
        15549,
        13,
        50576
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 66.12000274658203,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 62.91999816894531,
      "temperature": 0.0,
      "text": " We'll dive a lot more into actually using this tool.",
      "tokens": [
        50576,
        492,
        603,
        9192,
        257,
        688,
        544,
        666,
        767,
        1228,
        341,
        2290,
        13,
        50736
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 68.04000091552734,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 66.12000274658203,
      "temperature": 0.0,
      "text": " You know, there's a lot of chatter right now,",
      "tokens": [
        50736,
        509,
        458,
        11,
        456,
        311,
        257,
        688,
        295,
        26929,
        558,
        586,
        11,
        50832
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 70.4800033569336,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 68.04000091552734,
      "temperature": 0.0,
      "text": " you know, does this replace Cursor, Aider, Devon?",
      "tokens": [
        50832,
        291,
        458,
        11,
        775,
        341,
        7406,
        383,
        2156,
        284,
        11,
        316,
        1438,
        11,
        9096,
        266,
        30,
        50954
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 73.0,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 70.4800033569336,
      "temperature": 0.0,
      "text": " In their release, they explicitly mentioned, you know,",
      "tokens": [
        50954,
        682,
        641,
        4374,
        11,
        436,
        20803,
        2835,
        11,
        291,
        458,
        11,
        51080
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 77.04000091552734,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 73.0,
      "temperature": 0.0,
      "text": " Cursor mentioned Cloud Cognition, right?",
      "tokens": [
        51080,
        383,
        2156,
        284,
        2835,
        8061,
        383,
        2912,
        849,
        11,
        558,
        30,
        51282
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 79.55999755859375,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 77.04000091552734,
      "temperature": 0.0,
      "text": " So Devon, far better than any other model",
      "tokens": [
        51282,
        407,
        9096,
        266,
        11,
        1400,
        1101,
        813,
        604,
        661,
        2316,
        51408
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 82.63999938964844,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 79.55999755859375,
      "temperature": 0.0,
      "text": " at planning code changes and handling full stack updates,",
      "tokens": [
        51408,
        412,
        5038,
        3089,
        2962,
        293,
        13175,
        1577,
        8630,
        9205,
        11,
        51562
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 83.4800033569336,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 82.63999938964844,
      "temperature": 0.0,
      "text": " right?",
      "tokens": [
        51562,
        558,
        30,
        51604
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 84.36000061035156,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 83.4800033569336,
      "temperature": 0.0,
      "text": " Basically what they're saying here,",
      "tokens": [
        51604,
        8537,
        437,
        436,
        434,
        1566,
        510,
        11,
        51648
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.25890669226646423,
      "compression_ratio": 1.6917808055877686,
      "end": 87.4800033569336,
      "no_speech_prob": 0.017175918444991112,
      "seek": 5868,
      "start": 84.36000061035156,
      "temperature": 0.0,
      "text": " what everyone is saying is that this model",
      "tokens": [
        51648,
        437,
        1518,
        307,
        1566,
        307,
        300,
        341,
        2316,
        51804
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 91.04000091552734,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 87.4800033569336,
      "temperature": 0.0,
      "text": " powers my agents very well, all right?",
      "tokens": [
        50364,
        8674,
        452,
        12554,
        588,
        731,
        11,
        439,
        558,
        30,
        50542
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 93.5999984741211,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 91.04000091552734,
      "temperature": 0.0,
      "text": " And then of course, you know, it's great at coding too,",
      "tokens": [
        50542,
        400,
        550,
        295,
        1164,
        11,
        291,
        458,
        11,
        309,
        311,
        869,
        412,
        17720,
        886,
        11,
        50670
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 94.44000244140625,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 93.5999984741211,
      "temperature": 0.0,
      "text": " right?",
      "tokens": [
        50670,
        558,
        30,
        50712
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 95.27999877929688,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 94.44000244140625,
      "temperature": 0.0,
      "text": " It's kind of expected.",
      "tokens": [
        50712,
        467,
        311,
        733,
        295,
        5176,
        13,
        50754
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 98.04000091552734,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 95.27999877929688,
      "temperature": 0.0,
      "text": " This is the, you know, Cloud 3.5,",
      "tokens": [
        50754,
        639,
        307,
        264,
        11,
        291,
        458,
        11,
        8061,
        805,
        13,
        20,
        11,
        50892
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 101.55999755859375,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 98.04000091552734,
      "temperature": 0.0,
      "text": " Sonnet was the best in class base model for coding.",
      "tokens": [
        50892,
        5185,
        7129,
        390,
        264,
        1151,
        294,
        1508,
        3096,
        2316,
        337,
        17720,
        13,
        51068
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 103.68000030517578,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 101.55999755859375,
      "temperature": 0.0,
      "text": " 3.7 takes it to the next level.",
      "tokens": [
        51068,
        805,
        13,
        22,
        2516,
        309,
        281,
        264,
        958,
        1496,
        13,
        51174
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 107.26000213623047,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 103.68000030517578,
      "temperature": 0.0,
      "text": " And again, I'm super, super mind blown that",
      "tokens": [
        51174,
        400,
        797,
        11,
        286,
        478,
        1687,
        11,
        1687,
        1575,
        16479,
        300,
        51353
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 109.27999877929688,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 107.26000213623047,
      "temperature": 0.0,
      "text": " they only gave us two points here, right?",
      "tokens": [
        51353,
        436,
        787,
        2729,
        505,
        732,
        2793,
        510,
        11,
        558,
        30,
        51454
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 112.44000244140625,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 109.27999877929688,
      "temperature": 0.0,
      "text": " They only incremented the minor version here by two points,",
      "tokens": [
        51454,
        814,
        787,
        1946,
        14684,
        264,
        6696,
        3037,
        510,
        538,
        732,
        2793,
        11,
        51612
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 114.4000015258789,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 112.44000244140625,
      "temperature": 0.0,
      "text": " 3.7.",
      "tokens": [
        51612,
        805,
        13,
        22,
        13,
        51710
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.22204768657684326,
      "compression_ratio": 1.621212124824524,
      "end": 116.4800033569336,
      "no_speech_prob": 0.0015011634677648544,
      "seek": 8748,
      "start": 114.4000015258789,
      "temperature": 0.0,
      "text": " What else do they have in the bag?",
      "tokens": [
        51710,
        708,
        1646,
        360,
        436,
        362,
        294,
        264,
        3411,
        30,
        51814
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.24912412464618683,
      "compression_ratio": 1.482954502105713,
      "end": 119.19999694824219,
      "no_speech_prob": 0.02675689570605755,
      "seek": 11648,
      "start": 116.4800033569336,
      "temperature": 0.0,
      "text": " So let's go ahead and run my local MCP server.",
      "tokens": [
        50364,
        407,
        718,
        311,
        352,
        2286,
        293,
        1190,
        452,
        2654,
        8797,
        47,
        7154,
        13,
        50500
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.24912412464618683,
      "compression_ratio": 1.482954502105713,
      "end": 121.95999908447266,
      "no_speech_prob": 0.02675689570605755,
      "seek": 11648,
      "start": 119.19999694824219,
      "temperature": 0.0,
      "text": " All this is going to do is just call a weather endpoint,",
      "tokens": [
        50500,
        1057,
        341,
        307,
        516,
        281,
        360,
        307,
        445,
        818,
        257,
        5503,
        35795,
        11,
        50638
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.24912412464618683,
      "compression_ratio": 1.482954502105713,
      "end": 125.63999938964844,
      "no_speech_prob": 0.02675689570605755,
      "seek": 11648,
      "start": 121.95999908447266,
      "temperature": 0.0,
      "text": " but this really showcases how quickly you can set up a",
      "tokens": [
        50638,
        457,
        341,
        534,
        29794,
        1957,
        577,
        2661,
        291,
        393,
        992,
        493,
        257,
        50822
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.24912412464618683,
      "compression_ratio": 1.482954502105713,
      "end": 127.80000305175781,
      "no_speech_prob": 0.02675689570605755,
      "seek": 11648,
      "start": 125.63999938964844,
      "temperature": 0.0,
      "text": " MCP server when you have the right tooling.",
      "tokens": [
        50822,
        8797,
        47,
        7154,
        562,
        291,
        362,
        264,
        558,
        46593,
        13,
        50930
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.24912412464618683,
      "compression_ratio": 1.482954502105713,
      "end": 131.27999877929688,
      "no_speech_prob": 0.02675689570605755,
      "seek": 11648,
      "start": 127.80000305175781,
      "temperature": 0.0,
      "text": " So basically you just run this and then you fire up Cloud.",
      "tokens": [
        50930,
        407,
        1936,
        291,
        445,
        1190,
        341,
        293,
        550,
        291,
        2610,
        493,
        8061,
        13,
        51104
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835655.043925
}
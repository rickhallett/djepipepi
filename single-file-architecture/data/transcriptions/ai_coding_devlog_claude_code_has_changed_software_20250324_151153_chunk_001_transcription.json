{
  "audio_path": "data/chunks/ai_coding_devlog_claude_code_has_changed_software_20250324_151153_chunk_001.mp3",
  "text": "What's up engineers, IndyDevDan here. I have a special video for you today. This is a hands-on, no BS, AI coding devlog using Cloud Code and the Model Context Protocol. I have never adopted a tool faster than I've adopted Cloud Code. There is nothing more important going on right now for true software engineering in the Gen AI age than Cloud Code and MCP. In this video, I'll show why that's true. So we're going to boot up Cloud Code, but we're not going to prematurely jump in here and start firing off prompts iteratively. That's the old 2024 way to do things. First thing we need to do is gather all the context and information we need to run Cloud Code in its true agentic form. To do this, we're going to use a tool called RepoMix. RepoMix allows us to read entire code bases and collapse them into a single file that we can use as context for our AI tooling for Cloud Code. AI coding tools, LLMs, they love patterns. They love pre-existing information. So that's what we're going to do here. We're going to clone the Model Context Protocol server's GitHub repository, and then we're going to look at a specific example that we can pull from. So we're going to look at git here, and so we're going to cd into the git directory, and we can see there's the structure. We can run ls and tree to understand the high-level structure. And then we can run RepoMix. So RepoMix allows us to take this code base and collapse it into a single file. You can see we have 30k tokens there. And now we're just going to move this into our code base. So I'm going to get the path to our current code base, run that, and then move this into the AI docs directory. You may have seen this throughout some of the code.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.30126896500587463,
      "compression_ratio": 1.395209550857544,
      "end": 5.159999847412109,
      "no_speech_prob": 0.43936413526535034,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " What's up engineers, IndyDevDan here.",
      "tokens": [
        50364,
        708,
        311,
        493,
        11955,
        11,
        2333,
        88,
        11089,
        85,
        17087,
        510,
        13,
        50622
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.30126896500587463,
      "compression_ratio": 1.395209550857544,
      "end": 7.840000152587891,
      "no_speech_prob": 0.43936413526535034,
      "seek": 0,
      "start": 5.159999847412109,
      "temperature": 0.0,
      "text": " I have a special video for you today.",
      "tokens": [
        50622,
        286,
        362,
        257,
        2121,
        960,
        337,
        291,
        965,
        13,
        50756
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.30126896500587463,
      "compression_ratio": 1.395209550857544,
      "end": 16.799999237060547,
      "no_speech_prob": 0.43936413526535034,
      "seek": 0,
      "start": 7.840000152587891,
      "temperature": 0.0,
      "text": " This is a hands-on, no BS, AI coding devlog using Cloud Code and the Model Context Protocol.",
      "tokens": [
        50756,
        639,
        307,
        257,
        2377,
        12,
        266,
        11,
        572,
        27253,
        11,
        7318,
        17720,
        1905,
        4987,
        1228,
        8061,
        15549,
        293,
        264,
        17105,
        4839,
        3828,
        48753,
        13,
        51204
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.30126896500587463,
      "compression_ratio": 1.395209550857544,
      "end": 23.0,
      "no_speech_prob": 0.43936413526535034,
      "seek": 0,
      "start": 16.799999237060547,
      "temperature": 0.0,
      "text": " I have never adopted a tool faster than I've adopted Cloud Code.",
      "tokens": [
        51204,
        286,
        362,
        1128,
        12175,
        257,
        2290,
        4663,
        813,
        286,
        600,
        12175,
        8061,
        15549,
        13,
        51514
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.23126628994941711,
      "compression_ratio": 1.5045454502105713,
      "end": 30.0,
      "no_speech_prob": 0.11751245707273483,
      "seek": 2300,
      "start": 23.0,
      "temperature": 0.0,
      "text": " There is nothing more important going on right now for true software engineering in",
      "tokens": [
        50364,
        821,
        307,
        1825,
        544,
        1021,
        516,
        322,
        558,
        586,
        337,
        2074,
        4722,
        7043,
        294,
        50714
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.23126628994941711,
      "compression_ratio": 1.5045454502105713,
      "end": 34.900001525878906,
      "no_speech_prob": 0.11751245707273483,
      "seek": 2300,
      "start": 30.0,
      "temperature": 0.0,
      "text": " the Gen AI age than Cloud Code and MCP.",
      "tokens": [
        50714,
        264,
        3632,
        7318,
        3205,
        813,
        8061,
        15549,
        293,
        8797,
        47,
        13,
        50959
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.23126628994941711,
      "compression_ratio": 1.5045454502105713,
      "end": 38.31999969482422,
      "no_speech_prob": 0.11751245707273483,
      "seek": 2300,
      "start": 34.900001525878906,
      "temperature": 0.0,
      "text": " In this video, I'll show why that's true.",
      "tokens": [
        50959,
        682,
        341,
        960,
        11,
        286,
        603,
        855,
        983,
        300,
        311,
        2074,
        13,
        51130
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.23126628994941711,
      "compression_ratio": 1.5045454502105713,
      "end": 43.119998931884766,
      "no_speech_prob": 0.11751245707273483,
      "seek": 2300,
      "start": 38.31999969482422,
      "temperature": 0.0,
      "text": " So we're going to boot up Cloud Code, but we're not going to prematurely jump in here",
      "tokens": [
        51130,
        407,
        321,
        434,
        516,
        281,
        11450,
        493,
        8061,
        15549,
        11,
        457,
        321,
        434,
        406,
        516,
        281,
        34877,
        356,
        3012,
        294,
        510,
        51370
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.23126628994941711,
      "compression_ratio": 1.5045454502105713,
      "end": 46.720001220703125,
      "no_speech_prob": 0.11751245707273483,
      "seek": 2300,
      "start": 43.119998931884766,
      "temperature": 0.0,
      "text": " and start firing off prompts iteratively.",
      "tokens": [
        51370,
        293,
        722,
        16045,
        766,
        41095,
        17138,
        19020,
        13,
        51550
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.23126628994941711,
      "compression_ratio": 1.5045454502105713,
      "end": 50.439998626708984,
      "no_speech_prob": 0.11751245707273483,
      "seek": 2300,
      "start": 46.720001220703125,
      "temperature": 0.0,
      "text": " That's the old 2024 way to do things.",
      "tokens": [
        51550,
        663,
        311,
        264,
        1331,
        45237,
        636,
        281,
        360,
        721,
        13,
        51736
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.2631888687610626,
      "compression_ratio": 1.6040608882904053,
      "end": 56.720001220703125,
      "no_speech_prob": 0.11754930764436722,
      "seek": 5044,
      "start": 50.439998626708984,
      "temperature": 0.0,
      "text": " First thing we need to do is gather all the context and information we need to run Cloud",
      "tokens": [
        50364,
        2386,
        551,
        321,
        643,
        281,
        360,
        307,
        5448,
        439,
        264,
        4319,
        293,
        1589,
        321,
        643,
        281,
        1190,
        8061,
        50678
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.2631888687610626,
      "compression_ratio": 1.6040608882904053,
      "end": 60.31999969482422,
      "no_speech_prob": 0.11754930764436722,
      "seek": 5044,
      "start": 56.720001220703125,
      "temperature": 0.0,
      "text": " Code in its true agentic form.",
      "tokens": [
        50678,
        15549,
        294,
        1080,
        2074,
        9461,
        299,
        1254,
        13,
        50858
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.2631888687610626,
      "compression_ratio": 1.6040608882904053,
      "end": 63.91999816894531,
      "no_speech_prob": 0.11754930764436722,
      "seek": 5044,
      "start": 60.31999969482422,
      "temperature": 0.0,
      "text": " To do this, we're going to use a tool called RepoMix.",
      "tokens": [
        50858,
        1407,
        360,
        341,
        11,
        321,
        434,
        516,
        281,
        764,
        257,
        2290,
        1219,
        3696,
        78,
        44,
        970,
        13,
        51038
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.2631888687610626,
      "compression_ratio": 1.6040608882904053,
      "end": 71.27999877929688,
      "no_speech_prob": 0.11754930764436722,
      "seek": 5044,
      "start": 63.91999816894531,
      "temperature": 0.0,
      "text": " RepoMix allows us to read entire code bases and collapse them into a single file that",
      "tokens": [
        51038,
        3696,
        78,
        44,
        970,
        4045,
        505,
        281,
        1401,
        2302,
        3089,
        17949,
        293,
        15584,
        552,
        666,
        257,
        2167,
        3991,
        300,
        51406
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.2631888687610626,
      "compression_ratio": 1.6040608882904053,
      "end": 76.04000091552734,
      "no_speech_prob": 0.11754930764436722,
      "seek": 5044,
      "start": 71.27999877929688,
      "temperature": 0.0,
      "text": " we can use as context for our AI tooling for Cloud Code.",
      "tokens": [
        51406,
        321,
        393,
        764,
        382,
        4319,
        337,
        527,
        7318,
        46593,
        337,
        8061,
        15549,
        13,
        51644
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.2969980239868164,
      "compression_ratio": 1.8192771673202515,
      "end": 79.91999816894531,
      "no_speech_prob": 0.39591777324676514,
      "seek": 7604,
      "start": 76.44000244140625,
      "temperature": 0.0,
      "text": " AI coding tools, LLMs, they love patterns.",
      "tokens": [
        50384,
        7318,
        17720,
        3873,
        11,
        441,
        43,
        26386,
        11,
        436,
        959,
        8294,
        13,
        50558
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.2969980239868164,
      "compression_ratio": 1.8192771673202515,
      "end": 82.91999816894531,
      "no_speech_prob": 0.39591777324676514,
      "seek": 7604,
      "start": 79.91999816894531,
      "temperature": 0.0,
      "text": " They love pre-existing information.",
      "tokens": [
        50558,
        814,
        959,
        659,
        12,
        36447,
        1589,
        13,
        50708
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.2969980239868164,
      "compression_ratio": 1.8192771673202515,
      "end": 84.16000366210938,
      "no_speech_prob": 0.39591777324676514,
      "seek": 7604,
      "start": 82.91999816894531,
      "temperature": 0.0,
      "text": " So that's what we're going to do here.",
      "tokens": [
        50708,
        407,
        300,
        311,
        437,
        321,
        434,
        516,
        281,
        360,
        510,
        13,
        50770
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.2969980239868164,
      "compression_ratio": 1.8192771673202515,
      "end": 90.83999633789062,
      "no_speech_prob": 0.39591777324676514,
      "seek": 7604,
      "start": 84.16000366210938,
      "temperature": 0.0,
      "text": " We're going to clone the Model Context Protocol server's GitHub repository, and then we're",
      "tokens": [
        50770,
        492,
        434,
        516,
        281,
        26506,
        264,
        17105,
        4839,
        3828,
        48753,
        7154,
        311,
        23331,
        25841,
        11,
        293,
        550,
        321,
        434,
        51104
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2969980239868164,
      "compression_ratio": 1.8192771673202515,
      "end": 93.83999633789062,
      "no_speech_prob": 0.39591777324676514,
      "seek": 7604,
      "start": 90.83999633789062,
      "temperature": 0.0,
      "text": " going to look at a specific example that we can pull from.",
      "tokens": [
        51104,
        516,
        281,
        574,
        412,
        257,
        2685,
        1365,
        300,
        321,
        393,
        2235,
        490,
        13,
        51254
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2969980239868164,
      "compression_ratio": 1.8192771673202515,
      "end": 99.5999984741211,
      "no_speech_prob": 0.39591777324676514,
      "seek": 7604,
      "start": 93.83999633789062,
      "temperature": 0.0,
      "text": " So we're going to look at git here, and so we're going to cd into the git directory,",
      "tokens": [
        51254,
        407,
        321,
        434,
        516,
        281,
        574,
        412,
        18331,
        510,
        11,
        293,
        370,
        321,
        434,
        516,
        281,
        269,
        67,
        666,
        264,
        18331,
        21120,
        11,
        51542
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2969980239868164,
      "compression_ratio": 1.8192771673202515,
      "end": 101.4800033569336,
      "no_speech_prob": 0.39591777324676514,
      "seek": 7604,
      "start": 99.5999984741211,
      "temperature": 0.0,
      "text": " and we can see there's the structure.",
      "tokens": [
        51542,
        293,
        321,
        393,
        536,
        456,
        311,
        264,
        3877,
        13,
        51636
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.2969980239868164,
      "compression_ratio": 1.8192771673202515,
      "end": 105.16000366210938,
      "no_speech_prob": 0.39591777324676514,
      "seek": 7604,
      "start": 101.4800033569336,
      "temperature": 0.0,
      "text": " We can run ls and tree to understand the high-level structure.",
      "tokens": [
        51636,
        492,
        393,
        1190,
        287,
        82,
        293,
        4230,
        281,
        1223,
        264,
        1090,
        12,
        12418,
        3877,
        13,
        51820
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.2818303406238556,
      "compression_ratio": 1.6576576232910156,
      "end": 107.72000122070312,
      "no_speech_prob": 0.0011334664886817336,
      "seek": 10516,
      "start": 105.16000366210938,
      "temperature": 0.0,
      "text": " And then we can run RepoMix.",
      "tokens": [
        50364,
        400,
        550,
        321,
        393,
        1190,
        3696,
        78,
        44,
        970,
        13,
        50492
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.2818303406238556,
      "compression_ratio": 1.6576576232910156,
      "end": 113.12000274658203,
      "no_speech_prob": 0.0011334664886817336,
      "seek": 10516,
      "start": 107.72000122070312,
      "temperature": 0.0,
      "text": " So RepoMix allows us to take this code base and collapse it into a single file.",
      "tokens": [
        50492,
        407,
        3696,
        78,
        44,
        970,
        4045,
        505,
        281,
        747,
        341,
        3089,
        3096,
        293,
        15584,
        309,
        666,
        257,
        2167,
        3991,
        13,
        50762
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.2818303406238556,
      "compression_ratio": 1.6576576232910156,
      "end": 115.87999725341797,
      "no_speech_prob": 0.0011334664886817336,
      "seek": 10516,
      "start": 113.12000274658203,
      "temperature": 0.0,
      "text": " You can see we have 30k tokens there.",
      "tokens": [
        50762,
        509,
        393,
        536,
        321,
        362,
        2217,
        74,
        22667,
        456,
        13,
        50900
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.2818303406238556,
      "compression_ratio": 1.6576576232910156,
      "end": 118.68000030517578,
      "no_speech_prob": 0.0011334664886817336,
      "seek": 10516,
      "start": 115.87999725341797,
      "temperature": 0.0,
      "text": " And now we're just going to move this into our code base.",
      "tokens": [
        50900,
        400,
        586,
        321,
        434,
        445,
        516,
        281,
        1286,
        341,
        666,
        527,
        3089,
        3096,
        13,
        51040
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.2818303406238556,
      "compression_ratio": 1.6576576232910156,
      "end": 125.44000244140625,
      "no_speech_prob": 0.0011334664886817336,
      "seek": 10516,
      "start": 118.68000030517578,
      "temperature": 0.0,
      "text": " So I'm going to get the path to our current code base, run that, and then move this into",
      "tokens": [
        51040,
        407,
        286,
        478,
        516,
        281,
        483,
        264,
        3100,
        281,
        527,
        2190,
        3089,
        3096,
        11,
        1190,
        300,
        11,
        293,
        550,
        1286,
        341,
        666,
        51378
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.2818303406238556,
      "compression_ratio": 1.6576576232910156,
      "end": 129.36000061035156,
      "no_speech_prob": 0.0011334664886817336,
      "seek": 10516,
      "start": 125.44000244140625,
      "temperature": 0.0,
      "text": " the AI docs directory.",
      "tokens": [
        51378,
        264,
        7318,
        45623,
        21120,
        13,
        51574
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.2818303406238556,
      "compression_ratio": 1.6576576232910156,
      "end": 131.0800018310547,
      "no_speech_prob": 0.0011334664886817336,
      "seek": 10516,
      "start": 129.36000061035156,
      "temperature": 0.0,
      "text": " You may have seen this throughout some of the code.",
      "tokens": [
        51574,
        509,
        815,
        362,
        1612,
        341,
        3710,
        512,
        295,
        264,
        3089,
        13,
        51660
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834716.688479
}
{
  "audio_path": "data/chunks/ai_coding_devlog_claude_code_has_changed_software_20250324_151153_chunk_005.mp3",
  "text": "your AI Coding Assistant continue, right? Keep going with the pattern, right? Fill in the blanks. Feel free to pause the video there. This is something that we talk about in principle AI Coding, but just by typing that dot, dot, dot there, our AI Coding Assistant knows to create the other Pydantic types. Filling in some more implementation notes here. You know, nothing super crazy, nothing super new happening here. And we're just working through everything that we want done here, right? So we're referencing our documentation. We're saying that we want all of our tags to be lowercase. And now we're looking at the MCP Git server. We wanna see the dependencies it has, right? So I wanna make sure that I'm covering the dependencies. We also want PyTest. We're going to need this for closed loop self-validation. And of course, SQLite 3, this is built in. So I'm going to make sure that I mentioned that. Okay. And I'm telling the, you know, I'm telling Cloud Code how to run things, right? And so just adding some more implementation notes here. I definitely could have added some of these inside of the project structure, but it's important to not overthink things too much. You just want to have the information visible to your AI coding tool, right? Keep things simple. Now we're doing something really, really important. Again, principal AI coding members know why this is so important. We're closing the loop here by telling our language model how to validate itself. So we're working through here. We almost have a final version. We're going to make one tweak to our plan. And, you know, you may be like, holy crap, you haven't done anything yet. You know, we spent 10 minutes writing this plan. That's right, we have. And you're going to see why and how powerful it is in just a moment here. And so as I was working through this, I realized that I don't think I had enough information to complete the work needed for the find command. And now that I'm playing this back, I'm actually, I actually completely write this incorrectly. So I'm using pocket add instead of pocket find. So, you know, there's just a glaring mistake there. We'll see if our AI coding assistant picks it up.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 3.5199999809265137,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " your AI Coding Assistant continue, right?",
      "tokens": [
        50364,
        428,
        7318,
        383,
        8616,
        14890,
        2354,
        11,
        558,
        30,
        50540
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 5.239999771118164,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 3.5199999809265137,
      "temperature": 0.0,
      "text": " Keep going with the pattern, right?",
      "tokens": [
        50540,
        5527,
        516,
        365,
        264,
        5102,
        11,
        558,
        30,
        50626
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 6.320000171661377,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 5.239999771118164,
      "temperature": 0.0,
      "text": " Fill in the blanks.",
      "tokens": [
        50626,
        25315,
        294,
        264,
        8247,
        82,
        13,
        50680
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 8.319999694824219,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 6.320000171661377,
      "temperature": 0.0,
      "text": " Feel free to pause the video there.",
      "tokens": [
        50680,
        14113,
        1737,
        281,
        10465,
        264,
        960,
        456,
        13,
        50780
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 9.899999618530273,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 8.319999694824219,
      "temperature": 0.0,
      "text": " This is something that we talk about",
      "tokens": [
        50780,
        639,
        307,
        746,
        300,
        321,
        751,
        466,
        50859
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 10.800000190734863,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 9.899999618530273,
      "temperature": 0.0,
      "text": " in principle AI Coding,",
      "tokens": [
        50859,
        294,
        8665,
        7318,
        383,
        8616,
        11,
        50904
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 13.760000228881836,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 10.800000190734863,
      "temperature": 0.0,
      "text": " but just by typing that dot, dot, dot there,",
      "tokens": [
        50904,
        457,
        445,
        538,
        18444,
        300,
        5893,
        11,
        5893,
        11,
        5893,
        456,
        11,
        51052
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 14.920000076293945,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 13.760000228881836,
      "temperature": 0.0,
      "text": " our AI Coding Assistant knows",
      "tokens": [
        51052,
        527,
        7318,
        383,
        8616,
        14890,
        3255,
        51110
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 17.399999618530273,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 14.920000076293945,
      "temperature": 0.0,
      "text": " to create the other Pydantic types.",
      "tokens": [
        51110,
        281,
        1884,
        264,
        661,
        430,
        6655,
        7128,
        3467,
        13,
        51234
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 19.1200008392334,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 17.399999618530273,
      "temperature": 0.0,
      "text": " Filling in some more implementation notes here.",
      "tokens": [
        51234,
        479,
        7345,
        294,
        512,
        544,
        11420,
        5570,
        510,
        13,
        51320
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 20.559999465942383,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 19.1200008392334,
      "temperature": 0.0,
      "text": " You know, nothing super crazy,",
      "tokens": [
        51320,
        509,
        458,
        11,
        1825,
        1687,
        3219,
        11,
        51392
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 22.459999084472656,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 20.559999465942383,
      "temperature": 0.0,
      "text": " nothing super new happening here.",
      "tokens": [
        51392,
        1825,
        1687,
        777,
        2737,
        510,
        13,
        51487
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 24.440000534057617,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 22.459999084472656,
      "temperature": 0.0,
      "text": " And we're just working through",
      "tokens": [
        51487,
        400,
        321,
        434,
        445,
        1364,
        807,
        51586
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 25.639999389648438,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 24.440000534057617,
      "temperature": 0.0,
      "text": " everything that we want done here, right?",
      "tokens": [
        51586,
        1203,
        300,
        321,
        528,
        1096,
        510,
        11,
        558,
        30,
        51646
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.2538265287876129,
      "compression_ratio": 1.7939189672470093,
      "end": 29.719999313354492,
      "no_speech_prob": 0.10811787098646164,
      "seek": 0,
      "start": 25.639999389648438,
      "temperature": 0.0,
      "text": " So we're referencing our documentation.",
      "tokens": [
        51646,
        407,
        321,
        434,
        40582,
        527,
        14333,
        13,
        51850
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 32.959999084472656,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 29.719999313354492,
      "temperature": 0.0,
      "text": " We're saying that we want all of our tags to be lowercase.",
      "tokens": [
        50364,
        492,
        434,
        1566,
        300,
        321,
        528,
        439,
        295,
        527,
        18632,
        281,
        312,
        3126,
        9765,
        13,
        50526
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 37.31999969482422,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 32.959999084472656,
      "temperature": 0.0,
      "text": " And now we're looking at the MCP Git server.",
      "tokens": [
        50526,
        400,
        586,
        321,
        434,
        1237,
        412,
        264,
        8797,
        47,
        16939,
        7154,
        13,
        50744
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 39.20000076293945,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 37.31999969482422,
      "temperature": 0.0,
      "text": " We wanna see the dependencies it has, right?",
      "tokens": [
        50744,
        492,
        1948,
        536,
        264,
        36606,
        309,
        575,
        11,
        558,
        30,
        50838
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 41.279998779296875,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 39.20000076293945,
      "temperature": 0.0,
      "text": " So I wanna make sure that I'm covering the dependencies.",
      "tokens": [
        50838,
        407,
        286,
        1948,
        652,
        988,
        300,
        286,
        478,
        10322,
        264,
        36606,
        13,
        50942
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 42.560001373291016,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 41.279998779296875,
      "temperature": 0.0,
      "text": " We also want PyTest.",
      "tokens": [
        50942,
        492,
        611,
        528,
        9953,
        51,
        377,
        13,
        51006
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 46.400001525878906,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 42.560001373291016,
      "temperature": 0.0,
      "text": " We're going to need this for closed loop self-validation.",
      "tokens": [
        51006,
        492,
        434,
        516,
        281,
        643,
        341,
        337,
        5395,
        6367,
        2698,
        12,
        3337,
        327,
        399,
        13,
        51198
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 48.560001373291016,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 46.400001525878906,
      "temperature": 0.0,
      "text": " And of course, SQLite 3, this is built in.",
      "tokens": [
        51198,
        400,
        295,
        1164,
        11,
        19200,
        642,
        805,
        11,
        341,
        307,
        3094,
        294,
        13,
        51306
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 51.560001373291016,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 48.560001373291016,
      "temperature": 0.0,
      "text": " So I'm going to make sure that I mentioned that.",
      "tokens": [
        51306,
        407,
        286,
        478,
        516,
        281,
        652,
        988,
        300,
        286,
        2835,
        300,
        13,
        51456
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 52.400001525878906,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 51.560001373291016,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51456,
        1033,
        13,
        51498
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 54.47999954223633,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 52.400001525878906,
      "temperature": 0.0,
      "text": " And I'm telling the, you know,",
      "tokens": [
        51498,
        400,
        286,
        478,
        3585,
        264,
        11,
        291,
        458,
        11,
        51602
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.22679780423641205,
      "compression_ratio": 1.6799999475479126,
      "end": 59.47999954223633,
      "no_speech_prob": 0.0005112383514642715,
      "seek": 2972,
      "start": 54.47999954223633,
      "temperature": 0.0,
      "text": " I'm telling Cloud Code how to run things, right?",
      "tokens": [
        51602,
        286,
        478,
        3585,
        8061,
        15549,
        577,
        281,
        1190,
        721,
        11,
        558,
        30,
        51852
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 63.439998626708984,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 60.08000183105469,
      "temperature": 0.0,
      "text": " And so just adding some more implementation notes here.",
      "tokens": [
        50382,
        400,
        370,
        445,
        5127,
        512,
        544,
        11420,
        5570,
        510,
        13,
        50550
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 65.44000244140625,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 63.439998626708984,
      "temperature": 0.0,
      "text": " I definitely could have added some of these",
      "tokens": [
        50550,
        286,
        2138,
        727,
        362,
        3869,
        512,
        295,
        613,
        50650
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 68.5999984741211,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 65.44000244140625,
      "temperature": 0.0,
      "text": " inside of the project structure,",
      "tokens": [
        50650,
        1854,
        295,
        264,
        1716,
        3877,
        11,
        50808
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 71.9800033569336,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 68.5999984741211,
      "temperature": 0.0,
      "text": " but it's important to not overthink things too much.",
      "tokens": [
        50808,
        457,
        309,
        311,
        1021,
        281,
        406,
        670,
        21074,
        721,
        886,
        709,
        13,
        50977
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 75.4000015258789,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 71.9800033569336,
      "temperature": 0.0,
      "text": " You just want to have the information visible",
      "tokens": [
        50977,
        509,
        445,
        528,
        281,
        362,
        264,
        1589,
        8974,
        51148
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 77.5,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 75.4000015258789,
      "temperature": 0.0,
      "text": " to your AI coding tool, right?",
      "tokens": [
        51148,
        281,
        428,
        7318,
        17720,
        2290,
        11,
        558,
        30,
        51253
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 78.55999755859375,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 77.5,
      "temperature": 0.0,
      "text": " Keep things simple.",
      "tokens": [
        51253,
        5527,
        721,
        2199,
        13,
        51306
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 80.30000305175781,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 78.55999755859375,
      "temperature": 0.0,
      "text": " Now we're doing something really, really important.",
      "tokens": [
        51306,
        823,
        321,
        434,
        884,
        746,
        534,
        11,
        534,
        1021,
        13,
        51393
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 82.04000091552734,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 80.30000305175781,
      "temperature": 0.0,
      "text": " Again, principal AI coding members",
      "tokens": [
        51393,
        3764,
        11,
        9716,
        7318,
        17720,
        2679,
        51480
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 84.37999725341797,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 82.04000091552734,
      "temperature": 0.0,
      "text": " know why this is so important.",
      "tokens": [
        51480,
        458,
        983,
        341,
        307,
        370,
        1021,
        13,
        51597
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 85.4800033569336,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 84.37999725341797,
      "temperature": 0.0,
      "text": " We're closing the loop here",
      "tokens": [
        51597,
        492,
        434,
        10377,
        264,
        6367,
        510,
        51652
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.21242251992225647,
      "compression_ratio": 1.6794425249099731,
      "end": 89.66000366210938,
      "no_speech_prob": 0.0007793470867909491,
      "seek": 5972,
      "start": 85.4800033569336,
      "temperature": 0.0,
      "text": " by telling our language model how to validate itself.",
      "tokens": [
        51652,
        538,
        3585,
        527,
        2856,
        2316,
        577,
        281,
        29562,
        2564,
        13,
        51861
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 91.37999725341797,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 90.5,
      "temperature": 0.0,
      "text": " So we're working through here.",
      "tokens": [
        50406,
        407,
        321,
        434,
        1364,
        807,
        510,
        13,
        50450
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 93.0199966430664,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 91.37999725341797,
      "temperature": 0.0,
      "text": " We almost have a final version.",
      "tokens": [
        50450,
        492,
        1920,
        362,
        257,
        2572,
        3037,
        13,
        50532
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 95.94000244140625,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 93.0199966430664,
      "temperature": 0.0,
      "text": " We're going to make one tweak to our plan.",
      "tokens": [
        50532,
        492,
        434,
        516,
        281,
        652,
        472,
        29879,
        281,
        527,
        1393,
        13,
        50678
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 98.05999755859375,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 95.94000244140625,
      "temperature": 0.0,
      "text": " And, you know, you may be like,",
      "tokens": [
        50678,
        400,
        11,
        291,
        458,
        11,
        291,
        815,
        312,
        411,
        11,
        50784
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 99.73999786376953,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 98.05999755859375,
      "temperature": 0.0,
      "text": " holy crap, you haven't done anything yet.",
      "tokens": [
        50784,
        10622,
        12426,
        11,
        291,
        2378,
        380,
        1096,
        1340,
        1939,
        13,
        50868
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 102.58000183105469,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 99.73999786376953,
      "temperature": 0.0,
      "text": " You know, we spent 10 minutes writing this plan.",
      "tokens": [
        50868,
        509,
        458,
        11,
        321,
        4418,
        1266,
        2077,
        3579,
        341,
        1393,
        13,
        51010
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 104.30000305175781,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 102.58000183105469,
      "temperature": 0.0,
      "text": " That's right, we have.",
      "tokens": [
        51010,
        663,
        311,
        558,
        11,
        321,
        362,
        13,
        51096
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 105.58000183105469,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 104.30000305175781,
      "temperature": 0.0,
      "text": " And you're going to see why",
      "tokens": [
        51096,
        400,
        291,
        434,
        516,
        281,
        536,
        983,
        51160
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 108.45999908447266,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 105.58000183105469,
      "temperature": 0.0,
      "text": " and how powerful it is in just a moment here.",
      "tokens": [
        51160,
        293,
        577,
        4005,
        309,
        307,
        294,
        445,
        257,
        1623,
        510,
        13,
        51304
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 109.5,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 108.45999908447266,
      "temperature": 0.0,
      "text": " And so as I was working through this,",
      "tokens": [
        51304,
        400,
        370,
        382,
        286,
        390,
        1364,
        807,
        341,
        11,
        51356
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 112.62000274658203,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 109.5,
      "temperature": 0.0,
      "text": " I realized that I don't think I had enough information",
      "tokens": [
        51356,
        286,
        5334,
        300,
        286,
        500,
        380,
        519,
        286,
        632,
        1547,
        1589,
        51512
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 117.18000030517578,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 112.62000274658203,
      "temperature": 0.0,
      "text": " to complete the work needed for the find command.",
      "tokens": [
        51512,
        281,
        3566,
        264,
        589,
        2978,
        337,
        264,
        915,
        5622,
        13,
        51740
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.20080237090587616,
      "compression_ratio": 1.7142857313156128,
      "end": 118.86000061035156,
      "no_speech_prob": 0.0006070640520192683,
      "seek": 8966,
      "start": 117.18000030517578,
      "temperature": 0.0,
      "text": " And now that I'm playing this back,",
      "tokens": [
        51740,
        400,
        586,
        300,
        286,
        478,
        2433,
        341,
        646,
        11,
        51824
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.2986568510532379,
      "compression_ratio": 1.384105920791626,
      "end": 123.41999816894531,
      "no_speech_prob": 0.0021488869097083807,
      "seek": 11886,
      "start": 118.86000061035156,
      "temperature": 0.0,
      "text": " I'm actually, I actually completely write this incorrectly.",
      "tokens": [
        50364,
        286,
        478,
        767,
        11,
        286,
        767,
        2584,
        2464,
        341,
        42892,
        13,
        50592
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.2986568510532379,
      "compression_ratio": 1.384105920791626,
      "end": 127.0199966430664,
      "no_speech_prob": 0.0021488869097083807,
      "seek": 11886,
      "start": 123.41999816894531,
      "temperature": 0.0,
      "text": " So I'm using pocket add instead of pocket find.",
      "tokens": [
        50592,
        407,
        286,
        478,
        1228,
        8963,
        909,
        2602,
        295,
        8963,
        915,
        13,
        50772
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.2986568510532379,
      "compression_ratio": 1.384105920791626,
      "end": 129.5399932861328,
      "no_speech_prob": 0.0021488869097083807,
      "seek": 11886,
      "start": 127.0199966430664,
      "temperature": 0.0,
      "text": " So, you know, there's just a glaring mistake there.",
      "tokens": [
        50772,
        407,
        11,
        291,
        458,
        11,
        456,
        311,
        445,
        257,
        1563,
        1921,
        6146,
        456,
        13,
        50898
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.2986568510532379,
      "compression_ratio": 1.384105920791626,
      "end": 131.94000244140625,
      "no_speech_prob": 0.0021488869097083807,
      "seek": 11886,
      "start": 129.5399932861328,
      "temperature": 0.0,
      "text": " We'll see if our AI coding assistant picks it up.",
      "tokens": [
        50898,
        492,
        603,
        536,
        498,
        527,
        7318,
        17720,
        10994,
        16137,
        309,
        493,
        13,
        51018
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834758.8656268
}
{
  "audio_path": "data/chunks/single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_012.mp3",
  "text": "or, you know, loops, we're running O3 mini is a powerful reasoning model. So, you know, as it's thinking through what tools to call and solving these problems, it's doing an extraordinary job. An interesting way to think about the AI agent is that the more compute you're giving it, basically what we're doing is we're extending the prompt chain, right? We're elongating the number of compute runs that it has. So if we wanted to solve a really hard problem, for instance, you know, OpenAI's deep research tool, this thing runs for five to 30 minutes, right? So you can imagine, you know, it's compute loop is, you know, blasted up to like a hundred across various tools, various functions, you know, various capabilities. That's a really powerful idea we're gonna be looking into more on the channel. Like I mentioned, I'm gonna have these single file agents in a code base for you to check out, tweak and make your own. I'll add a couple additional versions here that I was playing with so that you can, you know, check them out and build out your own. I have a version where I have the meta prompt we've talked about on the channel inside of a single file agent. You can just quickly query your meta prompting agent to generate a new prompt for you. Things are moving fast, agents are here. One of the most important agents and one of the most important things you can do right now is learn how to write code with AI and not just learn, but really scale your capabilities with writing code with AI. Many of you on the channel, you've already dove in to principled AI coding. Let me just pitch this for those who haven't taken it yet. This is really important and I wanna make sure I'm sharing this tool so that everyone is understanding the state engineering is in and how they can progress, keep up and thrive in the new world of generative AI. So principled AI coding is my take on how to transition from the old ways of engineering to the new way. We now have over a thousand engineers that have taken principled AI coding, that have a new perspective and actionable patterns and principles they can use for their engineering in today's landscape of generative AI and more importantly, for the next wave of generative AI based engineering. So, I don't know if you've noticed, if your eyes are open, you've probably noticed this, but software engineering has changed and it's time to change with it.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 3.3399999141693115,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " or, you know, loops, we're running O3 mini",
      "tokens": [
        50364,
        420,
        11,
        291,
        458,
        11,
        16121,
        11,
        321,
        434,
        2614,
        422,
        18,
        8382,
        50531
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 4.420000076293945,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 3.3399999141693115,
      "temperature": 0.0,
      "text": " is a powerful reasoning model.",
      "tokens": [
        50531,
        307,
        257,
        4005,
        21577,
        2316,
        13,
        50585
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 6.5,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 4.420000076293945,
      "temperature": 0.0,
      "text": " So, you know, as it's thinking through what tools to call",
      "tokens": [
        50585,
        407,
        11,
        291,
        458,
        11,
        382,
        309,
        311,
        1953,
        807,
        437,
        3873,
        281,
        818,
        50689
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 7.579999923706055,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 6.5,
      "temperature": 0.0,
      "text": " and solving these problems,",
      "tokens": [
        50689,
        293,
        12606,
        613,
        2740,
        11,
        50743
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 9.260000228881836,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 7.579999923706055,
      "temperature": 0.0,
      "text": " it's doing an extraordinary job.",
      "tokens": [
        50743,
        309,
        311,
        884,
        364,
        10581,
        1691,
        13,
        50827
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 11.65999984741211,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 9.260000228881836,
      "temperature": 0.0,
      "text": " An interesting way to think about the AI agent is",
      "tokens": [
        50827,
        1107,
        1880,
        636,
        281,
        519,
        466,
        264,
        7318,
        9461,
        307,
        50947
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 13.079999923706055,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 11.65999984741211,
      "temperature": 0.0,
      "text": " that the more compute you're giving it,",
      "tokens": [
        50947,
        300,
        264,
        544,
        14722,
        291,
        434,
        2902,
        309,
        11,
        51018
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 14.100000381469727,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 13.079999923706055,
      "temperature": 0.0,
      "text": " basically what we're doing is",
      "tokens": [
        51018,
        1936,
        437,
        321,
        434,
        884,
        307,
        51069
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 16.219999313354492,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 14.100000381469727,
      "temperature": 0.0,
      "text": " we're extending the prompt chain, right?",
      "tokens": [
        51069,
        321,
        434,
        24360,
        264,
        12391,
        5021,
        11,
        558,
        30,
        51175
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 19.979999542236328,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 16.219999313354492,
      "temperature": 0.0,
      "text": " We're elongating the number of compute runs that it has.",
      "tokens": [
        51175,
        492,
        434,
        40786,
        990,
        264,
        1230,
        295,
        14722,
        6676,
        300,
        309,
        575,
        13,
        51363
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 22.299999237060547,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 19.979999542236328,
      "temperature": 0.0,
      "text": " So if we wanted to solve a really hard problem,",
      "tokens": [
        51363,
        407,
        498,
        321,
        1415,
        281,
        5039,
        257,
        534,
        1152,
        1154,
        11,
        51479
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 25.6200008392334,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 22.299999237060547,
      "temperature": 0.0,
      "text": " for instance, you know, OpenAI's deep research tool,",
      "tokens": [
        51479,
        337,
        5197,
        11,
        291,
        458,
        11,
        7238,
        48698,
        311,
        2452,
        2132,
        2290,
        11,
        51645
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.22963613271713257,
      "compression_ratio": 1.7383177280426025,
      "end": 28.899999618530273,
      "no_speech_prob": 0.039042823016643524,
      "seek": 0,
      "start": 25.6200008392334,
      "temperature": 0.0,
      "text": " this thing runs for five to 30 minutes, right?",
      "tokens": [
        51645,
        341,
        551,
        6676,
        337,
        1732,
        281,
        2217,
        2077,
        11,
        558,
        30,
        51809
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 30.219999313354492,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 28.899999618530273,
      "temperature": 0.0,
      "text": " So you can imagine, you know,",
      "tokens": [
        50364,
        407,
        291,
        393,
        3811,
        11,
        291,
        458,
        11,
        50430
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 32.34000015258789,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 30.219999313354492,
      "temperature": 0.0,
      "text": " it's compute loop is, you know,",
      "tokens": [
        50430,
        309,
        311,
        14722,
        6367,
        307,
        11,
        291,
        458,
        11,
        50536
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 35.779998779296875,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 32.34000015258789,
      "temperature": 0.0,
      "text": " blasted up to like a hundred across various tools,",
      "tokens": [
        50536,
        12035,
        292,
        493,
        281,
        411,
        257,
        3262,
        2108,
        3683,
        3873,
        11,
        50708
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 38.41999816894531,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 35.779998779296875,
      "temperature": 0.0,
      "text": " various functions, you know, various capabilities.",
      "tokens": [
        50708,
        3683,
        6828,
        11,
        291,
        458,
        11,
        3683,
        10862,
        13,
        50840
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 39.81999969482422,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 38.41999816894531,
      "temperature": 0.0,
      "text": " That's a really powerful idea",
      "tokens": [
        50840,
        663,
        311,
        257,
        534,
        4005,
        1558,
        50910
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 42.41999816894531,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 39.81999969482422,
      "temperature": 0.0,
      "text": " we're gonna be looking into more on the channel.",
      "tokens": [
        50910,
        321,
        434,
        799,
        312,
        1237,
        666,
        544,
        322,
        264,
        2269,
        13,
        51040
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 44.86000061035156,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 42.41999816894531,
      "temperature": 0.0,
      "text": " Like I mentioned, I'm gonna have these single file agents",
      "tokens": [
        51040,
        1743,
        286,
        2835,
        11,
        286,
        478,
        799,
        362,
        613,
        2167,
        3991,
        12554,
        51162
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 46.540000915527344,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 44.86000061035156,
      "temperature": 0.0,
      "text": " in a code base for you to check out,",
      "tokens": [
        51162,
        294,
        257,
        3089,
        3096,
        337,
        291,
        281,
        1520,
        484,
        11,
        51246
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 48.099998474121094,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 46.540000915527344,
      "temperature": 0.0,
      "text": " tweak and make your own.",
      "tokens": [
        51246,
        29879,
        293,
        652,
        428,
        1065,
        13,
        51324
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 49.619998931884766,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 48.099998474121094,
      "temperature": 0.0,
      "text": " I'll add a couple additional versions here",
      "tokens": [
        51324,
        286,
        603,
        909,
        257,
        1916,
        4497,
        9606,
        510,
        51400
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 51.34000015258789,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 49.619998931884766,
      "temperature": 0.0,
      "text": " that I was playing with so that you can, you know,",
      "tokens": [
        51400,
        300,
        286,
        390,
        2433,
        365,
        370,
        300,
        291,
        393,
        11,
        291,
        458,
        11,
        51486
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 52.779998779296875,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 51.34000015258789,
      "temperature": 0.0,
      "text": " check them out and build out your own.",
      "tokens": [
        51486,
        1520,
        552,
        484,
        293,
        1322,
        484,
        428,
        1065,
        13,
        51558
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 55.18000030517578,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 52.779998779296875,
      "temperature": 0.0,
      "text": " I have a version where I have the meta prompt",
      "tokens": [
        51558,
        286,
        362,
        257,
        3037,
        689,
        286,
        362,
        264,
        19616,
        12391,
        51678
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 56.41999816894531,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 55.18000030517578,
      "temperature": 0.0,
      "text": " we've talked about on the channel",
      "tokens": [
        51678,
        321,
        600,
        2825,
        466,
        322,
        264,
        2269,
        51740
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.2016514539718628,
      "compression_ratio": 1.8419452905654907,
      "end": 57.97999954223633,
      "no_speech_prob": 0.0007793608820065856,
      "seek": 2890,
      "start": 56.41999816894531,
      "temperature": 0.0,
      "text": " inside of a single file agent.",
      "tokens": [
        51740,
        1854,
        295,
        257,
        2167,
        3991,
        9461,
        13,
        51818
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 61.220001220703125,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 57.97999954223633,
      "temperature": 0.0,
      "text": " You can just quickly query your meta prompting agent",
      "tokens": [
        50364,
        509,
        393,
        445,
        2661,
        14581,
        428,
        19616,
        12391,
        278,
        9461,
        50526
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 62.540000915527344,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 61.220001220703125,
      "temperature": 0.0,
      "text": " to generate a new prompt for you.",
      "tokens": [
        50526,
        281,
        8460,
        257,
        777,
        12391,
        337,
        291,
        13,
        50592
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 64.69999694824219,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 62.540000915527344,
      "temperature": 0.0,
      "text": " Things are moving fast, agents are here.",
      "tokens": [
        50592,
        9514,
        366,
        2684,
        2370,
        11,
        12554,
        366,
        510,
        13,
        50700
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 66.18000030517578,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 64.69999694824219,
      "temperature": 0.0,
      "text": " One of the most important agents",
      "tokens": [
        50700,
        1485,
        295,
        264,
        881,
        1021,
        12554,
        50774
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 69.30000305175781,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 66.18000030517578,
      "temperature": 0.0,
      "text": " and one of the most important things you can do right now",
      "tokens": [
        50774,
        293,
        472,
        295,
        264,
        881,
        1021,
        721,
        291,
        393,
        360,
        558,
        586,
        50930
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 73.33999633789062,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 69.30000305175781,
      "temperature": 0.0,
      "text": " is learn how to write code with AI and not just learn,",
      "tokens": [
        50930,
        307,
        1466,
        577,
        281,
        2464,
        3089,
        365,
        7318,
        293,
        406,
        445,
        1466,
        11,
        51132
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 76.45999908447266,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 73.33999633789062,
      "temperature": 0.0,
      "text": " but really scale your capabilities",
      "tokens": [
        51132,
        457,
        534,
        4373,
        428,
        10862,
        51288
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 78.22000122070312,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 76.45999908447266,
      "temperature": 0.0,
      "text": " with writing code with AI.",
      "tokens": [
        51288,
        365,
        3579,
        3089,
        365,
        7318,
        13,
        51376
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 79.16000366210938,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 78.22000122070312,
      "temperature": 0.0,
      "text": " Many of you on the channel,",
      "tokens": [
        51376,
        5126,
        295,
        291,
        322,
        264,
        2269,
        11,
        51423
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 81.69999694824219,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 79.16000366210938,
      "temperature": 0.0,
      "text": " you've already dove in to principled AI coding.",
      "tokens": [
        51423,
        291,
        600,
        1217,
        23287,
        294,
        281,
        3681,
        15551,
        7318,
        17720,
        13,
        51550
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 84.41999816894531,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 81.69999694824219,
      "temperature": 0.0,
      "text": " Let me just pitch this for those who haven't taken it yet.",
      "tokens": [
        51550,
        961,
        385,
        445,
        7293,
        341,
        337,
        729,
        567,
        2378,
        380,
        2726,
        309,
        1939,
        13,
        51686
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 85.73999786376953,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 84.41999816894531,
      "temperature": 0.0,
      "text": " This is really important",
      "tokens": [
        51686,
        639,
        307,
        534,
        1021,
        51752
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.20268793404102325,
      "compression_ratio": 1.7672131061553955,
      "end": 87.73999786376953,
      "no_speech_prob": 0.002050714334473014,
      "seek": 5798,
      "start": 85.73999786376953,
      "temperature": 0.0,
      "text": " and I wanna make sure I'm sharing this tool",
      "tokens": [
        51752,
        293,
        286,
        1948,
        652,
        988,
        286,
        478,
        5414,
        341,
        2290,
        51852
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 89.94000244140625,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 88.5,
      "temperature": 0.0,
      "text": " so that everyone is understanding",
      "tokens": [
        50402,
        370,
        300,
        1518,
        307,
        3701,
        50474
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 93.13999938964844,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 89.94000244140625,
      "temperature": 0.0,
      "text": " the state engineering is in and how they can progress,",
      "tokens": [
        50474,
        264,
        1785,
        7043,
        307,
        294,
        293,
        577,
        436,
        393,
        4205,
        11,
        50634
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 96.9800033569336,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 93.13999938964844,
      "temperature": 0.0,
      "text": " keep up and thrive in the new world of generative AI.",
      "tokens": [
        50634,
        1066,
        493,
        293,
        21233,
        294,
        264,
        777,
        1002,
        295,
        1337,
        1166,
        7318,
        13,
        50826
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 99.69999694824219,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 96.9800033569336,
      "temperature": 0.0,
      "text": " So principled AI coding is my take",
      "tokens": [
        50826,
        407,
        3681,
        15551,
        7318,
        17720,
        307,
        452,
        747,
        50962
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 102.94000244140625,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 99.69999694824219,
      "temperature": 0.0,
      "text": " on how to transition from the old ways of engineering",
      "tokens": [
        50962,
        322,
        577,
        281,
        6034,
        490,
        264,
        1331,
        2098,
        295,
        7043,
        51124
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 103.94000244140625,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 102.94000244140625,
      "temperature": 0.0,
      "text": " to the new way.",
      "tokens": [
        51124,
        281,
        264,
        777,
        636,
        13,
        51174
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 106.87999725341797,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 103.94000244140625,
      "temperature": 0.0,
      "text": " We now have over a thousand engineers",
      "tokens": [
        51174,
        492,
        586,
        362,
        670,
        257,
        4714,
        11955,
        51321
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 108.45999908447266,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 106.87999725341797,
      "temperature": 0.0,
      "text": " that have taken principled AI coding,",
      "tokens": [
        51321,
        300,
        362,
        2726,
        3681,
        15551,
        7318,
        17720,
        11,
        51400
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 112.19999694824219,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 108.45999908447266,
      "temperature": 0.0,
      "text": " that have a new perspective and actionable patterns",
      "tokens": [
        51400,
        300,
        362,
        257,
        777,
        4585,
        293,
        45098,
        8294,
        51587
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.209640771150589,
      "compression_ratio": 1.8478261232376099,
      "end": 115.05999755859375,
      "no_speech_prob": 0.0008295766310766339,
      "seek": 8774,
      "start": 112.19999694824219,
      "temperature": 0.0,
      "text": " and principles they can use for their engineering",
      "tokens": [
        51587,
        293,
        9156,
        436,
        393,
        764,
        337,
        641,
        7043,
        51730
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 117.81999969482422,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 115.05999755859375,
      "temperature": 0.0,
      "text": " in today's landscape of generative AI",
      "tokens": [
        50364,
        294,
        965,
        311,
        9661,
        295,
        1337,
        1166,
        7318,
        50502
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 118.69999694824219,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 117.81999969482422,
      "temperature": 0.0,
      "text": " and more importantly,",
      "tokens": [
        50502,
        293,
        544,
        8906,
        11,
        50546
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 122.77999877929688,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 118.69999694824219,
      "temperature": 0.0,
      "text": " for the next wave of generative AI based engineering.",
      "tokens": [
        50546,
        337,
        264,
        958,
        5772,
        295,
        1337,
        1166,
        7318,
        2361,
        7043,
        13,
        50750
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 125.05999755859375,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 122.77999877929688,
      "temperature": 0.0,
      "text": " So, I don't know if you've noticed,",
      "tokens": [
        50750,
        407,
        11,
        286,
        500,
        380,
        458,
        498,
        291,
        600,
        5694,
        11,
        50864
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 126.9000015258789,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 125.05999755859375,
      "temperature": 0.0,
      "text": " if your eyes are open, you've probably noticed this,",
      "tokens": [
        50864,
        498,
        428,
        2575,
        366,
        1269,
        11,
        291,
        600,
        1391,
        5694,
        341,
        11,
        50956
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 128.6999969482422,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 126.9000015258789,
      "temperature": 0.0,
      "text": " but software engineering has changed",
      "tokens": [
        50956,
        457,
        4722,
        7043,
        575,
        3105,
        51046
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.22144947946071625,
      "compression_ratio": 1.5722543001174927,
      "end": 130.74000549316406,
      "no_speech_prob": 0.0288681760430336,
      "seek": 11506,
      "start": 128.6999969482422,
      "temperature": 0.0,
      "text": " and it's time to change with it.",
      "tokens": [
        51046,
        293,
        309,
        311,
        565,
        281,
        1319,
        365,
        309,
        13,
        51148
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835040.229727
}
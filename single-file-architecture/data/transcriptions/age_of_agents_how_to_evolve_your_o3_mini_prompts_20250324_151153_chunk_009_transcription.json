{
  "audio_path": "data/chunks/age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_009.mp3",
  "text": "It has name and args. It's running make deletions here, just cutting out this one word. It's running another tool call here, editing out a few additional words, so on and so forth, right? You can see here it just continues to call make deletion. We run over and over and over and over, and then once we get to the bottom, it now calls an explicit tool. Instead of returning an empty list, it calls complete edit when it's done. So if we scroll all the way to the bottom, we'll get that exact same structure. So you can see the scratch pack active memory pattern is going to be really important for rolling out useful personal AI assistance. It just took out scratch pad. Didn't think scratch pad was important, so it edited that out, okay? So this is something that will just happen sometimes. You know, you can see here between the prompt chain and the AI assistant on this single use case, more compute isn't always better. And this is a really important thing to call out, okay? So this is our AI agent, and we can, of course, scale this up. Let's go ahead and let our O3 mini run the AI agent version, and let's go ahead and take a look at the AI agent code, okay? So we'll go ahead, kick this off, and let's dive into what the AI agent version of this looks like. So same deal on the top level, just logging and setup. And then this is where all the work happens, okay? So generate, cut, deletions, V3. So we'll hop in here, and let's open this up. Couple things are different right away. We have an entire class to support our AI agent. Why is that? Because we need to better manage state and tool calls. So just like the prompt chain, you can see there's our loop. And we'll go into the class in just a moment here, but you can see we're setting up the agent as a new class. We're passing in our starting state, and then the agent just gets updated with this one call, right? We just run prompt over and over, and then it just returns if it's done, right? Because our agents know what work to do. They know when to tell us when they're done. It's just a matter of letting them loop, letting them do the work, and then they'll let us know when they're done, right? This is kind of an interesting paradigm shift when we move into these longer-running assistants, these longer-running jobs. You know, a while back we put out this video called the two-way prompting, and that video really does set up the future of how we'll be operating with agentic technology. It might start out with us prompting them, but then they will prompt us, right? And we just saw this with deep research.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 2.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " It has name and args.",
      "tokens": [
        50364,
        467,
        575,
        1315,
        293,
        3882,
        82,
        13,
        50464
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 4.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 2.0,
      "temperature": 0.0,
      "text": " It's running make deletions here,",
      "tokens": [
        50464,
        467,
        311,
        2614,
        652,
        1103,
        302,
        626,
        510,
        11,
        50564
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 6.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 4.0,
      "temperature": 0.0,
      "text": " just cutting out this one word.",
      "tokens": [
        50564,
        445,
        6492,
        484,
        341,
        472,
        1349,
        13,
        50664
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 8.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 6.0,
      "temperature": 0.0,
      "text": " It's running another tool call here,",
      "tokens": [
        50664,
        467,
        311,
        2614,
        1071,
        2290,
        818,
        510,
        11,
        50764
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 10.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 8.0,
      "temperature": 0.0,
      "text": " editing out a few additional words,",
      "tokens": [
        50764,
        10000,
        484,
        257,
        1326,
        4497,
        2283,
        11,
        50864
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 11.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 10.0,
      "temperature": 0.0,
      "text": " so on and so forth, right?",
      "tokens": [
        50864,
        370,
        322,
        293,
        370,
        5220,
        11,
        558,
        30,
        50914
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 13.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 11.0,
      "temperature": 0.0,
      "text": " You can see here it just continues to call make deletion.",
      "tokens": [
        50914,
        509,
        393,
        536,
        510,
        309,
        445,
        6515,
        281,
        818,
        652,
        1103,
        302,
        313,
        13,
        51014
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 15.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 13.0,
      "temperature": 0.0,
      "text": " We run over and over and over and over,",
      "tokens": [
        51014,
        492,
        1190,
        670,
        293,
        670,
        293,
        670,
        293,
        670,
        11,
        51114
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 16.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 15.0,
      "temperature": 0.0,
      "text": " and then once we get to the bottom,",
      "tokens": [
        51114,
        293,
        550,
        1564,
        321,
        483,
        281,
        264,
        2767,
        11,
        51164
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 18.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 16.0,
      "temperature": 0.0,
      "text": " it now calls an explicit tool.",
      "tokens": [
        51164,
        309,
        586,
        5498,
        364,
        13691,
        2290,
        13,
        51264
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 20.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 18.0,
      "temperature": 0.0,
      "text": " Instead of returning an empty list,",
      "tokens": [
        51264,
        7156,
        295,
        12678,
        364,
        6707,
        1329,
        11,
        51364
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 22.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 20.0,
      "temperature": 0.0,
      "text": " it calls complete edit when it's done.",
      "tokens": [
        51364,
        309,
        5498,
        3566,
        8129,
        562,
        309,
        311,
        1096,
        13,
        51464
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 24.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 22.0,
      "temperature": 0.0,
      "text": " So if we scroll all the way to the bottom,",
      "tokens": [
        51464,
        407,
        498,
        321,
        11369,
        439,
        264,
        636,
        281,
        264,
        2767,
        11,
        51564
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 26.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 24.0,
      "temperature": 0.0,
      "text": " we'll get that exact same structure.",
      "tokens": [
        51564,
        321,
        603,
        483,
        300,
        1900,
        912,
        3877,
        13,
        51664
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.21408258378505707,
      "compression_ratio": 1.8576159477233887,
      "end": 28.0,
      "no_speech_prob": 0.23366083204746246,
      "seek": 0,
      "start": 26.0,
      "temperature": 0.0,
      "text": " So you can see the scratch pack active memory pattern",
      "tokens": [
        51664,
        407,
        291,
        393,
        536,
        264,
        8459,
        2844,
        4967,
        4675,
        5102,
        51764
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 30.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 28.0,
      "temperature": 0.0,
      "text": " is going to be really important for rolling out",
      "tokens": [
        50364,
        307,
        516,
        281,
        312,
        534,
        1021,
        337,
        9439,
        484,
        50464
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 31.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 30.0,
      "temperature": 0.0,
      "text": " useful personal AI assistance.",
      "tokens": [
        50464,
        4420,
        2973,
        7318,
        9683,
        13,
        50514
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 33.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 31.0,
      "temperature": 0.0,
      "text": " It just took out scratch pad.",
      "tokens": [
        50514,
        467,
        445,
        1890,
        484,
        8459,
        6887,
        13,
        50614
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 34.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 33.0,
      "temperature": 0.0,
      "text": " Didn't think scratch pad was important,",
      "tokens": [
        50614,
        11151,
        380,
        519,
        8459,
        6887,
        390,
        1021,
        11,
        50664
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 36.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 34.0,
      "temperature": 0.0,
      "text": " so it edited that out, okay?",
      "tokens": [
        50664,
        370,
        309,
        23016,
        300,
        484,
        11,
        1392,
        30,
        50764
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 38.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 36.0,
      "temperature": 0.0,
      "text": " So this is something that will just happen sometimes.",
      "tokens": [
        50764,
        407,
        341,
        307,
        746,
        300,
        486,
        445,
        1051,
        2171,
        13,
        50864
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 40.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 38.0,
      "temperature": 0.0,
      "text": " You know, you can see here between the prompt chain",
      "tokens": [
        50864,
        509,
        458,
        11,
        291,
        393,
        536,
        510,
        1296,
        264,
        12391,
        5021,
        50964
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 42.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 40.0,
      "temperature": 0.0,
      "text": " and the AI assistant on this single use case,",
      "tokens": [
        50964,
        293,
        264,
        7318,
        10994,
        322,
        341,
        2167,
        764,
        1389,
        11,
        51064
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 44.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 42.0,
      "temperature": 0.0,
      "text": " more compute isn't always better.",
      "tokens": [
        51064,
        544,
        14722,
        1943,
        380,
        1009,
        1101,
        13,
        51164
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 46.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 44.0,
      "temperature": 0.0,
      "text": " And this is a really important thing to call out, okay?",
      "tokens": [
        51164,
        400,
        341,
        307,
        257,
        534,
        1021,
        551,
        281,
        818,
        484,
        11,
        1392,
        30,
        51264
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 49.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 46.0,
      "temperature": 0.0,
      "text": " So this is our AI agent,",
      "tokens": [
        51264,
        407,
        341,
        307,
        527,
        7318,
        9461,
        11,
        51414
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 51.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 49.0,
      "temperature": 0.0,
      "text": " and we can, of course, scale this up.",
      "tokens": [
        51414,
        293,
        321,
        393,
        11,
        295,
        1164,
        11,
        4373,
        341,
        493,
        13,
        51514
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 54.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 51.0,
      "temperature": 0.0,
      "text": " Let's go ahead and let our O3 mini",
      "tokens": [
        51514,
        961,
        311,
        352,
        2286,
        293,
        718,
        527,
        422,
        18,
        8382,
        51664
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.19621305167675018,
      "compression_ratio": 1.7745097875595093,
      "end": 56.0,
      "no_speech_prob": 0.21464437246322632,
      "seek": 2800,
      "start": 54.0,
      "temperature": 0.0,
      "text": " run the AI agent version,",
      "tokens": [
        51664,
        1190,
        264,
        7318,
        9461,
        3037,
        11,
        51764
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 58.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 56.0,
      "temperature": 0.0,
      "text": " and let's go ahead and take a look at the AI agent code, okay?",
      "tokens": [
        50364,
        293,
        718,
        311,
        352,
        2286,
        293,
        747,
        257,
        574,
        412,
        264,
        7318,
        9461,
        3089,
        11,
        1392,
        30,
        50464
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 60.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 58.0,
      "temperature": 0.0,
      "text": " So we'll go ahead, kick this off,",
      "tokens": [
        50464,
        407,
        321,
        603,
        352,
        2286,
        11,
        4437,
        341,
        766,
        11,
        50564
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 64.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 60.0,
      "temperature": 0.0,
      "text": " and let's dive into what the AI agent version of this looks like.",
      "tokens": [
        50564,
        293,
        718,
        311,
        9192,
        666,
        437,
        264,
        7318,
        9461,
        3037,
        295,
        341,
        1542,
        411,
        13,
        50764
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 67.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 64.0,
      "temperature": 0.0,
      "text": " So same deal on the top level, just logging and setup.",
      "tokens": [
        50764,
        407,
        912,
        2028,
        322,
        264,
        1192,
        1496,
        11,
        445,
        27991,
        293,
        8657,
        13,
        50914
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 69.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 67.0,
      "temperature": 0.0,
      "text": " And then this is where all the work happens, okay?",
      "tokens": [
        50914,
        400,
        550,
        341,
        307,
        689,
        439,
        264,
        589,
        2314,
        11,
        1392,
        30,
        51014
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 72.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 69.0,
      "temperature": 0.0,
      "text": " So generate, cut, deletions, V3.",
      "tokens": [
        51014,
        407,
        8460,
        11,
        1723,
        11,
        1103,
        302,
        626,
        11,
        691,
        18,
        13,
        51164
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 74.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 72.0,
      "temperature": 0.0,
      "text": " So we'll hop in here, and let's open this up.",
      "tokens": [
        51164,
        407,
        321,
        603,
        3818,
        294,
        510,
        11,
        293,
        718,
        311,
        1269,
        341,
        493,
        13,
        51264
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 76.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 74.0,
      "temperature": 0.0,
      "text": " Couple things are different right away.",
      "tokens": [
        51264,
        38266,
        721,
        366,
        819,
        558,
        1314,
        13,
        51364
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 79.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 76.0,
      "temperature": 0.0,
      "text": " We have an entire class to support our AI agent.",
      "tokens": [
        51364,
        492,
        362,
        364,
        2302,
        1508,
        281,
        1406,
        527,
        7318,
        9461,
        13,
        51514
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 80.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 79.0,
      "temperature": 0.0,
      "text": " Why is that?",
      "tokens": [
        51514,
        1545,
        307,
        300,
        30,
        51564
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 83.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 80.0,
      "temperature": 0.0,
      "text": " Because we need to better manage state and tool calls.",
      "tokens": [
        51564,
        1436,
        321,
        643,
        281,
        1101,
        3067,
        1785,
        293,
        2290,
        5498,
        13,
        51714
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.16139595210552216,
      "compression_ratio": 1.722561001777649,
      "end": 85.0,
      "no_speech_prob": 0.4454374313354492,
      "seek": 5600,
      "start": 83.0,
      "temperature": 0.0,
      "text": " So just like the prompt chain, you can see there's our loop.",
      "tokens": [
        51714,
        407,
        445,
        411,
        264,
        12391,
        5021,
        11,
        291,
        393,
        536,
        456,
        311,
        527,
        6367,
        13,
        51814
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 87.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 85.0,
      "temperature": 0.0,
      "text": " And we'll go into the class in just a moment here,",
      "tokens": [
        50364,
        400,
        321,
        603,
        352,
        666,
        264,
        1508,
        294,
        445,
        257,
        1623,
        510,
        11,
        50464
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 90.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 87.0,
      "temperature": 0.0,
      "text": " but you can see we're setting up the agent as a new class.",
      "tokens": [
        50464,
        457,
        291,
        393,
        536,
        321,
        434,
        3287,
        493,
        264,
        9461,
        382,
        257,
        777,
        1508,
        13,
        50614
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 92.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 90.0,
      "temperature": 0.0,
      "text": " We're passing in our starting state,",
      "tokens": [
        50614,
        492,
        434,
        8437,
        294,
        527,
        2891,
        1785,
        11,
        50714
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 95.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 92.0,
      "temperature": 0.0,
      "text": " and then the agent just gets updated with this one call, right?",
      "tokens": [
        50714,
        293,
        550,
        264,
        9461,
        445,
        2170,
        10588,
        365,
        341,
        472,
        818,
        11,
        558,
        30,
        50864
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 97.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 95.0,
      "temperature": 0.0,
      "text": " We just run prompt over and over,",
      "tokens": [
        50864,
        492,
        445,
        1190,
        12391,
        670,
        293,
        670,
        11,
        50964
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 99.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 97.0,
      "temperature": 0.0,
      "text": " and then it just returns if it's done, right?",
      "tokens": [
        50964,
        293,
        550,
        309,
        445,
        11247,
        498,
        309,
        311,
        1096,
        11,
        558,
        30,
        51064
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 101.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 99.0,
      "temperature": 0.0,
      "text": " Because our agents know what work to do.",
      "tokens": [
        51064,
        1436,
        527,
        12554,
        458,
        437,
        589,
        281,
        360,
        13,
        51164
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 103.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 101.0,
      "temperature": 0.0,
      "text": " They know when to tell us when they're done.",
      "tokens": [
        51164,
        814,
        458,
        562,
        281,
        980,
        505,
        562,
        436,
        434,
        1096,
        13,
        51264
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 105.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 103.0,
      "temperature": 0.0,
      "text": " It's just a matter of letting them loop,",
      "tokens": [
        51264,
        467,
        311,
        445,
        257,
        1871,
        295,
        8295,
        552,
        6367,
        11,
        51364
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 106.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 105.0,
      "temperature": 0.0,
      "text": " letting them do the work,",
      "tokens": [
        51364,
        8295,
        552,
        360,
        264,
        589,
        11,
        51414
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 109.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 106.0,
      "temperature": 0.0,
      "text": " and then they'll let us know when they're done, right?",
      "tokens": [
        51414,
        293,
        550,
        436,
        603,
        718,
        505,
        458,
        562,
        436,
        434,
        1096,
        11,
        558,
        30,
        51564
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 111.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 109.0,
      "temperature": 0.0,
      "text": " This is kind of an interesting paradigm shift",
      "tokens": [
        51564,
        639,
        307,
        733,
        295,
        364,
        1880,
        24709,
        5513,
        51664
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.15062008798122406,
      "compression_ratio": 1.8829114437103271,
      "end": 114.0,
      "no_speech_prob": 0.022628335282206535,
      "seek": 8500,
      "start": 111.0,
      "temperature": 0.0,
      "text": " when we move into these longer-running assistants,",
      "tokens": [
        51664,
        562,
        321,
        1286,
        666,
        613,
        2854,
        12,
        45482,
        34949,
        11,
        51814
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 115.0,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 114.0,
      "temperature": 0.0,
      "text": " these longer-running jobs.",
      "tokens": [
        50364,
        613,
        2854,
        12,
        45482,
        4782,
        13,
        50414
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 117.0,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 115.0,
      "temperature": 0.0,
      "text": " You know, a while back we put out this video",
      "tokens": [
        50414,
        509,
        458,
        11,
        257,
        1339,
        646,
        321,
        829,
        484,
        341,
        960,
        50514
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 119.0,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 117.0,
      "temperature": 0.0,
      "text": " called the two-way prompting,",
      "tokens": [
        50514,
        1219,
        264,
        732,
        12,
        676,
        12391,
        278,
        11,
        50614
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 121.0,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 119.0,
      "temperature": 0.0,
      "text": " and that video really does set up the future",
      "tokens": [
        50614,
        293,
        300,
        960,
        534,
        775,
        992,
        493,
        264,
        2027,
        50714
      ]
    },
    {
      "id": 58,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 125.0,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 121.0,
      "temperature": 0.0,
      "text": " of how we'll be operating with agentic technology.",
      "tokens": [
        50714,
        295,
        577,
        321,
        603,
        312,
        7447,
        365,
        9461,
        299,
        2899,
        13,
        50914
      ]
    },
    {
      "id": 59,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 127.0,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 125.0,
      "temperature": 0.0,
      "text": " It might start out with us prompting them,",
      "tokens": [
        50914,
        467,
        1062,
        722,
        484,
        365,
        505,
        12391,
        278,
        552,
        11,
        51014
      ]
    },
    {
      "id": 60,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 129.0,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 127.0,
      "temperature": 0.0,
      "text": " but then they will prompt us, right?",
      "tokens": [
        51014,
        457,
        550,
        436,
        486,
        12391,
        505,
        11,
        558,
        30,
        51114
      ]
    },
    {
      "id": 61,
      "avg_logprob": -0.17196503281593323,
      "compression_ratio": 1.521531105041504,
      "end": 131.0,
      "no_speech_prob": 0.017174843698740005,
      "seek": 11400,
      "start": 129.0,
      "temperature": 0.0,
      "text": " And we just saw this with deep research.",
      "tokens": [
        51114,
        400,
        321,
        445,
        1866,
        341,
        365,
        2452,
        2132,
        13,
        51214
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835413.799665
}
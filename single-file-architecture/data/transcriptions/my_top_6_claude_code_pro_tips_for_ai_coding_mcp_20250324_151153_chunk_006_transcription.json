{
  "audio_path": "data/chunks/my_top_6_claude_code_pro_tips_for_ai_coding_mcp_20250324_151153_chunk_006.mp3",
  "text": "you can see that there are release notes now. That's tip three. It might seem simple, but the Cloud Code engineers are really shipping in the shadows here and you wanna be keeping track of everything you're releasing if we hit enter here. I wanna point out something really, really cool that was just released. You can say, ask Cloud to make a plan with thinking mode. So obviously they're tapping into Cloud's hybrid base reasoning model capabilities. If you say think, think harder or ultra think, you will tap into these. So that's tip number four. Let's go ahead and use that tip. We just set up this brand new efficiency flag by pulling in this context using an MCP server. Here it is here. And I'm gonna update this prompt just a little bit, create a Flask API with three endpoints inside of agent workspace. Yeah, sure, that looks good. And so now we have this here. It's gonna run in efficiency mode and we're also gonna have thinking tokens. What I wanna do here is create two versions, right? I want this to run without efficiency and with efficiency so that we can actually see the difference. I'm not gonna run this, right? There's no reason for me to do this. I'm gonna hand this work off to Cloud Code. I'm gonna hand this work off to my AI coding tools. So I'm gonna copy this and then we're going to also combine this with a think mode. And so here's what I'll do. I'll move over to our temporary file. I'll paste this command in, test out the token efficient exactly, the following command without dash dash efficiency. And then we'll say with, and there we go. We're getting some great auto completions from cursor tab. And then what I wanna say here is record, think hard in the review process, okay? I'm gonna paste this into Cloud Code and then I'm gonna fire this off, okay? So now it's going to actually run the agent itself. It's going to keep track of the results and then it's going to run both in efficiency mode and without efficiency mode, okay? So you can see the output of our agent there. We had an issue with our thinking tokens. It looks like we're passing in way too many thinking tokens. Let's go ahead and drop that down. So I'm gonna drop this down. Let's run this at the minimum for thinking tokens, which is 1,024. So I'll copy and then paste this back in.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 3.4800000190734863,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " you can see that there are release notes now.",
      "tokens": [
        50364,
        291,
        393,
        536,
        300,
        456,
        366,
        4374,
        5570,
        586,
        13,
        50538
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 4.460000038146973,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 3.4800000190734863,
      "temperature": 0.0,
      "text": " That's tip three.",
      "tokens": [
        50538,
        663,
        311,
        4125,
        1045,
        13,
        50587
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 5.539999961853027,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 4.460000038146973,
      "temperature": 0.0,
      "text": " It might seem simple,",
      "tokens": [
        50587,
        467,
        1062,
        1643,
        2199,
        11,
        50641
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 7.460000038146973,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 5.539999961853027,
      "temperature": 0.0,
      "text": " but the Cloud Code engineers are really shipping",
      "tokens": [
        50641,
        457,
        264,
        8061,
        15549,
        11955,
        366,
        534,
        14122,
        50737
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 8.300000190734863,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 7.460000038146973,
      "temperature": 0.0,
      "text": " in the shadows here",
      "tokens": [
        50737,
        294,
        264,
        14740,
        510,
        50779
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 10.600000381469727,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 8.300000190734863,
      "temperature": 0.0,
      "text": " and you wanna be keeping track of everything you're releasing",
      "tokens": [
        50779,
        293,
        291,
        1948,
        312,
        5145,
        2837,
        295,
        1203,
        291,
        434,
        16327,
        50894
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 12.420000076293945,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 10.600000381469727,
      "temperature": 0.0,
      "text": " if we hit enter here.",
      "tokens": [
        50894,
        498,
        321,
        2045,
        3242,
        510,
        13,
        50985
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 14.5,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 12.420000076293945,
      "temperature": 0.0,
      "text": " I wanna point out something really, really cool",
      "tokens": [
        50985,
        286,
        1948,
        935,
        484,
        746,
        534,
        11,
        534,
        1627,
        51089
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 15.65999984741211,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 14.5,
      "temperature": 0.0,
      "text": " that was just released.",
      "tokens": [
        51089,
        300,
        390,
        445,
        4736,
        13,
        51147
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 19.459999084472656,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 15.65999984741211,
      "temperature": 0.0,
      "text": " You can say, ask Cloud to make a plan with thinking mode.",
      "tokens": [
        51147,
        509,
        393,
        584,
        11,
        1029,
        8061,
        281,
        652,
        257,
        1393,
        365,
        1953,
        4391,
        13,
        51337
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 21.780000686645508,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 19.459999084472656,
      "temperature": 0.0,
      "text": " So obviously they're tapping",
      "tokens": [
        51337,
        407,
        2745,
        436,
        434,
        21444,
        51453
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 26.420000076293945,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 21.780000686645508,
      "temperature": 0.0,
      "text": " into Cloud's hybrid base reasoning model capabilities.",
      "tokens": [
        51453,
        666,
        8061,
        311,
        13051,
        3096,
        21577,
        2316,
        10862,
        13,
        51685
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.2608173191547394,
      "compression_ratio": 1.7447552680969238,
      "end": 29.700000762939453,
      "no_speech_prob": 0.18709796667099,
      "seek": 0,
      "start": 26.420000076293945,
      "temperature": 0.0,
      "text": " If you say think, think harder or ultra think,",
      "tokens": [
        51685,
        759,
        291,
        584,
        519,
        11,
        519,
        6081,
        420,
        14808,
        519,
        11,
        51849
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 31.1200008392334,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 29.700000762939453,
      "temperature": 0.0,
      "text": " you will tap into these.",
      "tokens": [
        50364,
        291,
        486,
        5119,
        666,
        613,
        13,
        50435
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 32.560001373291016,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 31.1200008392334,
      "temperature": 0.0,
      "text": " So that's tip number four.",
      "tokens": [
        50435,
        407,
        300,
        311,
        4125,
        1230,
        1451,
        13,
        50507
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 34.119998931884766,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 32.560001373291016,
      "temperature": 0.0,
      "text": " Let's go ahead and use that tip.",
      "tokens": [
        50507,
        961,
        311,
        352,
        2286,
        293,
        764,
        300,
        4125,
        13,
        50585
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 36.560001373291016,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 34.119998931884766,
      "temperature": 0.0,
      "text": " We just set up this brand new efficiency flag",
      "tokens": [
        50585,
        492,
        445,
        992,
        493,
        341,
        3360,
        777,
        10493,
        7166,
        50707
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 41.15999984741211,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 36.560001373291016,
      "temperature": 0.0,
      "text": " by pulling in this context using an MCP server.",
      "tokens": [
        50707,
        538,
        8407,
        294,
        341,
        4319,
        1228,
        364,
        8797,
        47,
        7154,
        13,
        50937
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 42.15999984741211,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 41.15999984741211,
      "temperature": 0.0,
      "text": " Here it is here.",
      "tokens": [
        50937,
        1692,
        309,
        307,
        510,
        13,
        50987
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 43.91999816894531,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 42.15999984741211,
      "temperature": 0.0,
      "text": " And I'm gonna update this prompt just a little bit,",
      "tokens": [
        50987,
        400,
        286,
        478,
        799,
        5623,
        341,
        12391,
        445,
        257,
        707,
        857,
        11,
        51075
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 46.34000015258789,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 43.91999816894531,
      "temperature": 0.0,
      "text": " create a Flask API with three endpoints",
      "tokens": [
        51075,
        1884,
        257,
        3235,
        3863,
        9362,
        365,
        1045,
        917,
        20552,
        51196
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 48.79999923706055,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 46.34000015258789,
      "temperature": 0.0,
      "text": " inside of agent workspace.",
      "tokens": [
        51196,
        1854,
        295,
        9461,
        32706,
        13,
        51319
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 50.20000076293945,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 48.79999923706055,
      "temperature": 0.0,
      "text": " Yeah, sure, that looks good.",
      "tokens": [
        51319,
        865,
        11,
        988,
        11,
        300,
        1542,
        665,
        13,
        51389
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 52.279998779296875,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 50.20000076293945,
      "temperature": 0.0,
      "text": " And so now we have this here.",
      "tokens": [
        51389,
        400,
        370,
        586,
        321,
        362,
        341,
        510,
        13,
        51493
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 54.08000183105469,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 52.279998779296875,
      "temperature": 0.0,
      "text": " It's gonna run in efficiency mode",
      "tokens": [
        51493,
        467,
        311,
        799,
        1190,
        294,
        10493,
        4391,
        51583
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 55.36000061035156,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 54.08000183105469,
      "temperature": 0.0,
      "text": " and we're also gonna have thinking tokens.",
      "tokens": [
        51583,
        293,
        321,
        434,
        611,
        799,
        362,
        1953,
        22667,
        13,
        51647
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.18630225956439972,
      "compression_ratio": 1.6193548440933228,
      "end": 58.15999984741211,
      "no_speech_prob": 0.00011774333688663319,
      "seek": 2970,
      "start": 55.36000061035156,
      "temperature": 0.0,
      "text": " What I wanna do here is create two versions, right?",
      "tokens": [
        51647,
        708,
        286,
        1948,
        360,
        510,
        307,
        1884,
        732,
        9606,
        11,
        558,
        30,
        51787
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 62.13999938964844,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 58.15999984741211,
      "temperature": 0.0,
      "text": " I want this to run without efficiency and with efficiency",
      "tokens": [
        50364,
        286,
        528,
        341,
        281,
        1190,
        1553,
        10493,
        293,
        365,
        10493,
        50563
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 63.86000061035156,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 62.13999938964844,
      "temperature": 0.0,
      "text": " so that we can actually see the difference.",
      "tokens": [
        50563,
        370,
        300,
        321,
        393,
        767,
        536,
        264,
        2649,
        13,
        50649
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 65.13999938964844,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 63.86000061035156,
      "temperature": 0.0,
      "text": " I'm not gonna run this, right?",
      "tokens": [
        50649,
        286,
        478,
        406,
        799,
        1190,
        341,
        11,
        558,
        30,
        50713
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 67.05999755859375,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 65.13999938964844,
      "temperature": 0.0,
      "text": " There's no reason for me to do this.",
      "tokens": [
        50713,
        821,
        311,
        572,
        1778,
        337,
        385,
        281,
        360,
        341,
        13,
        50809
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 69.30000305175781,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 67.05999755859375,
      "temperature": 0.0,
      "text": " I'm gonna hand this work off to Cloud Code.",
      "tokens": [
        50809,
        286,
        478,
        799,
        1011,
        341,
        589,
        766,
        281,
        8061,
        15549,
        13,
        50921
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 71.94000244140625,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 69.30000305175781,
      "temperature": 0.0,
      "text": " I'm gonna hand this work off to my AI coding tools.",
      "tokens": [
        50921,
        286,
        478,
        799,
        1011,
        341,
        589,
        766,
        281,
        452,
        7318,
        17720,
        3873,
        13,
        51053
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 73.18000030517578,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 71.94000244140625,
      "temperature": 0.0,
      "text": " So I'm gonna copy this",
      "tokens": [
        51053,
        407,
        286,
        478,
        799,
        5055,
        341,
        51115
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 77.22000122070312,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 73.18000030517578,
      "temperature": 0.0,
      "text": " and then we're going to also combine this with a think mode.",
      "tokens": [
        51115,
        293,
        550,
        321,
        434,
        516,
        281,
        611,
        10432,
        341,
        365,
        257,
        519,
        4391,
        13,
        51317
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 78.05999755859375,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 77.22000122070312,
      "temperature": 0.0,
      "text": " And so here's what I'll do.",
      "tokens": [
        51317,
        400,
        370,
        510,
        311,
        437,
        286,
        603,
        360,
        13,
        51359
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 80.18000030517578,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 78.05999755859375,
      "temperature": 0.0,
      "text": " I'll move over to our temporary file.",
      "tokens": [
        51359,
        286,
        603,
        1286,
        670,
        281,
        527,
        13413,
        3991,
        13,
        51465
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 81.66000366210938,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 80.18000030517578,
      "temperature": 0.0,
      "text": " I'll paste this command in,",
      "tokens": [
        51465,
        286,
        603,
        9163,
        341,
        5622,
        294,
        11,
        51539
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 84.68000030517578,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 81.66000366210938,
      "temperature": 0.0,
      "text": " test out the token efficient exactly,",
      "tokens": [
        51539,
        1500,
        484,
        264,
        14862,
        7148,
        2293,
        11,
        51690
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.17760416865348816,
      "compression_ratio": 1.8701754808425903,
      "end": 88.0999984741211,
      "no_speech_prob": 0.00136701634619385,
      "seek": 5816,
      "start": 84.68000030517578,
      "temperature": 0.0,
      "text": " the following command without dash dash efficiency.",
      "tokens": [
        51690,
        264,
        3480,
        5622,
        1553,
        8240,
        8240,
        10493,
        13,
        51861
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 90.12000274658203,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 89.04000091552734,
      "temperature": 0.0,
      "text": " And then we'll say with, and there we go.",
      "tokens": [
        50411,
        400,
        550,
        321,
        603,
        584,
        365,
        11,
        293,
        456,
        321,
        352,
        13,
        50465
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 93.27999877929688,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 90.12000274658203,
      "temperature": 0.0,
      "text": " We're getting some great auto completions from cursor tab.",
      "tokens": [
        50465,
        492,
        434,
        1242,
        512,
        869,
        8399,
        1557,
        626,
        490,
        28169,
        4421,
        13,
        50623
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 96.0999984741211,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 93.27999877929688,
      "temperature": 0.0,
      "text": " And then what I wanna say here is record,",
      "tokens": [
        50623,
        400,
        550,
        437,
        286,
        1948,
        584,
        510,
        307,
        2136,
        11,
        50764
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 99.27999877929688,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 96.0999984741211,
      "temperature": 0.0,
      "text": " think hard in the review process, okay?",
      "tokens": [
        50764,
        519,
        1152,
        294,
        264,
        3131,
        1399,
        11,
        1392,
        30,
        50923
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 100.9800033569336,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 99.27999877929688,
      "temperature": 0.0,
      "text": " I'm gonna paste this into Cloud Code",
      "tokens": [
        50923,
        286,
        478,
        799,
        9163,
        341,
        666,
        8061,
        15549,
        51008
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 103.08000183105469,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 100.9800033569336,
      "temperature": 0.0,
      "text": " and then I'm gonna fire this off, okay?",
      "tokens": [
        51008,
        293,
        550,
        286,
        478,
        799,
        2610,
        341,
        766,
        11,
        1392,
        30,
        51113
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 106.27999877929688,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 103.08000183105469,
      "temperature": 0.0,
      "text": " So now it's going to actually run the agent itself.",
      "tokens": [
        51113,
        407,
        586,
        309,
        311,
        516,
        281,
        767,
        1190,
        264,
        9461,
        2564,
        13,
        51273
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 109.36000061035156,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 106.27999877929688,
      "temperature": 0.0,
      "text": " It's going to keep track of the results",
      "tokens": [
        51273,
        467,
        311,
        516,
        281,
        1066,
        2837,
        295,
        264,
        3542,
        51427
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 112.91999816894531,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 109.36000061035156,
      "temperature": 0.0,
      "text": " and then it's going to run both in efficiency mode",
      "tokens": [
        51427,
        293,
        550,
        309,
        311,
        516,
        281,
        1190,
        1293,
        294,
        10493,
        4391,
        51605
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 115.83999633789062,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 112.91999816894531,
      "temperature": 0.0,
      "text": " and without efficiency mode, okay?",
      "tokens": [
        51605,
        293,
        1553,
        10493,
        4391,
        11,
        1392,
        30,
        51751
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.2242647111415863,
      "compression_ratio": 1.8089888095855713,
      "end": 118.08000183105469,
      "no_speech_prob": 0.00032503384863957763,
      "seek": 8810,
      "start": 115.83999633789062,
      "temperature": 0.0,
      "text": " So you can see the output of our agent there.",
      "tokens": [
        51751,
        407,
        291,
        393,
        536,
        264,
        5598,
        295,
        527,
        9461,
        456,
        13,
        51863
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.23832152783870697,
      "compression_ratio": 1.5988372564315796,
      "end": 120.66000366210938,
      "no_speech_prob": 0.004331146366894245,
      "seek": 11808,
      "start": 118.94000244140625,
      "temperature": 0.0,
      "text": " We had an issue with our thinking tokens.",
      "tokens": [
        50407,
        492,
        632,
        364,
        2734,
        365,
        527,
        1953,
        22667,
        13,
        50493
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.23832152783870697,
      "compression_ratio": 1.5988372564315796,
      "end": 122.77999877929688,
      "no_speech_prob": 0.004331146366894245,
      "seek": 11808,
      "start": 120.66000366210938,
      "temperature": 0.0,
      "text": " It looks like we're passing in way too many thinking tokens.",
      "tokens": [
        50493,
        467,
        1542,
        411,
        321,
        434,
        8437,
        294,
        636,
        886,
        867,
        1953,
        22667,
        13,
        50599
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.23832152783870697,
      "compression_ratio": 1.5988372564315796,
      "end": 123.81999969482422,
      "no_speech_prob": 0.004331146366894245,
      "seek": 11808,
      "start": 122.77999877929688,
      "temperature": 0.0,
      "text": " Let's go ahead and drop that down.",
      "tokens": [
        50599,
        961,
        311,
        352,
        2286,
        293,
        3270,
        300,
        760,
        13,
        50651
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.23832152783870697,
      "compression_ratio": 1.5988372564315796,
      "end": 125.18000030517578,
      "no_speech_prob": 0.004331146366894245,
      "seek": 11808,
      "start": 123.81999969482422,
      "temperature": 0.0,
      "text": " So I'm gonna drop this down.",
      "tokens": [
        50651,
        407,
        286,
        478,
        799,
        3270,
        341,
        760,
        13,
        50719
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.23832152783870697,
      "compression_ratio": 1.5988372564315796,
      "end": 127.5999984741211,
      "no_speech_prob": 0.004331146366894245,
      "seek": 11808,
      "start": 125.18000030517578,
      "temperature": 0.0,
      "text": " Let's run this at the minimum for thinking tokens,",
      "tokens": [
        50719,
        961,
        311,
        1190,
        341,
        412,
        264,
        7285,
        337,
        1953,
        22667,
        11,
        50840
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.23832152783870697,
      "compression_ratio": 1.5988372564315796,
      "end": 129.17999267578125,
      "no_speech_prob": 0.004331146366894245,
      "seek": 11808,
      "start": 127.5999984741211,
      "temperature": 0.0,
      "text": " which is 1,024.",
      "tokens": [
        50840,
        597,
        307,
        502,
        11,
        15,
        7911,
        13,
        50919
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.23832152783870697,
      "compression_ratio": 1.5988372564315796,
      "end": 131.3800048828125,
      "no_speech_prob": 0.004331146366894245,
      "seek": 11808,
      "start": 129.17999267578125,
      "temperature": 0.0,
      "text": " So I'll copy and then paste this back in.",
      "tokens": [
        50919,
        407,
        286,
        603,
        5055,
        293,
        550,
        9163,
        341,
        646,
        294,
        13,
        51029
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834630.296947
}
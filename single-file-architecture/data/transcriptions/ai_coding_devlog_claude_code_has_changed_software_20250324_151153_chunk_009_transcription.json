{
  "audio_path": "data/chunks/ai_coding_devlog_claude_code_has_changed_software_20250324_151153_chunk_009.mp3",
  "text": "Right about a thousand tokens. Okay, so, you know just looking at it from a point-blank perspective I just 16 X my impact right I multiply what I could do by 16 X not Considering any complications not considering any of the time it takes to actually write the code. That's just on a per line Basis, okay Really? It's more like a 30 or 40 or 50 X because it takes time to think through and test all this code Right, and we just packaged it We created a great package. We created a great plan. And what do we do? We handed it off to our AI tooling. We handed it off to our AI coding assistant We gave it to Claude code the new agentic coder on the block and we said here's a great comprehensive plan Build this for us, okay So I hope you can see why that's so valuable if you kind of get it if you understand where things are going hit like hit subscribe join the journey as we dig into using these tools and getting massive value out of these tools for your engineering work for your career and for your Projects as mentioned in principle a coding soon. There will be nowhere else to go AI coding tools are taking over Engineers using these tools as you can see here They're doing more than ever thought possible before an engineer even writing iterative prompts over and over and over They're not Coding like this, right? They're not generating as much as they could be. Okay, so this is really important So what are we doing now? So now we're actually Running our MCP server, right? So we just created a brand new pocket pick code base as a MCP first tool So now we're going to test it. All right Now we're firing up Claude you can see there no tools right no MCP tools and now we're going to take this command right Claude MCP add pocket pick and You know, I'm adding some documentation here for snippet reuse and We're gonna fire that off",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.37209177017211914,
      "compression_ratio": 1.4637681245803833,
      "end": 6.320000171661377,
      "no_speech_prob": 0.2719295024871826,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " Right about a thousand tokens. Okay, so, you know just looking at it from a point-blank perspective",
      "tokens": [
        50364,
        1779,
        466,
        257,
        4714,
        22667,
        13,
        1033,
        11,
        370,
        11,
        291,
        458,
        445,
        1237,
        412,
        309,
        490,
        257,
        935,
        12,
        5199,
        657,
        4585,
        50680
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.37209177017211914,
      "compression_ratio": 1.4637681245803833,
      "end": 13.34000015258789,
      "no_speech_prob": 0.2719295024871826,
      "seek": 0,
      "start": 6.480000019073486,
      "temperature": 0.0,
      "text": " I just 16 X my impact right I multiply what I could do by 16 X not",
      "tokens": [
        50688,
        286,
        445,
        3165,
        1783,
        452,
        2712,
        558,
        286,
        12972,
        437,
        286,
        727,
        360,
        538,
        3165,
        1783,
        406,
        51031
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.37209177017211914,
      "compression_ratio": 1.4637681245803833,
      "end": 20.959999084472656,
      "no_speech_prob": 0.2719295024871826,
      "seek": 0,
      "start": 13.640000343322754,
      "temperature": 0.0,
      "text": " Considering any complications not considering any of the time it takes to actually write the code. That's just on a per line",
      "tokens": [
        51046,
        33854,
        604,
        26566,
        406,
        8079,
        604,
        295,
        264,
        565,
        309,
        2516,
        281,
        767,
        2464,
        264,
        3089,
        13,
        663,
        311,
        445,
        322,
        257,
        680,
        1622,
        51412
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.37209177017211914,
      "compression_ratio": 1.4637681245803833,
      "end": 22.719999313354492,
      "no_speech_prob": 0.2719295024871826,
      "seek": 0,
      "start": 21.360000610351562,
      "temperature": 0.0,
      "text": " Basis, okay",
      "tokens": [
        51432,
        5859,
        271,
        11,
        1392,
        51500
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.21934989094734192,
      "compression_ratio": 1.708695650100708,
      "end": 30.479999542236328,
      "no_speech_prob": 0.04534526541829109,
      "seek": 2272,
      "start": 22.719999313354492,
      "temperature": 0.0,
      "text": " Really? It's more like a 30 or 40 or 50 X because it takes time to think through and test all this code",
      "tokens": [
        50364,
        4083,
        30,
        467,
        311,
        544,
        411,
        257,
        2217,
        420,
        3356,
        420,
        2625,
        1783,
        570,
        309,
        2516,
        565,
        281,
        519,
        807,
        293,
        1500,
        439,
        341,
        3089,
        50752
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.21934989094734192,
      "compression_ratio": 1.708695650100708,
      "end": 32.47999954223633,
      "no_speech_prob": 0.04534526541829109,
      "seek": 2272,
      "start": 30.479999542236328,
      "temperature": 0.0,
      "text": " Right, and we just packaged it",
      "tokens": [
        50752,
        1779,
        11,
        293,
        321,
        445,
        38162,
        309,
        50852
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.21934989094734192,
      "compression_ratio": 1.708695650100708,
      "end": 37.08000183105469,
      "no_speech_prob": 0.04534526541829109,
      "seek": 2272,
      "start": 32.7599983215332,
      "temperature": 0.0,
      "text": " We created a great package. We created a great plan. And what do we do?",
      "tokens": [
        50866,
        492,
        2942,
        257,
        869,
        7372,
        13,
        492,
        2942,
        257,
        869,
        1393,
        13,
        400,
        437,
        360,
        321,
        360,
        30,
        51082
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.21934989094734192,
      "compression_ratio": 1.708695650100708,
      "end": 43.439998626708984,
      "no_speech_prob": 0.04534526541829109,
      "seek": 2272,
      "start": 37.08000183105469,
      "temperature": 0.0,
      "text": " We handed it off to our AI tooling. We handed it off to our AI coding assistant",
      "tokens": [
        51082,
        492,
        16013,
        309,
        766,
        281,
        527,
        7318,
        46593,
        13,
        492,
        16013,
        309,
        766,
        281,
        527,
        7318,
        17720,
        10994,
        51400
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.21934989094734192,
      "compression_ratio": 1.708695650100708,
      "end": 51.0,
      "no_speech_prob": 0.04534526541829109,
      "seek": 2272,
      "start": 43.439998626708984,
      "temperature": 0.0,
      "text": " We gave it to Claude code the new agentic coder on the block and we said here's a great comprehensive plan",
      "tokens": [
        51400,
        492,
        2729,
        309,
        281,
        12947,
        2303,
        3089,
        264,
        777,
        9461,
        299,
        17656,
        260,
        322,
        264,
        3461,
        293,
        321,
        848,
        510,
        311,
        257,
        869,
        13914,
        1393,
        51778
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.3218258023262024,
      "compression_ratio": 1.6827309131622314,
      "end": 53.68000030517578,
      "no_speech_prob": 0.0010004636133089662,
      "seek": 5100,
      "start": 51.68000030517578,
      "temperature": 0.0,
      "text": " Build this for us, okay",
      "tokens": [
        50398,
        11875,
        341,
        337,
        505,
        11,
        1392,
        50498
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.3218258023262024,
      "compression_ratio": 1.6827309131622314,
      "end": 59.599998474121094,
      "no_speech_prob": 0.0010004636133089662,
      "seek": 5100,
      "start": 53.68000030517578,
      "temperature": 0.0,
      "text": " So I hope you can see why that's so valuable if you kind of get it if you understand where things are going hit like",
      "tokens": [
        50498,
        407,
        286,
        1454,
        291,
        393,
        536,
        983,
        300,
        311,
        370,
        8263,
        498,
        291,
        733,
        295,
        483,
        309,
        498,
        291,
        1223,
        689,
        721,
        366,
        516,
        2045,
        411,
        50794
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.3218258023262024,
      "compression_ratio": 1.6827309131622314,
      "end": 62.560001373291016,
      "no_speech_prob": 0.0010004636133089662,
      "seek": 5100,
      "start": 59.599998474121094,
      "temperature": 0.0,
      "text": " hit subscribe join the journey as we",
      "tokens": [
        50794,
        2045,
        3022,
        3917,
        264,
        4671,
        382,
        321,
        50942
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.3218258023262024,
      "compression_ratio": 1.6827309131622314,
      "end": 64.36000061035156,
      "no_speech_prob": 0.0010004636133089662,
      "seek": 5100,
      "start": 62.959999084472656,
      "temperature": 0.0,
      "text": " dig into",
      "tokens": [
        50962,
        2528,
        666,
        51032
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.3218258023262024,
      "compression_ratio": 1.6827309131622314,
      "end": 70.5999984741211,
      "no_speech_prob": 0.0010004636133089662,
      "seek": 5100,
      "start": 64.36000061035156,
      "temperature": 0.0,
      "text": " using these tools and getting massive value out of these tools for your engineering work for your career and for your",
      "tokens": [
        51032,
        1228,
        613,
        3873,
        293,
        1242,
        5994,
        2158,
        484,
        295,
        613,
        3873,
        337,
        428,
        7043,
        589,
        337,
        428,
        3988,
        293,
        337,
        428,
        51344
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.3218258023262024,
      "compression_ratio": 1.6827309131622314,
      "end": 78.27999877929688,
      "no_speech_prob": 0.0010004636133089662,
      "seek": 5100,
      "start": 71.08000183105469,
      "temperature": 0.0,
      "text": " Projects as mentioned in principle a coding soon. There will be nowhere else to go AI coding tools are",
      "tokens": [
        51368,
        9849,
        82,
        382,
        2835,
        294,
        8665,
        257,
        17720,
        2321,
        13,
        821,
        486,
        312,
        11159,
        1646,
        281,
        352,
        7318,
        17720,
        3873,
        366,
        51728
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.3218258023262024,
      "compression_ratio": 1.6827309131622314,
      "end": 80.19999694824219,
      "no_speech_prob": 0.0010004636133089662,
      "seek": 5100,
      "start": 78.83999633789062,
      "temperature": 0.0,
      "text": " taking over",
      "tokens": [
        51756,
        1940,
        670,
        51824
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.25679129362106323,
      "compression_ratio": 1.6528302431106567,
      "end": 83.23999786376953,
      "no_speech_prob": 0.007815689779818058,
      "seek": 8020,
      "start": 80.23999786376953,
      "temperature": 0.0,
      "text": " Engineers using these tools as you can see here",
      "tokens": [
        50366,
        43950,
        1228,
        613,
        3873,
        382,
        291,
        393,
        536,
        510,
        50516
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.25679129362106323,
      "compression_ratio": 1.6528302431106567,
      "end": 91.31999969482422,
      "no_speech_prob": 0.007815689779818058,
      "seek": 8020,
      "start": 83.27999877929688,
      "temperature": 0.0,
      "text": " They're doing more than ever thought possible before an engineer even writing iterative prompts over and over and over",
      "tokens": [
        50518,
        814,
        434,
        884,
        544,
        813,
        1562,
        1194,
        1944,
        949,
        364,
        11403,
        754,
        3579,
        17138,
        1166,
        41095,
        670,
        293,
        670,
        293,
        670,
        50920
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.25679129362106323,
      "compression_ratio": 1.6528302431106567,
      "end": 92.76000213623047,
      "no_speech_prob": 0.007815689779818058,
      "seek": 8020,
      "start": 91.31999969482422,
      "temperature": 0.0,
      "text": " They're not",
      "tokens": [
        50920,
        814,
        434,
        406,
        50992
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.25679129362106323,
      "compression_ratio": 1.6528302431106567,
      "end": 98.95999908447266,
      "no_speech_prob": 0.007815689779818058,
      "seek": 8020,
      "start": 92.76000213623047,
      "temperature": 0.0,
      "text": " Coding like this, right? They're not generating as much as they could be. Okay, so this is really important",
      "tokens": [
        50992,
        383,
        8616,
        411,
        341,
        11,
        558,
        30,
        814,
        434,
        406,
        17746,
        382,
        709,
        382,
        436,
        727,
        312,
        13,
        1033,
        11,
        370,
        341,
        307,
        534,
        1021,
        51302
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.25679129362106323,
      "compression_ratio": 1.6528302431106567,
      "end": 100.95999908447266,
      "no_speech_prob": 0.007815689779818058,
      "seek": 8020,
      "start": 98.95999908447266,
      "temperature": 0.0,
      "text": " So what are we doing now? So now we're actually",
      "tokens": [
        51302,
        407,
        437,
        366,
        321,
        884,
        586,
        30,
        407,
        586,
        321,
        434,
        767,
        51402
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.25679129362106323,
      "compression_ratio": 1.6528302431106567,
      "end": 109.4000015258789,
      "no_speech_prob": 0.007815689779818058,
      "seek": 8020,
      "start": 101.68000030517578,
      "temperature": 0.0,
      "text": " Running our MCP server, right? So we just created a brand new pocket pick code base as a MCP first tool",
      "tokens": [
        51438,
        28136,
        527,
        8797,
        47,
        7154,
        11,
        558,
        30,
        407,
        321,
        445,
        2942,
        257,
        3360,
        777,
        8963,
        1888,
        3089,
        3096,
        382,
        257,
        8797,
        47,
        700,
        2290,
        51824
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.2941652238368988,
      "compression_ratio": 1.5955055952072144,
      "end": 111.55999755859375,
      "no_speech_prob": 8.480578981107101e-05,
      "seek": 10940,
      "start": 109.55999755859375,
      "temperature": 0.0,
      "text": " So now we're going to test it. All right",
      "tokens": [
        50372,
        407,
        586,
        321,
        434,
        516,
        281,
        1500,
        309,
        13,
        1057,
        558,
        50472
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.2941652238368988,
      "compression_ratio": 1.5955055952072144,
      "end": 121.16000366210938,
      "no_speech_prob": 8.480578981107101e-05,
      "seek": 10940,
      "start": 114.16000366210938,
      "temperature": 0.0,
      "text": " Now we're firing up Claude you can see there no tools right no MCP tools and now we're going to take this command",
      "tokens": [
        50602,
        823,
        321,
        434,
        16045,
        493,
        12947,
        2303,
        291,
        393,
        536,
        456,
        572,
        3873,
        558,
        572,
        8797,
        47,
        3873,
        293,
        586,
        321,
        434,
        516,
        281,
        747,
        341,
        5622,
        50952
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.2941652238368988,
      "compression_ratio": 1.5955055952072144,
      "end": 124.19999694824219,
      "no_speech_prob": 8.480578981107101e-05,
      "seek": 10940,
      "start": 121.87999725341797,
      "temperature": 0.0,
      "text": " right Claude MCP add pocket pick and",
      "tokens": [
        50988,
        558,
        12947,
        2303,
        8797,
        47,
        909,
        8963,
        1888,
        293,
        51104
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.2941652238368988,
      "compression_ratio": 1.5955055952072144,
      "end": 128.9199981689453,
      "no_speech_prob": 8.480578981107101e-05,
      "seek": 10940,
      "start": 124.95999908447266,
      "temperature": 0.0,
      "text": " You know, I'm adding some documentation here for snippet reuse and",
      "tokens": [
        51142,
        509,
        458,
        11,
        286,
        478,
        5127,
        512,
        14333,
        510,
        337,
        35623,
        302,
        26225,
        293,
        51340
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.2941652238368988,
      "compression_ratio": 1.5955055952072144,
      "end": 132.0,
      "no_speech_prob": 8.480578981107101e-05,
      "seek": 10940,
      "start": 130.0,
      "temperature": 0.0,
      "text": " We're gonna fire that off",
      "tokens": [
        51394,
        492,
        434,
        799,
        2610,
        300,
        766,
        51494
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834801.882134
}
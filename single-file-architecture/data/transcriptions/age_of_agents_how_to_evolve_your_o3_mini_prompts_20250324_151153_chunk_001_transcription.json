{
  "audio_path": "data/chunks/age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_001.mp3",
  "text": "What's up, engineers? Indie Dev Dan here. We've entered the age of agents. Microsoft is rolling out co-pilot agent mode. OpenAI had back-to-back launches with Operator right into Deep Research. This is the most comprehensive Deep Research tool I've ever seen and used. Gemini has a version of Deep Research. More notably, they have their Notebook AI agent. Meanwhile, Anthropic created computer use and kind of set off this entire stream of generative AI companies, building agents on top of their own technology. The computer use, text editor, and Bash tools are still some of the most slept on tools to date. Check this out. Here's a simple bun logging script. I can open up the terminal. I have a file editing agent built on top of Anthropic's file editing tool. We can run this prompt and it'll make three distinct changes for us. It's going to read this file, update it, it's going to add the directory param just like we're asking, and then it's going to add a confirmation flag. You can see that just came in there. Then it's going to create two new versions, a shell script version and a PowerShell version. There it is. If I run that grep command again, you can see we now have those three individual files. Here's the updated bun version, clearlogs.sh. Here's the shell version, clearlogs.ps1. Here's the PowerShell version. With a single command, I was able to generate three changes thanks to my file AI agent. If it's not clear to you already, AI agents are extremely powerful. Why is that? It's because they turn your prompt, context, and model into actions at scale. It's important that you and I, the engineer, know how and when to build and deploy AI agents across your developer tooling projects and work. In this video, I want to take you through the prompt, the prompt chain, and the AI agent to help you understand which one you need to get the job done. We'll lean on Anthropic's incredible building effective agents post, and I'll share my distillation of what matters and mistakes I've made when building.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 2.319999933242798,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " What's up, engineers? Indie Dev Dan here.",
      "tokens": [
        50364,
        708,
        311,
        493,
        11,
        11955,
        30,
        2333,
        414,
        9096,
        3394,
        510,
        13,
        50480
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 5.320000171661377,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 2.319999933242798,
      "temperature": 0.0,
      "text": " We've entered the age of agents.",
      "tokens": [
        50480,
        492,
        600,
        9065,
        264,
        3205,
        295,
        12554,
        13,
        50630
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 8.600000381469727,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 5.320000171661377,
      "temperature": 0.0,
      "text": " Microsoft is rolling out co-pilot agent mode.",
      "tokens": [
        50630,
        8116,
        307,
        9439,
        484,
        598,
        12,
        79,
        31516,
        9461,
        4391,
        13,
        50794
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 14.239999771118164,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 8.600000381469727,
      "temperature": 0.0,
      "text": " OpenAI had back-to-back launches with Operator right into Deep Research.",
      "tokens": [
        50794,
        7238,
        48698,
        632,
        646,
        12,
        1353,
        12,
        3207,
        31841,
        365,
        12480,
        1639,
        558,
        666,
        14895,
        10303,
        13,
        51076
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 19.559999465942383,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 14.239999771118164,
      "temperature": 0.0,
      "text": " This is the most comprehensive Deep Research tool I've ever seen and used.",
      "tokens": [
        51076,
        639,
        307,
        264,
        881,
        13914,
        14895,
        10303,
        2290,
        286,
        600,
        1562,
        1612,
        293,
        1143,
        13,
        51342
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 21.920000076293945,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 19.559999465942383,
      "temperature": 0.0,
      "text": " Gemini has a version of Deep Research.",
      "tokens": [
        51342,
        22894,
        3812,
        575,
        257,
        3037,
        295,
        14895,
        10303,
        13,
        51460
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 25.31999969482422,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 21.920000076293945,
      "temperature": 0.0,
      "text": " More notably, they have their Notebook AI agent.",
      "tokens": [
        51460,
        5048,
        31357,
        11,
        436,
        362,
        641,
        11633,
        2939,
        7318,
        9461,
        13,
        51630
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.29756638407707214,
      "compression_ratio": 1.553903341293335,
      "end": 29.68000030517578,
      "no_speech_prob": 0.004608605057001114,
      "seek": 0,
      "start": 25.31999969482422,
      "temperature": 0.0,
      "text": " Meanwhile, Anthropic created computer use and kind of set off",
      "tokens": [
        51630,
        13879,
        11,
        12727,
        39173,
        2942,
        3820,
        764,
        293,
        733,
        295,
        992,
        766,
        51848
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 32.84000015258789,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 29.68000030517578,
      "temperature": 0.0,
      "text": " this entire stream of generative AI companies,",
      "tokens": [
        50364,
        341,
        2302,
        4309,
        295,
        1337,
        1166,
        7318,
        3431,
        11,
        50522
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 35.36000061035156,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 32.84000015258789,
      "temperature": 0.0,
      "text": " building agents on top of their own technology.",
      "tokens": [
        50522,
        2390,
        12554,
        322,
        1192,
        295,
        641,
        1065,
        2899,
        13,
        50648
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 37.720001220703125,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 35.36000061035156,
      "temperature": 0.0,
      "text": " The computer use, text editor,",
      "tokens": [
        50648,
        440,
        3820,
        764,
        11,
        2487,
        9839,
        11,
        50766
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 42.560001373291016,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 37.720001220703125,
      "temperature": 0.0,
      "text": " and Bash tools are still some of the most slept on tools to date.",
      "tokens": [
        50766,
        293,
        43068,
        3873,
        366,
        920,
        512,
        295,
        264,
        881,
        17400,
        322,
        3873,
        281,
        4002,
        13,
        51008
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 45.52000045776367,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 42.560001373291016,
      "temperature": 0.0,
      "text": " Check this out. Here's a simple bun logging script.",
      "tokens": [
        51008,
        6881,
        341,
        484,
        13,
        1692,
        311,
        257,
        2199,
        6702,
        27991,
        5755,
        13,
        51156
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 46.84000015258789,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 45.52000045776367,
      "temperature": 0.0,
      "text": " I can open up the terminal.",
      "tokens": [
        51156,
        286,
        393,
        1269,
        493,
        264,
        14709,
        13,
        51222
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 51.52000045776367,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 46.84000015258789,
      "temperature": 0.0,
      "text": " I have a file editing agent built on top of Anthropic's file editing tool.",
      "tokens": [
        51222,
        286,
        362,
        257,
        3991,
        10000,
        9461,
        3094,
        322,
        1192,
        295,
        12727,
        39173,
        311,
        3991,
        10000,
        2290,
        13,
        51456
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 54.880001068115234,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 51.52000045776367,
      "temperature": 0.0,
      "text": " We can run this prompt and it'll make three distinct changes for us.",
      "tokens": [
        51456,
        492,
        393,
        1190,
        341,
        12391,
        293,
        309,
        603,
        652,
        1045,
        10644,
        2962,
        337,
        505,
        13,
        51624
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 56.31999969482422,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 54.880001068115234,
      "temperature": 0.0,
      "text": " It's going to read this file,",
      "tokens": [
        51624,
        467,
        311,
        516,
        281,
        1401,
        341,
        3991,
        11,
        51696
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.22667571902275085,
      "compression_ratio": 1.6872963905334473,
      "end": 59.36000061035156,
      "no_speech_prob": 0.0017545548034831882,
      "seek": 2968,
      "start": 56.31999969482422,
      "temperature": 0.0,
      "text": " update it, it's going to add the directory param just like we're asking,",
      "tokens": [
        51696,
        5623,
        309,
        11,
        309,
        311,
        516,
        281,
        909,
        264,
        21120,
        6220,
        445,
        411,
        321,
        434,
        3365,
        11,
        51848
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 60.959999084472656,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 59.36000061035156,
      "temperature": 0.0,
      "text": " and then it's going to add a confirmation flag.",
      "tokens": [
        50364,
        293,
        550,
        309,
        311,
        516,
        281,
        909,
        257,
        21871,
        7166,
        13,
        50444
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 62.20000076293945,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 60.959999084472656,
      "temperature": 0.0,
      "text": " You can see that just came in there.",
      "tokens": [
        50444,
        509,
        393,
        536,
        300,
        445,
        1361,
        294,
        456,
        13,
        50506
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 64.0,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 62.20000076293945,
      "temperature": 0.0,
      "text": " Then it's going to create two new versions,",
      "tokens": [
        50506,
        1396,
        309,
        311,
        516,
        281,
        1884,
        732,
        777,
        9606,
        11,
        50596
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 67.0,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 64.0,
      "temperature": 0.0,
      "text": " a shell script version and a PowerShell version.",
      "tokens": [
        50596,
        257,
        8720,
        5755,
        3037,
        293,
        257,
        7086,
        9526,
        285,
        3037,
        13,
        50746
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 70.68000030517578,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 67.0,
      "temperature": 0.0,
      "text": " There it is. If I run that grep command again,",
      "tokens": [
        50746,
        821,
        309,
        307,
        13,
        759,
        286,
        1190,
        300,
        6066,
        79,
        5622,
        797,
        11,
        50930
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 74.12000274658203,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 70.68000030517578,
      "temperature": 0.0,
      "text": " you can see we now have those three individual files.",
      "tokens": [
        50930,
        291,
        393,
        536,
        321,
        586,
        362,
        729,
        1045,
        2609,
        7098,
        13,
        51102
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 75.80000305175781,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 74.12000274658203,
      "temperature": 0.0,
      "text": " Here's the updated bun version,",
      "tokens": [
        51102,
        1692,
        311,
        264,
        10588,
        6702,
        3037,
        11,
        51186
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 79.4000015258789,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 75.80000305175781,
      "temperature": 0.0,
      "text": " clearlogs.sh. Here's the shell version,",
      "tokens": [
        51186,
        1850,
        4987,
        82,
        13,
        2716,
        13,
        1692,
        311,
        264,
        8720,
        3037,
        11,
        51366
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 82.95999908447266,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 79.4000015258789,
      "temperature": 0.0,
      "text": " clearlogs.ps1. Here's the PowerShell version.",
      "tokens": [
        51366,
        1850,
        4987,
        82,
        13,
        1878,
        16,
        13,
        1692,
        311,
        264,
        7086,
        9526,
        285,
        3037,
        13,
        51544
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 84.5999984741211,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 82.95999908447266,
      "temperature": 0.0,
      "text": " With a single command,",
      "tokens": [
        51544,
        2022,
        257,
        2167,
        5622,
        11,
        51626
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.18936634063720703,
      "compression_ratio": 1.8167331218719482,
      "end": 87.16000366210938,
      "no_speech_prob": 0.003172539407387376,
      "seek": 5936,
      "start": 84.5999984741211,
      "temperature": 0.0,
      "text": " I was able to generate three changes",
      "tokens": [
        51626,
        286,
        390,
        1075,
        281,
        8460,
        1045,
        2962,
        51754
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 89.63999938964844,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 87.19999694824219,
      "temperature": 0.0,
      "text": " thanks to my file AI agent.",
      "tokens": [
        50366,
        3231,
        281,
        452,
        3991,
        7318,
        9461,
        13,
        50488
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 91.31999969482422,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 89.63999938964844,
      "temperature": 0.0,
      "text": " If it's not clear to you already,",
      "tokens": [
        50488,
        759,
        309,
        311,
        406,
        1850,
        281,
        291,
        1217,
        11,
        50572
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 94.80000305175781,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 91.31999969482422,
      "temperature": 0.0,
      "text": " AI agents are extremely powerful.",
      "tokens": [
        50572,
        7318,
        12554,
        366,
        4664,
        4005,
        13,
        50746
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 95.76000213623047,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 94.80000305175781,
      "temperature": 0.0,
      "text": " Why is that?",
      "tokens": [
        50746,
        1545,
        307,
        300,
        30,
        50794
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 97.63999938964844,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 95.76000213623047,
      "temperature": 0.0,
      "text": " It's because they turn your prompt,",
      "tokens": [
        50794,
        467,
        311,
        570,
        436,
        1261,
        428,
        12391,
        11,
        50888
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 101.76000213623047,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 97.63999938964844,
      "temperature": 0.0,
      "text": " context, and model into actions at scale.",
      "tokens": [
        50888,
        4319,
        11,
        293,
        2316,
        666,
        5909,
        412,
        4373,
        13,
        51094
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 103.55999755859375,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 101.76000213623047,
      "temperature": 0.0,
      "text": " It's important that you and I,",
      "tokens": [
        51094,
        467,
        311,
        1021,
        300,
        291,
        293,
        286,
        11,
        51184
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 107.4000015258789,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 103.55999755859375,
      "temperature": 0.0,
      "text": " the engineer, know how and when to build and deploy",
      "tokens": [
        51184,
        264,
        11403,
        11,
        458,
        577,
        293,
        562,
        281,
        1322,
        293,
        7274,
        51376
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 111.80000305175781,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 107.4000015258789,
      "temperature": 0.0,
      "text": " AI agents across your developer tooling projects and work.",
      "tokens": [
        51376,
        7318,
        12554,
        2108,
        428,
        10754,
        46593,
        4455,
        293,
        589,
        13,
        51596
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.231049582362175,
      "compression_ratio": 1.5916666984558105,
      "end": 114.36000061035156,
      "no_speech_prob": 0.35932865738868713,
      "seek": 8716,
      "start": 111.80000305175781,
      "temperature": 0.0,
      "text": " In this video, I want to take you through the prompt,",
      "tokens": [
        51596,
        682,
        341,
        960,
        11,
        286,
        528,
        281,
        747,
        291,
        807,
        264,
        12391,
        11,
        51724
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 116.80000305175781,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 114.4800033569336,
      "temperature": 0.0,
      "text": " the prompt chain, and the AI agent",
      "tokens": [
        50370,
        264,
        12391,
        5021,
        11,
        293,
        264,
        7318,
        9461,
        50486
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 119.16000366210938,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 116.80000305175781,
      "temperature": 0.0,
      "text": " to help you understand which one you need",
      "tokens": [
        50486,
        281,
        854,
        291,
        1223,
        597,
        472,
        291,
        643,
        50604
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 120.95999908447266,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 119.16000366210938,
      "temperature": 0.0,
      "text": " to get the job done.",
      "tokens": [
        50604,
        281,
        483,
        264,
        1691,
        1096,
        13,
        50694
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 123.5199966430664,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 120.95999908447266,
      "temperature": 0.0,
      "text": " We'll lean on Anthropic's incredible",
      "tokens": [
        50694,
        492,
        603,
        11659,
        322,
        12727,
        39173,
        311,
        4651,
        50822
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 125.5999984741211,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 123.5199966430664,
      "temperature": 0.0,
      "text": " building effective agents post,",
      "tokens": [
        50822,
        2390,
        4942,
        12554,
        2183,
        11,
        50926
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 128.83999633789062,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 125.5999984741211,
      "temperature": 0.0,
      "text": " and I'll share my distillation of what matters",
      "tokens": [
        50926,
        293,
        286,
        603,
        2073,
        452,
        42923,
        399,
        295,
        437,
        7001,
        51088
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.25459012389183044,
      "compression_ratio": 1.459302306175232,
      "end": 131.0800018310547,
      "no_speech_prob": 0.03461062163114548,
      "seek": 11436,
      "start": 128.83999633789062,
      "temperature": 0.0,
      "text": " and mistakes I've made when building.",
      "tokens": [
        51088,
        293,
        8038,
        286,
        600,
        1027,
        562,
        2390,
        13,
        51200
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835305.353696
}
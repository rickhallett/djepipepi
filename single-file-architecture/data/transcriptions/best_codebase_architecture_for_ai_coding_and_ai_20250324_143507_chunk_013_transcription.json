{
  "audio_path": "data/chunks/best_codebase_architecture_for_ai_coding_and_ai_20250324_143507_chunk_013.mp3",
  "text": "management for us and our AI tools. Later, and the more time that goes on, I think you can more easily argue that, as LLMs and Gen AI evolves, the codebase structure that you're working with matters a lot less. But, you know, I think you can see here from just these few simple examples on, you know, small and, you know, really full-on codebases, context management matters. If you manage your context, you manage your results. So, you know, precise context management still matters. AI needs clear pathways, right? LLMs to be specific. Our LLMs, our AI coding tools, they need clear pathways to, you know, not just one file, but collections of files, right? Collections of information. We all know, you know, Cloud Code, Cline, a lot of these tools, they chew up tokens and they chew them up just looking for stuff, right? They're not even doing work. They're not even creating value. And it's the poor organization of our codebase, right? Not to just harp on it, but, you know, the layered architecture really forces our AI coding tools to just read everything, right? Look through all of it. We know we're looking for an API file somewhere. Let's look through one of these 20 files in our API, right? You know, this is where the atomic structure and, you know, most notably the vertical slice structure, the vertical slice architecture really stand out. If you can build this codebase structure, you will save a ton of tokens, right? And I think you can see why, you know, that's important. When you organize your codebase, you make it easy to save time, tokens, and that means money, right? Well-structured code is cost effective, okay? The balance is really key here. So, you know, most of us are still operating, we're building for human readability. It's time to flip that trend, okay? I am flipping that trend. I want you to join me. I want you to get ahead of the curve. AI will be writing most code moving forward, right? Our AI tools, AI coding assistants, agentic coding tools, they'll be writing most of the code. That means we need to start thinking about our codebases.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 3.0,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " management for us and our AI tools.",
      "tokens": [
        50364,
        4592,
        337,
        505,
        293,
        527,
        7318,
        3873,
        13,
        50514
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 5.199999809265137,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 3.0,
      "temperature": 0.0,
      "text": " Later, and the more time that goes on,",
      "tokens": [
        50514,
        11965,
        11,
        293,
        264,
        544,
        565,
        300,
        1709,
        322,
        11,
        50624
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 7.679999828338623,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 5.199999809265137,
      "temperature": 0.0,
      "text": " I think you can more easily argue that,",
      "tokens": [
        50624,
        286,
        519,
        291,
        393,
        544,
        3612,
        9695,
        300,
        11,
        50748
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 10.319999694824219,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 7.679999828338623,
      "temperature": 0.0,
      "text": " as LLMs and Gen AI evolves,",
      "tokens": [
        50748,
        382,
        441,
        43,
        26386,
        293,
        3632,
        7318,
        43737,
        11,
        50880
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 12.15999984741211,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 10.319999694824219,
      "temperature": 0.0,
      "text": " the codebase structure that you're working with",
      "tokens": [
        50880,
        264,
        3089,
        17429,
        3877,
        300,
        291,
        434,
        1364,
        365,
        50972
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 14.15999984741211,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 12.15999984741211,
      "temperature": 0.0,
      "text": " matters a lot less.",
      "tokens": [
        50972,
        7001,
        257,
        688,
        1570,
        13,
        51072
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 15.84000015258789,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 14.15999984741211,
      "temperature": 0.0,
      "text": " But, you know, I think you can see here",
      "tokens": [
        51072,
        583,
        11,
        291,
        458,
        11,
        286,
        519,
        291,
        393,
        536,
        510,
        51156
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 18.559999465942383,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 15.84000015258789,
      "temperature": 0.0,
      "text": " from just these few simple examples",
      "tokens": [
        51156,
        490,
        445,
        613,
        1326,
        2199,
        5110,
        51292
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 20.200000762939453,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 18.559999465942383,
      "temperature": 0.0,
      "text": " on, you know, small and, you know,",
      "tokens": [
        51292,
        322,
        11,
        291,
        458,
        11,
        1359,
        293,
        11,
        291,
        458,
        11,
        51374
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 22.959999084472656,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 20.200000762939453,
      "temperature": 0.0,
      "text": " really full-on codebases,",
      "tokens": [
        51374,
        534,
        1577,
        12,
        266,
        3089,
        65,
        1957,
        11,
        51512
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 25.34000015258789,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 22.959999084472656,
      "temperature": 0.0,
      "text": " context management matters.",
      "tokens": [
        51512,
        4319,
        4592,
        7001,
        13,
        51631
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 27.360000610351562,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 25.34000015258789,
      "temperature": 0.0,
      "text": " If you manage your context,",
      "tokens": [
        51631,
        759,
        291,
        3067,
        428,
        4319,
        11,
        51732
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.24152131378650665,
      "compression_ratio": 1.7685950994491577,
      "end": 29.81999969482422,
      "no_speech_prob": 0.0049820574931800365,
      "seek": 0,
      "start": 27.360000610351562,
      "temperature": 0.0,
      "text": " you manage your results.",
      "tokens": [
        51732,
        291,
        3067,
        428,
        3542,
        13,
        51855
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 32.939998626708984,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 29.81999969482422,
      "temperature": 0.0,
      "text": " So, you know, precise context management still matters.",
      "tokens": [
        50364,
        407,
        11,
        291,
        458,
        11,
        13600,
        4319,
        4592,
        920,
        7001,
        13,
        50520
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 35.5,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 32.939998626708984,
      "temperature": 0.0,
      "text": " AI needs clear pathways, right?",
      "tokens": [
        50520,
        7318,
        2203,
        1850,
        22988,
        11,
        558,
        30,
        50648
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 36.900001525878906,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 35.5,
      "temperature": 0.0,
      "text": " LLMs to be specific.",
      "tokens": [
        50648,
        441,
        43,
        26386,
        281,
        312,
        2685,
        13,
        50718
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 38.70000076293945,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 36.900001525878906,
      "temperature": 0.0,
      "text": " Our LLMs, our AI coding tools,",
      "tokens": [
        50718,
        2621,
        441,
        43,
        26386,
        11,
        527,
        7318,
        17720,
        3873,
        11,
        50808
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 42.02000045776367,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 38.70000076293945,
      "temperature": 0.0,
      "text": " they need clear pathways to, you know,",
      "tokens": [
        50808,
        436,
        643,
        1850,
        22988,
        281,
        11,
        291,
        458,
        11,
        50974
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 45.20000076293945,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 42.02000045776367,
      "temperature": 0.0,
      "text": " not just one file, but collections of files, right?",
      "tokens": [
        50974,
        406,
        445,
        472,
        3991,
        11,
        457,
        16641,
        295,
        7098,
        11,
        558,
        30,
        51133
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 46.900001525878906,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 45.20000076293945,
      "temperature": 0.0,
      "text": " Collections of information.",
      "tokens": [
        51133,
        31896,
        626,
        295,
        1589,
        13,
        51218
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 49.63999938964844,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 46.900001525878906,
      "temperature": 0.0,
      "text": " We all know, you know, Cloud Code, Cline,",
      "tokens": [
        51218,
        492,
        439,
        458,
        11,
        291,
        458,
        11,
        8061,
        15549,
        11,
        2033,
        533,
        11,
        51355
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 52.540000915527344,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 49.63999938964844,
      "temperature": 0.0,
      "text": " a lot of these tools, they chew up tokens",
      "tokens": [
        51355,
        257,
        688,
        295,
        613,
        3873,
        11,
        436,
        21200,
        493,
        22667,
        51500
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 56.619998931884766,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 52.540000915527344,
      "temperature": 0.0,
      "text": " and they chew them up just looking for stuff, right?",
      "tokens": [
        51500,
        293,
        436,
        21200,
        552,
        493,
        445,
        1237,
        337,
        1507,
        11,
        558,
        30,
        51704
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.206046462059021,
      "compression_ratio": 1.7165992259979248,
      "end": 57.81999969482422,
      "no_speech_prob": 6.605140515603125e-05,
      "seek": 2982,
      "start": 56.619998931884766,
      "temperature": 0.0,
      "text": " They're not even doing work.",
      "tokens": [
        51704,
        814,
        434,
        406,
        754,
        884,
        589,
        13,
        51764
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 60.060001373291016,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 57.81999969482422,
      "temperature": 0.0,
      "text": " They're not even creating value.",
      "tokens": [
        50364,
        814,
        434,
        406,
        754,
        4084,
        2158,
        13,
        50476
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 64.0199966430664,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 60.060001373291016,
      "temperature": 0.0,
      "text": " And it's the poor organization of our codebase, right?",
      "tokens": [
        50476,
        400,
        309,
        311,
        264,
        4716,
        4475,
        295,
        527,
        3089,
        17429,
        11,
        558,
        30,
        50674
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 66.18000030517578,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 64.0199966430664,
      "temperature": 0.0,
      "text": " Not to just harp on it, but, you know,",
      "tokens": [
        50674,
        1726,
        281,
        445,
        50093,
        322,
        309,
        11,
        457,
        11,
        291,
        458,
        11,
        50782
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 68.94000244140625,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 66.18000030517578,
      "temperature": 0.0,
      "text": " the layered architecture really forces",
      "tokens": [
        50782,
        264,
        34666,
        9482,
        534,
        5874,
        50920
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 71.80000305175781,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 68.94000244140625,
      "temperature": 0.0,
      "text": " our AI coding tools to just read everything, right?",
      "tokens": [
        50920,
        527,
        7318,
        17720,
        3873,
        281,
        445,
        1401,
        1203,
        11,
        558,
        30,
        51063
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 73.37999725341797,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 71.80000305175781,
      "temperature": 0.0,
      "text": " Look through all of it.",
      "tokens": [
        51063,
        2053,
        807,
        439,
        295,
        309,
        13,
        51142
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 76.12000274658203,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 73.37999725341797,
      "temperature": 0.0,
      "text": " We know we're looking for an API file somewhere.",
      "tokens": [
        51142,
        492,
        458,
        321,
        434,
        1237,
        337,
        364,
        9362,
        3991,
        4079,
        13,
        51279
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 80.58000183105469,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 76.12000274658203,
      "temperature": 0.0,
      "text": " Let's look through one of these 20 files in our API, right?",
      "tokens": [
        51279,
        961,
        311,
        574,
        807,
        472,
        295,
        613,
        945,
        7098,
        294,
        527,
        9362,
        11,
        558,
        30,
        51502
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.185296893119812,
      "compression_ratio": 1.6056910753250122,
      "end": 83.30000305175781,
      "no_speech_prob": 0.0009850002825260162,
      "seek": 5782,
      "start": 80.58000183105469,
      "temperature": 0.0,
      "text": " You know, this is where the atomic structure",
      "tokens": [
        51502,
        509,
        458,
        11,
        341,
        307,
        689,
        264,
        22275,
        3877,
        51638
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 87.94000244140625,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 83.33999633789062,
      "temperature": 0.0,
      "text": " and, you know, most notably the vertical slice structure,",
      "tokens": [
        50366,
        293,
        11,
        291,
        458,
        11,
        881,
        31357,
        264,
        9429,
        13153,
        3877,
        11,
        50596
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 91.5,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 87.94000244140625,
      "temperature": 0.0,
      "text": " the vertical slice architecture really stand out.",
      "tokens": [
        50596,
        264,
        9429,
        13153,
        9482,
        534,
        1463,
        484,
        13,
        50774
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 93.77999877929688,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 91.5,
      "temperature": 0.0,
      "text": " If you can build this codebase structure,",
      "tokens": [
        50774,
        759,
        291,
        393,
        1322,
        341,
        3089,
        17429,
        3877,
        11,
        50888
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 97.0199966430664,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 93.77999877929688,
      "temperature": 0.0,
      "text": " you will save a ton of tokens, right?",
      "tokens": [
        50888,
        291,
        486,
        3155,
        257,
        2952,
        295,
        22667,
        11,
        558,
        30,
        51050
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 99.18000030517578,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 97.0199966430664,
      "temperature": 0.0,
      "text": " And I think you can see why, you know, that's important.",
      "tokens": [
        51050,
        400,
        286,
        519,
        291,
        393,
        536,
        983,
        11,
        291,
        458,
        11,
        300,
        311,
        1021,
        13,
        51158
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 100.30000305175781,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 99.18000030517578,
      "temperature": 0.0,
      "text": " When you organize your codebase,",
      "tokens": [
        51158,
        1133,
        291,
        13859,
        428,
        3089,
        17429,
        11,
        51214
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 102.13999938964844,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 100.30000305175781,
      "temperature": 0.0,
      "text": " you make it easy to save time, tokens,",
      "tokens": [
        51214,
        291,
        652,
        309,
        1858,
        281,
        3155,
        565,
        11,
        22667,
        11,
        51306
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 104.30000305175781,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 102.13999938964844,
      "temperature": 0.0,
      "text": " and that means money, right?",
      "tokens": [
        51306,
        293,
        300,
        1355,
        1460,
        11,
        558,
        30,
        51414
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 107.69999694824219,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 104.30000305175781,
      "temperature": 0.0,
      "text": " Well-structured code is cost effective, okay?",
      "tokens": [
        51414,
        1042,
        12,
        372,
        46847,
        3089,
        307,
        2063,
        4942,
        11,
        1392,
        30,
        51584
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 108.86000061035156,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 107.69999694824219,
      "temperature": 0.0,
      "text": " The balance is really key here.",
      "tokens": [
        51584,
        440,
        4772,
        307,
        534,
        2141,
        510,
        13,
        51642
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.19406738877296448,
      "compression_ratio": 1.7698112726211548,
      "end": 111.23999786376953,
      "no_speech_prob": 0.0003250351292081177,
      "seek": 8330,
      "start": 108.86000061035156,
      "temperature": 0.0,
      "text": " So, you know, most of us are still operating,",
      "tokens": [
        51642,
        407,
        11,
        291,
        458,
        11,
        881,
        295,
        505,
        366,
        920,
        7447,
        11,
        51761
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 113.72000122070312,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 111.27999877929688,
      "temperature": 0.0,
      "text": " we're building for human readability.",
      "tokens": [
        50366,
        321,
        434,
        2390,
        337,
        1952,
        1401,
        2310,
        13,
        50488
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 115.73999786376953,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 113.72000122070312,
      "temperature": 0.0,
      "text": " It's time to flip that trend, okay?",
      "tokens": [
        50488,
        467,
        311,
        565,
        281,
        7929,
        300,
        6028,
        11,
        1392,
        30,
        50589
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 117.12000274658203,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 115.73999786376953,
      "temperature": 0.0,
      "text": " I am flipping that trend.",
      "tokens": [
        50589,
        286,
        669,
        26886,
        300,
        6028,
        13,
        50658
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 118.12000274658203,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 117.12000274658203,
      "temperature": 0.0,
      "text": " I want you to join me.",
      "tokens": [
        50658,
        286,
        528,
        291,
        281,
        3917,
        385,
        13,
        50708
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 119.5199966430664,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 118.12000274658203,
      "temperature": 0.0,
      "text": " I want you to get ahead of the curve.",
      "tokens": [
        50708,
        286,
        528,
        291,
        281,
        483,
        2286,
        295,
        264,
        7605,
        13,
        50778
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 122.80000305175781,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 119.5199966430664,
      "temperature": 0.0,
      "text": " AI will be writing most code moving forward, right?",
      "tokens": [
        50778,
        7318,
        486,
        312,
        3579,
        881,
        3089,
        2684,
        2128,
        11,
        558,
        30,
        50942
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 124.83999633789062,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 122.80000305175781,
      "temperature": 0.0,
      "text": " Our AI tools, AI coding assistants,",
      "tokens": [
        50942,
        2621,
        7318,
        3873,
        11,
        7318,
        17720,
        34949,
        11,
        51044
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 127.36000061035156,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 124.83999633789062,
      "temperature": 0.0,
      "text": " agentic coding tools, they'll be writing most of the code.",
      "tokens": [
        51044,
        9461,
        299,
        17720,
        3873,
        11,
        436,
        603,
        312,
        3579,
        881,
        295,
        264,
        3089,
        13,
        51170
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.22600054740905762,
      "compression_ratio": 1.6820276975631714,
      "end": 130.9199981689453,
      "no_speech_prob": 0.008710992522537708,
      "seek": 11124,
      "start": 127.36000061035156,
      "temperature": 0.0,
      "text": " That means we need to start thinking about our codebases.",
      "tokens": [
        51170,
        663,
        1355,
        321,
        643,
        281,
        722,
        1953,
        466,
        527,
        3089,
        65,
        1957,
        13,
        51348
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835249.311425
}
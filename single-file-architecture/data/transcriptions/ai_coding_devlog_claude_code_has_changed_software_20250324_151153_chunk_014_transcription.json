{
  "audio_path": "data/chunks/ai_coding_devlog_claude_code_has_changed_software_20250324_151153_chunk_014.mp3",
  "text": "Now we're going to go ahead and find all of my items. I'm gonna look for all of my LLM tags and then create a Markdown file with all the models, right? So there we go. So we're gonna run that first command. You can see that that was wrong. That was the wrong command. So immediately cloud code pivoted to the pocket list command versus the pocket find. Pocket find is for looking up texts and pocket list is for searching via tags. I probably could have improved the naming there, but as you can see here, we're working through it, making progress. There's that LLM models file. That all looks great. And now I'm just going to do some more, you know, ad hoc testing. You've seen me do this in a couple of previous videos, you know, create a YAML and JSON version. I'm just kind of playing with cloud code here and, you know, validating some functionality. So, you know, this tool, these tools are incredibly powerful, okay? It's important to stay up to date. It's important to understand what you can do with these tools. On the channel, I try to share, you know, as much as I can with the time that I do have, I try to share with you these kind of key AI coding ideas and principles and patterns. But, you know, in every video, we only really scratch the surface of what we can do. I highly, highly recommend you check out principled AI coding if you haven't already. This is my take on how to transition from the old ways of engineering to the new way, where we code and build faster than ever with AI coding tools like Aitor, Cursor, and now Cloud Code, right? And whatever's coming next. In the course, we focus on principles, not tools. We focus on principles, not models. We know that models will continue to evolve. We know that tools will just keep changing. But, you know, what matters, and I'm really proud of this, the fact that, you know, with every passing day, with every release, principled AI coding is still relevant. In fact, it's even more relevant than it was when it was launched, okay? So I highly recommend you check it out.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 5.0,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " Now we're going to go ahead and find all of my items.",
      "tokens": [
        50364,
        823,
        321,
        434,
        516,
        281,
        352,
        2286,
        293,
        915,
        439,
        295,
        452,
        4754,
        13,
        50614
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 8.680000305175781,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 5.840000152587891,
      "temperature": 0.0,
      "text": " I'm gonna look for all of my LLM tags",
      "tokens": [
        50656,
        286,
        478,
        799,
        574,
        337,
        439,
        295,
        452,
        441,
        43,
        44,
        18632,
        50798
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 12.800000190734863,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 9.640000343322754,
      "temperature": 0.0,
      "text": " and then create a Markdown file with all the models, right?",
      "tokens": [
        50846,
        293,
        550,
        1884,
        257,
        3934,
        5093,
        3991,
        365,
        439,
        264,
        5245,
        11,
        558,
        30,
        51004
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 14.039999961853027,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 12.800000190734863,
      "temperature": 0.0,
      "text": " So there we go.",
      "tokens": [
        51004,
        407,
        456,
        321,
        352,
        13,
        51066
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 15.039999961853027,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 14.039999961853027,
      "temperature": 0.0,
      "text": " So we're gonna run that first command.",
      "tokens": [
        51066,
        407,
        321,
        434,
        799,
        1190,
        300,
        700,
        5622,
        13,
        51116
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 16.1200008392334,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 15.039999961853027,
      "temperature": 0.0,
      "text": " You can see that that was wrong.",
      "tokens": [
        51116,
        509,
        393,
        536,
        300,
        300,
        390,
        2085,
        13,
        51170
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 17.040000915527344,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 16.1200008392334,
      "temperature": 0.0,
      "text": " That was the wrong command.",
      "tokens": [
        51170,
        663,
        390,
        264,
        2085,
        5622,
        13,
        51216
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 19.200000762939453,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 17.040000915527344,
      "temperature": 0.0,
      "text": " So immediately cloud code pivoted",
      "tokens": [
        51216,
        407,
        4258,
        4588,
        3089,
        14538,
        292,
        51324
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 23.360000610351562,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 19.200000762939453,
      "temperature": 0.0,
      "text": " to the pocket list command versus the pocket find.",
      "tokens": [
        51324,
        281,
        264,
        8963,
        1329,
        5622,
        5717,
        264,
        8963,
        915,
        13,
        51532
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 26.559999465942383,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 23.360000610351562,
      "temperature": 0.0,
      "text": " Pocket find is for looking up texts",
      "tokens": [
        51532,
        44594,
        915,
        307,
        337,
        1237,
        493,
        15765,
        51692
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.27368950843811035,
      "compression_ratio": 1.7449393272399902,
      "end": 29.979999542236328,
      "no_speech_prob": 0.24500787258148193,
      "seek": 0,
      "start": 26.559999465942383,
      "temperature": 0.0,
      "text": " and pocket list is for searching via tags.",
      "tokens": [
        51692,
        293,
        8963,
        1329,
        307,
        337,
        10808,
        5766,
        18632,
        13,
        51863
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 31.6200008392334,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 29.979999542236328,
      "temperature": 0.0,
      "text": " I probably could have improved the naming there,",
      "tokens": [
        50364,
        286,
        1391,
        727,
        362,
        9689,
        264,
        25290,
        456,
        11,
        50446
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 33.86000061035156,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 31.6200008392334,
      "temperature": 0.0,
      "text": " but as you can see here,",
      "tokens": [
        50446,
        457,
        382,
        291,
        393,
        536,
        510,
        11,
        50558
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 36.02000045776367,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 33.86000061035156,
      "temperature": 0.0,
      "text": " we're working through it, making progress.",
      "tokens": [
        50558,
        321,
        434,
        1364,
        807,
        309,
        11,
        1455,
        4205,
        13,
        50666
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 38.7400016784668,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 36.02000045776367,
      "temperature": 0.0,
      "text": " There's that LLM models file.",
      "tokens": [
        50666,
        821,
        311,
        300,
        441,
        43,
        44,
        5245,
        3991,
        13,
        50802
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 40.13999938964844,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 38.7400016784668,
      "temperature": 0.0,
      "text": " That all looks great.",
      "tokens": [
        50802,
        663,
        439,
        1542,
        869,
        13,
        50872
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 42.619998931884766,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 40.13999938964844,
      "temperature": 0.0,
      "text": " And now I'm just going to do some more, you know,",
      "tokens": [
        50872,
        400,
        586,
        286,
        478,
        445,
        516,
        281,
        360,
        512,
        544,
        11,
        291,
        458,
        11,
        50996
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 43.959999084472656,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 42.619998931884766,
      "temperature": 0.0,
      "text": " ad hoc testing.",
      "tokens": [
        50996,
        614,
        16708,
        4997,
        13,
        51063
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 46.63999938964844,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 43.959999084472656,
      "temperature": 0.0,
      "text": " You've seen me do this in a couple of previous videos,",
      "tokens": [
        51063,
        509,
        600,
        1612,
        385,
        360,
        341,
        294,
        257,
        1916,
        295,
        3894,
        2145,
        11,
        51197
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 48.619998931884766,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 46.63999938964844,
      "temperature": 0.0,
      "text": " you know, create a YAML and JSON version.",
      "tokens": [
        51197,
        291,
        458,
        11,
        1884,
        257,
        398,
        2865,
        43,
        293,
        31828,
        3037,
        13,
        51296
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 51.099998474121094,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 48.619998931884766,
      "temperature": 0.0,
      "text": " I'm just kind of playing with cloud code here",
      "tokens": [
        51296,
        286,
        478,
        445,
        733,
        295,
        2433,
        365,
        4588,
        3089,
        510,
        51420
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 52.97999954223633,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 51.099998474121094,
      "temperature": 0.0,
      "text": " and, you know, validating some functionality.",
      "tokens": [
        51420,
        293,
        11,
        291,
        458,
        11,
        7363,
        990,
        512,
        14980,
        13,
        51514
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 55.540000915527344,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 52.97999954223633,
      "temperature": 0.0,
      "text": " So, you know, this tool,",
      "tokens": [
        51514,
        407,
        11,
        291,
        458,
        11,
        341,
        2290,
        11,
        51642
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.19327910244464874,
      "compression_ratio": 1.6587837934494019,
      "end": 59.81999969482422,
      "no_speech_prob": 0.004905210342258215,
      "seek": 2998,
      "start": 55.540000915527344,
      "temperature": 0.0,
      "text": " these tools are incredibly powerful, okay?",
      "tokens": [
        51642,
        613,
        3873,
        366,
        6252,
        4005,
        11,
        1392,
        30,
        51856
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 61.5,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 60.65999984741211,
      "temperature": 0.0,
      "text": " It's important to stay up to date.",
      "tokens": [
        50406,
        467,
        311,
        1021,
        281,
        1754,
        493,
        281,
        4002,
        13,
        50448
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 62.779998779296875,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 61.5,
      "temperature": 0.0,
      "text": " It's important to understand",
      "tokens": [
        50448,
        467,
        311,
        1021,
        281,
        1223,
        50512
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 64.33999633789062,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 62.779998779296875,
      "temperature": 0.0,
      "text": " what you can do with these tools.",
      "tokens": [
        50512,
        437,
        291,
        393,
        360,
        365,
        613,
        3873,
        13,
        50590
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 66.22000122070312,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 64.33999633789062,
      "temperature": 0.0,
      "text": " On the channel, I try to share, you know,",
      "tokens": [
        50590,
        1282,
        264,
        2269,
        11,
        286,
        853,
        281,
        2073,
        11,
        291,
        458,
        11,
        50684
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 68.31999969482422,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 66.22000122070312,
      "temperature": 0.0,
      "text": " as much as I can with the time that I do have,",
      "tokens": [
        50684,
        382,
        709,
        382,
        286,
        393,
        365,
        264,
        565,
        300,
        286,
        360,
        362,
        11,
        50789
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 71.13999938964844,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 68.31999969482422,
      "temperature": 0.0,
      "text": " I try to share with you these kind of key AI coding ideas",
      "tokens": [
        50789,
        286,
        853,
        281,
        2073,
        365,
        291,
        613,
        733,
        295,
        2141,
        7318,
        17720,
        3487,
        50930
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 72.36000061035156,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 71.13999938964844,
      "temperature": 0.0,
      "text": " and principles and patterns.",
      "tokens": [
        50930,
        293,
        9156,
        293,
        8294,
        13,
        50991
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 73.9000015258789,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 72.36000061035156,
      "temperature": 0.0,
      "text": " But, you know, in every video,",
      "tokens": [
        50991,
        583,
        11,
        291,
        458,
        11,
        294,
        633,
        960,
        11,
        51068
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 77.62000274658203,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 73.9000015258789,
      "temperature": 0.0,
      "text": " we only really scratch the surface of what we can do.",
      "tokens": [
        51068,
        321,
        787,
        534,
        8459,
        264,
        3753,
        295,
        437,
        321,
        393,
        360,
        13,
        51254
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 79.9800033569336,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 77.62000274658203,
      "temperature": 0.0,
      "text": " I highly, highly recommend you check out",
      "tokens": [
        51254,
        286,
        5405,
        11,
        5405,
        2748,
        291,
        1520,
        484,
        51372
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 82.73999786376953,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 79.9800033569336,
      "temperature": 0.0,
      "text": " principled AI coding if you haven't already.",
      "tokens": [
        51372,
        3681,
        15551,
        7318,
        17720,
        498,
        291,
        2378,
        380,
        1217,
        13,
        51510
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 85.66000366210938,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 82.73999786376953,
      "temperature": 0.0,
      "text": " This is my take on how to transition",
      "tokens": [
        51510,
        639,
        307,
        452,
        747,
        322,
        577,
        281,
        6034,
        51656
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.2078881710767746,
      "compression_ratio": 1.7905405759811401,
      "end": 88.95999908447266,
      "no_speech_prob": 0.0005883921985514462,
      "seek": 5982,
      "start": 85.66000366210938,
      "temperature": 0.0,
      "text": " from the old ways of engineering to the new way,",
      "tokens": [
        51656,
        490,
        264,
        1331,
        2098,
        295,
        7043,
        281,
        264,
        777,
        636,
        11,
        51821
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 91.4800033569336,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 89.0,
      "temperature": 0.0,
      "text": " where we code and build faster than ever",
      "tokens": [
        50366,
        689,
        321,
        3089,
        293,
        1322,
        4663,
        813,
        1562,
        50490
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 95.19999694824219,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 91.4800033569336,
      "temperature": 0.0,
      "text": " with AI coding tools like Aitor, Cursor,",
      "tokens": [
        50490,
        365,
        7318,
        17720,
        3873,
        411,
        316,
        3029,
        11,
        383,
        2156,
        284,
        11,
        50676
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 97.5199966430664,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 95.19999694824219,
      "temperature": 0.0,
      "text": " and now Cloud Code, right?",
      "tokens": [
        50676,
        293,
        586,
        8061,
        15549,
        11,
        558,
        30,
        50792
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 99.08000183105469,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 97.5199966430664,
      "temperature": 0.0,
      "text": " And whatever's coming next.",
      "tokens": [
        50792,
        400,
        2035,
        311,
        1348,
        958,
        13,
        50870
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 102.4800033569336,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 99.08000183105469,
      "temperature": 0.0,
      "text": " In the course, we focus on principles, not tools.",
      "tokens": [
        50870,
        682,
        264,
        1164,
        11,
        321,
        1879,
        322,
        9156,
        11,
        406,
        3873,
        13,
        51040
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 104.83999633789062,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 102.4800033569336,
      "temperature": 0.0,
      "text": " We focus on principles, not models.",
      "tokens": [
        51040,
        492,
        1879,
        322,
        9156,
        11,
        406,
        5245,
        13,
        51158
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 108.45999908447266,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 104.83999633789062,
      "temperature": 0.0,
      "text": " We know that models will continue to evolve.",
      "tokens": [
        51158,
        492,
        458,
        300,
        5245,
        486,
        2354,
        281,
        16693,
        13,
        51339
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 111.68000030517578,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 108.45999908447266,
      "temperature": 0.0,
      "text": " We know that tools will just keep changing.",
      "tokens": [
        51339,
        492,
        458,
        300,
        3873,
        486,
        445,
        1066,
        4473,
        13,
        51500
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 114.12000274658203,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 111.68000030517578,
      "temperature": 0.0,
      "text": " But, you know, what matters,",
      "tokens": [
        51500,
        583,
        11,
        291,
        458,
        11,
        437,
        7001,
        11,
        51622
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 115.68000030517578,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 114.12000274658203,
      "temperature": 0.0,
      "text": " and I'm really proud of this,",
      "tokens": [
        51622,
        293,
        286,
        478,
        534,
        4570,
        295,
        341,
        11,
        51700
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.19514183700084686,
      "compression_ratio": 1.7102041244506836,
      "end": 117.91999816894531,
      "no_speech_prob": 0.0005112375365570188,
      "seek": 8896,
      "start": 115.68000030517578,
      "temperature": 0.0,
      "text": " the fact that, you know, with every passing day,",
      "tokens": [
        51700,
        264,
        1186,
        300,
        11,
        291,
        458,
        11,
        365,
        633,
        8437,
        786,
        11,
        51812
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.22161218523979187,
      "compression_ratio": 1.3129770755767822,
      "end": 119.19999694824219,
      "no_speech_prob": 0.007576527073979378,
      "seek": 11792,
      "start": 117.95999908447266,
      "temperature": 0.0,
      "text": " with every release,",
      "tokens": [
        50366,
        365,
        633,
        4374,
        11,
        50428
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.22161218523979187,
      "compression_ratio": 1.3129770755767822,
      "end": 121.63999938964844,
      "no_speech_prob": 0.007576527073979378,
      "seek": 11792,
      "start": 119.19999694824219,
      "temperature": 0.0,
      "text": " principled AI coding is still relevant.",
      "tokens": [
        50428,
        3681,
        15551,
        7318,
        17720,
        307,
        920,
        7340,
        13,
        50550
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.22161218523979187,
      "compression_ratio": 1.3129770755767822,
      "end": 125.4800033569336,
      "no_speech_prob": 0.007576527073979378,
      "seek": 11792,
      "start": 121.63999938964844,
      "temperature": 0.0,
      "text": " In fact, it's even more relevant",
      "tokens": [
        50550,
        682,
        1186,
        11,
        309,
        311,
        754,
        544,
        7340,
        50742
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.22161218523979187,
      "compression_ratio": 1.3129770755767822,
      "end": 127.37999725341797,
      "no_speech_prob": 0.007576527073979378,
      "seek": 11792,
      "start": 125.4800033569336,
      "temperature": 0.0,
      "text": " than it was when it was launched, okay?",
      "tokens": [
        50742,
        813,
        309,
        390,
        562,
        309,
        390,
        8730,
        11,
        1392,
        30,
        50837
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.22161218523979187,
      "compression_ratio": 1.3129770755767822,
      "end": 129.32000732421875,
      "no_speech_prob": 0.007576527073979378,
      "seek": 11792,
      "start": 127.37999725341797,
      "temperature": 0.0,
      "text": " So I highly recommend you check it out.",
      "tokens": [
        50837,
        407,
        286,
        5405,
        2748,
        291,
        1520,
        309,
        484,
        13,
        50934
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834863.338809
}
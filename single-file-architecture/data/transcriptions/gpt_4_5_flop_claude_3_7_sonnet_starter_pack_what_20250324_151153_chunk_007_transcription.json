{
  "audio_path": "data/chunks/gpt_4_5_flop_claude_3_7_sonnet_starter_pack_what_20250324_151153_chunk_007.mp3",
  "text": "Shift R. Now I have the relative path to this file. So I'm going to paste this in and I'm going to say, update this file, add a usage example. All right. So Cloud Code kicking off. It's running a read tool. There was a batch tool. Now we're running the read tool. It's reading this entire file, right? I think that's the entire file. Yep. 253 lines. It's thinking, it's working through this. It's understanding what it needs to do. And then in a moment here, it's going to call the update tool. Okay. Update tool requires the file path. And it also is going to have, you know, whatever it's actually going to update with, right? So you can see here, here's another example. It's a little too heavy for me. So I'm going to say, I'm just going to tap escape. Just add the UV run. What is the dot, dot, dot to the usage examples. Nothing else. As incredible as this tool is, it's still going to make mistakes, right? So there we go. So I had to be more specific with my prompt there. And do you want me to make this edit? Yes. So this is really cool, right? You can go into YOLO mode or you can run one by one. All right. So I'm going to hit yes. And then you can see there, it ran update file with that change. I just want to really emphasize this point. We have update. We have read. We have bash. This is an agent. This is an AI agent. It has a suite of tools, a really powerful prompt, right? A powerful comprehensive prompt. As you likely know, you can connect to model context provider server. If we just go ahead and clear and rerun, you can see there, I have these two servers connected. Let's hop into our server fetch example. So this file showcases how you can add an MCP server directly to Cloud Code. I've already run this. So basically you run Cloud MCP add fetch, and then you specify the CLI arguments that you would need to run this. We're using UV so that we don't have to do any setup. And then you can run Cloud MCP list. If we open up a new terminal here and run this, you can see I have those two servers set up and you can see the exact commands, right? So we're going to run my.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 3.4000000953674316,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " Shift R. Now I have the relative path to this file.",
      "tokens": [
        50364,
        28304,
        497,
        13,
        823,
        286,
        362,
        264,
        4972,
        3100,
        281,
        341,
        3991,
        13,
        50534
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 6.0,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 3.4000000953674316,
      "temperature": 0.0,
      "text": " So I'm going to paste this in and I'm going to say,",
      "tokens": [
        50534,
        407,
        286,
        478,
        516,
        281,
        9163,
        341,
        294,
        293,
        286,
        478,
        516,
        281,
        584,
        11,
        50664
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 10.5600004196167,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 6.0,
      "temperature": 0.0,
      "text": " update this file, add a usage example.",
      "tokens": [
        50664,
        5623,
        341,
        3991,
        11,
        909,
        257,
        14924,
        1365,
        13,
        50892
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 11.399999618530273,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 10.5600004196167,
      "temperature": 0.0,
      "text": " All right.",
      "tokens": [
        50892,
        1057,
        558,
        13,
        50934
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 13.5600004196167,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 11.399999618530273,
      "temperature": 0.0,
      "text": " So Cloud Code kicking off.",
      "tokens": [
        50934,
        407,
        8061,
        15549,
        19137,
        766,
        13,
        51042
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 15.84000015258789,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 13.5600004196167,
      "temperature": 0.0,
      "text": " It's running a read tool.",
      "tokens": [
        51042,
        467,
        311,
        2614,
        257,
        1401,
        2290,
        13,
        51156
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 16.68000030517578,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 15.84000015258789,
      "temperature": 0.0,
      "text": " There was a batch tool.",
      "tokens": [
        51156,
        821,
        390,
        257,
        15245,
        2290,
        13,
        51198
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 18.200000762939453,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 16.68000030517578,
      "temperature": 0.0,
      "text": " Now we're running the read tool.",
      "tokens": [
        51198,
        823,
        321,
        434,
        2614,
        264,
        1401,
        2290,
        13,
        51274
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 20.200000762939453,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 18.200000762939453,
      "temperature": 0.0,
      "text": " It's reading this entire file, right?",
      "tokens": [
        51274,
        467,
        311,
        3760,
        341,
        2302,
        3991,
        11,
        558,
        30,
        51374
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 21.15999984741211,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 20.200000762939453,
      "temperature": 0.0,
      "text": " I think that's the entire file.",
      "tokens": [
        51374,
        286,
        519,
        300,
        311,
        264,
        2302,
        3991,
        13,
        51422
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 23.0,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 21.15999984741211,
      "temperature": 0.0,
      "text": " Yep. 253 lines.",
      "tokens": [
        51422,
        7010,
        13,
        3552,
        18,
        3876,
        13,
        51514
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 24.399999618530273,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 23.0,
      "temperature": 0.0,
      "text": " It's thinking, it's working through this.",
      "tokens": [
        51514,
        467,
        311,
        1953,
        11,
        309,
        311,
        1364,
        807,
        341,
        13,
        51584
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 26.440000534057617,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 24.399999618530273,
      "temperature": 0.0,
      "text": " It's understanding what it needs to do.",
      "tokens": [
        51584,
        467,
        311,
        3701,
        437,
        309,
        2203,
        281,
        360,
        13,
        51686
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.262250691652298,
      "compression_ratio": 1.7026022672653198,
      "end": 27.799999237060547,
      "no_speech_prob": 0.020022330805659294,
      "seek": 0,
      "start": 26.440000534057617,
      "temperature": 0.0,
      "text": " And then in a moment here,",
      "tokens": [
        51686,
        400,
        550,
        294,
        257,
        1623,
        510,
        11,
        51754
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 31.040000915527344,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 27.799999237060547,
      "temperature": 0.0,
      "text": " it's going to call the update tool.",
      "tokens": [
        50364,
        309,
        311,
        516,
        281,
        818,
        264,
        5623,
        2290,
        13,
        50526
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 31.8799991607666,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 31.040000915527344,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50526,
        1033,
        13,
        50568
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 34.47999954223633,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 31.8799991607666,
      "temperature": 0.0,
      "text": " Update tool requires the file path.",
      "tokens": [
        50568,
        28923,
        2290,
        7029,
        264,
        3991,
        3100,
        13,
        50698
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 37.20000076293945,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 34.47999954223633,
      "temperature": 0.0,
      "text": " And it also is going to have, you know,",
      "tokens": [
        50698,
        400,
        309,
        611,
        307,
        516,
        281,
        362,
        11,
        291,
        458,
        11,
        50834
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 39.91999816894531,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 37.20000076293945,
      "temperature": 0.0,
      "text": " whatever it's actually going to update with, right?",
      "tokens": [
        50834,
        2035,
        309,
        311,
        767,
        516,
        281,
        5623,
        365,
        11,
        558,
        30,
        50970
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 42.36000061035156,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 39.91999816894531,
      "temperature": 0.0,
      "text": " So you can see here, here's another example.",
      "tokens": [
        50970,
        407,
        291,
        393,
        536,
        510,
        11,
        510,
        311,
        1071,
        1365,
        13,
        51092
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 43.68000030517578,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 42.36000061035156,
      "temperature": 0.0,
      "text": " It's a little too heavy for me.",
      "tokens": [
        51092,
        467,
        311,
        257,
        707,
        886,
        4676,
        337,
        385,
        13,
        51158
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 45.720001220703125,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 43.68000030517578,
      "temperature": 0.0,
      "text": " So I'm going to say, I'm just going to tap escape.",
      "tokens": [
        51158,
        407,
        286,
        478,
        516,
        281,
        584,
        11,
        286,
        478,
        445,
        516,
        281,
        5119,
        7615,
        13,
        51260
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 48.52000045776367,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 45.720001220703125,
      "temperature": 0.0,
      "text": " Just add the UV run.",
      "tokens": [
        51260,
        1449,
        909,
        264,
        17887,
        1190,
        13,
        51400
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 52.560001373291016,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 48.52000045776367,
      "temperature": 0.0,
      "text": " What is the dot, dot, dot to the usage examples.",
      "tokens": [
        51400,
        708,
        307,
        264,
        5893,
        11,
        5893,
        11,
        5893,
        281,
        264,
        14924,
        5110,
        13,
        51602
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 53.880001068115234,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 52.560001373291016,
      "temperature": 0.0,
      "text": " Nothing else.",
      "tokens": [
        51602,
        6693,
        1646,
        13,
        51668
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 55.84000015258789,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 53.880001068115234,
      "temperature": 0.0,
      "text": " As incredible as this tool is,",
      "tokens": [
        51668,
        1018,
        4651,
        382,
        341,
        2290,
        307,
        11,
        51766
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.19443221390247345,
      "compression_ratio": 1.706766963005066,
      "end": 57.5,
      "no_speech_prob": 0.00037409141077660024,
      "seek": 2780,
      "start": 55.84000015258789,
      "temperature": 0.0,
      "text": " it's still going to make mistakes, right?",
      "tokens": [
        51766,
        309,
        311,
        920,
        516,
        281,
        652,
        8038,
        11,
        558,
        30,
        51849
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 59.02000045776367,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 58.20000076293945,
      "temperature": 0.0,
      "text": " So there we go.",
      "tokens": [
        50399,
        407,
        456,
        321,
        352,
        13,
        50440
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 60.70000076293945,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 59.02000045776367,
      "temperature": 0.0,
      "text": " So I had to be more specific with my prompt there.",
      "tokens": [
        50440,
        407,
        286,
        632,
        281,
        312,
        544,
        2685,
        365,
        452,
        12391,
        456,
        13,
        50524
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 62.2400016784668,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 60.70000076293945,
      "temperature": 0.0,
      "text": " And do you want me to make this edit?",
      "tokens": [
        50524,
        400,
        360,
        291,
        528,
        385,
        281,
        652,
        341,
        8129,
        30,
        50601
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 63.08000183105469,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 62.2400016784668,
      "temperature": 0.0,
      "text": " Yes.",
      "tokens": [
        50601,
        1079,
        13,
        50643
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 63.97999954223633,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 63.08000183105469,
      "temperature": 0.0,
      "text": " So this is really cool, right?",
      "tokens": [
        50643,
        407,
        341,
        307,
        534,
        1627,
        11,
        558,
        30,
        50688
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 67.5,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 63.97999954223633,
      "temperature": 0.0,
      "text": " You can go into YOLO mode or you can run one by one.",
      "tokens": [
        50688,
        509,
        393,
        352,
        666,
        398,
        5046,
        46,
        4391,
        420,
        291,
        393,
        1190,
        472,
        538,
        472,
        13,
        50864
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 68.33999633789062,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 67.5,
      "temperature": 0.0,
      "text": " All right.",
      "tokens": [
        50864,
        1057,
        558,
        13,
        50906
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 69.31999969482422,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 68.33999633789062,
      "temperature": 0.0,
      "text": " So I'm going to hit yes.",
      "tokens": [
        50906,
        407,
        286,
        478,
        516,
        281,
        2045,
        2086,
        13,
        50955
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 70.9000015258789,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 69.31999969482422,
      "temperature": 0.0,
      "text": " And then you can see there,",
      "tokens": [
        50955,
        400,
        550,
        291,
        393,
        536,
        456,
        11,
        51034
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 74.04000091552734,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 70.9000015258789,
      "temperature": 0.0,
      "text": " it ran update file with that change.",
      "tokens": [
        51034,
        309,
        5872,
        5623,
        3991,
        365,
        300,
        1319,
        13,
        51191
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 75.62000274658203,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 74.04000091552734,
      "temperature": 0.0,
      "text": " I just want to really emphasize this point.",
      "tokens": [
        51191,
        286,
        445,
        528,
        281,
        534,
        16078,
        341,
        935,
        13,
        51270
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 76.5199966430664,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 75.62000274658203,
      "temperature": 0.0,
      "text": " We have update.",
      "tokens": [
        51270,
        492,
        362,
        5623,
        13,
        51315
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 78.5,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 76.5199966430664,
      "temperature": 0.0,
      "text": " We have read.",
      "tokens": [
        51315,
        492,
        362,
        1401,
        13,
        51414
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 79.83999633789062,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 78.5,
      "temperature": 0.0,
      "text": " We have bash.",
      "tokens": [
        51414,
        492,
        362,
        46183,
        13,
        51481
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 81.0199966430664,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 79.83999633789062,
      "temperature": 0.0,
      "text": " This is an agent.",
      "tokens": [
        51481,
        639,
        307,
        364,
        9461,
        13,
        51540
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 83.05999755859375,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 81.0199966430664,
      "temperature": 0.0,
      "text": " This is an AI agent.",
      "tokens": [
        51540,
        639,
        307,
        364,
        7318,
        9461,
        13,
        51642
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 84.72000122070312,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 83.05999755859375,
      "temperature": 0.0,
      "text": " It has a suite of tools,",
      "tokens": [
        51642,
        467,
        575,
        257,
        14205,
        295,
        3873,
        11,
        51725
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.2118481546640396,
      "compression_ratio": 1.7230216264724731,
      "end": 86.77999877929688,
      "no_speech_prob": 0.002050716197118163,
      "seek": 5750,
      "start": 84.72000122070312,
      "temperature": 0.0,
      "text": " a really powerful prompt, right?",
      "tokens": [
        51725,
        257,
        534,
        4005,
        12391,
        11,
        558,
        30,
        51828
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 88.26000213623047,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 86.77999877929688,
      "temperature": 0.0,
      "text": " A powerful comprehensive prompt.",
      "tokens": [
        50364,
        316,
        4005,
        13914,
        12391,
        13,
        50438
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 89.54000091552734,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 88.26000213623047,
      "temperature": 0.0,
      "text": " As you likely know,",
      "tokens": [
        50438,
        1018,
        291,
        3700,
        458,
        11,
        50502
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 93.30000305175781,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 89.54000091552734,
      "temperature": 0.0,
      "text": " you can connect to model context provider server.",
      "tokens": [
        50502,
        291,
        393,
        1745,
        281,
        2316,
        4319,
        12398,
        7154,
        13,
        50690
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 100.66000366210938,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 96.9800033569336,
      "temperature": 0.0,
      "text": " If we just go ahead and clear and rerun,",
      "tokens": [
        50874,
        759,
        321,
        445,
        352,
        2286,
        293,
        1850,
        293,
        43819,
        409,
        11,
        51058
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 103.5,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 100.66000366210938,
      "temperature": 0.0,
      "text": " you can see there, I have these two servers connected.",
      "tokens": [
        51058,
        291,
        393,
        536,
        456,
        11,
        286,
        362,
        613,
        732,
        15909,
        4582,
        13,
        51200
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 106.87999725341797,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 103.5,
      "temperature": 0.0,
      "text": " Let's hop into our server fetch example.",
      "tokens": [
        51200,
        961,
        311,
        3818,
        666,
        527,
        7154,
        23673,
        1365,
        13,
        51369
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 110.62000274658203,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 106.87999725341797,
      "temperature": 0.0,
      "text": " So this file showcases how you can add an MCP server",
      "tokens": [
        51369,
        407,
        341,
        3991,
        29794,
        1957,
        577,
        291,
        393,
        909,
        364,
        8797,
        47,
        7154,
        51556
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 112.54000091552734,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 110.62000274658203,
      "temperature": 0.0,
      "text": " directly to Cloud Code.",
      "tokens": [
        51556,
        3838,
        281,
        8061,
        15549,
        13,
        51652
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 113.44000244140625,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 112.54000091552734,
      "temperature": 0.0,
      "text": " I've already run this.",
      "tokens": [
        51652,
        286,
        600,
        1217,
        1190,
        341,
        13,
        51697
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.2792056202888489,
      "compression_ratio": 1.6075949668884277,
      "end": 116.22000122070312,
      "no_speech_prob": 0.0063881780952215195,
      "seek": 8678,
      "start": 113.44000244140625,
      "temperature": 0.0,
      "text": " So basically you run Cloud MCP add fetch,",
      "tokens": [
        51697,
        407,
        1936,
        291,
        1190,
        8061,
        8797,
        47,
        909,
        23673,
        11,
        51836
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.24689212441444397,
      "compression_ratio": 1.5679612159729004,
      "end": 118.41999816894531,
      "no_speech_prob": 0.012239981442689896,
      "seek": 11622,
      "start": 116.66000366210938,
      "temperature": 0.0,
      "text": " and then you specify the CLI arguments",
      "tokens": [
        50386,
        293,
        550,
        291,
        16500,
        264,
        12855,
        40,
        12869,
        50474
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.24689212441444397,
      "compression_ratio": 1.5679612159729004,
      "end": 119.26000213623047,
      "no_speech_prob": 0.012239981442689896,
      "seek": 11622,
      "start": 118.41999816894531,
      "temperature": 0.0,
      "text": " that you would need to run this.",
      "tokens": [
        50474,
        300,
        291,
        576,
        643,
        281,
        1190,
        341,
        13,
        50516
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.24689212441444397,
      "compression_ratio": 1.5679612159729004,
      "end": 121.73999786376953,
      "no_speech_prob": 0.012239981442689896,
      "seek": 11622,
      "start": 119.26000213623047,
      "temperature": 0.0,
      "text": " We're using UV so that we don't have to do any setup.",
      "tokens": [
        50516,
        492,
        434,
        1228,
        17887,
        370,
        300,
        321,
        500,
        380,
        362,
        281,
        360,
        604,
        8657,
        13,
        50640
      ]
    },
    {
      "id": 58,
      "avg_logprob": -0.24689212441444397,
      "compression_ratio": 1.5679612159729004,
      "end": 123.66000366210938,
      "no_speech_prob": 0.012239981442689896,
      "seek": 11622,
      "start": 121.73999786376953,
      "temperature": 0.0,
      "text": " And then you can run Cloud MCP list.",
      "tokens": [
        50640,
        400,
        550,
        291,
        393,
        1190,
        8061,
        8797,
        47,
        1329,
        13,
        50736
      ]
    },
    {
      "id": 59,
      "avg_logprob": -0.24689212441444397,
      "compression_ratio": 1.5679612159729004,
      "end": 126.13999938964844,
      "no_speech_prob": 0.012239981442689896,
      "seek": 11622,
      "start": 123.66000366210938,
      "temperature": 0.0,
      "text": " If we open up a new terminal here and run this,",
      "tokens": [
        50736,
        759,
        321,
        1269,
        493,
        257,
        777,
        14709,
        510,
        293,
        1190,
        341,
        11,
        50860
      ]
    },
    {
      "id": 60,
      "avg_logprob": -0.24689212441444397,
      "compression_ratio": 1.5679612159729004,
      "end": 128.94000244140625,
      "no_speech_prob": 0.012239981442689896,
      "seek": 11622,
      "start": 126.13999938964844,
      "temperature": 0.0,
      "text": " you can see I have those two servers set up",
      "tokens": [
        50860,
        291,
        393,
        536,
        286,
        362,
        729,
        732,
        15909,
        992,
        493,
        51000
      ]
    },
    {
      "id": 61,
      "avg_logprob": -0.24689212441444397,
      "compression_ratio": 1.5679612159729004,
      "end": 130.4199981689453,
      "no_speech_prob": 0.012239981442689896,
      "seek": 11622,
      "start": 128.94000244140625,
      "temperature": 0.0,
      "text": " and you can see the exact commands, right?",
      "tokens": [
        51000,
        293,
        291,
        393,
        536,
        264,
        1900,
        16901,
        11,
        558,
        30,
        51074
      ]
    },
    {
      "id": 62,
      "avg_logprob": -0.24689212441444397,
      "compression_ratio": 1.5679612159729004,
      "end": 131.66000366210938,
      "no_speech_prob": 0.012239981442689896,
      "seek": 11622,
      "start": 130.4199981689453,
      "temperature": 0.0,
      "text": " So we're going to run my.",
      "tokens": [
        51074,
        407,
        321,
        434,
        516,
        281,
        1190,
        452,
        13,
        51136
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835630.072733
}
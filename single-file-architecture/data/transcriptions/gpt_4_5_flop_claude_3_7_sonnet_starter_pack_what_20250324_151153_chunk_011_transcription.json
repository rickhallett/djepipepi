{
  "audio_path": "data/chunks/gpt_4_5_flop_claude_3_7_sonnet_starter_pack_what_20250324_151153_chunk_011.mp3",
  "text": "All right, so you can see here, Washington DC, unknown, unknown, unknown. And now it's trying again. Now it's doing something really, really cool. It's firing off a task. I don't know if there's a lot of documentation on the task tool. Let's go ahead and see. Yeah, so there's not really any documentation on the task tool, but the task tool in itself is really, really interesting. You can see here, it's fired off, you know, it missed, missed, missed, and then it created this task. So this agent is kind of passing off work to a sub-agent. Very, very important idea there for agent orchestration and context management. Then we got a bunch of additional weather calls, and then we got the create, and now we can fire this off. You can see that that is coming in sorted. And once again, we can just click open this file format, and you can see there, we have capital, country, temperature, top to bottom. The agent is doing a series, a chain, a job set of work for us, and we are typing in natural language. We're making sure that our prompt is communicating what we want, and we're moving more toward prompting. Something like this is a lot different than prompting a crap ton of code. So you don't really need the mid, low-level prompt details that we discuss in principled AI coding, but you can see here, just with the right details, with the right amount of information, we have 10 tool calls happening, right? And it's all about that information density in your prompt. Are you communicating the right ideas to your agent to get the job done? So incredible stuff there. That's the local MCP server. Again, all this stuff is gonna be linked in the description for you to check out, really dive in and understand how this is set up and how you can build your own MCP servers, how you can reuse existing MCP servers. There are quite a few MCP servers that you can get and use just right out of the box, right? All the ones you would expect, SQLite, right? We have Postgres, and we have tons of third-party tools. So it really is looking like Anthropic with Cloud Code. They are paving the way in this next age, in this next kind of phase.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 2.0199999809265137,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " All right, so you can see here, Washington DC,",
      "tokens": [
        50364,
        1057,
        558,
        11,
        370,
        291,
        393,
        536,
        510,
        11,
        6149,
        9114,
        11,
        50465
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 3.4200000762939453,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 2.0199999809265137,
      "temperature": 0.0,
      "text": " unknown, unknown, unknown.",
      "tokens": [
        50465,
        9841,
        11,
        9841,
        11,
        9841,
        13,
        50535
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 5.159999847412109,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 3.4200000762939453,
      "temperature": 0.0,
      "text": " And now it's trying again.",
      "tokens": [
        50535,
        400,
        586,
        309,
        311,
        1382,
        797,
        13,
        50622
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 6.659999847412109,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 5.159999847412109,
      "temperature": 0.0,
      "text": " Now it's doing something really, really cool.",
      "tokens": [
        50622,
        823,
        309,
        311,
        884,
        746,
        534,
        11,
        534,
        1627,
        13,
        50697
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 8.300000190734863,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 6.659999847412109,
      "temperature": 0.0,
      "text": " It's firing off a task.",
      "tokens": [
        50697,
        467,
        311,
        16045,
        766,
        257,
        5633,
        13,
        50779
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 9.619999885559082,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 8.300000190734863,
      "temperature": 0.0,
      "text": " I don't know if there's a lot of documentation",
      "tokens": [
        50779,
        286,
        500,
        380,
        458,
        498,
        456,
        311,
        257,
        688,
        295,
        14333,
        50845
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 10.460000038146973,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 9.619999885559082,
      "temperature": 0.0,
      "text": " on the task tool.",
      "tokens": [
        50845,
        322,
        264,
        5633,
        2290,
        13,
        50887
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 11.380000114440918,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 10.460000038146973,
      "temperature": 0.0,
      "text": " Let's go ahead and see.",
      "tokens": [
        50887,
        961,
        311,
        352,
        2286,
        293,
        536,
        13,
        50933
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 13.539999961853027,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 11.380000114440918,
      "temperature": 0.0,
      "text": " Yeah, so there's not really any documentation",
      "tokens": [
        50933,
        865,
        11,
        370,
        456,
        311,
        406,
        534,
        604,
        14333,
        51041
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 14.579999923706055,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 13.539999961853027,
      "temperature": 0.0,
      "text": " on the task tool,",
      "tokens": [
        51041,
        322,
        264,
        5633,
        2290,
        11,
        51093
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 16.81999969482422,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 14.579999923706055,
      "temperature": 0.0,
      "text": " but the task tool in itself is really, really interesting.",
      "tokens": [
        51093,
        457,
        264,
        5633,
        2290,
        294,
        2564,
        307,
        534,
        11,
        534,
        1880,
        13,
        51205
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 18.940000534057617,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 16.81999969482422,
      "temperature": 0.0,
      "text": " You can see here, it's fired off, you know,",
      "tokens": [
        51205,
        509,
        393,
        536,
        510,
        11,
        309,
        311,
        11777,
        766,
        11,
        291,
        458,
        11,
        51311
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 20.219999313354492,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 18.940000534057617,
      "temperature": 0.0,
      "text": " it missed, missed, missed,",
      "tokens": [
        51311,
        309,
        6721,
        11,
        6721,
        11,
        6721,
        11,
        51375
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 23.200000762939453,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 20.219999313354492,
      "temperature": 0.0,
      "text": " and then it created this task.",
      "tokens": [
        51375,
        293,
        550,
        309,
        2942,
        341,
        5633,
        13,
        51524
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.22901709377765656,
      "compression_ratio": 1.9566787481307983,
      "end": 28.100000381469727,
      "no_speech_prob": 0.010485622100532055,
      "seek": 0,
      "start": 23.200000762939453,
      "temperature": 0.0,
      "text": " So this agent is kind of passing off work to a sub-agent.",
      "tokens": [
        51524,
        407,
        341,
        9461,
        307,
        733,
        295,
        8437,
        766,
        589,
        281,
        257,
        1422,
        12,
        559,
        317,
        13,
        51769
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 31.040000915527344,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 28.1200008392334,
      "temperature": 0.0,
      "text": " Very, very important idea there for agent orchestration",
      "tokens": [
        50365,
        4372,
        11,
        588,
        1021,
        1558,
        456,
        337,
        9461,
        14161,
        2405,
        50511
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 32.47999954223633,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 31.040000915527344,
      "temperature": 0.0,
      "text": " and context management.",
      "tokens": [
        50511,
        293,
        4319,
        4592,
        13,
        50583
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 35.31999969482422,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 32.47999954223633,
      "temperature": 0.0,
      "text": " Then we got a bunch of additional weather calls,",
      "tokens": [
        50583,
        1396,
        321,
        658,
        257,
        3840,
        295,
        4497,
        5503,
        5498,
        11,
        50725
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 36.400001525878906,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 35.31999969482422,
      "temperature": 0.0,
      "text": " and then we got the create,",
      "tokens": [
        50725,
        293,
        550,
        321,
        658,
        264,
        1884,
        11,
        50779
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 37.720001220703125,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 36.400001525878906,
      "temperature": 0.0,
      "text": " and now we can fire this off.",
      "tokens": [
        50779,
        293,
        586,
        321,
        393,
        2610,
        341,
        766,
        13,
        50845
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 40.36000061035156,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 37.720001220703125,
      "temperature": 0.0,
      "text": " You can see that that is coming in sorted.",
      "tokens": [
        50845,
        509,
        393,
        536,
        300,
        300,
        307,
        1348,
        294,
        25462,
        13,
        50977
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 44.47999954223633,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 40.36000061035156,
      "temperature": 0.0,
      "text": " And once again, we can just click open this file format,",
      "tokens": [
        50977,
        400,
        1564,
        797,
        11,
        321,
        393,
        445,
        2052,
        1269,
        341,
        3991,
        7877,
        11,
        51183
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 45.68000030517578,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 44.47999954223633,
      "temperature": 0.0,
      "text": " and you can see there,",
      "tokens": [
        51183,
        293,
        291,
        393,
        536,
        456,
        11,
        51243
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 49.0,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 45.68000030517578,
      "temperature": 0.0,
      "text": " we have capital, country, temperature, top to bottom.",
      "tokens": [
        51243,
        321,
        362,
        4238,
        11,
        1941,
        11,
        4292,
        11,
        1192,
        281,
        2767,
        13,
        51409
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.2144807130098343,
      "compression_ratio": 1.6708333492279053,
      "end": 53.91999816894531,
      "no_speech_prob": 0.0019569837022572756,
      "seek": 2810,
      "start": 49.0,
      "temperature": 0.0,
      "text": " The agent is doing a series, a chain,",
      "tokens": [
        51409,
        440,
        9461,
        307,
        884,
        257,
        2638,
        11,
        257,
        5021,
        11,
        51655
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 58.34000015258789,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 54.70000076293945,
      "temperature": 0.0,
      "text": " a job set of work for us,",
      "tokens": [
        50403,
        257,
        1691,
        992,
        295,
        589,
        337,
        505,
        11,
        50585
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 60.20000076293945,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 58.34000015258789,
      "temperature": 0.0,
      "text": " and we are typing in natural language.",
      "tokens": [
        50585,
        293,
        321,
        366,
        18444,
        294,
        3303,
        2856,
        13,
        50678
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 61.220001220703125,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 60.20000076293945,
      "temperature": 0.0,
      "text": " We're making sure that our prompt",
      "tokens": [
        50678,
        492,
        434,
        1455,
        988,
        300,
        527,
        12391,
        50729
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 62.779998779296875,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 61.220001220703125,
      "temperature": 0.0,
      "text": " is communicating what we want,",
      "tokens": [
        50729,
        307,
        17559,
        437,
        321,
        528,
        11,
        50807
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 65.30000305175781,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 62.779998779296875,
      "temperature": 0.0,
      "text": " and we're moving more toward prompting.",
      "tokens": [
        50807,
        293,
        321,
        434,
        2684,
        544,
        7361,
        12391,
        278,
        13,
        50933
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 66.45999908447266,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 65.30000305175781,
      "temperature": 0.0,
      "text": " Something like this is a lot different",
      "tokens": [
        50933,
        6595,
        411,
        341,
        307,
        257,
        688,
        819,
        50991
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 68.81999969482422,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 66.45999908447266,
      "temperature": 0.0,
      "text": " than prompting a crap ton of code.",
      "tokens": [
        50991,
        813,
        12391,
        278,
        257,
        12426,
        2952,
        295,
        3089,
        13,
        51109
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 72.9800033569336,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 68.81999969482422,
      "temperature": 0.0,
      "text": " So you don't really need the mid, low-level prompt details",
      "tokens": [
        51109,
        407,
        291,
        500,
        380,
        534,
        643,
        264,
        2062,
        11,
        2295,
        12,
        12418,
        12391,
        4365,
        51317
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 76.0199966430664,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 72.9800033569336,
      "temperature": 0.0,
      "text": " that we discuss in principled AI coding,",
      "tokens": [
        51317,
        300,
        321,
        2248,
        294,
        3681,
        15551,
        7318,
        17720,
        11,
        51469
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 78.66000366210938,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 76.0199966430664,
      "temperature": 0.0,
      "text": " but you can see here, just with the right details,",
      "tokens": [
        51469,
        457,
        291,
        393,
        536,
        510,
        11,
        445,
        365,
        264,
        558,
        4365,
        11,
        51601
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.25376588106155396,
      "compression_ratio": 1.6551724672317505,
      "end": 80.54000091552734,
      "no_speech_prob": 0.019718315452337265,
      "seek": 5392,
      "start": 78.66000366210938,
      "temperature": 0.0,
      "text": " with the right amount of information,",
      "tokens": [
        51601,
        365,
        264,
        558,
        2372,
        295,
        1589,
        11,
        51695
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 84.22000122070312,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 80.54000091552734,
      "temperature": 0.0,
      "text": " we have 10 tool calls happening, right?",
      "tokens": [
        50364,
        321,
        362,
        1266,
        2290,
        5498,
        2737,
        11,
        558,
        30,
        50548
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 87.81999969482422,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 84.22000122070312,
      "temperature": 0.0,
      "text": " And it's all about that information density in your prompt.",
      "tokens": [
        50548,
        400,
        309,
        311,
        439,
        466,
        300,
        1589,
        10305,
        294,
        428,
        12391,
        13,
        50728
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 91.19999694824219,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 87.81999969482422,
      "temperature": 0.0,
      "text": " Are you communicating the right ideas to your agent",
      "tokens": [
        50728,
        2014,
        291,
        17559,
        264,
        558,
        3487,
        281,
        428,
        9461,
        50897
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 92.31999969482422,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 91.19999694824219,
      "temperature": 0.0,
      "text": " to get the job done?",
      "tokens": [
        50897,
        281,
        483,
        264,
        1691,
        1096,
        30,
        50953
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 94.08000183105469,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 92.31999969482422,
      "temperature": 0.0,
      "text": " So incredible stuff there.",
      "tokens": [
        50953,
        407,
        4651,
        1507,
        456,
        13,
        51041
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 95.5999984741211,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 94.08000183105469,
      "temperature": 0.0,
      "text": " That's the local MCP server.",
      "tokens": [
        51041,
        663,
        311,
        264,
        2654,
        8797,
        47,
        7154,
        13,
        51117
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 97.83999633789062,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 95.5999984741211,
      "temperature": 0.0,
      "text": " Again, all this stuff is gonna be linked",
      "tokens": [
        51117,
        3764,
        11,
        439,
        341,
        1507,
        307,
        799,
        312,
        9408,
        51229
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 99.63999938964844,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 97.83999633789062,
      "temperature": 0.0,
      "text": " in the description for you to check out,",
      "tokens": [
        51229,
        294,
        264,
        3855,
        337,
        291,
        281,
        1520,
        484,
        11,
        51319
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 102.68000030517578,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 99.63999938964844,
      "temperature": 0.0,
      "text": " really dive in and understand how this is set up",
      "tokens": [
        51319,
        534,
        9192,
        294,
        293,
        1223,
        577,
        341,
        307,
        992,
        493,
        51471
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 104.72000122070312,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 102.68000030517578,
      "temperature": 0.0,
      "text": " and how you can build your own MCP servers,",
      "tokens": [
        51471,
        293,
        577,
        291,
        393,
        1322,
        428,
        1065,
        8797,
        47,
        15909,
        11,
        51573
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 107.12000274658203,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 104.72000122070312,
      "temperature": 0.0,
      "text": " how you can reuse existing MCP servers.",
      "tokens": [
        51573,
        577,
        291,
        393,
        26225,
        6741,
        8797,
        47,
        15909,
        13,
        51693
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.174499049782753,
      "compression_ratio": 1.6795774698257446,
      "end": 110.5199966430664,
      "no_speech_prob": 0.0020829313434660435,
      "seek": 8054,
      "start": 107.12000274658203,
      "temperature": 0.0,
      "text": " There are quite a few MCP servers",
      "tokens": [
        51693,
        821,
        366,
        1596,
        257,
        1326,
        8797,
        47,
        15909,
        51863
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.2674330174922943,
      "compression_ratio": 1.471794843673706,
      "end": 114.13999938964844,
      "no_speech_prob": 0.0016484613297507167,
      "seek": 11052,
      "start": 111.36000061035156,
      "temperature": 0.0,
      "text": " that you can get and use just right out of the box, right?",
      "tokens": [
        50406,
        300,
        291,
        393,
        483,
        293,
        764,
        445,
        558,
        484,
        295,
        264,
        2424,
        11,
        558,
        30,
        50545
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.2674330174922943,
      "compression_ratio": 1.471794843673706,
      "end": 116.77999877929688,
      "no_speech_prob": 0.0016484613297507167,
      "seek": 11052,
      "start": 114.13999938964844,
      "temperature": 0.0,
      "text": " All the ones you would expect, SQLite, right?",
      "tokens": [
        50545,
        1057,
        264,
        2306,
        291,
        576,
        2066,
        11,
        19200,
        642,
        11,
        558,
        30,
        50677
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.2674330174922943,
      "compression_ratio": 1.471794843673706,
      "end": 121.18000030517578,
      "no_speech_prob": 0.0016484613297507167,
      "seek": 11052,
      "start": 116.77999877929688,
      "temperature": 0.0,
      "text": " We have Postgres, and we have tons of third-party tools.",
      "tokens": [
        50677,
        492,
        362,
        10223,
        45189,
        11,
        293,
        321,
        362,
        9131,
        295,
        2636,
        12,
        23409,
        3873,
        13,
        50897
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.2674330174922943,
      "compression_ratio": 1.471794843673706,
      "end": 126.18000030517578,
      "no_speech_prob": 0.0016484613297507167,
      "seek": 11052,
      "start": 121.18000030517578,
      "temperature": 0.0,
      "text": " So it really is looking like Anthropic with Cloud Code.",
      "tokens": [
        50897,
        407,
        309,
        534,
        307,
        1237,
        411,
        12727,
        39173,
        365,
        8061,
        15549,
        13,
        51147
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.2674330174922943,
      "compression_ratio": 1.471794843673706,
      "end": 130.02000427246094,
      "no_speech_prob": 0.0016484613297507167,
      "seek": 11052,
      "start": 126.30000305175781,
      "temperature": 0.0,
      "text": " They are paving the way in this next age,",
      "tokens": [
        51153,
        814,
        366,
        280,
        6152,
        264,
        636,
        294,
        341,
        958,
        3205,
        11,
        51339
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.2674330174922943,
      "compression_ratio": 1.471794843673706,
      "end": 131.4199981689453,
      "no_speech_prob": 0.0016484613297507167,
      "seek": 11052,
      "start": 130.02000427246094,
      "temperature": 0.0,
      "text": " in this next kind of phase.",
      "tokens": [
        51339,
        294,
        341,
        958,
        733,
        295,
        5574,
        13,
        51409
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835676.958622
}
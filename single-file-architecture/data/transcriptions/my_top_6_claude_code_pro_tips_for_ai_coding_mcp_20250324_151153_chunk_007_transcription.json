{
  "audio_path": "data/chunks/my_top_6_claude_code_pro_tips_for_ai_coding_mcp_20250324_151153_chunk_007.mp3",
  "text": "and rerun. So we're gonna kick off the first man here running without the efficiency beta flag. There we go. So we can see you know there's the total token usage there and now we're gonna run with the efficiency flag. So you can see we use a total of you know 5,700 tokens. We just go ahead and copy that out and we'll just throw this in a file here and then we'll go ahead and run with efficiency. Looks like we're getting a little error here. We're gonna go ahead and let Claude do its thing. Okay so you can see here Sonnet picking up on an error that it made. It actually is using this older syntax where you import anthropic.beta. This is good. This is why we have the documentation there. It can automatically make corrections when it needs to. So there it is. It just made that change and you can see there yep nice. So we're gonna continue down the line. All we want to do is check to see if we have that use efficiency token there. There we go. We can get rid of that code. That looks great and then we're just going to remove. I always like to be really careful when I look at there you know any type of RM but that looks good. We want to remove that one file. That's fine and now we should be in a good place to rerun. Yeah let's go ahead and take a look at this. Okay so we want to run without efficiency flag. That's fine. It wants to redo the process. There we go. So let's go ahead and copy this value here. Right we have 6,000 tokens. Let's go ahead and update our token value. So we have 6,000 tokens here. Then it wants to reset and basically run it again right with the efficiency flag. So let's go ahead and hit yes and let's see how the efficiency token flag can save us some tokens for our agents. So let's take a look. You can see here Claude code is giving us a nice analysis. It looks like without token efficiency we got 6k tokens and with we got 5.7. So not a major you know saving but not too bad either right. It looks like we got 5.7 percent reduction and it looks like the big savings which is honestly where you want to have the savings is in the output tokens right because the output",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.25369301438331604,
      "compression_ratio": 1.8979592323303223,
      "end": 4.440000057220459,
      "no_speech_prob": 0.22263365983963013,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " and rerun. So we're gonna kick off the first man here running without the",
      "tokens": [
        50364,
        293,
        43819,
        409,
        13,
        407,
        321,
        434,
        799,
        4437,
        766,
        264,
        700,
        587,
        510,
        2614,
        1553,
        264,
        50586
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.25369301438331604,
      "compression_ratio": 1.8979592323303223,
      "end": 9.119999885559082,
      "no_speech_prob": 0.22263365983963013,
      "seek": 0,
      "start": 4.440000057220459,
      "temperature": 0.0,
      "text": " efficiency beta flag. There we go. So we can see you know there's the total token",
      "tokens": [
        50586,
        10493,
        9861,
        7166,
        13,
        821,
        321,
        352,
        13,
        407,
        321,
        393,
        536,
        291,
        458,
        456,
        311,
        264,
        3217,
        14862,
        50820
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.25369301438331604,
      "compression_ratio": 1.8979592323303223,
      "end": 14.600000381469727,
      "no_speech_prob": 0.22263365983963013,
      "seek": 0,
      "start": 9.119999885559082,
      "temperature": 0.0,
      "text": " usage there and now we're gonna run with the efficiency flag. So you can see we",
      "tokens": [
        50820,
        14924,
        456,
        293,
        586,
        321,
        434,
        799,
        1190,
        365,
        264,
        10493,
        7166,
        13,
        407,
        291,
        393,
        536,
        321,
        51094
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.25369301438331604,
      "compression_ratio": 1.8979592323303223,
      "end": 18.479999542236328,
      "no_speech_prob": 0.22263365983963013,
      "seek": 0,
      "start": 14.600000381469727,
      "temperature": 0.0,
      "text": " use a total of you know 5,700 tokens. We just go ahead and copy that out and",
      "tokens": [
        51094,
        764,
        257,
        3217,
        295,
        291,
        458,
        1025,
        11,
        18197,
        22667,
        13,
        492,
        445,
        352,
        2286,
        293,
        5055,
        300,
        484,
        293,
        51288
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.25369301438331604,
      "compression_ratio": 1.8979592323303223,
      "end": 23.8799991607666,
      "no_speech_prob": 0.22263365983963013,
      "seek": 0,
      "start": 18.479999542236328,
      "temperature": 0.0,
      "text": " we'll just throw this in a file here and then we'll go ahead and run with",
      "tokens": [
        51288,
        321,
        603,
        445,
        3507,
        341,
        294,
        257,
        3991,
        510,
        293,
        550,
        321,
        603,
        352,
        2286,
        293,
        1190,
        365,
        51558
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.25369301438331604,
      "compression_ratio": 1.8979592323303223,
      "end": 26.600000381469727,
      "no_speech_prob": 0.22263365983963013,
      "seek": 0,
      "start": 23.8799991607666,
      "temperature": 0.0,
      "text": " efficiency. Looks like we're getting a little error here. We're gonna go ahead",
      "tokens": [
        51558,
        10493,
        13,
        10027,
        411,
        321,
        434,
        1242,
        257,
        707,
        6713,
        510,
        13,
        492,
        434,
        799,
        352,
        2286,
        51694
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.26383736729621887,
      "compression_ratio": 1.6798560619354248,
      "end": 31.559999465942383,
      "no_speech_prob": 0.03161574527621269,
      "seek": 2660,
      "start": 26.600000381469727,
      "temperature": 0.0,
      "text": " and let Claude do its thing. Okay so you can see here Sonnet picking up on an",
      "tokens": [
        50364,
        293,
        718,
        12947,
        2303,
        360,
        1080,
        551,
        13,
        1033,
        370,
        291,
        393,
        536,
        510,
        5185,
        7129,
        8867,
        493,
        322,
        364,
        50612
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.26383736729621887,
      "compression_ratio": 1.6798560619354248,
      "end": 36.599998474121094,
      "no_speech_prob": 0.03161574527621269,
      "seek": 2660,
      "start": 31.559999465942383,
      "temperature": 0.0,
      "text": " error that it made. It actually is using this older syntax where you import",
      "tokens": [
        50612,
        6713,
        300,
        309,
        1027,
        13,
        467,
        767,
        307,
        1228,
        341,
        4906,
        28431,
        689,
        291,
        974,
        50864
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.26383736729621887,
      "compression_ratio": 1.6798560619354248,
      "end": 40.20000076293945,
      "no_speech_prob": 0.03161574527621269,
      "seek": 2660,
      "start": 36.599998474121094,
      "temperature": 0.0,
      "text": " anthropic.beta. This is good. This is why we have the documentation there.",
      "tokens": [
        50864,
        25820,
        39173,
        13,
        65,
        7664,
        13,
        639,
        307,
        665,
        13,
        639,
        307,
        983,
        321,
        362,
        264,
        14333,
        456,
        13,
        51044
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.26383736729621887,
      "compression_ratio": 1.6798560619354248,
      "end": 44.959999084472656,
      "no_speech_prob": 0.03161574527621269,
      "seek": 2660,
      "start": 40.20000076293945,
      "temperature": 0.0,
      "text": " It can automatically make corrections when it needs to. So there it is. It just",
      "tokens": [
        51044,
        467,
        393,
        6772,
        652,
        36406,
        562,
        309,
        2203,
        281,
        13,
        407,
        456,
        309,
        307,
        13,
        467,
        445,
        51282
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.26383736729621887,
      "compression_ratio": 1.6798560619354248,
      "end": 48.880001068115234,
      "no_speech_prob": 0.03161574527621269,
      "seek": 2660,
      "start": 44.959999084472656,
      "temperature": 0.0,
      "text": " made that change and you can see there yep nice. So we're gonna continue down",
      "tokens": [
        51282,
        1027,
        300,
        1319,
        293,
        291,
        393,
        536,
        456,
        18633,
        1481,
        13,
        407,
        321,
        434,
        799,
        2354,
        760,
        51478
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.26383736729621887,
      "compression_ratio": 1.6798560619354248,
      "end": 54.70000076293945,
      "no_speech_prob": 0.03161574527621269,
      "seek": 2660,
      "start": 48.880001068115234,
      "temperature": 0.0,
      "text": " the line. All we want to do is check to see if we have that use efficiency token",
      "tokens": [
        51478,
        264,
        1622,
        13,
        1057,
        321,
        528,
        281,
        360,
        307,
        1520,
        281,
        536,
        498,
        321,
        362,
        300,
        764,
        10493,
        14862,
        51769
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.21136707067489624,
      "compression_ratio": 1.7985074520111084,
      "end": 59.58000183105469,
      "no_speech_prob": 0.07476450502872467,
      "seek": 5470,
      "start": 54.70000076293945,
      "temperature": 0.0,
      "text": " there. There we go. We can get rid of that code. That looks great and then we're",
      "tokens": [
        50364,
        456,
        13,
        821,
        321,
        352,
        13,
        492,
        393,
        483,
        3973,
        295,
        300,
        3089,
        13,
        663,
        1542,
        869,
        293,
        550,
        321,
        434,
        50608
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.21136707067489624,
      "compression_ratio": 1.7985074520111084,
      "end": 63.65999984741211,
      "no_speech_prob": 0.07476450502872467,
      "seek": 5470,
      "start": 59.58000183105469,
      "temperature": 0.0,
      "text": " just going to remove. I always like to be really careful when I look at there you",
      "tokens": [
        50608,
        445,
        516,
        281,
        4159,
        13,
        286,
        1009,
        411,
        281,
        312,
        534,
        5026,
        562,
        286,
        574,
        412,
        456,
        291,
        50812
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.21136707067489624,
      "compression_ratio": 1.7985074520111084,
      "end": 68.0199966430664,
      "no_speech_prob": 0.07476450502872467,
      "seek": 5470,
      "start": 63.65999984741211,
      "temperature": 0.0,
      "text": " know any type of RM but that looks good. We want to remove that one file. That's",
      "tokens": [
        50812,
        458,
        604,
        2010,
        295,
        23790,
        457,
        300,
        1542,
        665,
        13,
        492,
        528,
        281,
        4159,
        300,
        472,
        3991,
        13,
        663,
        311,
        51030
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.21136707067489624,
      "compression_ratio": 1.7985074520111084,
      "end": 72.18000030517578,
      "no_speech_prob": 0.07476450502872467,
      "seek": 5470,
      "start": 68.0199966430664,
      "temperature": 0.0,
      "text": " fine and now we should be in a good place to rerun. Yeah let's go ahead and",
      "tokens": [
        51030,
        2489,
        293,
        586,
        321,
        820,
        312,
        294,
        257,
        665,
        1081,
        281,
        43819,
        409,
        13,
        865,
        718,
        311,
        352,
        2286,
        293,
        51238
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.21136707067489624,
      "compression_ratio": 1.7985074520111084,
      "end": 76.77999877929688,
      "no_speech_prob": 0.07476450502872467,
      "seek": 5470,
      "start": 72.18000030517578,
      "temperature": 0.0,
      "text": " take a look at this. Okay so we want to run without efficiency flag. That's fine.",
      "tokens": [
        51238,
        747,
        257,
        574,
        412,
        341,
        13,
        1033,
        370,
        321,
        528,
        281,
        1190,
        1553,
        10493,
        7166,
        13,
        663,
        311,
        2489,
        13,
        51468
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.21136707067489624,
      "compression_ratio": 1.7985074520111084,
      "end": 81.77999877929688,
      "no_speech_prob": 0.07476450502872467,
      "seek": 5470,
      "start": 76.77999877929688,
      "temperature": 0.0,
      "text": " It wants to redo the process. There we go. So let's go ahead and copy this value",
      "tokens": [
        51468,
        467,
        2738,
        281,
        29956,
        264,
        1399,
        13,
        821,
        321,
        352,
        13,
        407,
        718,
        311,
        352,
        2286,
        293,
        5055,
        341,
        2158,
        51718
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.24625593423843384,
      "compression_ratio": 1.7472527027130127,
      "end": 89.41999816894531,
      "no_speech_prob": 0.02262824773788452,
      "seek": 8178,
      "start": 81.77999877929688,
      "temperature": 0.0,
      "text": " here. Right we have 6,000 tokens. Let's go ahead and update our token value. So we",
      "tokens": [
        50364,
        510,
        13,
        1779,
        321,
        362,
        1386,
        11,
        1360,
        22667,
        13,
        961,
        311,
        352,
        2286,
        293,
        5623,
        527,
        14862,
        2158,
        13,
        407,
        321,
        50746
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.24625593423843384,
      "compression_ratio": 1.7472527027130127,
      "end": 93.18000030517578,
      "no_speech_prob": 0.02262824773788452,
      "seek": 8178,
      "start": 89.41999816894531,
      "temperature": 0.0,
      "text": " have 6,000 tokens here. Then it wants to reset and basically run it again right",
      "tokens": [
        50746,
        362,
        1386,
        11,
        1360,
        22667,
        510,
        13,
        1396,
        309,
        2738,
        281,
        14322,
        293,
        1936,
        1190,
        309,
        797,
        558,
        50934
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.24625593423843384,
      "compression_ratio": 1.7472527027130127,
      "end": 96.9000015258789,
      "no_speech_prob": 0.02262824773788452,
      "seek": 8178,
      "start": 93.18000030517578,
      "temperature": 0.0,
      "text": " with the efficiency flag. So let's go ahead and hit yes and let's see how the",
      "tokens": [
        50934,
        365,
        264,
        10493,
        7166,
        13,
        407,
        718,
        311,
        352,
        2286,
        293,
        2045,
        2086,
        293,
        718,
        311,
        536,
        577,
        264,
        51120
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.24625593423843384,
      "compression_ratio": 1.7472527027130127,
      "end": 106.62000274658203,
      "no_speech_prob": 0.02262824773788452,
      "seek": 8178,
      "start": 96.9000015258789,
      "temperature": 0.0,
      "text": " efficiency token flag can save us some tokens for our agents. So let's take a",
      "tokens": [
        51120,
        10493,
        14862,
        7166,
        393,
        3155,
        505,
        512,
        22667,
        337,
        527,
        12554,
        13,
        407,
        718,
        311,
        747,
        257,
        51606
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.3172801434993744,
      "compression_ratio": 1.7397260665893555,
      "end": 111.26000213623047,
      "no_speech_prob": 0.043351586908102036,
      "seek": 10662,
      "start": 106.62000274658203,
      "temperature": 0.0,
      "text": " look. You can see here Claude code is giving us a nice analysis. It looks like",
      "tokens": [
        50364,
        574,
        13,
        509,
        393,
        536,
        510,
        12947,
        2303,
        3089,
        307,
        2902,
        505,
        257,
        1481,
        5215,
        13,
        467,
        1542,
        411,
        50596
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.3172801434993744,
      "compression_ratio": 1.7397260665893555,
      "end": 118.22000122070312,
      "no_speech_prob": 0.043351586908102036,
      "seek": 10662,
      "start": 111.26000213623047,
      "temperature": 0.0,
      "text": " without token efficiency we got 6k tokens and with we got 5.7. So not a",
      "tokens": [
        50596,
        1553,
        14862,
        10493,
        321,
        658,
        1386,
        74,
        22667,
        293,
        365,
        321,
        658,
        1025,
        13,
        22,
        13,
        407,
        406,
        257,
        50944
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.3172801434993744,
      "compression_ratio": 1.7397260665893555,
      "end": 123.62000274658203,
      "no_speech_prob": 0.043351586908102036,
      "seek": 10662,
      "start": 118.22000122070312,
      "temperature": 0.0,
      "text": " major you know saving but not too bad either right. It looks like we got 5.7",
      "tokens": [
        50944,
        2563,
        291,
        458,
        6816,
        457,
        406,
        886,
        1578,
        2139,
        558,
        13,
        467,
        1542,
        411,
        321,
        658,
        1025,
        13,
        22,
        51214
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.3172801434993744,
      "compression_ratio": 1.7397260665893555,
      "end": 128.10000610351562,
      "no_speech_prob": 0.043351586908102036,
      "seek": 10662,
      "start": 123.62000274658203,
      "temperature": 0.0,
      "text": " percent reduction and it looks like the big savings which is honestly where you",
      "tokens": [
        51214,
        3043,
        11004,
        293,
        309,
        1542,
        411,
        264,
        955,
        13454,
        597,
        307,
        6095,
        689,
        291,
        51438
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.3172801434993744,
      "compression_ratio": 1.7397260665893555,
      "end": 133.5800018310547,
      "no_speech_prob": 0.043351586908102036,
      "seek": 10662,
      "start": 128.10000610351562,
      "temperature": 0.0,
      "text": " want to have the savings is in the output tokens right because the output",
      "tokens": [
        51438,
        528,
        281,
        362,
        264,
        13454,
        307,
        294,
        264,
        5598,
        22667,
        558,
        570,
        264,
        5598,
        51712
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834641.053546
}
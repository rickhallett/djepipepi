{
  "audio_path": "data/chunks/single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_005.mp3",
  "text": "same as our run final SQL query and we can go ahead and fire off our agent again and just take a look to see if it's actually going to kick off this call. Sometimes it completely skips the run test SQL query because it just doesn't need it, it doesn't need the test. But we can do something like this, create a new table, high score users from the user table and select all users with score greater than 80 that are active and 2025. Let's pass it off to our DuckDB AI agent and just see how it does with this. I'm also going to kick up the compute loop just in case it needs a little bit more energy. Let's kick that off and let's see how it does here. So you can see it's first validating the structure right and needs to find the table so it's running list tables. It's seeing the schema structure of that table. It's now running this test SQL command so it's verifying that what we're going to ask for will work. Instead of looking for human in the loop feedback or instead of running the final query, what it's doing here is running this test SQL query. This is a really important pattern for building out great agents. You don't have to wait to close the loop to let your agent fully validate the process. So I have this run test SQL, it's running this internally, adding more information to its context window, gathering information about how to solve the problem of creating this query, creating this new table, and then finally after it's validated it, it's then running this final query here. So after validation it's now saying we can take this query, it's safe, it works, it looks good. Let's go ahead and run this final query and create this new table. So now of course if we hit up and we hit up again let's get a smaller command to work with and we just say list all tables and one sample row for each table and we fire that off. We should now get this brand new high score. So there's the high score users and the users table. So this is fantastic. There's the sample. Our AI agent is understanding these table structures. It's understanding what we want and what we want to do and then it's giving us these concrete outputs. You can see here how important it is to have the reasoning inside your agents.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 4.960000038146973,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " same as our run final SQL query and we can go ahead and fire off our agent",
      "tokens": [
        50364,
        912,
        382,
        527,
        1190,
        2572,
        19200,
        14581,
        293,
        321,
        393,
        352,
        2286,
        293,
        2610,
        766,
        527,
        9461,
        50612
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 8.5600004196167,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 4.960000038146973,
      "temperature": 0.0,
      "text": " again and just take a look to see if it's actually going to kick off this",
      "tokens": [
        50612,
        797,
        293,
        445,
        747,
        257,
        574,
        281,
        536,
        498,
        309,
        311,
        767,
        516,
        281,
        4437,
        766,
        341,
        50792
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 12.920000076293945,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 8.5600004196167,
      "temperature": 0.0,
      "text": " call. Sometimes it completely skips the run test SQL query because it just",
      "tokens": [
        50792,
        818,
        13,
        4803,
        309,
        2584,
        1110,
        2600,
        264,
        1190,
        1500,
        19200,
        14581,
        570,
        309,
        445,
        51010
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 16.600000381469727,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 12.920000076293945,
      "temperature": 0.0,
      "text": " doesn't need it, it doesn't need the test. But we can do something like this, create",
      "tokens": [
        51010,
        1177,
        380,
        643,
        309,
        11,
        309,
        1177,
        380,
        643,
        264,
        1500,
        13,
        583,
        321,
        393,
        360,
        746,
        411,
        341,
        11,
        1884,
        51194
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.26399973034858704,
      "compression_ratio": 1.6410256624221802,
      "end": 24.079999923706055,
      "no_speech_prob": 0.0726199746131897,
      "seek": 0,
      "start": 16.600000381469727,
      "temperature": 0.0,
      "text": " a new table, high score users from the user table and select all users with",
      "tokens": [
        51194,
        257,
        777,
        3199,
        11,
        1090,
        6175,
        5022,
        490,
        264,
        4195,
        3199,
        293,
        3048,
        439,
        5022,
        365,
        51568
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 30.31999969482422,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 24.079999923706055,
      "temperature": 0.0,
      "text": " score greater than 80 that are active and 2025. Let's pass it off to our DuckDB",
      "tokens": [
        50364,
        6175,
        5044,
        813,
        4688,
        300,
        366,
        4967,
        293,
        945,
        17,
        20,
        13,
        961,
        311,
        1320,
        309,
        766,
        281,
        527,
        29266,
        27735,
        50676
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 34.119998931884766,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 30.31999969482422,
      "temperature": 0.0,
      "text": " AI agent and just see how it does with this. I'm also going to kick up the",
      "tokens": [
        50676,
        7318,
        9461,
        293,
        445,
        536,
        577,
        309,
        775,
        365,
        341,
        13,
        286,
        478,
        611,
        516,
        281,
        4437,
        493,
        264,
        50866
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 37.400001525878906,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 34.119998931884766,
      "temperature": 0.0,
      "text": " compute loop just in case it needs a little bit more energy. Let's kick that",
      "tokens": [
        50866,
        14722,
        6367,
        445,
        294,
        1389,
        309,
        2203,
        257,
        707,
        857,
        544,
        2281,
        13,
        961,
        311,
        4437,
        300,
        51030
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 41.79999923706055,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 37.400001525878906,
      "temperature": 0.0,
      "text": " off and let's see how it does here. So you can see it's first validating the",
      "tokens": [
        51030,
        766,
        293,
        718,
        311,
        536,
        577,
        309,
        775,
        510,
        13,
        407,
        291,
        393,
        536,
        309,
        311,
        700,
        7363,
        990,
        264,
        51250
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 45.0,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 41.79999923706055,
      "temperature": 0.0,
      "text": " structure right and needs to find the table so it's running list tables. It's",
      "tokens": [
        51250,
        3877,
        558,
        293,
        2203,
        281,
        915,
        264,
        3199,
        370,
        309,
        311,
        2614,
        1329,
        8020,
        13,
        467,
        311,
        51410
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.27228835225105286,
      "compression_ratio": 1.6974170207977295,
      "end": 50.400001525878906,
      "no_speech_prob": 0.030213013291358948,
      "seek": 2408,
      "start": 45.0,
      "temperature": 0.0,
      "text": " seeing the schema structure of that table. It's now running this test SQL",
      "tokens": [
        51410,
        2577,
        264,
        34078,
        3877,
        295,
        300,
        3199,
        13,
        467,
        311,
        586,
        2614,
        341,
        1500,
        19200,
        51680
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 54.959999084472656,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 50.400001525878906,
      "temperature": 0.0,
      "text": " command so it's verifying that what we're going to ask for will work. Instead",
      "tokens": [
        50364,
        5622,
        370,
        309,
        311,
        1306,
        5489,
        300,
        437,
        321,
        434,
        516,
        281,
        1029,
        337,
        486,
        589,
        13,
        7156,
        50592
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 59.08000183105469,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 54.959999084472656,
      "temperature": 0.0,
      "text": " of looking for human in the loop feedback or instead of running the",
      "tokens": [
        50592,
        295,
        1237,
        337,
        1952,
        294,
        264,
        6367,
        5824,
        420,
        2602,
        295,
        2614,
        264,
        50798
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 62.880001068115234,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 59.08000183105469,
      "temperature": 0.0,
      "text": " final query, what it's doing here is running this test SQL query. This is a",
      "tokens": [
        50798,
        2572,
        14581,
        11,
        437,
        309,
        311,
        884,
        510,
        307,
        2614,
        341,
        1500,
        19200,
        14581,
        13,
        639,
        307,
        257,
        50988
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 67.16000366210938,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 62.880001068115234,
      "temperature": 0.0,
      "text": " really important pattern for building out great agents. You don't have to wait",
      "tokens": [
        50988,
        534,
        1021,
        5102,
        337,
        2390,
        484,
        869,
        12554,
        13,
        509,
        500,
        380,
        362,
        281,
        1699,
        51202
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 71.95999908447266,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 67.16000366210938,
      "temperature": 0.0,
      "text": " to close the loop to let your agent fully validate the process. So I",
      "tokens": [
        51202,
        281,
        1998,
        264,
        6367,
        281,
        718,
        428,
        9461,
        4498,
        29562,
        264,
        1399,
        13,
        407,
        286,
        51442
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 76.72000122070312,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 71.95999908447266,
      "temperature": 0.0,
      "text": " have this run test SQL, it's running this internally, adding more information to",
      "tokens": [
        51442,
        362,
        341,
        1190,
        1500,
        19200,
        11,
        309,
        311,
        2614,
        341,
        19501,
        11,
        5127,
        544,
        1589,
        281,
        51680
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.23949794471263885,
      "compression_ratio": 1.7820069789886475,
      "end": 80.19999694824219,
      "no_speech_prob": 0.0032730225939303637,
      "seek": 5040,
      "start": 76.72000122070312,
      "temperature": 0.0,
      "text": " its context window, gathering information about how to solve the",
      "tokens": [
        51680,
        1080,
        4319,
        4910,
        11,
        13519,
        1589,
        466,
        577,
        281,
        5039,
        264,
        51854
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 85.19999694824219,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 80.23999786376953,
      "temperature": 0.0,
      "text": " problem of creating this query, creating this new table, and then finally",
      "tokens": [
        50366,
        1154,
        295,
        4084,
        341,
        14581,
        11,
        4084,
        341,
        777,
        3199,
        11,
        293,
        550,
        2721,
        50614
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 89.27999877929688,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 85.19999694824219,
      "temperature": 0.0,
      "text": " after it's validated it, it's then running this final query here. So",
      "tokens": [
        50614,
        934,
        309,
        311,
        40693,
        309,
        11,
        309,
        311,
        550,
        2614,
        341,
        2572,
        14581,
        510,
        13,
        407,
        50818
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 93.19999694824219,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 89.27999877929688,
      "temperature": 0.0,
      "text": " after validation it's now saying we can take this query, it's safe, it",
      "tokens": [
        50818,
        934,
        24071,
        309,
        311,
        586,
        1566,
        321,
        393,
        747,
        341,
        14581,
        11,
        309,
        311,
        3273,
        11,
        309,
        51014
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 97.91999816894531,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 93.19999694824219,
      "temperature": 0.0,
      "text": " works, it looks good. Let's go ahead and run this final query and create this new",
      "tokens": [
        51014,
        1985,
        11,
        309,
        1542,
        665,
        13,
        961,
        311,
        352,
        2286,
        293,
        1190,
        341,
        2572,
        14581,
        293,
        1884,
        341,
        777,
        51250
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 101.95999908447266,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 97.91999816894531,
      "temperature": 0.0,
      "text": " table. So now of course if we hit up and we hit up again let's get a smaller",
      "tokens": [
        51250,
        3199,
        13,
        407,
        586,
        295,
        1164,
        498,
        321,
        2045,
        493,
        293,
        321,
        2045,
        493,
        797,
        718,
        311,
        483,
        257,
        4356,
        51452
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.2592002749443054,
      "compression_ratio": 1.9298245906829834,
      "end": 107.5999984741211,
      "no_speech_prob": 0.010488675907254219,
      "seek": 8020,
      "start": 101.95999908447266,
      "temperature": 0.0,
      "text": " command to work with and we just say list all tables and one sample",
      "tokens": [
        51452,
        5622,
        281,
        589,
        365,
        293,
        321,
        445,
        584,
        1329,
        439,
        8020,
        293,
        472,
        6889,
        51734
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 112.68000030517578,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 107.5999984741211,
      "temperature": 0.0,
      "text": " row for each table and we fire that off. We should now get this brand new high",
      "tokens": [
        50364,
        5386,
        337,
        1184,
        3199,
        293,
        321,
        2610,
        300,
        766,
        13,
        492,
        820,
        586,
        483,
        341,
        3360,
        777,
        1090,
        50618
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 116.12000274658203,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 112.68000030517578,
      "temperature": 0.0,
      "text": " score. So there's the high score users and the users table. So this is",
      "tokens": [
        50618,
        6175,
        13,
        407,
        456,
        311,
        264,
        1090,
        6175,
        5022,
        293,
        264,
        5022,
        3199,
        13,
        407,
        341,
        307,
        50790
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 120.87999725341797,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 116.12000274658203,
      "temperature": 0.0,
      "text": " fantastic. There's the sample. Our AI agent is understanding these table",
      "tokens": [
        50790,
        5456,
        13,
        821,
        311,
        264,
        6889,
        13,
        2621,
        7318,
        9461,
        307,
        3701,
        613,
        3199,
        51028
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 124.31999969482422,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 120.87999725341797,
      "temperature": 0.0,
      "text": " structures. It's understanding what we want and what we want to do and then",
      "tokens": [
        51028,
        9227,
        13,
        467,
        311,
        3701,
        437,
        321,
        528,
        293,
        437,
        321,
        528,
        281,
        360,
        293,
        550,
        51200
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 128.24000549316406,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 124.31999969482422,
      "temperature": 0.0,
      "text": " it's giving us these concrete outputs. You can see here how",
      "tokens": [
        51200,
        309,
        311,
        2902,
        505,
        613,
        9859,
        23930,
        13,
        509,
        393,
        536,
        510,
        577,
        51396
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.29939061403274536,
      "compression_ratio": 1.7405858039855957,
      "end": 133.0399932861328,
      "no_speech_prob": 0.004330988973379135,
      "seek": 10760,
      "start": 128.24000549316406,
      "temperature": 0.0,
      "text": " important it is to have the reasoning inside your agents.",
      "tokens": [
        51396,
        1021,
        309,
        307,
        281,
        362,
        264,
        21577,
        1854,
        428,
        12554,
        13,
        51636
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834953.403153
}
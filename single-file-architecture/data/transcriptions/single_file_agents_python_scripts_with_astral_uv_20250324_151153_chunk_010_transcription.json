{
  "audio_path": "data/chunks/single_file_agents_python_scripts_with_astral_uv_20250324_151153_chunk_010.mp3",
  "text": "version of this, I'll paste this in, and you can see my SQLite extension showing this table here, right? So this is our users table, let's go ahead and close this. So we now have this ready for our new SQLite agent. Let's go ahead and save this. And now let's just run our SQLite agent, SFA, single file agent, and we're gonna run our SQLite version, dash D, analytics, SQLite database, dash P, list five rows from user table. And for our compute, we'll just say five, right? Should be pretty simple. So far so good, right? Our code compiles, so that looks great. We have our first tool call, that looks awesome. There it is. So SQLite running just like our DuckDB did. We're getting a slightly different output format because of course we're using SQLite. We were able to reuse our existing single file agent architecture. We made an update to it with a clean prompt chain of length four, where every prompt was us kicking off Adr. We have an architect and then an editor, and then we just basically doubled it, right? Our reflection actually saved us a little bit of energy. This idea of scaling up your compute really does translate to almost anywhere you're using language models, anywhere you're running a prompt, right? Even if it's embedded inside of a tool like Adr, right? You have to remember all of these tools, right? Cursor, Adr, ChatGPT, Claude, right? Every one of these tools at the end is running the new fundamental unit of knowledge work. It's all about the prompt and agents is how we scale the prompt up. This is how we scale up our impact. At the beginning, I said we would talk about, why is everyone so obsessed with agents? This is why, it's because agents lets us scale up our compute usage. And in the age of generative AI, when you scale your compute, you scale your impact. This is a big theme on the Andi Dev Dan channel. Right now in Q1, 2025, the most important thing we can do is figure out how to scale our compute. Agents are the name of the game. You just saw what we did here with a DuckDB domain-specific focus agent with only five tools, right? It gathers context, it understands the structure, it then internally validates for hard problems, and then it gives us the fun.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 2.0799999237060547,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " version of this, I'll paste this in,",
      "tokens": [
        50364,
        3037,
        295,
        341,
        11,
        286,
        603,
        9163,
        341,
        294,
        11,
        50468
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 5.239999771118164,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 2.0799999237060547,
      "temperature": 0.0,
      "text": " and you can see my SQLite extension",
      "tokens": [
        50468,
        293,
        291,
        393,
        536,
        452,
        19200,
        642,
        10320,
        50626
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 7.119999885559082,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 5.239999771118164,
      "temperature": 0.0,
      "text": " showing this table here, right?",
      "tokens": [
        50626,
        4099,
        341,
        3199,
        510,
        11,
        558,
        30,
        50720
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 9.359999656677246,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 7.119999885559082,
      "temperature": 0.0,
      "text": " So this is our users table, let's go ahead and close this.",
      "tokens": [
        50720,
        407,
        341,
        307,
        527,
        5022,
        3199,
        11,
        718,
        311,
        352,
        2286,
        293,
        1998,
        341,
        13,
        50832
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 12.0,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 9.359999656677246,
      "temperature": 0.0,
      "text": " So we now have this ready for our new SQLite agent.",
      "tokens": [
        50832,
        407,
        321,
        586,
        362,
        341,
        1919,
        337,
        527,
        777,
        19200,
        642,
        9461,
        13,
        50964
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 13.640000343322754,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 12.0,
      "temperature": 0.0,
      "text": " Let's go ahead and save this.",
      "tokens": [
        50964,
        961,
        311,
        352,
        2286,
        293,
        3155,
        341,
        13,
        51046
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 16.280000686645508,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 13.640000343322754,
      "temperature": 0.0,
      "text": " And now let's just run our SQLite agent,",
      "tokens": [
        51046,
        400,
        586,
        718,
        311,
        445,
        1190,
        527,
        19200,
        642,
        9461,
        11,
        51178
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 17.8799991607666,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 16.280000686645508,
      "temperature": 0.0,
      "text": " SFA, single file agent,",
      "tokens": [
        51178,
        318,
        19684,
        11,
        2167,
        3991,
        9461,
        11,
        51258
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 19.959999084472656,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 17.8799991607666,
      "temperature": 0.0,
      "text": " and we're gonna run our SQLite version,",
      "tokens": [
        51258,
        293,
        321,
        434,
        799,
        1190,
        527,
        19200,
        642,
        3037,
        11,
        51362
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 22.899999618530273,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 19.959999084472656,
      "temperature": 0.0,
      "text": " dash D, analytics, SQLite database,",
      "tokens": [
        51362,
        8240,
        413,
        11,
        15370,
        11,
        19200,
        642,
        8149,
        11,
        51509
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 27.040000915527344,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 22.899999618530273,
      "temperature": 0.0,
      "text": " dash P, list five rows from user table.",
      "tokens": [
        51509,
        8240,
        430,
        11,
        1329,
        1732,
        13241,
        490,
        4195,
        3199,
        13,
        51716
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.22810706496238708,
      "compression_ratio": 1.826923131942749,
      "end": 29.15999984741211,
      "no_speech_prob": 0.03676621988415718,
      "seek": 0,
      "start": 27.040000915527344,
      "temperature": 0.0,
      "text": " And for our compute, we'll just say five, right?",
      "tokens": [
        51716,
        400,
        337,
        527,
        14722,
        11,
        321,
        603,
        445,
        584,
        1732,
        11,
        558,
        30,
        51822
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 30.15999984741211,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 29.15999984741211,
      "temperature": 0.0,
      "text": " Should be pretty simple.",
      "tokens": [
        50364,
        6454,
        312,
        1238,
        2199,
        13,
        50414
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 31.0,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 30.15999984741211,
      "temperature": 0.0,
      "text": " So far so good, right?",
      "tokens": [
        50414,
        407,
        1400,
        370,
        665,
        11,
        558,
        30,
        50456
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 32.560001373291016,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 31.0,
      "temperature": 0.0,
      "text": " Our code compiles, so that looks great.",
      "tokens": [
        50456,
        2621,
        3089,
        715,
        4680,
        11,
        370,
        300,
        1542,
        869,
        13,
        50534
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 34.7599983215332,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 32.560001373291016,
      "temperature": 0.0,
      "text": " We have our first tool call, that looks awesome.",
      "tokens": [
        50534,
        492,
        362,
        527,
        700,
        2290,
        818,
        11,
        300,
        1542,
        3476,
        13,
        50644
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 35.599998474121094,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 34.7599983215332,
      "temperature": 0.0,
      "text": " There it is.",
      "tokens": [
        50644,
        821,
        309,
        307,
        13,
        50686
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 39.599998474121094,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 35.599998474121094,
      "temperature": 0.0,
      "text": " So SQLite running just like our DuckDB did.",
      "tokens": [
        50686,
        407,
        19200,
        642,
        2614,
        445,
        411,
        527,
        29266,
        27735,
        630,
        13,
        50886
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 41.599998474121094,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 39.599998474121094,
      "temperature": 0.0,
      "text": " We're getting a slightly different output format",
      "tokens": [
        50886,
        492,
        434,
        1242,
        257,
        4748,
        819,
        5598,
        7877,
        50986
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 43.20000076293945,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 41.599998474121094,
      "temperature": 0.0,
      "text": " because of course we're using SQLite.",
      "tokens": [
        50986,
        570,
        295,
        1164,
        321,
        434,
        1228,
        19200,
        642,
        13,
        51066
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 44.720001220703125,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 43.20000076293945,
      "temperature": 0.0,
      "text": " We were able to reuse",
      "tokens": [
        51066,
        492,
        645,
        1075,
        281,
        26225,
        51142
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 47.0,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 44.720001220703125,
      "temperature": 0.0,
      "text": " our existing single file agent architecture.",
      "tokens": [
        51142,
        527,
        6741,
        2167,
        3991,
        9461,
        9482,
        13,
        51256
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 50.08000183105469,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 47.0,
      "temperature": 0.0,
      "text": " We made an update to it with a clean prompt chain",
      "tokens": [
        51256,
        492,
        1027,
        364,
        5623,
        281,
        309,
        365,
        257,
        2541,
        12391,
        5021,
        51410
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 53.540000915527344,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 50.08000183105469,
      "temperature": 0.0,
      "text": " of length four, where every prompt was us kicking off Adr.",
      "tokens": [
        51410,
        295,
        4641,
        1451,
        11,
        689,
        633,
        12391,
        390,
        505,
        19137,
        766,
        1999,
        81,
        13,
        51583
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 55.52000045776367,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 53.540000915527344,
      "temperature": 0.0,
      "text": " We have an architect and then an editor,",
      "tokens": [
        51583,
        492,
        362,
        364,
        6331,
        293,
        550,
        364,
        9839,
        11,
        51682
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.23639608919620514,
      "compression_ratio": 1.670769214630127,
      "end": 57.20000076293945,
      "no_speech_prob": 0.0001634641084820032,
      "seek": 2916,
      "start": 55.52000045776367,
      "temperature": 0.0,
      "text": " and then we just basically doubled it, right?",
      "tokens": [
        51682,
        293,
        550,
        321,
        445,
        1936,
        24405,
        309,
        11,
        558,
        30,
        51766
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 60.36000061035156,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 57.20000076293945,
      "temperature": 0.0,
      "text": " Our reflection actually saved us a little bit of energy.",
      "tokens": [
        50364,
        2621,
        12914,
        767,
        6624,
        505,
        257,
        707,
        857,
        295,
        2281,
        13,
        50522
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 62.7599983215332,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 60.36000061035156,
      "temperature": 0.0,
      "text": " This idea of scaling up your compute",
      "tokens": [
        50522,
        639,
        1558,
        295,
        21589,
        493,
        428,
        14722,
        50642
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 65.5199966430664,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 62.7599983215332,
      "temperature": 0.0,
      "text": " really does translate to almost anywhere",
      "tokens": [
        50642,
        534,
        775,
        13799,
        281,
        1920,
        4992,
        50780
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 67.23999786376953,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 65.5199966430664,
      "temperature": 0.0,
      "text": " you're using language models,",
      "tokens": [
        50780,
        291,
        434,
        1228,
        2856,
        5245,
        11,
        50866
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 69.30000305175781,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 67.23999786376953,
      "temperature": 0.0,
      "text": " anywhere you're running a prompt, right?",
      "tokens": [
        50866,
        4992,
        291,
        434,
        2614,
        257,
        12391,
        11,
        558,
        30,
        50969
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 71.91999816894531,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 69.30000305175781,
      "temperature": 0.0,
      "text": " Even if it's embedded inside of a tool like Adr, right?",
      "tokens": [
        50969,
        2754,
        498,
        309,
        311,
        16741,
        1854,
        295,
        257,
        2290,
        411,
        1999,
        81,
        11,
        558,
        30,
        51100
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 73.76000213623047,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 71.91999816894531,
      "temperature": 0.0,
      "text": " You have to remember all of these tools, right?",
      "tokens": [
        51100,
        509,
        362,
        281,
        1604,
        439,
        295,
        613,
        3873,
        11,
        558,
        30,
        51192
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 77.13999938964844,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 73.76000213623047,
      "temperature": 0.0,
      "text": " Cursor, Adr, ChatGPT, Claude, right?",
      "tokens": [
        51192,
        383,
        2156,
        284,
        11,
        1999,
        81,
        11,
        27503,
        38,
        47,
        51,
        11,
        12947,
        2303,
        11,
        558,
        30,
        51361
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 78.94000244140625,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 77.13999938964844,
      "temperature": 0.0,
      "text": " Every one of these tools at the end",
      "tokens": [
        51361,
        2048,
        472,
        295,
        613,
        3873,
        412,
        264,
        917,
        51451
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 82.36000061035156,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 78.94000244140625,
      "temperature": 0.0,
      "text": " is running the new fundamental unit of knowledge work.",
      "tokens": [
        51451,
        307,
        2614,
        264,
        777,
        8088,
        4985,
        295,
        3601,
        589,
        13,
        51622
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.2086242288351059,
      "compression_ratio": 1.6775362491607666,
      "end": 84.08000183105469,
      "no_speech_prob": 0.004198766779154539,
      "seek": 5720,
      "start": 82.36000061035156,
      "temperature": 0.0,
      "text": " It's all about the prompt",
      "tokens": [
        51622,
        467,
        311,
        439,
        466,
        264,
        12391,
        51708
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 87.19999694824219,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 84.08000183105469,
      "temperature": 0.0,
      "text": " and agents is how we scale the prompt up.",
      "tokens": [
        50364,
        293,
        12554,
        307,
        577,
        321,
        4373,
        264,
        12391,
        493,
        13,
        50520
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 89.5999984741211,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 87.19999694824219,
      "temperature": 0.0,
      "text": " This is how we scale up our impact.",
      "tokens": [
        50520,
        639,
        307,
        577,
        321,
        4373,
        493,
        527,
        2712,
        13,
        50640
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 91.44000244140625,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 89.5999984741211,
      "temperature": 0.0,
      "text": " At the beginning, I said we would talk about,",
      "tokens": [
        50640,
        1711,
        264,
        2863,
        11,
        286,
        848,
        321,
        576,
        751,
        466,
        11,
        50732
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 93.80000305175781,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 91.44000244140625,
      "temperature": 0.0,
      "text": " why is everyone so obsessed with agents?",
      "tokens": [
        50732,
        983,
        307,
        1518,
        370,
        16923,
        365,
        12554,
        30,
        50850
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 96.19999694824219,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 93.80000305175781,
      "temperature": 0.0,
      "text": " This is why, it's because agents",
      "tokens": [
        50850,
        639,
        307,
        983,
        11,
        309,
        311,
        570,
        12554,
        50970
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 99.04000091552734,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 96.19999694824219,
      "temperature": 0.0,
      "text": " lets us scale up our compute usage.",
      "tokens": [
        50970,
        6653,
        505,
        4373,
        493,
        527,
        14722,
        14924,
        13,
        51112
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 100.68000030517578,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 99.04000091552734,
      "temperature": 0.0,
      "text": " And in the age of generative AI,",
      "tokens": [
        51112,
        400,
        294,
        264,
        3205,
        295,
        1337,
        1166,
        7318,
        11,
        51194
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 104.4000015258789,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 100.68000030517578,
      "temperature": 0.0,
      "text": " when you scale your compute, you scale your impact.",
      "tokens": [
        51194,
        562,
        291,
        4373,
        428,
        14722,
        11,
        291,
        4373,
        428,
        2712,
        13,
        51380
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 107.44000244140625,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 104.4000015258789,
      "temperature": 0.0,
      "text": " This is a big theme on the Andi Dev Dan channel.",
      "tokens": [
        51380,
        639,
        307,
        257,
        955,
        6314,
        322,
        264,
        400,
        72,
        9096,
        3394,
        2269,
        13,
        51532
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 109.5,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 107.44000244140625,
      "temperature": 0.0,
      "text": " Right now in Q1, 2025,",
      "tokens": [
        51532,
        1779,
        586,
        294,
        1249,
        16,
        11,
        39209,
        11,
        51635
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 110.95999908447266,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 109.5,
      "temperature": 0.0,
      "text": " the most important thing we can do",
      "tokens": [
        51635,
        264,
        881,
        1021,
        551,
        321,
        393,
        360,
        51708
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.20335310697555542,
      "compression_ratio": 1.7481203079223633,
      "end": 113.80000305175781,
      "no_speech_prob": 0.005554885137826204,
      "seek": 8408,
      "start": 110.95999908447266,
      "temperature": 0.0,
      "text": " is figure out how to scale our compute.",
      "tokens": [
        51708,
        307,
        2573,
        484,
        577,
        281,
        4373,
        527,
        14722,
        13,
        51850
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 115.63999938964844,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 114.4800033569336,
      "temperature": 0.0,
      "text": " Agents are the name of the game.",
      "tokens": [
        50398,
        2725,
        791,
        366,
        264,
        1315,
        295,
        264,
        1216,
        13,
        50456
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 117.16000366210938,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 115.63999938964844,
      "temperature": 0.0,
      "text": " You just saw what we did here",
      "tokens": [
        50456,
        509,
        445,
        1866,
        437,
        321,
        630,
        510,
        50532
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 120.68000030517578,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 117.16000366210938,
      "temperature": 0.0,
      "text": " with a DuckDB domain-specific focus agent",
      "tokens": [
        50532,
        365,
        257,
        29266,
        27735,
        9274,
        12,
        29258,
        1879,
        9461,
        50708
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 123.5199966430664,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 120.68000030517578,
      "temperature": 0.0,
      "text": " with only five tools, right?",
      "tokens": [
        50708,
        365,
        787,
        1732,
        3873,
        11,
        558,
        30,
        50850
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 126.4800033569336,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 123.5199966430664,
      "temperature": 0.0,
      "text": " It gathers context, it understands the structure,",
      "tokens": [
        50850,
        467,
        290,
        11850,
        4319,
        11,
        309,
        15146,
        264,
        3877,
        11,
        50998
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 129.8800048828125,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 126.4800033569336,
      "temperature": 0.0,
      "text": " it then internally validates for hard problems,",
      "tokens": [
        50998,
        309,
        550,
        19501,
        7363,
        1024,
        337,
        1152,
        2740,
        11,
        51168
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.3016662001609802,
      "compression_ratio": 1.4340659379959106,
      "end": 131.39999389648438,
      "no_speech_prob": 0.1081758439540863,
      "seek": 11380,
      "start": 129.8800048828125,
      "temperature": 0.0,
      "text": " and then it gives us the fun.",
      "tokens": [
        51168,
        293,
        550,
        309,
        2709,
        505,
        264,
        1019,
        13,
        51244
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835012.025187
}
{
  "audio_path": "data/chunks/age_of_agents_how_to_evolve_your_o3_mini_prompts_20250324_151153_chunk_004.mp3",
  "text": "So let's open up the logging and just look at this individual prompt. So we can open this up. I've been experimenting a lot lately with markdown based logging, just for a more easier to read logging experience. And let's go top to bottom here. So here's the original text and here's the target text. So every one of our benchmarking problems coming out of our benchmarking file, it looks like this, right? Here's the structure of it, right? So we have the problem ID, we have that slice. And remember the slice is a piece of the transcript. And then we have the correct text and the beginning text inside of the slice. Here's what a slice looks like. Most importantly, we have the words and we have the text. So let's look at what we're starting with and what we're ending up with. So a bunch of gibberish in the beginning. These are all real transcripts from videos, from previous videos, by the way. So yeah, this is me just, you know, stuttering and saying, ah, over and over. Turns out talking about technology can be sometimes harder than the technology itself. We then say the scratchpad active memory is going to be really important. So basically what we wanna do here is get rid of this intro, right? So that's the target text, right? It's everything remaining. This is what we want our model to edit down to, okay? So you can see we wrote the prompt. We'll look at what exactly this prompt looks like in just a moment. Our LLM created these deletions for us. Start time, end time, the duration, explanation. You can see the exact words that it removed. So it's gonna remove a, and then act the. Here's the original. Here's what we wanted to target. And then here's what the prediction was, right? Here's what our model output for us. You can see it didn't quite get the edit right. This is an example of where a prompt is not enough. And I'll link, just for fun, I'll link the original one prompt is not enough video that really kicked off the channel. Back then we were talking about the same concepts with much more primitive technology. It's incredible to think about how far we've come since that video. But you know, one prompt is not enough when you're trying to do more and more at scale and you're trying to accomplish and hand off a ton of work to your AI tooling. And here's the target text, right? So we can see here a simple prompt did not do the job. Let's look at what this prompt actually looks like. So if we open up this prompt, you can see here we have our classic clean XML-ish format. We have our.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 2.119999885559082,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " So let's open up the logging",
      "tokens": [
        50364,
        407,
        718,
        311,
        1269,
        493,
        264,
        27991,
        50470
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 3.9600000381469727,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 2.119999885559082,
      "temperature": 0.0,
      "text": " and just look at this individual prompt.",
      "tokens": [
        50470,
        293,
        445,
        574,
        412,
        341,
        2609,
        12391,
        13,
        50562
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 5.559999942779541,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 3.9600000381469727,
      "temperature": 0.0,
      "text": " So we can open this up.",
      "tokens": [
        50562,
        407,
        321,
        393,
        1269,
        341,
        493,
        13,
        50642
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 7.039999961853027,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 5.559999942779541,
      "temperature": 0.0,
      "text": " I've been experimenting a lot lately",
      "tokens": [
        50642,
        286,
        600,
        668,
        29070,
        257,
        688,
        12881,
        50716
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 9.319999694824219,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 7.039999961853027,
      "temperature": 0.0,
      "text": " with markdown based logging,",
      "tokens": [
        50716,
        365,
        1491,
        5093,
        2361,
        27991,
        11,
        50830
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 12.319999694824219,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 9.319999694824219,
      "temperature": 0.0,
      "text": " just for a more easier to read logging experience.",
      "tokens": [
        50830,
        445,
        337,
        257,
        544,
        3571,
        281,
        1401,
        27991,
        1752,
        13,
        50980
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 13.460000038146973,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 12.319999694824219,
      "temperature": 0.0,
      "text": " And let's go top to bottom here.",
      "tokens": [
        50980,
        400,
        718,
        311,
        352,
        1192,
        281,
        2767,
        510,
        13,
        51037
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 16.920000076293945,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 13.460000038146973,
      "temperature": 0.0,
      "text": " So here's the original text and here's the target text.",
      "tokens": [
        51037,
        407,
        510,
        311,
        264,
        3380,
        2487,
        293,
        510,
        311,
        264,
        3779,
        2487,
        13,
        51210
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 19.920000076293945,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 16.920000076293945,
      "temperature": 0.0,
      "text": " So every one of our benchmarking problems",
      "tokens": [
        51210,
        407,
        633,
        472,
        295,
        527,
        18927,
        278,
        2740,
        51360
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 21.559999465942383,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 19.920000076293945,
      "temperature": 0.0,
      "text": " coming out of our benchmarking file,",
      "tokens": [
        51360,
        1348,
        484,
        295,
        527,
        18927,
        278,
        3991,
        11,
        51442
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 22.540000915527344,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 21.559999465942383,
      "temperature": 0.0,
      "text": " it looks like this, right?",
      "tokens": [
        51442,
        309,
        1542,
        411,
        341,
        11,
        558,
        30,
        51491
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 23.639999389648438,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 22.540000915527344,
      "temperature": 0.0,
      "text": " Here's the structure of it, right?",
      "tokens": [
        51491,
        1692,
        311,
        264,
        3877,
        295,
        309,
        11,
        558,
        30,
        51546
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 26.280000686645508,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 23.639999389648438,
      "temperature": 0.0,
      "text": " So we have the problem ID, we have that slice.",
      "tokens": [
        51546,
        407,
        321,
        362,
        264,
        1154,
        7348,
        11,
        321,
        362,
        300,
        13153,
        13,
        51678
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.19347503781318665,
      "compression_ratio": 1.8181818723678589,
      "end": 29.0,
      "no_speech_prob": 0.00023230607621371746,
      "seek": 0,
      "start": 26.280000686645508,
      "temperature": 0.0,
      "text": " And remember the slice is a piece of the transcript.",
      "tokens": [
        51678,
        400,
        1604,
        264,
        13153,
        307,
        257,
        2522,
        295,
        264,
        24444,
        13,
        51814
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 30.520000457763672,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 29.0,
      "temperature": 0.0,
      "text": " And then we have the correct text",
      "tokens": [
        50364,
        400,
        550,
        321,
        362,
        264,
        3006,
        2487,
        50440
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 33.91999816894531,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 30.520000457763672,
      "temperature": 0.0,
      "text": " and the beginning text inside of the slice.",
      "tokens": [
        50440,
        293,
        264,
        2863,
        2487,
        1854,
        295,
        264,
        13153,
        13,
        50610
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 35.119998931884766,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 33.91999816894531,
      "temperature": 0.0,
      "text": " Here's what a slice looks like.",
      "tokens": [
        50610,
        1692,
        311,
        437,
        257,
        13153,
        1542,
        411,
        13,
        50670
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 38.0,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 35.119998931884766,
      "temperature": 0.0,
      "text": " Most importantly, we have the words and we have the text.",
      "tokens": [
        50670,
        4534,
        8906,
        11,
        321,
        362,
        264,
        2283,
        293,
        321,
        362,
        264,
        2487,
        13,
        50814
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 39.2400016784668,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 38.0,
      "temperature": 0.0,
      "text": " So let's look at what we're starting with",
      "tokens": [
        50814,
        407,
        718,
        311,
        574,
        412,
        437,
        321,
        434,
        2891,
        365,
        50876
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 40.279998779296875,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 39.2400016784668,
      "temperature": 0.0,
      "text": " and what we're ending up with.",
      "tokens": [
        50876,
        293,
        437,
        321,
        434,
        8121,
        493,
        365,
        13,
        50928
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 42.68000030517578,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 40.279998779296875,
      "temperature": 0.0,
      "text": " So a bunch of gibberish in the beginning.",
      "tokens": [
        50928,
        407,
        257,
        3840,
        295,
        4553,
        43189,
        294,
        264,
        2863,
        13,
        51048
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 45.400001525878906,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 42.68000030517578,
      "temperature": 0.0,
      "text": " These are all real transcripts from videos,",
      "tokens": [
        51048,
        1981,
        366,
        439,
        957,
        24444,
        82,
        490,
        2145,
        11,
        51184
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 46.459999084472656,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 45.400001525878906,
      "temperature": 0.0,
      "text": " from previous videos, by the way.",
      "tokens": [
        51184,
        490,
        3894,
        2145,
        11,
        538,
        264,
        636,
        13,
        51237
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 47.7599983215332,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 46.459999084472656,
      "temperature": 0.0,
      "text": " So yeah, this is me just, you know,",
      "tokens": [
        51237,
        407,
        1338,
        11,
        341,
        307,
        385,
        445,
        11,
        291,
        458,
        11,
        51302
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 50.15999984741211,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 47.7599983215332,
      "temperature": 0.0,
      "text": " stuttering and saying, ah, over and over.",
      "tokens": [
        51302,
        342,
        32224,
        293,
        1566,
        11,
        3716,
        11,
        670,
        293,
        670,
        13,
        51422
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 51.720001220703125,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 50.15999984741211,
      "temperature": 0.0,
      "text": " Turns out talking about technology",
      "tokens": [
        51422,
        29524,
        484,
        1417,
        466,
        2899,
        51500
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 54.439998626708984,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 51.720001220703125,
      "temperature": 0.0,
      "text": " can be sometimes harder than the technology itself.",
      "tokens": [
        51500,
        393,
        312,
        2171,
        6081,
        813,
        264,
        2899,
        2564,
        13,
        51636
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 56.31999969482422,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 54.439998626708984,
      "temperature": 0.0,
      "text": " We then say the scratchpad active memory",
      "tokens": [
        51636,
        492,
        550,
        584,
        264,
        8459,
        13647,
        4967,
        4675,
        51730
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 57.540000915527344,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 56.31999969482422,
      "temperature": 0.0,
      "text": " is going to be really important.",
      "tokens": [
        51730,
        307,
        516,
        281,
        312,
        534,
        1021,
        13,
        51791
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.21228447556495667,
      "compression_ratio": 1.8062678575515747,
      "end": 58.599998474121094,
      "no_speech_prob": 0.00013135053450241685,
      "seek": 2900,
      "start": 57.540000915527344,
      "temperature": 0.0,
      "text": " So basically what we wanna do here",
      "tokens": [
        51791,
        407,
        1936,
        437,
        321,
        1948,
        360,
        510,
        51844
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 60.0,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 59.15999984741211,
      "temperature": 0.0,
      "text": " is get rid of this intro, right?",
      "tokens": [
        50392,
        307,
        483,
        3973,
        295,
        341,
        12897,
        11,
        558,
        30,
        50434
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 61.63999938964844,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 60.0,
      "temperature": 0.0,
      "text": " So that's the target text, right?",
      "tokens": [
        50434,
        407,
        300,
        311,
        264,
        3779,
        2487,
        11,
        558,
        30,
        50516
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 62.599998474121094,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 61.63999938964844,
      "temperature": 0.0,
      "text": " It's everything remaining.",
      "tokens": [
        50516,
        467,
        311,
        1203,
        8877,
        13,
        50564
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 66.30000305175781,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 62.599998474121094,
      "temperature": 0.0,
      "text": " This is what we want our model to edit down to, okay?",
      "tokens": [
        50564,
        639,
        307,
        437,
        321,
        528,
        527,
        2316,
        281,
        8129,
        760,
        281,
        11,
        1392,
        30,
        50749
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 67.86000061035156,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 66.30000305175781,
      "temperature": 0.0,
      "text": " So you can see we wrote the prompt.",
      "tokens": [
        50749,
        407,
        291,
        393,
        536,
        321,
        4114,
        264,
        12391,
        13,
        50827
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 69.81999969482422,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 67.86000061035156,
      "temperature": 0.0,
      "text": " We'll look at what exactly this prompt looks like",
      "tokens": [
        50827,
        492,
        603,
        574,
        412,
        437,
        2293,
        341,
        12391,
        1542,
        411,
        50925
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 70.66000366210938,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 69.81999969482422,
      "temperature": 0.0,
      "text": " in just a moment.",
      "tokens": [
        50925,
        294,
        445,
        257,
        1623,
        13,
        50967
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 73.68000030517578,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 70.66000366210938,
      "temperature": 0.0,
      "text": " Our LLM created these deletions for us.",
      "tokens": [
        50967,
        2621,
        441,
        43,
        44,
        2942,
        613,
        1103,
        302,
        626,
        337,
        505,
        13,
        51118
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 76.62000274658203,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 73.68000030517578,
      "temperature": 0.0,
      "text": " Start time, end time, the duration, explanation.",
      "tokens": [
        51118,
        6481,
        565,
        11,
        917,
        565,
        11,
        264,
        16365,
        11,
        10835,
        13,
        51265
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 78.81999969482422,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 76.62000274658203,
      "temperature": 0.0,
      "text": " You can see the exact words that it removed.",
      "tokens": [
        51265,
        509,
        393,
        536,
        264,
        1900,
        2283,
        300,
        309,
        7261,
        13,
        51375
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 82.63999938964844,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 78.81999969482422,
      "temperature": 0.0,
      "text": " So it's gonna remove a, and then act the.",
      "tokens": [
        51375,
        407,
        309,
        311,
        799,
        4159,
        257,
        11,
        293,
        550,
        605,
        264,
        13,
        51566
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 84.08000183105469,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 82.63999938964844,
      "temperature": 0.0,
      "text": " Here's the original.",
      "tokens": [
        51566,
        1692,
        311,
        264,
        3380,
        13,
        51638
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 86.04000091552734,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 84.08000183105469,
      "temperature": 0.0,
      "text": " Here's what we wanted to target.",
      "tokens": [
        51638,
        1692,
        311,
        437,
        321,
        1415,
        281,
        3779,
        13,
        51736
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.2041015625,
      "compression_ratio": 1.7692307233810425,
      "end": 88.41999816894531,
      "no_speech_prob": 0.003765298519283533,
      "seek": 5860,
      "start": 86.04000091552734,
      "temperature": 0.0,
      "text": " And then here's what the prediction was, right?",
      "tokens": [
        51736,
        400,
        550,
        510,
        311,
        437,
        264,
        17630,
        390,
        11,
        558,
        30,
        51855
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 90.13999938964844,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 89.23999786376953,
      "temperature": 0.0,
      "text": " Here's what our model output for us.",
      "tokens": [
        50405,
        1692,
        311,
        437,
        527,
        2316,
        5598,
        337,
        505,
        13,
        50450
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 93.0999984741211,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 90.13999938964844,
      "temperature": 0.0,
      "text": " You can see it didn't quite get the edit right.",
      "tokens": [
        50450,
        509,
        393,
        536,
        309,
        994,
        380,
        1596,
        483,
        264,
        8129,
        558,
        13,
        50598
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 96.45999908447266,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 93.0999984741211,
      "temperature": 0.0,
      "text": " This is an example of where a prompt is not enough.",
      "tokens": [
        50598,
        639,
        307,
        364,
        1365,
        295,
        689,
        257,
        12391,
        307,
        406,
        1547,
        13,
        50766
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 99.26000213623047,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 96.45999908447266,
      "temperature": 0.0,
      "text": " And I'll link, just for fun, I'll link the original",
      "tokens": [
        50766,
        400,
        286,
        603,
        2113,
        11,
        445,
        337,
        1019,
        11,
        286,
        603,
        2113,
        264,
        3380,
        50906
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 100.95999908447266,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 99.26000213623047,
      "temperature": 0.0,
      "text": " one prompt is not enough video",
      "tokens": [
        50906,
        472,
        12391,
        307,
        406,
        1547,
        960,
        50991
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 102.80000305175781,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 100.95999908447266,
      "temperature": 0.0,
      "text": " that really kicked off the channel.",
      "tokens": [
        50991,
        300,
        534,
        14609,
        766,
        264,
        2269,
        13,
        51083
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 104.77999877929688,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 102.80000305175781,
      "temperature": 0.0,
      "text": " Back then we were talking about the same concepts",
      "tokens": [
        51083,
        5833,
        550,
        321,
        645,
        1417,
        466,
        264,
        912,
        10392,
        51182
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 106.69999694824219,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 104.77999877929688,
      "temperature": 0.0,
      "text": " with much more primitive technology.",
      "tokens": [
        51182,
        365,
        709,
        544,
        28540,
        2899,
        13,
        51278
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 108.58000183105469,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 106.69999694824219,
      "temperature": 0.0,
      "text": " It's incredible to think about how far we've come",
      "tokens": [
        51278,
        467,
        311,
        4651,
        281,
        519,
        466,
        577,
        1400,
        321,
        600,
        808,
        51372
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 109.41999816894531,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 108.58000183105469,
      "temperature": 0.0,
      "text": " since that video.",
      "tokens": [
        51372,
        1670,
        300,
        960,
        13,
        51414
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 111.62000274658203,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 109.41999816894531,
      "temperature": 0.0,
      "text": " But you know, one prompt is not enough",
      "tokens": [
        51414,
        583,
        291,
        458,
        11,
        472,
        12391,
        307,
        406,
        1547,
        51524
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 113.86000061035156,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 111.62000274658203,
      "temperature": 0.0,
      "text": " when you're trying to do more and more at scale",
      "tokens": [
        51524,
        562,
        291,
        434,
        1382,
        281,
        360,
        544,
        293,
        544,
        412,
        4373,
        51636
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.22041967511177063,
      "compression_ratio": 1.7633333206176758,
      "end": 115.05999755859375,
      "no_speech_prob": 0.0015730948653072119,
      "seek": 8842,
      "start": 113.86000061035156,
      "temperature": 0.0,
      "text": " and you're trying to accomplish",
      "tokens": [
        51636,
        293,
        291,
        434,
        1382,
        281,
        9021,
        51696
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 118.5,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 115.05999755859375,
      "temperature": 0.0,
      "text": " and hand off a ton of work to your AI tooling.",
      "tokens": [
        50364,
        293,
        1011,
        766,
        257,
        2952,
        295,
        589,
        281,
        428,
        7318,
        46593,
        13,
        50536
      ]
    },
    {
      "id": 58,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 119.86000061035156,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 118.5,
      "temperature": 0.0,
      "text": " And here's the target text, right?",
      "tokens": [
        50536,
        400,
        510,
        311,
        264,
        3779,
        2487,
        11,
        558,
        30,
        50604
      ]
    },
    {
      "id": 59,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 123.18000030517578,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 119.86000061035156,
      "temperature": 0.0,
      "text": " So we can see here a simple prompt did not do the job.",
      "tokens": [
        50604,
        407,
        321,
        393,
        536,
        510,
        257,
        2199,
        12391,
        630,
        406,
        360,
        264,
        1691,
        13,
        50770
      ]
    },
    {
      "id": 60,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 125.58000183105469,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 123.18000030517578,
      "temperature": 0.0,
      "text": " Let's look at what this prompt actually looks like.",
      "tokens": [
        50770,
        961,
        311,
        574,
        412,
        437,
        341,
        12391,
        767,
        1542,
        411,
        13,
        50890
      ]
    },
    {
      "id": 61,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 127.66000366210938,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 125.58000183105469,
      "temperature": 0.0,
      "text": " So if we open up this prompt, you can see here",
      "tokens": [
        50890,
        407,
        498,
        321,
        1269,
        493,
        341,
        12391,
        11,
        291,
        393,
        536,
        510,
        50994
      ]
    },
    {
      "id": 62,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 130.86000061035156,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 127.66000366210938,
      "temperature": 0.0,
      "text": " we have our classic clean XML-ish format.",
      "tokens": [
        50994,
        321,
        362,
        527,
        7230,
        2541,
        43484,
        12,
        742,
        7877,
        13,
        51154
      ]
    },
    {
      "id": 63,
      "avg_logprob": -0.20948834717273712,
      "compression_ratio": 1.518324613571167,
      "end": 131.6999969482422,
      "no_speech_prob": 0.047417253255844116,
      "seek": 11506,
      "start": 130.86000061035156,
      "temperature": 0.0,
      "text": " We have our.",
      "tokens": [
        51154,
        492,
        362,
        527,
        13,
        51196
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835343.740682
}
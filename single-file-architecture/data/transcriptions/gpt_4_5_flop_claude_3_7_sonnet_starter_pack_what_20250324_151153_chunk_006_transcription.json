{
  "audio_path": "data/chunks/gpt_4_5_flop_claude_3_7_sonnet_starter_pack_what_20250324_151153_chunk_006.mp3",
  "text": "and just type Claude. You can see here I have two MCP servers connected. We'll talk about these in a moment, but let's just, at a high level, really discuss what this is, okay? What is Claude code really? Anthropic explicitly mentions this a couple times. If we just search agent, you can see this keyword coming up a couple times, okay? This is a very, very important keyword and paradigm shift that's happening right now. We're moving up the abstraction chain of generative AI. As we've talked about in many previous videos over the course of the past two years, you start with a prompt, then you move to the prompt chain. Prompt chains are also known as these agentic workflows or graphs, but then the next step is give the agent the tool it needs, give it a powerful model, tell it how to solve your problem, and then let it run off and actually solve the problem for you. To be super, super clear, what is Claude code? Claude code is an AI agent. This is pure genius from Anthropic, a research preview developer tool where we pay for their model, send them our prompts so that they can improve the tool and their model. I have upped my token usage, maybe I'll throw a photo on the screen, 100-fold using the new Claude 3.7 model in agents and in the new Claude code. What can we do with this tool? I just want to run a couple commands that showcase what this thing can really do. You know, we had some examples here, right? Some puzzle examples. Claude code, obviously it can write code. You're going to see a hundred videos on Claude code writing code. We'll dive into that a little bit more later. I want to stress how important it is that this is an agent, so we can do agentic things, right? It has several tools available. List files, respect, git ignore. Now Claude is thinking and it's going to use one of several tools available to it. It's not using traditional LS. It's using git LS files. Okay, so I'm going to hit yes. This model called the bash tool. Let's run something else, update and I'm going to use a hotkey. I strongly strongly recommend that you set up this hotkey. For me, it's command.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 1.600000023841858,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " and just type Claude.",
      "tokens": [
        50364,
        293,
        445,
        2010,
        12947,
        2303,
        13,
        50444
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 4.099999904632568,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 1.600000023841858,
      "temperature": 0.0,
      "text": " You can see here I have two MCP servers connected.",
      "tokens": [
        50444,
        509,
        393,
        536,
        510,
        286,
        362,
        732,
        8797,
        47,
        15909,
        4582,
        13,
        50569
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 5.599999904632568,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 4.099999904632568,
      "temperature": 0.0,
      "text": " We'll talk about these in a moment,",
      "tokens": [
        50569,
        492,
        603,
        751,
        466,
        613,
        294,
        257,
        1623,
        11,
        50644
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 7.800000190734863,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 5.599999904632568,
      "temperature": 0.0,
      "text": " but let's just, at a high level,",
      "tokens": [
        50644,
        457,
        718,
        311,
        445,
        11,
        412,
        257,
        1090,
        1496,
        11,
        50754
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 10.600000381469727,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 7.800000190734863,
      "temperature": 0.0,
      "text": " really discuss what this is, okay?",
      "tokens": [
        50754,
        534,
        2248,
        437,
        341,
        307,
        11,
        1392,
        30,
        50894
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 13.199999809265137,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 10.600000381469727,
      "temperature": 0.0,
      "text": " What is Claude code really?",
      "tokens": [
        50894,
        708,
        307,
        12947,
        2303,
        3089,
        534,
        30,
        51024
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 17.0,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 13.199999809265137,
      "temperature": 0.0,
      "text": " Anthropic explicitly mentions this a couple times.",
      "tokens": [
        51024,
        12727,
        39173,
        20803,
        23844,
        341,
        257,
        1916,
        1413,
        13,
        51214
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 18.299999237060547,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 17.0,
      "temperature": 0.0,
      "text": " If we just search agent,",
      "tokens": [
        51214,
        759,
        321,
        445,
        3164,
        9461,
        11,
        51279
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 22.799999237060547,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 18.299999237060547,
      "temperature": 0.0,
      "text": " you can see this keyword coming up a couple times, okay?",
      "tokens": [
        51279,
        291,
        393,
        536,
        341,
        20428,
        1348,
        493,
        257,
        1916,
        1413,
        11,
        1392,
        30,
        51504
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 24.799999237060547,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 22.799999237060547,
      "temperature": 0.0,
      "text": " This is a very, very important keyword",
      "tokens": [
        51504,
        639,
        307,
        257,
        588,
        11,
        588,
        1021,
        20428,
        51604
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.27523112297058105,
      "compression_ratio": 1.5902255773544312,
      "end": 27.5,
      "no_speech_prob": 0.02800428308546543,
      "seek": 0,
      "start": 24.799999237060547,
      "temperature": 0.0,
      "text": " and paradigm shift that's happening right now.",
      "tokens": [
        51604,
        293,
        24709,
        5513,
        300,
        311,
        2737,
        558,
        586,
        13,
        51739
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 31.899999618530273,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 27.700000762939453,
      "temperature": 0.0,
      "text": " We're moving up the abstraction chain of generative AI.",
      "tokens": [
        50374,
        492,
        434,
        2684,
        493,
        264,
        37765,
        5021,
        295,
        1337,
        1166,
        7318,
        13,
        50584
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 34.400001525878906,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 31.899999618530273,
      "temperature": 0.0,
      "text": " As we've talked about in many previous videos",
      "tokens": [
        50584,
        1018,
        321,
        600,
        2825,
        466,
        294,
        867,
        3894,
        2145,
        50709
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 36.29999923706055,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 34.400001525878906,
      "temperature": 0.0,
      "text": " over the course of the past two years,",
      "tokens": [
        50709,
        670,
        264,
        1164,
        295,
        264,
        1791,
        732,
        924,
        11,
        50804
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 37.400001525878906,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 36.29999923706055,
      "temperature": 0.0,
      "text": " you start with a prompt,",
      "tokens": [
        50804,
        291,
        722,
        365,
        257,
        12391,
        11,
        50859
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 38.70000076293945,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 37.400001525878906,
      "temperature": 0.0,
      "text": " then you move to the prompt chain.",
      "tokens": [
        50859,
        550,
        291,
        1286,
        281,
        264,
        12391,
        5021,
        13,
        50924
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 41.5,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 38.70000076293945,
      "temperature": 0.0,
      "text": " Prompt chains are also known as these agentic workflows",
      "tokens": [
        50924,
        15833,
        662,
        12626,
        366,
        611,
        2570,
        382,
        613,
        9461,
        299,
        43461,
        51064
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 45.099998474121094,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 41.5,
      "temperature": 0.0,
      "text": " or graphs, but then the next step is",
      "tokens": [
        51064,
        420,
        24877,
        11,
        457,
        550,
        264,
        958,
        1823,
        307,
        51244
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 47.0,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 45.099998474121094,
      "temperature": 0.0,
      "text": " give the agent the tool it needs,",
      "tokens": [
        51244,
        976,
        264,
        9461,
        264,
        2290,
        309,
        2203,
        11,
        51339
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 48.29999923706055,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 47.0,
      "temperature": 0.0,
      "text": " give it a powerful model,",
      "tokens": [
        51339,
        976,
        309,
        257,
        4005,
        2316,
        11,
        51404
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 49.70000076293945,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 48.29999923706055,
      "temperature": 0.0,
      "text": " tell it how to solve your problem,",
      "tokens": [
        51404,
        980,
        309,
        577,
        281,
        5039,
        428,
        1154,
        11,
        51474
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 51.20000076293945,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 49.70000076293945,
      "temperature": 0.0,
      "text": " and then let it run off",
      "tokens": [
        51474,
        293,
        550,
        718,
        309,
        1190,
        766,
        51549
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 53.5,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 51.20000076293945,
      "temperature": 0.0,
      "text": " and actually solve the problem for you.",
      "tokens": [
        51549,
        293,
        767,
        5039,
        264,
        1154,
        337,
        291,
        13,
        51664
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.18858444690704346,
      "compression_ratio": 1.6688963174819946,
      "end": 55.79999923706055,
      "no_speech_prob": 0.002287152921780944,
      "seek": 2750,
      "start": 53.5,
      "temperature": 0.0,
      "text": " To be super, super clear, what is Claude code?",
      "tokens": [
        51664,
        1407,
        312,
        1687,
        11,
        1687,
        1850,
        11,
        437,
        307,
        12947,
        2303,
        3089,
        30,
        51779
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 58.599998474121094,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 55.79999923706055,
      "temperature": 0.0,
      "text": " Claude code is an AI agent.",
      "tokens": [
        50364,
        12947,
        2303,
        3089,
        307,
        364,
        7318,
        9461,
        13,
        50504
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 60.70000076293945,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 58.599998474121094,
      "temperature": 0.0,
      "text": " This is pure genius from Anthropic,",
      "tokens": [
        50504,
        639,
        307,
        6075,
        14017,
        490,
        12727,
        39173,
        11,
        50609
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 62.5,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 60.70000076293945,
      "temperature": 0.0,
      "text": " a research preview developer tool",
      "tokens": [
        50609,
        257,
        2132,
        14281,
        10754,
        2290,
        50699
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 65.5999984741211,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 62.5,
      "temperature": 0.0,
      "text": " where we pay for their model,",
      "tokens": [
        50699,
        689,
        321,
        1689,
        337,
        641,
        2316,
        11,
        50854
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 67.0999984741211,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 65.5999984741211,
      "temperature": 0.0,
      "text": " send them our prompts",
      "tokens": [
        50854,
        2845,
        552,
        527,
        41095,
        50929
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 70.9000015258789,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 67.0999984741211,
      "temperature": 0.0,
      "text": " so that they can improve the tool and their model.",
      "tokens": [
        50929,
        370,
        300,
        436,
        393,
        3470,
        264,
        2290,
        293,
        641,
        2316,
        13,
        51119
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 73.5999984741211,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 70.9000015258789,
      "temperature": 0.0,
      "text": " I have upped my token usage,",
      "tokens": [
        51119,
        286,
        362,
        344,
        3320,
        452,
        14862,
        14924,
        11,
        51254
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 75.30000305175781,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 73.5999984741211,
      "temperature": 0.0,
      "text": " maybe I'll throw a photo on the screen,",
      "tokens": [
        51254,
        1310,
        286,
        603,
        3507,
        257,
        5052,
        322,
        264,
        2568,
        11,
        51339
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 80.80000305175781,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 75.30000305175781,
      "temperature": 0.0,
      "text": " 100-fold using the new Claude 3.7 model in agents",
      "tokens": [
        51339,
        2319,
        12,
        18353,
        1228,
        264,
        777,
        12947,
        2303,
        805,
        13,
        22,
        2316,
        294,
        12554,
        51614
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 82.30000305175781,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 80.80000305175781,
      "temperature": 0.0,
      "text": " and in the new Claude code.",
      "tokens": [
        51614,
        293,
        294,
        264,
        777,
        12947,
        2303,
        3089,
        13,
        51689
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 83.5999984741211,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 82.30000305175781,
      "temperature": 0.0,
      "text": " What can we do with this tool?",
      "tokens": [
        51689,
        708,
        393,
        321,
        360,
        365,
        341,
        2290,
        30,
        51754
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.16975000500679016,
      "compression_ratio": 1.5839694738388062,
      "end": 85.30000305175781,
      "no_speech_prob": 0.00017400251817889512,
      "seek": 5580,
      "start": 83.5999984741211,
      "temperature": 0.0,
      "text": " I just want to run a couple commands",
      "tokens": [
        51754,
        286,
        445,
        528,
        281,
        1190,
        257,
        1916,
        16901,
        51839
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 87.9000015258789,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 85.30000305175781,
      "temperature": 0.0,
      "text": " that showcase what this thing can really do.",
      "tokens": [
        50364,
        300,
        20388,
        437,
        341,
        551,
        393,
        534,
        360,
        13,
        50494
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 89.80000305175781,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 87.9000015258789,
      "temperature": 0.0,
      "text": " You know, we had some examples here, right?",
      "tokens": [
        50494,
        509,
        458,
        11,
        321,
        632,
        512,
        5110,
        510,
        11,
        558,
        30,
        50589
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 91.0,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 89.80000305175781,
      "temperature": 0.0,
      "text": " Some puzzle examples.",
      "tokens": [
        50589,
        2188,
        12805,
        5110,
        13,
        50649
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 93.4000015258789,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 91.0,
      "temperature": 0.0,
      "text": " Claude code, obviously it can write code.",
      "tokens": [
        50649,
        12947,
        2303,
        3089,
        11,
        2745,
        309,
        393,
        2464,
        3089,
        13,
        50769
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 94.80000305175781,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 93.4000015258789,
      "temperature": 0.0,
      "text": " You're going to see a hundred videos",
      "tokens": [
        50769,
        509,
        434,
        516,
        281,
        536,
        257,
        3262,
        2145,
        50839
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 96.30000305175781,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 94.80000305175781,
      "temperature": 0.0,
      "text": " on Claude code writing code.",
      "tokens": [
        50839,
        322,
        12947,
        2303,
        3089,
        3579,
        3089,
        13,
        50914
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 98.0,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 96.30000305175781,
      "temperature": 0.0,
      "text": " We'll dive into that a little bit more later.",
      "tokens": [
        50914,
        492,
        603,
        9192,
        666,
        300,
        257,
        707,
        857,
        544,
        1780,
        13,
        50999
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 99.19999694824219,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 98.0,
      "temperature": 0.0,
      "text": " I want to stress how important it is",
      "tokens": [
        50999,
        286,
        528,
        281,
        4244,
        577,
        1021,
        309,
        307,
        51059
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 100.69999694824219,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 99.19999694824219,
      "temperature": 0.0,
      "text": " that this is an agent,",
      "tokens": [
        51059,
        300,
        341,
        307,
        364,
        9461,
        11,
        51134
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 103.30000305175781,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 100.69999694824219,
      "temperature": 0.0,
      "text": " so we can do agentic things, right?",
      "tokens": [
        51134,
        370,
        321,
        393,
        360,
        9461,
        299,
        721,
        11,
        558,
        30,
        51264
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 104.80000305175781,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 103.30000305175781,
      "temperature": 0.0,
      "text": " It has several tools available.",
      "tokens": [
        51264,
        467,
        575,
        2940,
        3873,
        2435,
        13,
        51339
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 109.0999984741211,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 104.80000305175781,
      "temperature": 0.0,
      "text": " List files, respect, git ignore.",
      "tokens": [
        51339,
        17668,
        7098,
        11,
        3104,
        11,
        18331,
        11200,
        13,
        51554
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 110.80000305175781,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 109.0999984741211,
      "temperature": 0.0,
      "text": " Now Claude is thinking",
      "tokens": [
        51554,
        823,
        12947,
        2303,
        307,
        1953,
        51639
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.19771738350391388,
      "compression_ratio": 1.7162162065505981,
      "end": 114.4000015258789,
      "no_speech_prob": 0.006097301375120878,
      "seek": 8530,
      "start": 110.80000305175781,
      "temperature": 0.0,
      "text": " and it's going to use one of several tools available to it.",
      "tokens": [
        51639,
        293,
        309,
        311,
        516,
        281,
        764,
        472,
        295,
        2940,
        3873,
        2435,
        281,
        309,
        13,
        51819
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.23128534853458405,
      "compression_ratio": 1.517241358757019,
      "end": 116.30000305175781,
      "no_speech_prob": 0.0028893272392451763,
      "seek": 11440,
      "start": 114.4000015258789,
      "temperature": 0.0,
      "text": " It's not using traditional LS.",
      "tokens": [
        50364,
        467,
        311,
        406,
        1228,
        5164,
        36657,
        13,
        50459
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.23128534853458405,
      "compression_ratio": 1.517241358757019,
      "end": 119.0999984741211,
      "no_speech_prob": 0.0028893272392451763,
      "seek": 11440,
      "start": 116.30000305175781,
      "temperature": 0.0,
      "text": " It's using git LS files.",
      "tokens": [
        50459,
        467,
        311,
        1228,
        18331,
        36657,
        7098,
        13,
        50599
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.23128534853458405,
      "compression_ratio": 1.517241358757019,
      "end": 120.5,
      "no_speech_prob": 0.0028893272392451763,
      "seek": 11440,
      "start": 119.0999984741211,
      "temperature": 0.0,
      "text": " Okay, so I'm going to hit yes.",
      "tokens": [
        50599,
        1033,
        11,
        370,
        286,
        478,
        516,
        281,
        2045,
        2086,
        13,
        50669
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.23128534853458405,
      "compression_ratio": 1.517241358757019,
      "end": 123.5,
      "no_speech_prob": 0.0028893272392451763,
      "seek": 11440,
      "start": 120.5,
      "temperature": 0.0,
      "text": " This model called the bash tool.",
      "tokens": [
        50669,
        639,
        2316,
        1219,
        264,
        46183,
        2290,
        13,
        50819
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.23128534853458405,
      "compression_ratio": 1.517241358757019,
      "end": 125.0999984741211,
      "no_speech_prob": 0.0028893272392451763,
      "seek": 11440,
      "start": 123.5,
      "temperature": 0.0,
      "text": " Let's run something else, update",
      "tokens": [
        50819,
        961,
        311,
        1190,
        746,
        1646,
        11,
        5623,
        50899
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.23128534853458405,
      "compression_ratio": 1.517241358757019,
      "end": 127.0,
      "no_speech_prob": 0.0028893272392451763,
      "seek": 11440,
      "start": 125.0999984741211,
      "temperature": 0.0,
      "text": " and I'm going to use a hotkey.",
      "tokens": [
        50899,
        293,
        286,
        478,
        516,
        281,
        764,
        257,
        2368,
        4119,
        13,
        50994
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.23128534853458405,
      "compression_ratio": 1.517241358757019,
      "end": 130.1999969482422,
      "no_speech_prob": 0.0028893272392451763,
      "seek": 11440,
      "start": 127.0,
      "temperature": 0.0,
      "text": " I strongly strongly recommend that you set up this hotkey.",
      "tokens": [
        50994,
        286,
        10613,
        10613,
        2748,
        300,
        291,
        992,
        493,
        341,
        2368,
        4119,
        13,
        51154
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.23128534853458405,
      "compression_ratio": 1.517241358757019,
      "end": 131.10000610351562,
      "no_speech_prob": 0.0028893272392451763,
      "seek": 11440,
      "start": 130.1999969482422,
      "temperature": 0.0,
      "text": " For me, it's command.",
      "tokens": [
        51154,
        1171,
        385,
        11,
        309,
        311,
        5622,
        13,
        51199
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742835619.4879382
}
{
  "audio_path": "data/chunks/ai_coding_devlog_claude_code_has_changed_software_20250324_151153_chunk_003.mp3",
  "text": "different. I've been waiting to pull the trigger on this. We're going to build this tool as an MCP server first. So there will be no other way to interact with this tool other than MCP. I think this is going to be the direction things will go as MCP grows and develops. So PocketPick is all about quickly being able to save and then reference ideas, patterns, and code snippets for your engineering work. We're setting up the project structure, so quite literally the directory structure of this new tool. Just above you can see the simple PocketPick SQLite table structure. I love when I can boil down data structures to just the essentials. We have ID, created text, and tags. This is all we need to create a great first version of our personal knowledge base of our PocketPicks. You might be asking, why are we building out this plan? Why aren't we just starting to prompt? Because I can guarantee you that if you're writing prompts iteratively, you are not doing as much as you can and you're not scaling your impact as much as you could be. In this video, you'll see exactly what I mean. I'm creating that classic implementation notes section. This is where you just basically write ad hoc information. It's where you work through things. It's kind of a catch-all section. We're doing some API-based design here. A great way to communicate information to your AI coding tools is to create the interface in which you would use to operate with it. What we're doing here is creating a CLI-based API design. This will very clearly communicate to our AI coding assistant what we want the API to look like. You can see here I'm using cursor tab as well to help me quickly create this spec prompt. I think the tech ecosystem has a massive problem in thinking that there are best tools. What's the best tool? What's the best AI coding tool I can use? Is it Cursor? Is it CloudCode? Is it Aitor? Devon? What's the best tool? I just want to use the best tool. I think this is a very limiting mindset because it forces you to always...",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.19214867055416107,
      "compression_ratio": 1.6150627136230469,
      "end": 4.880000114440918,
      "no_speech_prob": 0.14219187200069427,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " different. I've been waiting to pull the trigger on this. We're going to build this tool as an",
      "tokens": [
        50364,
        819,
        13,
        286,
        600,
        668,
        3806,
        281,
        2235,
        264,
        7875,
        322,
        341,
        13,
        492,
        434,
        516,
        281,
        1322,
        341,
        2290,
        382,
        364,
        50608
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.19214867055416107,
      "compression_ratio": 1.6150627136230469,
      "end": 11.520000457763672,
      "no_speech_prob": 0.14219187200069427,
      "seek": 0,
      "start": 4.880000114440918,
      "temperature": 0.0,
      "text": " MCP server first. So there will be no other way to interact with this tool other than MCP. I think",
      "tokens": [
        50608,
        8797,
        47,
        7154,
        700,
        13,
        407,
        456,
        486,
        312,
        572,
        661,
        636,
        281,
        4648,
        365,
        341,
        2290,
        661,
        813,
        8797,
        47,
        13,
        286,
        519,
        50940
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.19214867055416107,
      "compression_ratio": 1.6150627136230469,
      "end": 18.799999237060547,
      "no_speech_prob": 0.14219187200069427,
      "seek": 0,
      "start": 11.520000457763672,
      "temperature": 0.0,
      "text": " this is going to be the direction things will go as MCP grows and develops. So PocketPick is all",
      "tokens": [
        50940,
        341,
        307,
        516,
        281,
        312,
        264,
        3513,
        721,
        486,
        352,
        382,
        8797,
        47,
        13156,
        293,
        25453,
        13,
        407,
        44594,
        47,
        618,
        307,
        439,
        51304
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.19214867055416107,
      "compression_ratio": 1.6150627136230469,
      "end": 25.760000228881836,
      "no_speech_prob": 0.14219187200069427,
      "seek": 0,
      "start": 18.799999237060547,
      "temperature": 0.0,
      "text": " about quickly being able to save and then reference ideas, patterns, and code snippets for your",
      "tokens": [
        51304,
        466,
        2661,
        885,
        1075,
        281,
        3155,
        293,
        550,
        6408,
        3487,
        11,
        8294,
        11,
        293,
        3089,
        35623,
        1385,
        337,
        428,
        51652
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.18347974121570587,
      "compression_ratio": 1.5583332777023315,
      "end": 30.719999313354492,
      "no_speech_prob": 0.01854436844587326,
      "seek": 2576,
      "start": 25.760000228881836,
      "temperature": 0.0,
      "text": " engineering work. We're setting up the project structure, so quite literally the directory",
      "tokens": [
        50364,
        7043,
        589,
        13,
        492,
        434,
        3287,
        493,
        264,
        1716,
        3877,
        11,
        370,
        1596,
        3736,
        264,
        21120,
        50612
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.18347974121570587,
      "compression_ratio": 1.5583332777023315,
      "end": 37.36000061035156,
      "no_speech_prob": 0.01854436844587326,
      "seek": 2576,
      "start": 30.719999313354492,
      "temperature": 0.0,
      "text": " structure of this new tool. Just above you can see the simple PocketPick SQLite table structure.",
      "tokens": [
        50612,
        3877,
        295,
        341,
        777,
        2290,
        13,
        1449,
        3673,
        291,
        393,
        536,
        264,
        2199,
        44594,
        47,
        618,
        19200,
        642,
        3199,
        3877,
        13,
        50944
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.18347974121570587,
      "compression_ratio": 1.5583332777023315,
      "end": 44.400001525878906,
      "no_speech_prob": 0.01854436844587326,
      "seek": 2576,
      "start": 38.15999984741211,
      "temperature": 0.0,
      "text": " I love when I can boil down data structures to just the essentials. We have ID, created text,",
      "tokens": [
        50984,
        286,
        959,
        562,
        286,
        393,
        13329,
        760,
        1412,
        9227,
        281,
        445,
        264,
        46884,
        13,
        492,
        362,
        7348,
        11,
        2942,
        2487,
        11,
        51296
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.18347974121570587,
      "compression_ratio": 1.5583332777023315,
      "end": 51.52000045776367,
      "no_speech_prob": 0.01854436844587326,
      "seek": 2576,
      "start": 44.400001525878906,
      "temperature": 0.0,
      "text": " and tags. This is all we need to create a great first version of our personal knowledge base",
      "tokens": [
        51296,
        293,
        18632,
        13,
        639,
        307,
        439,
        321,
        643,
        281,
        1884,
        257,
        869,
        700,
        3037,
        295,
        527,
        2973,
        3601,
        3096,
        51652
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.1875,
      "compression_ratio": 1.659649133682251,
      "end": 57.119998931884766,
      "no_speech_prob": 0.02442128397524357,
      "seek": 5152,
      "start": 51.52000045776367,
      "temperature": 0.0,
      "text": " of our PocketPicks. You might be asking, why are we building out this plan? Why aren't we just",
      "tokens": [
        50364,
        295,
        527,
        44594,
        47,
        7663,
        13,
        509,
        1062,
        312,
        3365,
        11,
        983,
        366,
        321,
        2390,
        484,
        341,
        1393,
        30,
        1545,
        3212,
        380,
        321,
        445,
        50644
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.1875,
      "compression_ratio": 1.659649133682251,
      "end": 63.36000061035156,
      "no_speech_prob": 0.02442128397524357,
      "seek": 5152,
      "start": 57.119998931884766,
      "temperature": 0.0,
      "text": " starting to prompt? Because I can guarantee you that if you're writing prompts iteratively,",
      "tokens": [
        50644,
        2891,
        281,
        12391,
        30,
        1436,
        286,
        393,
        10815,
        291,
        300,
        498,
        291,
        434,
        3579,
        41095,
        17138,
        19020,
        11,
        50956
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.1875,
      "compression_ratio": 1.659649133682251,
      "end": 70.08000183105469,
      "no_speech_prob": 0.02442128397524357,
      "seek": 5152,
      "start": 63.36000061035156,
      "temperature": 0.0,
      "text": " you are not doing as much as you can and you're not scaling your impact as much as you could be.",
      "tokens": [
        50956,
        291,
        366,
        406,
        884,
        382,
        709,
        382,
        291,
        393,
        293,
        291,
        434,
        406,
        21589,
        428,
        2712,
        382,
        709,
        382,
        291,
        727,
        312,
        13,
        51292
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.1875,
      "compression_ratio": 1.659649133682251,
      "end": 75.83999633789062,
      "no_speech_prob": 0.02442128397524357,
      "seek": 5152,
      "start": 70.08000183105469,
      "temperature": 0.0,
      "text": " In this video, you'll see exactly what I mean. I'm creating that classic implementation notes",
      "tokens": [
        51292,
        682,
        341,
        960,
        11,
        291,
        603,
        536,
        2293,
        437,
        286,
        914,
        13,
        286,
        478,
        4084,
        300,
        7230,
        11420,
        5570,
        51580
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.1875,
      "compression_ratio": 1.659649133682251,
      "end": 80.4800033569336,
      "no_speech_prob": 0.02442128397524357,
      "seek": 5152,
      "start": 75.83999633789062,
      "temperature": 0.0,
      "text": " section. This is where you just basically write ad hoc information. It's where you work through",
      "tokens": [
        51580,
        3541,
        13,
        639,
        307,
        689,
        291,
        445,
        1936,
        2464,
        614,
        16708,
        1589,
        13,
        467,
        311,
        689,
        291,
        589,
        807,
        51812
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.17859101295471191,
      "compression_ratio": 1.66304349899292,
      "end": 86.80000305175781,
      "no_speech_prob": 0.006387979257851839,
      "seek": 8048,
      "start": 80.4800033569336,
      "temperature": 0.0,
      "text": " things. It's kind of a catch-all section. We're doing some API-based design here. A great way to",
      "tokens": [
        50364,
        721,
        13,
        467,
        311,
        733,
        295,
        257,
        3745,
        12,
        336,
        3541,
        13,
        492,
        434,
        884,
        512,
        9362,
        12,
        6032,
        1715,
        510,
        13,
        316,
        869,
        636,
        281,
        50680
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.17859101295471191,
      "compression_ratio": 1.66304349899292,
      "end": 92.55999755859375,
      "no_speech_prob": 0.006387979257851839,
      "seek": 8048,
      "start": 86.80000305175781,
      "temperature": 0.0,
      "text": " communicate information to your AI coding tools is to create the interface in which you would use",
      "tokens": [
        50680,
        7890,
        1589,
        281,
        428,
        7318,
        17720,
        3873,
        307,
        281,
        1884,
        264,
        9226,
        294,
        597,
        291,
        576,
        764,
        50968
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.17859101295471191,
      "compression_ratio": 1.66304349899292,
      "end": 98.23999786376953,
      "no_speech_prob": 0.006387979257851839,
      "seek": 8048,
      "start": 92.55999755859375,
      "temperature": 0.0,
      "text": " to operate with it. What we're doing here is creating a CLI-based API design. This will",
      "tokens": [
        50968,
        281,
        9651,
        365,
        309,
        13,
        708,
        321,
        434,
        884,
        510,
        307,
        4084,
        257,
        12855,
        40,
        12,
        6032,
        9362,
        1715,
        13,
        639,
        486,
        51252
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.17859101295471191,
      "compression_ratio": 1.66304349899292,
      "end": 102.08000183105469,
      "no_speech_prob": 0.006387979257851839,
      "seek": 8048,
      "start": 98.23999786376953,
      "temperature": 0.0,
      "text": " very clearly communicate to our AI coding assistant what we want the API to look like.",
      "tokens": [
        51252,
        588,
        4448,
        7890,
        281,
        527,
        7318,
        17720,
        10994,
        437,
        321,
        528,
        264,
        9362,
        281,
        574,
        411,
        13,
        51444
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.17859101295471191,
      "compression_ratio": 1.66304349899292,
      "end": 108.80000305175781,
      "no_speech_prob": 0.006387979257851839,
      "seek": 8048,
      "start": 102.08000183105469,
      "temperature": 0.0,
      "text": " You can see here I'm using cursor tab as well to help me quickly create this spec prompt.",
      "tokens": [
        51444,
        509,
        393,
        536,
        510,
        286,
        478,
        1228,
        28169,
        4421,
        382,
        731,
        281,
        854,
        385,
        2661,
        1884,
        341,
        1608,
        12391,
        13,
        51780
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.2531350255012512,
      "compression_ratio": 1.7434555292129517,
      "end": 116.16000366210938,
      "no_speech_prob": 0.0006666521658189595,
      "seek": 10880,
      "start": 108.80000305175781,
      "temperature": 0.0,
      "text": " I think the tech ecosystem has a massive problem in thinking that there are best tools.",
      "tokens": [
        50364,
        286,
        519,
        264,
        7553,
        11311,
        575,
        257,
        5994,
        1154,
        294,
        1953,
        300,
        456,
        366,
        1151,
        3873,
        13,
        50732
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2531350255012512,
      "compression_ratio": 1.7434555292129517,
      "end": 122.87999725341797,
      "no_speech_prob": 0.0006666521658189595,
      "seek": 10880,
      "start": 118.63999938964844,
      "temperature": 0.0,
      "text": " What's the best tool? What's the best AI coding tool I can use? Is it Cursor? Is it CloudCode?",
      "tokens": [
        50856,
        708,
        311,
        264,
        1151,
        2290,
        30,
        708,
        311,
        264,
        1151,
        7318,
        17720,
        2290,
        286,
        393,
        764,
        30,
        1119,
        309,
        383,
        2156,
        284,
        30,
        1119,
        309,
        8061,
        34,
        1429,
        30,
        51068
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2531350255012512,
      "compression_ratio": 1.7434555292129517,
      "end": 126.95999908447266,
      "no_speech_prob": 0.0006666521658189595,
      "seek": 10880,
      "start": 122.87999725341797,
      "temperature": 0.0,
      "text": " Is it Aitor? Devon? What's the best tool? I just want to use the best tool.",
      "tokens": [
        51068,
        1119,
        309,
        316,
        3029,
        30,
        9096,
        266,
        30,
        708,
        311,
        264,
        1151,
        2290,
        30,
        286,
        445,
        528,
        281,
        764,
        264,
        1151,
        2290,
        13,
        51272
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2531350255012512,
      "compression_ratio": 1.7434555292129517,
      "end": 130.8800048828125,
      "no_speech_prob": 0.0006666521658189595,
      "seek": 10880,
      "start": 126.95999908447266,
      "temperature": 0.0,
      "text": " I think this is a very limiting mindset because it forces you to always...",
      "tokens": [
        51272,
        286,
        519,
        341,
        307,
        257,
        588,
        22083,
        12543,
        570,
        309,
        5874,
        291,
        281,
        1009,
        485,
        51468
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834736.435053
}
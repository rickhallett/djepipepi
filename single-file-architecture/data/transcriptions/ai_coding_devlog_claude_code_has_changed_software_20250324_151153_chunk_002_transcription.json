{
  "audio_path": "data/chunks/ai_coding_devlog_claude_code_has_changed_software_20250324_151153_chunk_002.mp3",
  "text": "codebases that I work on. Maybe you have your own pattern for this. This is super important for just organizing information that your AI tooling can reference. All right, so there's that. We now have the MCP server for Git. And now we can use this as a key guiding example, a key guiding structure for our new tool that we're building, our new MCP server that we're going to build in this video called PocketPick. So there's that. Now we're gonna do something super, super important. We're going to create a spec. We're going to create a plan. So before we dive into what this plan is all about, I'm curious what you think. Comment down below. Let me know what you think is a more important release, model context protocol or cloud code. I feel like these are two massively game-changing tools. Let me know which tool you're using the most. Are you fully on board with cloud code and are you fully on board with MCP servers? I've been holding off trying to wait to understand the landscape of the model context protocol. There are of course risks associated with committing to a technology like this, but I think Anthropic is doing it in such a way that it makes sense. It's open source, it's public. Anyone can build these. This is turning out to be the standard for building AI agents, for building AI tools. As you'll see in this video, you can quickly build your own MCP servers. So what are we building and what is the spec, right? What is the spec prompt? What is this plan that we're building? So we are building PocketPick. This is your personal knowledge base for reusability of ideas, patterns, and code snippets. This is something that we started building out in lesson eight of principled AI coding. And what we're going to do here in this video is use Cloud Code in its true agentic coding form to build out a full version of this built completely on MCP. So this is something.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 1.159999966621399,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " codebases that I work on.",
      "tokens": [
        50364,
        3089,
        65,
        1957,
        300,
        286,
        589,
        322,
        13,
        50422
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 3.799999952316284,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 1.159999966621399,
      "temperature": 0.0,
      "text": " Maybe you have your own pattern for this.",
      "tokens": [
        50422,
        2704,
        291,
        362,
        428,
        1065,
        5102,
        337,
        341,
        13,
        50554
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 7.159999847412109,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 3.799999952316284,
      "temperature": 0.0,
      "text": " This is super important for just organizing information",
      "tokens": [
        50554,
        639,
        307,
        1687,
        1021,
        337,
        445,
        17608,
        1589,
        50722
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 9.960000038146973,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 7.159999847412109,
      "temperature": 0.0,
      "text": " that your AI tooling can reference.",
      "tokens": [
        50722,
        300,
        428,
        7318,
        46593,
        393,
        6408,
        13,
        50862
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 11.779999732971191,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 9.960000038146973,
      "temperature": 0.0,
      "text": " All right, so there's that.",
      "tokens": [
        50862,
        1057,
        558,
        11,
        370,
        456,
        311,
        300,
        13,
        50953
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 16.780000686645508,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 11.779999732971191,
      "temperature": 0.0,
      "text": " We now have the MCP server for Git.",
      "tokens": [
        50953,
        492,
        586,
        362,
        264,
        8797,
        47,
        7154,
        337,
        16939,
        13,
        51203
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 22.079999923706055,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 17.280000686645508,
      "temperature": 0.0,
      "text": " And now we can use this as a key guiding example,",
      "tokens": [
        51228,
        400,
        586,
        321,
        393,
        764,
        341,
        382,
        257,
        2141,
        25061,
        1365,
        11,
        51468
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 25.84000015258789,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 22.079999923706055,
      "temperature": 0.0,
      "text": " a key guiding structure for our new tool",
      "tokens": [
        51468,
        257,
        2141,
        25061,
        3877,
        337,
        527,
        777,
        2290,
        51656
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 27.760000228881836,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 25.84000015258789,
      "temperature": 0.0,
      "text": " that we're building, our new MCP server",
      "tokens": [
        51656,
        300,
        321,
        434,
        2390,
        11,
        527,
        777,
        8797,
        47,
        7154,
        51752
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.22578829526901245,
      "compression_ratio": 1.6554621458053589,
      "end": 29.540000915527344,
      "no_speech_prob": 0.24197594821453094,
      "seek": 0,
      "start": 27.760000228881836,
      "temperature": 0.0,
      "text": " that we're going to build in this video",
      "tokens": [
        51752,
        300,
        321,
        434,
        516,
        281,
        1322,
        294,
        341,
        960,
        51841
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 31.420000076293945,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 29.540000915527344,
      "temperature": 0.0,
      "text": " called PocketPick.",
      "tokens": [
        50364,
        1219,
        44594,
        47,
        618,
        13,
        50458
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 32.79999923706055,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 31.420000076293945,
      "temperature": 0.0,
      "text": " So there's that.",
      "tokens": [
        50458,
        407,
        456,
        311,
        300,
        13,
        50527
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 35.099998474121094,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 32.79999923706055,
      "temperature": 0.0,
      "text": " Now we're gonna do something super, super important.",
      "tokens": [
        50527,
        823,
        321,
        434,
        799,
        360,
        746,
        1687,
        11,
        1687,
        1021,
        13,
        50642
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 37.540000915527344,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 35.099998474121094,
      "temperature": 0.0,
      "text": " We're going to create a spec.",
      "tokens": [
        50642,
        492,
        434,
        516,
        281,
        1884,
        257,
        1608,
        13,
        50764
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 40.13999938964844,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 37.540000915527344,
      "temperature": 0.0,
      "text": " We're going to create a plan.",
      "tokens": [
        50764,
        492,
        434,
        516,
        281,
        1884,
        257,
        1393,
        13,
        50894
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 43.939998626708984,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 40.13999938964844,
      "temperature": 0.0,
      "text": " So before we dive into what this plan is all about,",
      "tokens": [
        50894,
        407,
        949,
        321,
        9192,
        666,
        437,
        341,
        1393,
        307,
        439,
        466,
        11,
        51084
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 45.65999984741211,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 43.939998626708984,
      "temperature": 0.0,
      "text": " I'm curious what you think.",
      "tokens": [
        51084,
        286,
        478,
        6369,
        437,
        291,
        519,
        13,
        51170
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 46.540000915527344,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 45.65999984741211,
      "temperature": 0.0,
      "text": " Comment down below.",
      "tokens": [
        51170,
        16328,
        760,
        2507,
        13,
        51214
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 49.720001220703125,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 46.540000915527344,
      "temperature": 0.0,
      "text": " Let me know what you think is a more important release,",
      "tokens": [
        51214,
        961,
        385,
        458,
        437,
        291,
        519,
        307,
        257,
        544,
        1021,
        4374,
        11,
        51373
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 52.880001068115234,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 49.720001220703125,
      "temperature": 0.0,
      "text": " model context protocol or cloud code.",
      "tokens": [
        51373,
        2316,
        4319,
        10336,
        420,
        4588,
        3089,
        13,
        51531
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 56.58000183105469,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 52.880001068115234,
      "temperature": 0.0,
      "text": " I feel like these are two massively game-changing tools.",
      "tokens": [
        51531,
        286,
        841,
        411,
        613,
        366,
        732,
        29379,
        1216,
        12,
        27123,
        3873,
        13,
        51716
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2081298828125,
      "compression_ratio": 1.7049808502197266,
      "end": 58.939998626708984,
      "no_speech_prob": 0.001700676279142499,
      "seek": 2954,
      "start": 56.58000183105469,
      "temperature": 0.0,
      "text": " Let me know which tool you're using the most.",
      "tokens": [
        51716,
        961,
        385,
        458,
        597,
        2290,
        291,
        434,
        1228,
        264,
        881,
        13,
        51834
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 61.34000015258789,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 59.29999923706055,
      "temperature": 0.0,
      "text": " Are you fully on board with cloud code",
      "tokens": [
        50382,
        2014,
        291,
        4498,
        322,
        3150,
        365,
        4588,
        3089,
        50484
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 65.41999816894531,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 61.34000015258789,
      "temperature": 0.0,
      "text": " and are you fully on board with MCP servers?",
      "tokens": [
        50484,
        293,
        366,
        291,
        4498,
        322,
        3150,
        365,
        8797,
        47,
        15909,
        30,
        50688
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 69.77999877929688,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 65.41999816894531,
      "temperature": 0.0,
      "text": " I've been holding off trying to wait to understand",
      "tokens": [
        50688,
        286,
        600,
        668,
        5061,
        766,
        1382,
        281,
        1699,
        281,
        1223,
        50906
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 73.26000213623047,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 69.77999877929688,
      "temperature": 0.0,
      "text": " the landscape of the model context protocol.",
      "tokens": [
        50906,
        264,
        9661,
        295,
        264,
        2316,
        4319,
        10336,
        13,
        51080
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 76.5,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 73.26000213623047,
      "temperature": 0.0,
      "text": " There are of course risks associated",
      "tokens": [
        51080,
        821,
        366,
        295,
        1164,
        10888,
        6615,
        51242
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 78.18000030517578,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 76.5,
      "temperature": 0.0,
      "text": " with committing to a technology like this,",
      "tokens": [
        51242,
        365,
        26659,
        281,
        257,
        2899,
        411,
        341,
        11,
        51326
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 81.5,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 78.18000030517578,
      "temperature": 0.0,
      "text": " but I think Anthropic is doing it in such a way",
      "tokens": [
        51326,
        457,
        286,
        519,
        12727,
        39173,
        307,
        884,
        309,
        294,
        1270,
        257,
        636,
        51492
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 82.81999969482422,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 81.5,
      "temperature": 0.0,
      "text": " that it makes sense.",
      "tokens": [
        51492,
        300,
        309,
        1669,
        2020,
        13,
        51558
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 84.33999633789062,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 82.81999969482422,
      "temperature": 0.0,
      "text": " It's open source, it's public.",
      "tokens": [
        51558,
        467,
        311,
        1269,
        4009,
        11,
        309,
        311,
        1908,
        13,
        51634
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 85.69999694824219,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 84.33999633789062,
      "temperature": 0.0,
      "text": " Anyone can build these.",
      "tokens": [
        51634,
        14643,
        393,
        1322,
        613,
        13,
        51702
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.21559758484363556,
      "compression_ratio": 1.6168582439422607,
      "end": 88.86000061035156,
      "no_speech_prob": 0.0015977987786754966,
      "seek": 5894,
      "start": 85.69999694824219,
      "temperature": 0.0,
      "text": " This is turning out to be the standard",
      "tokens": [
        51702,
        639,
        307,
        6246,
        484,
        281,
        312,
        264,
        3832,
        51860
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 92.81999969482422,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 89.77999877929688,
      "temperature": 0.0,
      "text": " for building AI agents, for building AI tools.",
      "tokens": [
        50410,
        337,
        2390,
        7318,
        12554,
        11,
        337,
        2390,
        7318,
        3873,
        13,
        50562
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 93.69999694824219,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 92.81999969482422,
      "temperature": 0.0,
      "text": " As you'll see in this video,",
      "tokens": [
        50562,
        1018,
        291,
        603,
        536,
        294,
        341,
        960,
        11,
        50606
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 97.30000305175781,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 93.69999694824219,
      "temperature": 0.0,
      "text": " you can quickly build your own MCP servers.",
      "tokens": [
        50606,
        291,
        393,
        2661,
        1322,
        428,
        1065,
        8797,
        47,
        15909,
        13,
        50786
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 100.37999725341797,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 97.30000305175781,
      "temperature": 0.0,
      "text": " So what are we building and what is the spec, right?",
      "tokens": [
        50786,
        407,
        437,
        366,
        321,
        2390,
        293,
        437,
        307,
        264,
        1608,
        11,
        558,
        30,
        50940
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 101.37999725341797,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 100.37999725341797,
      "temperature": 0.0,
      "text": " What is the spec prompt?",
      "tokens": [
        50940,
        708,
        307,
        264,
        1608,
        12391,
        30,
        50990
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 103.5,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 101.37999725341797,
      "temperature": 0.0,
      "text": " What is this plan that we're building?",
      "tokens": [
        50990,
        708,
        307,
        341,
        1393,
        300,
        321,
        434,
        2390,
        30,
        51096
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 105.0999984741211,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 103.5,
      "temperature": 0.0,
      "text": " So we are building PocketPick.",
      "tokens": [
        51096,
        407,
        321,
        366,
        2390,
        44594,
        47,
        618,
        13,
        51176
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 107.30000305175781,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 105.0999984741211,
      "temperature": 0.0,
      "text": " This is your personal knowledge base",
      "tokens": [
        51176,
        639,
        307,
        428,
        2973,
        3601,
        3096,
        51286
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 112.30000305175781,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 107.30000305175781,
      "temperature": 0.0,
      "text": " for reusability of ideas, patterns, and code snippets.",
      "tokens": [
        51286,
        337,
        38860,
        2310,
        295,
        3487,
        11,
        8294,
        11,
        293,
        3089,
        35623,
        1385,
        13,
        51536
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 114.63999938964844,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 112.87999725341797,
      "temperature": 0.0,
      "text": " This is something that we started building out",
      "tokens": [
        51565,
        639,
        307,
        746,
        300,
        321,
        1409,
        2390,
        484,
        51653
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.25628119707107544,
      "compression_ratio": 1.7192307710647583,
      "end": 117.13999938964844,
      "no_speech_prob": 0.0018968635704368353,
      "seek": 8886,
      "start": 114.63999938964844,
      "temperature": 0.0,
      "text": " in lesson eight of principled AI coding.",
      "tokens": [
        51653,
        294,
        6898,
        3180,
        295,
        3681,
        15551,
        7318,
        17720,
        13,
        51778
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.328058123588562,
      "compression_ratio": 1.3283581733703613,
      "end": 119.41999816894531,
      "no_speech_prob": 0.05031979829072952,
      "seek": 11714,
      "start": 117.13999938964844,
      "temperature": 0.0,
      "text": " And what we're going to do here in this video",
      "tokens": [
        50364,
        400,
        437,
        321,
        434,
        516,
        281,
        360,
        510,
        294,
        341,
        960,
        50478
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.328058123588562,
      "compression_ratio": 1.3283581733703613,
      "end": 124.41999816894531,
      "no_speech_prob": 0.05031979829072952,
      "seek": 11714,
      "start": 119.41999816894531,
      "temperature": 0.0,
      "text": " is use Cloud Code in its true agentic coding form",
      "tokens": [
        50478,
        307,
        764,
        8061,
        15549,
        294,
        1080,
        2074,
        9461,
        299,
        17720,
        1254,
        50728
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.328058123588562,
      "compression_ratio": 1.3283581733703613,
      "end": 129.5,
      "no_speech_prob": 0.05031979829072952,
      "seek": 11714,
      "start": 124.5,
      "temperature": 0.0,
      "text": " to build out a full version of this built completely on MCP.",
      "tokens": [
        50732,
        281,
        1322,
        484,
        257,
        1577,
        3037,
        295,
        341,
        3094,
        2584,
        322,
        8797,
        47,
        13,
        50982
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.328058123588562,
      "compression_ratio": 1.3283581733703613,
      "end": 131.3000030517578,
      "no_speech_prob": 0.05031979829072952,
      "seek": 11714,
      "start": 129.97999572753906,
      "temperature": 0.0,
      "text": " So this is something.",
      "tokens": [
        51006,
        407,
        341,
        307,
        746,
        13,
        51072
      ]
    }
  ],
  "language": "english",
  "duration": 131.05999755859375,
  "timestamp": 1742834727.107379
}